
zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

00000000 <_vector_start>:

	return fd_entry->obj;
}

int z_reserve_fd(void)
{
   0:	20002400 	.word	0x20002400
#if defined(__ZEPHYR_SUPERVISOR__)
	ret = false;
#elif defined(__ZEPHYR_USER__)
	ret = true;
#else
	ret = arch_is_user_context();
   4:	000019f5 	.word	0x000019f5

extern int z_impl_k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout);
static inline int k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
   8:	00006169 	.word	0x00006169
static inline uintptr_t arch_syscall_invoke3(uintptr_t arg1, uintptr_t arg2,
					     uintptr_t arg3,
					     uintptr_t call_id)
{
	register uint32_t ret __asm__("r0") = arg1;
	register uint32_t r1 __asm__("r1") = arg2;
   c:	00001a25 	.word	0x00001a25
	register uint32_t r2 __asm__("r2") = arg3;
  10:	00001a25 	.word	0x00001a25
	register uint32_t r6 __asm__("r6") = call_id;

	__asm__ volatile("svc %[svid]\n"
  14:	00001a25 	.word	0x00001a25
	for (fd = 0; fd < ARRAY_SIZE(fdtable); fd++) {
  18:	00001a25 	.word	0x00001a25
	...
	errno = ENFILE;
  2c:	00001641 	.word	0x00001641
	return -1;
  30:	00001a25 	.word	0x00001a25
  34:	00000000 	.word	0x00000000
}

static inline uintptr_t arch_syscall_invoke1(uintptr_t arg1,
					     uintptr_t call_id)
{
	register uint32_t ret __asm__("r0") = arg1;
  38:	000015d1 	.word	0x000015d1
	register uint32_t r6 __asm__("r6") = call_id;

	__asm__ volatile("svc %[svid]\n"
  3c:	000060e7 	.word	0x000060e7

00000040 <_irq_vector_table>:
	}

	k_mutex_unlock(&fdtable_lock);

	return fd;
}
  40:	00001879 00001879 00001879 00001879     y...y...y...y...
		parm0.val = timeout;
		return (int) arch_syscall_invoke3(*(uintptr_t *)&mutex, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_MUTEX_LOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_lock(mutex, timeout);
  50:	00001879 00001879 00001879 00001879     y...y...y...y...
	if (z_syscall_trap()) {
		return (int) arch_syscall_invoke1(*(uintptr_t *)&mutex, K_SYSCALL_K_MUTEX_UNLOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_unlock(mutex);
  60:	00001879 00001879 00001879 00001879     y...y...y...y...
  70:	00001879 00001879 00001879 00001879     y...y...y...y...
  80:	00001879 00001879 00001879 00001879     y...y...y...y...
  90:	00001879 00001879 00001879 00001879     y...y...y...y...
  a0:	00001879 00001879 00001879 00001879     y...y...y...y...
  b0:	00001879 00001879 00001879 00001879     y...y...y...y...
  c0:	00001879 00001879 00001879 00001879     y...y...y...y...
  d0:	00001879 00001879 00001879              y...y...y...

Disassembly of section text:

000000dc <z_object_find>:
void z_object_wordlist_foreach(_wordlist_cb_func_t func, void *context)
	ALIAS_OF(z_object_gperf_wordlist_foreach);
#endif

Z_GENERIC_SECTION(.kobject_data.data) uint8_t _thread_idx_map[2] = { 0x80,  0xff, };
      dc:	4b0a      	ldr	r3, [pc, #40]	; (108 <CONFIG_KOBJECT_TEXT_AREA+0x8>)
      de:	f3c0 2207 	ubfx	r2, r0, #8, #8
      e2:	b2c1      	uxtb	r1, r0
      e4:	5c9a      	ldrb	r2, [r3, r2]
      e6:	5c5b      	ldrb	r3, [r3, r1]
      e8:	4413      	add	r3, r2
"\x30\x2e\x00\x20", {}, K_OBJ_DRIVER_UART, 0 | K_OBJ_FLAG_DRIVER, { .unused = 0 }
      ea:	2b3c      	cmp	r3, #60	; 0x3c
      ec:	dc09      	bgt.n	102 <CONFIG_KOBJECT_TEXT_AREA+0x2>
"\x88\x2e\x00\x20", {}, K_OBJ_MUTEX, 0 | K_OBJ_FLAG_INITIALIZED, { .unused = 0 }
      ee:	220c      	movs	r2, #12
      f0:	4906      	ldr	r1, [pc, #24]	; (10c <CONFIG_KOBJECT_TEXT_AREA+0xc>)
      f2:	435a      	muls	r2, r3
      f4:	188b      	adds	r3, r1, r2
struct z_object *z_object_gperf_find(void *obj)
      f6:	588a      	ldr	r2, [r1, r2]
{
      f8:	4290      	cmp	r0, r2
      fa:	bf0c      	ite	eq
      fc:	4618      	moveq	r0, r3
      fe:	2000      	movne	r0, #0
     100:	4770      	bx	lr

     102:	2000      	movs	r0, #0
}
     104:	4770      	bx	lr
     106:	bf00      	nop
     108:	00007872 	.word	0x00007872
     10c:	20002e9c 	.word	0x20002e9c

00000110 <z_object_gperf_wordlist_foreach>:
{
     110:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
     112:	4c07      	ldr	r4, [pc, #28]	; (130 <z_object_gperf_wordlist_foreach+0x20>)
     114:	4606      	mov	r6, r0
     116:	460f      	mov	r7, r1
    for (i = MIN_HASH_VALUE; i <= MAX_HASH_VALUE; i++) {
     118:	2500      	movs	r5, #0
        if (wordlist[i].name != NULL) {
     11a:	6823      	ldr	r3, [r4, #0]
     11c:	b113      	cbz	r3, 124 <z_object_gperf_wordlist_foreach+0x14>
            func(&wordlist[i], context);
     11e:	4639      	mov	r1, r7
     120:	4620      	mov	r0, r4
     122:	47b0      	blx	r6
    for (i = MIN_HASH_VALUE; i <= MAX_HASH_VALUE; i++) {
     124:	3501      	adds	r5, #1
     126:	2d3d      	cmp	r5, #61	; 0x3d
     128:	f104 040c 	add.w	r4, r4, #12
     12c:	d1f5      	bne.n	11a <z_object_gperf_wordlist_foreach+0xa>
}
     12e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
     130:	20002e9c 	.word	0x20002e9c

00000134 <_kobject_text_area_end>:
	...

000001dc <__aeabi_uldivmod>:
     1dc:	b953      	cbnz	r3, 1f4 <__aeabi_uldivmod+0x18>
     1de:	b94a      	cbnz	r2, 1f4 <__aeabi_uldivmod+0x18>
     1e0:	2900      	cmp	r1, #0
     1e2:	bf08      	it	eq
     1e4:	2800      	cmpeq	r0, #0
     1e6:	bf1c      	itt	ne
     1e8:	f04f 31ff 	movne.w	r1, #4294967295	; 0xffffffff
     1ec:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
     1f0:	f000 b96e 	b.w	4d0 <__aeabi_idiv0>
     1f4:	f1ad 0c08 	sub.w	ip, sp, #8
     1f8:	e96d ce04 	strd	ip, lr, [sp, #-16]!
     1fc:	f000 f806 	bl	20c <__udivmoddi4>
     200:	f8dd e004 	ldr.w	lr, [sp, #4]
     204:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
     208:	b004      	add	sp, #16
     20a:	4770      	bx	lr

0000020c <__udivmoddi4>:
     20c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
     210:	9d08      	ldr	r5, [sp, #32]
     212:	460e      	mov	r6, r1
     214:	4604      	mov	r4, r0
     216:	468c      	mov	ip, r1
     218:	2b00      	cmp	r3, #0
     21a:	f040 8081 	bne.w	320 <__udivmoddi4+0x114>
     21e:	428a      	cmp	r2, r1
     220:	4617      	mov	r7, r2
     222:	d945      	bls.n	2b0 <__udivmoddi4+0xa4>
     224:	fab2 f282 	clz	r2, r2
     228:	b14a      	cbz	r2, 23e <__udivmoddi4+0x32>
     22a:	f1c2 0120 	rsb	r1, r2, #32
     22e:	fa06 f302 	lsl.w	r3, r6, r2
     232:	fa20 f101 	lsr.w	r1, r0, r1
     236:	4097      	lsls	r7, r2
     238:	ea41 0c03 	orr.w	ip, r1, r3
     23c:	4094      	lsls	r4, r2
     23e:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     242:	0c23      	lsrs	r3, r4, #16
     244:	fbbc f6fe 	udiv	r6, ip, lr
     248:	b2b9      	uxth	r1, r7
     24a:	fb0e cc16 	mls	ip, lr, r6, ip
     24e:	ea43 430c 	orr.w	r3, r3, ip, lsl #16
     252:	fb06 f001 	mul.w	r0, r6, r1
     256:	4298      	cmp	r0, r3
     258:	d909      	bls.n	26e <__udivmoddi4+0x62>
     25a:	18fb      	adds	r3, r7, r3
     25c:	f106 3cff 	add.w	ip, r6, #4294967295	; 0xffffffff
     260:	f080 8115 	bcs.w	48e <CONFIG_MAIN_STACK_SIZE+0x8e>
     264:	4298      	cmp	r0, r3
     266:	f240 8112 	bls.w	48e <CONFIG_MAIN_STACK_SIZE+0x8e>
     26a:	3e02      	subs	r6, #2
     26c:	443b      	add	r3, r7
     26e:	1a1b      	subs	r3, r3, r0
     270:	b2a4      	uxth	r4, r4
     272:	fbb3 f0fe 	udiv	r0, r3, lr
     276:	fb0e 3310 	mls	r3, lr, r0, r3
     27a:	ea44 4403 	orr.w	r4, r4, r3, lsl #16
     27e:	fb00 f101 	mul.w	r1, r0, r1
     282:	42a1      	cmp	r1, r4
     284:	d909      	bls.n	29a <__udivmoddi4+0x8e>
     286:	193c      	adds	r4, r7, r4
     288:	f100 33ff 	add.w	r3, r0, #4294967295	; 0xffffffff
     28c:	f080 8101 	bcs.w	492 <CONFIG_MAIN_STACK_SIZE+0x92>
     290:	42a1      	cmp	r1, r4
     292:	f240 80fe 	bls.w	492 <CONFIG_MAIN_STACK_SIZE+0x92>
     296:	3802      	subs	r0, #2
     298:	443c      	add	r4, r7
     29a:	1a64      	subs	r4, r4, r1
     29c:	ea40 4006 	orr.w	r0, r0, r6, lsl #16
     2a0:	2100      	movs	r1, #0
     2a2:	b11d      	cbz	r5, 2ac <__udivmoddi4+0xa0>
     2a4:	40d4      	lsrs	r4, r2
     2a6:	2300      	movs	r3, #0
     2a8:	e9c5 4300 	strd	r4, r3, [r5]
     2ac:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
     2b0:	b902      	cbnz	r2, 2b4 <__udivmoddi4+0xa8>
     2b2:	deff      	udf	#255	; 0xff
     2b4:	fab2 f282 	clz	r2, r2
     2b8:	2a00      	cmp	r2, #0
     2ba:	d14f      	bne.n	35c <__udivmoddi4+0x150>
     2bc:	1bcb      	subs	r3, r1, r7
     2be:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     2c2:	fa1f f887 	uxth.w	r8, r7
     2c6:	2101      	movs	r1, #1
     2c8:	fbb3 fcfe 	udiv	ip, r3, lr
     2cc:	0c26      	lsrs	r6, r4, #16
     2ce:	fb0e 331c 	mls	r3, lr, ip, r3
     2d2:	ea46 4603 	orr.w	r6, r6, r3, lsl #16
     2d6:	fb08 f30c 	mul.w	r3, r8, ip
     2da:	42b3      	cmp	r3, r6
     2dc:	d907      	bls.n	2ee <__udivmoddi4+0xe2>
     2de:	19be      	adds	r6, r7, r6
     2e0:	f10c 30ff 	add.w	r0, ip, #4294967295	; 0xffffffff
     2e4:	d202      	bcs.n	2ec <__udivmoddi4+0xe0>
     2e6:	42b3      	cmp	r3, r6
     2e8:	f200 80eb 	bhi.w	4c2 <CONFIG_MAIN_STACK_SIZE+0xc2>
     2ec:	4684      	mov	ip, r0
     2ee:	1af6      	subs	r6, r6, r3
     2f0:	b2a3      	uxth	r3, r4
     2f2:	fbb6 f0fe 	udiv	r0, r6, lr
     2f6:	fb0e 6610 	mls	r6, lr, r0, r6
     2fa:	ea43 4406 	orr.w	r4, r3, r6, lsl #16
     2fe:	fb08 f800 	mul.w	r8, r8, r0
     302:	45a0      	cmp	r8, r4
     304:	d907      	bls.n	316 <__udivmoddi4+0x10a>
     306:	193c      	adds	r4, r7, r4
     308:	f100 33ff 	add.w	r3, r0, #4294967295	; 0xffffffff
     30c:	d202      	bcs.n	314 <__udivmoddi4+0x108>
     30e:	45a0      	cmp	r8, r4
     310:	f200 80d2 	bhi.w	4b8 <CONFIG_MAIN_STACK_SIZE+0xb8>
     314:	4618      	mov	r0, r3
     316:	eba4 0408 	sub.w	r4, r4, r8
     31a:	ea40 400c 	orr.w	r0, r0, ip, lsl #16
     31e:	e7c0      	b.n	2a2 <__udivmoddi4+0x96>
     320:	428b      	cmp	r3, r1
     322:	d908      	bls.n	336 <__udivmoddi4+0x12a>
     324:	2d00      	cmp	r5, #0
     326:	f000 80af 	beq.w	488 <CONFIG_MAIN_STACK_SIZE+0x88>
     32a:	2100      	movs	r1, #0
     32c:	e9c5 0600 	strd	r0, r6, [r5]
     330:	4608      	mov	r0, r1
     332:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
     336:	fab3 f183 	clz	r1, r3
     33a:	2900      	cmp	r1, #0
     33c:	d149      	bne.n	3d2 <__udivmoddi4+0x1c6>
     33e:	42b3      	cmp	r3, r6
     340:	d302      	bcc.n	348 <__udivmoddi4+0x13c>
     342:	4282      	cmp	r2, r0
     344:	f200 80bb 	bhi.w	4be <CONFIG_MAIN_STACK_SIZE+0xbe>
     348:	1a84      	subs	r4, r0, r2
     34a:	eb66 0303 	sbc.w	r3, r6, r3
     34e:	2001      	movs	r0, #1
     350:	469c      	mov	ip, r3
     352:	2d00      	cmp	r5, #0
     354:	d0aa      	beq.n	2ac <__udivmoddi4+0xa0>
     356:	e9c5 4c00 	strd	r4, ip, [r5]
     35a:	e7a7      	b.n	2ac <__udivmoddi4+0xa0>
     35c:	f1c2 0320 	rsb	r3, r2, #32
     360:	4097      	lsls	r7, r2
     362:	40d8      	lsrs	r0, r3
     364:	4091      	lsls	r1, r2
     366:	40de      	lsrs	r6, r3
     368:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     36c:	4308      	orrs	r0, r1
     36e:	ea4f 4c10 	mov.w	ip, r0, lsr #16
     372:	fbb6 f1fe 	udiv	r1, r6, lr
     376:	fa1f f887 	uxth.w	r8, r7
     37a:	fb0e 6611 	mls	r6, lr, r1, r6
     37e:	ea4c 4606 	orr.w	r6, ip, r6, lsl #16
     382:	fb01 f308 	mul.w	r3, r1, r8
     386:	42b3      	cmp	r3, r6
     388:	fa04 f402 	lsl.w	r4, r4, r2
     38c:	d909      	bls.n	3a2 <__udivmoddi4+0x196>
     38e:	19be      	adds	r6, r7, r6
     390:	f101 3cff 	add.w	ip, r1, #4294967295	; 0xffffffff
     394:	f080 808e 	bcs.w	4b4 <CONFIG_MAIN_STACK_SIZE+0xb4>
     398:	42b3      	cmp	r3, r6
     39a:	f240 808b 	bls.w	4b4 <CONFIG_MAIN_STACK_SIZE+0xb4>
     39e:	3902      	subs	r1, #2
     3a0:	443e      	add	r6, r7
     3a2:	1af3      	subs	r3, r6, r3
     3a4:	b286      	uxth	r6, r0
     3a6:	fbb3 f0fe 	udiv	r0, r3, lr
     3aa:	fb0e 3310 	mls	r3, lr, r0, r3
     3ae:	ea46 4603 	orr.w	r6, r6, r3, lsl #16
     3b2:	fb00 f308 	mul.w	r3, r0, r8
     3b6:	42b3      	cmp	r3, r6
     3b8:	d907      	bls.n	3ca <__udivmoddi4+0x1be>
     3ba:	19be      	adds	r6, r7, r6
     3bc:	f100 3cff 	add.w	ip, r0, #4294967295	; 0xffffffff
     3c0:	d274      	bcs.n	4ac <CONFIG_MAIN_STACK_SIZE+0xac>
     3c2:	42b3      	cmp	r3, r6
     3c4:	d972      	bls.n	4ac <CONFIG_MAIN_STACK_SIZE+0xac>
     3c6:	3802      	subs	r0, #2
     3c8:	443e      	add	r6, r7
     3ca:	1af3      	subs	r3, r6, r3
     3cc:	ea40 4101 	orr.w	r1, r0, r1, lsl #16
     3d0:	e77a      	b.n	2c8 <__udivmoddi4+0xbc>
     3d2:	f1c1 0720 	rsb	r7, r1, #32
     3d6:	fa03 f401 	lsl.w	r4, r3, r1
     3da:	fa22 f307 	lsr.w	r3, r2, r7
     3de:	431c      	orrs	r4, r3
     3e0:	fa20 f907 	lsr.w	r9, r0, r7
     3e4:	fa06 f301 	lsl.w	r3, r6, r1
     3e8:	ea4f 4c14 	mov.w	ip, r4, lsr #16
     3ec:	40fe      	lsrs	r6, r7
     3ee:	ea49 0903 	orr.w	r9, r9, r3
     3f2:	ea4f 4319 	mov.w	r3, r9, lsr #16
     3f6:	fbb6 fefc 	udiv	lr, r6, ip
     3fa:	fa1f f884 	uxth.w	r8, r4
     3fe:	fb0c 661e 	mls	r6, ip, lr, r6
     402:	ea43 4606 	orr.w	r6, r3, r6, lsl #16
     406:	fb0e fa08 	mul.w	sl, lr, r8
     40a:	45b2      	cmp	sl, r6
     40c:	fa02 f201 	lsl.w	r2, r2, r1
     410:	fa00 f301 	lsl.w	r3, r0, r1
     414:	d908      	bls.n	428 <CONFIG_MAIN_STACK_SIZE+0x28>
     416:	19a6      	adds	r6, r4, r6
     418:	f10e 30ff 	add.w	r0, lr, #4294967295	; 0xffffffff
     41c:	d248      	bcs.n	4b0 <CONFIG_MAIN_STACK_SIZE+0xb0>
     41e:	45b2      	cmp	sl, r6
     420:	d946      	bls.n	4b0 <CONFIG_MAIN_STACK_SIZE+0xb0>
     422:	f1ae 0e02 	sub.w	lr, lr, #2
     426:	4426      	add	r6, r4
     428:	eba6 060a 	sub.w	r6, r6, sl
     42c:	fa1f f989 	uxth.w	r9, r9
     430:	fbb6 f0fc 	udiv	r0, r6, ip
     434:	fb0c 6610 	mls	r6, ip, r0, r6
     438:	ea49 4606 	orr.w	r6, r9, r6, lsl #16
     43c:	fb00 f808 	mul.w	r8, r0, r8
     440:	45b0      	cmp	r8, r6
     442:	d907      	bls.n	454 <CONFIG_MAIN_STACK_SIZE+0x54>
     444:	19a6      	adds	r6, r4, r6
     446:	f100 3cff 	add.w	ip, r0, #4294967295	; 0xffffffff
     44a:	d22d      	bcs.n	4a8 <CONFIG_MAIN_STACK_SIZE+0xa8>
     44c:	45b0      	cmp	r8, r6
     44e:	d92b      	bls.n	4a8 <CONFIG_MAIN_STACK_SIZE+0xa8>
     450:	3802      	subs	r0, #2
     452:	4426      	add	r6, r4
     454:	ea40 400e 	orr.w	r0, r0, lr, lsl #16
     458:	eba6 0608 	sub.w	r6, r6, r8
     45c:	fba0 8902 	umull	r8, r9, r0, r2
     460:	454e      	cmp	r6, r9
     462:	46c4      	mov	ip, r8
     464:	46ce      	mov	lr, r9
     466:	d318      	bcc.n	49a <CONFIG_MAIN_STACK_SIZE+0x9a>
     468:	d015      	beq.n	496 <CONFIG_MAIN_STACK_SIZE+0x96>
     46a:	b375      	cbz	r5, 4ca <CONFIG_MAIN_STACK_SIZE+0xca>
     46c:	ebb3 020c 	subs.w	r2, r3, ip
     470:	eb66 060e 	sbc.w	r6, r6, lr
     474:	fa06 f707 	lsl.w	r7, r6, r7
     478:	fa22 f301 	lsr.w	r3, r2, r1
     47c:	40ce      	lsrs	r6, r1
     47e:	431f      	orrs	r7, r3
     480:	e9c5 7600 	strd	r7, r6, [r5]
     484:	2100      	movs	r1, #0
     486:	e711      	b.n	2ac <__udivmoddi4+0xa0>
     488:	4629      	mov	r1, r5
     48a:	4628      	mov	r0, r5
     48c:	e70e      	b.n	2ac <__udivmoddi4+0xa0>
     48e:	4666      	mov	r6, ip
     490:	e6ed      	b.n	26e <__udivmoddi4+0x62>
     492:	4618      	mov	r0, r3
     494:	e701      	b.n	29a <__udivmoddi4+0x8e>
     496:	4543      	cmp	r3, r8
     498:	d2e7      	bcs.n	46a <CONFIG_MAIN_STACK_SIZE+0x6a>
     49a:	ebb8 0c02 	subs.w	ip, r8, r2
     49e:	eb69 0404 	sbc.w	r4, r9, r4
     4a2:	3801      	subs	r0, #1
     4a4:	46a6      	mov	lr, r4
     4a6:	e7e0      	b.n	46a <CONFIG_MAIN_STACK_SIZE+0x6a>
     4a8:	4660      	mov	r0, ip
     4aa:	e7d3      	b.n	454 <CONFIG_MAIN_STACK_SIZE+0x54>
     4ac:	4660      	mov	r0, ip
     4ae:	e78c      	b.n	3ca <__udivmoddi4+0x1be>
     4b0:	4686      	mov	lr, r0
     4b2:	e7b9      	b.n	428 <CONFIG_MAIN_STACK_SIZE+0x28>
     4b4:	4661      	mov	r1, ip
     4b6:	e774      	b.n	3a2 <__udivmoddi4+0x196>
     4b8:	3802      	subs	r0, #2
     4ba:	443c      	add	r4, r7
     4bc:	e72b      	b.n	316 <__udivmoddi4+0x10a>
     4be:	4608      	mov	r0, r1
     4c0:	e747      	b.n	352 <__udivmoddi4+0x146>
     4c2:	f1ac 0c02 	sub.w	ip, ip, #2
     4c6:	443e      	add	r6, r7
     4c8:	e711      	b.n	2ee <__udivmoddi4+0xe2>
     4ca:	4629      	mov	r1, r5
     4cc:	e6ee      	b.n	2ac <__udivmoddi4+0xa0>
     4ce:	bf00      	nop

000004d0 <__aeabi_idiv0>:
     4d0:	4770      	bx	lr
     4d2:	bf00      	nop

000004d4 <k_stack_pop.constprop.0>:
static inline int k_stack_pop(struct k_stack * stack, stack_data_t * data, k_timeout_t timeout)
     4d4:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
     4d8:	4601      	mov	r1, r0
     4da:	461c      	mov	r4, r3
     4dc:	f005 f8da 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     4e0:	b128      	cbz	r0, 4ee <k_stack_pop.constprop.0+0x1a>
	register uint32_t ret __asm__("r0") = arg1;
     4e2:	4806      	ldr	r0, [pc, #24]	; (4fc <k_stack_pop.constprop.0+0x28>)
	register uint32_t r3 __asm__("r3") = arg4;
     4e4:	4623      	mov	r3, r4
	register uint32_t r6 __asm__("r6") = call_id;
     4e6:	268a      	movs	r6, #138	; 0x8a
	__asm__ volatile("svc %[svid]\n"
     4e8:	df03      	svc	3
}
     4ea:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return z_impl_k_stack_pop(stack, data, timeout);
     4ee:	4803      	ldr	r0, [pc, #12]	; (4fc <k_stack_pop.constprop.0+0x28>)
     4f0:	4623      	mov	r3, r4
}
     4f2:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
	return z_impl_k_stack_pop(stack, data, timeout);
     4f6:	f004 b991 	b.w	481c <z_impl_k_stack_pop>
     4fa:	bf00      	nop
     4fc:	200004d8 	.word	0x200004d8

00000500 <my_expiry_function>:
 * @return Previous value of @a target.
 */
#ifdef CONFIG_ATOMIC_OPERATIONS_BUILTIN
static inline atomic_val_t atomic_or(atomic_t *target, atomic_val_t value)
{
	return __atomic_fetch_or(target, value, __ATOMIC_SEQ_CST);
     500:	4909      	ldr	r1, [pc, #36]	; (528 <my_expiry_function+0x28>)
     502:	f3bf 8f5b 	dmb	ish
     506:	e851 3f00 	ldrex	r3, [r1]
     50a:	f043 0201 	orr.w	r2, r3, #1
     50e:	e841 2000 	strex	r0, r2, [r1]
     512:	2800      	cmp	r0, #0
     514:	d1f7      	bne.n	506 <my_expiry_function+0x6>
     516:	f3bf 8f5b 	dmb	ish
 * @return N/A
 */
static inline void k_work_submit_to_queue(struct k_work_q *work_q,
					  struct k_work *work)
{
	if (!atomic_test_and_set_bit(work->flags, K_WORK_STATE_PENDING)) {
     51a:	07db      	lsls	r3, r3, #31
     51c:	d403      	bmi.n	526 <my_expiry_function+0x26>
		k_queue_append(&work_q->queue, work);
     51e:	4803      	ldr	r0, [pc, #12]	; (52c <my_expiry_function+0x2c>)
     520:	3908      	subs	r1, #8
     522:	f006 b8b4 	b.w	668e <k_queue_append>
/*----------------TIMING-----------------------------*/

extern void my_expiry_function(struct k_timer *timer_id)
{
	k_work_submit_to_queue(&my_work_q,&my_work);
}
     526:	4770      	bx	lr
     528:	20000520 	.word	0x20000520
     52c:	200002b8 	.word	0x200002b8

00000530 <thread_b>:
extern void thread_b(){
     530:	b513      	push	{r0, r1, r4, lr}
	k_stack_pop(&my_stack,(uint32_t)&a,K_NO_WAIT);
     532:	2200      	movs	r2, #0
     534:	2300      	movs	r3, #0
     536:	a801      	add	r0, sp, #4
     538:	f7ff ffcc 	bl	4d4 <k_stack_pop.constprop.0>
		printk("\n\r Thread B hello world %d",*a);
     53c:	4c05      	ldr	r4, [pc, #20]	; (554 <thread_b+0x24>)
     53e:	9b01      	ldr	r3, [sp, #4]
     540:	4620      	mov	r0, r4
     542:	6819      	ldr	r1, [r3, #0]
     544:	f005 f9a2 	bl	588c <printk>
	return k_sleep(Z_TIMEOUT_MS(ms));
     548:	2100      	movs	r1, #0
     54a:	f44f 4080 	mov.w	r0, #16384	; 0x4000
     54e:	f005 f8ab 	bl	56a8 <k_sleep>
     552:	e7f4      	b.n	53e <thread_b+0xe>
     554:	00007704 	.word	0x00007704

00000558 <thread_a>:
extern void thread_a(void *arg, void *argv){
     558:	b537      	push	{r0, r1, r2, r4, r5, lr}
	k_stack_pop(&my_stack,(uint32_t)&b,K_NO_WAIT);
     55a:	2300      	movs	r3, #0
extern void thread_a(void *arg, void *argv){
     55c:	4604      	mov	r4, r0
	k_stack_pop(&my_stack,(uint32_t)&b,K_NO_WAIT);
     55e:	2200      	movs	r2, #0
     560:	a801      	add	r0, sp, #4
     562:	f7ff ffb7 	bl	4d4 <k_stack_pop.constprop.0>
		printk("\n\r Thread A hello world %s %d",(char *)arg,*b);
     566:	4d06      	ldr	r5, [pc, #24]	; (580 <thread_a+0x28>)
     568:	9b01      	ldr	r3, [sp, #4]
     56a:	4621      	mov	r1, r4
     56c:	4628      	mov	r0, r5
     56e:	681a      	ldr	r2, [r3, #0]
     570:	f005 f98c 	bl	588c <printk>
     574:	2100      	movs	r1, #0
     576:	f44f 4080 	mov.w	r0, #16384	; 0x4000
     57a:	f005 f895 	bl	56a8 <k_sleep>
     57e:	e7f3      	b.n	568 <thread_a+0x10>
     580:	0000771f 	.word	0x0000771f

00000584 <device_get_binding.constprop.0>:
#ifdef __cplusplus
extern "C" {
#endif

extern struct device * z_impl_device_get_binding(const char * name);
static inline struct device * device_get_binding(const char * name)
     584:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
     588:	f005 f884 	bl	5694 <arch_is_user_context>
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
     58c:	b120      	cbz	r0, 598 <device_get_binding.constprop.0+0x14>
	register uint32_t ret __asm__("r0") = arg1;
     58e:	4805      	ldr	r0, [pc, #20]	; (5a4 <device_get_binding.constprop.0+0x20>)
	register uint32_t r6 __asm__("r6") = call_id;
     590:	2627      	movs	r6, #39	; 0x27
	__asm__ volatile("svc %[svid]\n"
     592:	df03      	svc	3
		return (struct device *) arch_syscall_invoke1(*(uintptr_t *)&name, K_SYSCALL_DEVICE_GET_BINDING);
	}
#endif
	compiler_barrier();
	return z_impl_device_get_binding(name);
}
     594:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	return z_impl_device_get_binding(name);
     598:	4802      	ldr	r0, [pc, #8]	; (5a4 <device_get_binding.constprop.0+0x20>)
}
     59a:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_device_get_binding(name);
     59e:	f002 bd31 	b.w	3004 <z_impl_device_get_binding>
     5a2:	bf00      	nop
     5a4:	0000773d 	.word	0x0000773d

000005a8 <k_stack_push.constprop.0>:
static inline int k_stack_push(struct k_stack * stack, stack_data_t data)
     5a8:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
     5ac:	4601      	mov	r1, r0
     5ae:	f005 f871 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     5b2:	b120      	cbz	r0, 5be <k_stack_push.constprop.0+0x16>
	register uint32_t ret __asm__("r0") = arg1;
     5b4:	4804      	ldr	r0, [pc, #16]	; (5c8 <k_stack_push.constprop.0+0x20>)
	register uint32_t r6 __asm__("r6") = call_id;
     5b6:	268b      	movs	r6, #139	; 0x8b
	__asm__ volatile("svc %[svid]\n"
     5b8:	df03      	svc	3
}
     5ba:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	return z_impl_k_stack_push(stack, data);
     5be:	4802      	ldr	r0, [pc, #8]	; (5c8 <k_stack_push.constprop.0+0x20>)
}
     5c0:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_k_stack_push(stack, data);
     5c4:	f006 ba08 	b.w	69d8 <z_impl_k_stack_push>
     5c8:	200004d8 	.word	0x200004d8

000005cc <print_workqueue>:
{
     5cc:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
     5d0:	f005 f860 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     5d4:	b1b8      	cbz	r0, 606 <print_workqueue+0x3a>
	register uint32_t ret __asm__("r0") = arg1;
     5d6:	4810      	ldr	r0, [pc, #64]	; (618 <print_workqueue+0x4c>)
	register uint32_t r6 __asm__("r6") = call_id;
     5d8:	269e      	movs	r6, #158	; 0x9e
	__asm__ volatile("svc %[svid]\n"
     5da:	df03      	svc	3
		} else {
			return t * (to_hz / from_hz);
		}
	} else {
		if (result32) {
			return (uint32_t)((t * to_hz + off) / from_hz);
     5dc:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
     5e0:	fba0 0103 	umull	r0, r1, r0, r3
	status_timer = k_timer_remaining_get(&my_timer);
     5e4:	4c0d      	ldr	r4, [pc, #52]	; (61c <print_workqueue+0x50>)
     5e6:	0bc3      	lsrs	r3, r0, #15
     5e8:	ea43 4341 	orr.w	r3, r3, r1, lsl #17
 * @return The converted time value
 */
static TIME_CONSTEXPR inline uint32_t k_ticks_to_ms_floor32(uint32_t t)
{
	/* Generated.  Do not edit.  See above. */
	return z_tmcvt(t, Z_HZ_ticks, Z_HZ_ms, true, true, false, false);
     5ec:	6023      	str	r3, [r4, #0]
     5ee:	f005 f851 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     5f2:	b160      	cbz	r0, 60e <print_workqueue+0x42>
	register uint32_t ret __asm__("r0") = arg1;
     5f4:	4808      	ldr	r0, [pc, #32]	; (618 <print_workqueue+0x4c>)
	register uint32_t r6 __asm__("r6") = call_id;
     5f6:	26a2      	movs	r6, #162	; 0xa2
	__asm__ volatile("svc %[svid]\n"
     5f8:	df03      	svc	3
	printk("Value Counter Timer Expiry : %d \n\r",status_timer);	
     5fa:	6821      	ldr	r1, [r4, #0]
     5fc:	4808      	ldr	r0, [pc, #32]	; (620 <print_workqueue+0x54>)
}
     5fe:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
	printk("Value Counter Timer Expiry : %d \n\r",status_timer);	
     602:	f005 b943 	b.w	588c <printk>
	return z_timeout_remaining(&timer->timeout);
     606:	4804      	ldr	r0, [pc, #16]	; (618 <print_workqueue+0x4c>)
     608:	f006 fa67 	bl	6ada <z_timeout_remaining>
	return z_impl_k_timer_remaining_ticks(timer);
     60c:	e7e6      	b.n	5dc <print_workqueue+0x10>
	z_impl_k_timer_stop(timer);
     60e:	4802      	ldr	r0, [pc, #8]	; (618 <print_workqueue+0x4c>)
     610:	f006 fae1 	bl	6bd6 <z_impl_k_timer_stop>
     614:	e7f1      	b.n	5fa <print_workqueue+0x2e>
     616:	bf00      	nop
     618:	20000280 	.word	0x20000280
     61c:	20000524 	.word	0x20000524
     620:	00007744 	.word	0x00007744

00000624 <k_busy_wait.constprop.0>:
static inline void k_busy_wait(uint32_t usec_to_wait)
     624:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
     628:	f005 f834 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     62c:	b120      	cbz	r0, 638 <k_busy_wait.constprop.0+0x14>
	register uint32_t ret __asm__("r0") = arg1;
     62e:	4805      	ldr	r0, [pc, #20]	; (644 <k_busy_wait.constprop.0+0x20>)
	register uint32_t r6 __asm__("r6") = call_id;
     630:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
     632:	df03      	svc	3
}
     634:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	z_impl_k_busy_wait(usec_to_wait);
     638:	4802      	ldr	r0, [pc, #8]	; (644 <k_busy_wait.constprop.0+0x20>)
}
     63a:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_busy_wait(usec_to_wait);
     63e:	f006 ba0a 	b.w	6a56 <z_impl_k_busy_wait>
     642:	bf00      	nop
     644:	00030d40 	.word	0x00030d40

00000648 <Thread_receive>:

	}
	
}
extern void Thread_receive()
{
     648:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
		parm0.val = timeout;
		return (int) arch_syscall_invoke4(*(uintptr_t *)&msgq, *(uintptr_t *)&data, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_MSGQ_GET);
	}
#endif
	compiler_barrier();
	return z_impl_k_msgq_get(msgq, data, timeout);
     64c:	4d11      	ldr	r5, [pc, #68]	; (694 <Thread_receive+0x4c>)
	while (1)
	{
		for(char i = 0;i<=9;i++)
		{
			k_msgq_get(&my_msgq,&a,K_FOREVER);		
			printk("\n\r Thread Received %d ",a);
     64e:	4f12      	ldr	r7, [pc, #72]	; (698 <Thread_receive+0x50>)
{
     650:	240a      	movs	r4, #10
     652:	f005 f81f 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     656:	b198      	cbz	r0, 680 <Thread_receive+0x38>
	register uint32_t r2 __asm__("r2") = arg3;
     658:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
	register uint32_t ret __asm__("r0") = arg1;
     65c:	4628      	mov	r0, r5
	register uint32_t r1 __asm__("r1") = arg2;
     65e:	f10d 0107 	add.w	r1, sp, #7
	register uint32_t r3 __asm__("r3") = arg4;
     662:	4613      	mov	r3, r2
	register uint32_t r6 __asm__("r6") = call_id;
     664:	2664      	movs	r6, #100	; 0x64
	__asm__ volatile("svc %[svid]\n"
     666:	df03      	svc	3
			printk("\n\r Thread Received %d ",a);
     668:	f89d 1007 	ldrb.w	r1, [sp, #7]
     66c:	4638      	mov	r0, r7
     66e:	3c01      	subs	r4, #1
     670:	f005 f90c 	bl	588c <printk>
			k_busy_wait(200000);	
     674:	f7ff ffd6 	bl	624 <k_busy_wait.constprop.0>
		for(char i = 0;i<=9;i++)
     678:	f014 04ff 	ands.w	r4, r4, #255	; 0xff
     67c:	d1e9      	bne.n	652 <Thread_receive+0xa>
     67e:	e7e7      	b.n	650 <Thread_receive+0x8>
	return z_impl_k_msgq_get(msgq, data, timeout);
     680:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
     684:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
     688:	f10d 0107 	add.w	r1, sp, #7
     68c:	4628      	mov	r0, r5
     68e:	f002 fecb 	bl	3428 <z_impl_k_msgq_get>
     692:	e7e9      	b.n	668 <Thread_receive+0x20>
     694:	200004b0 	.word	0x200004b0
     698:	00007767 	.word	0x00007767

0000069c <Thread_send>:
{
     69c:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
	return z_impl_k_msgq_put(msgq, data, timeout);
     6a0:	4c13      	ldr	r4, [pc, #76]	; (6f0 <Thread_send+0x54>)
		printk("\n\r Thread Send");
     6a2:	4f14      	ldr	r7, [pc, #80]	; (6f4 <Thread_send+0x58>)
		for(char i = 1; i<=10 ; i++)
     6a4:	2501      	movs	r5, #1
     6a6:	f88d 5007 	strb.w	r5, [sp, #7]
     6aa:	f004 fff3 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     6ae:	b1a8      	cbz	r0, 6dc <Thread_send+0x40>
	register uint32_t r2 __asm__("r2") = arg3;
     6b0:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
	register uint32_t ret __asm__("r0") = arg1;
     6b4:	4620      	mov	r0, r4
	register uint32_t r1 __asm__("r1") = arg2;
     6b6:	f10d 0107 	add.w	r1, sp, #7
	register uint32_t r3 __asm__("r3") = arg4;
     6ba:	4613      	mov	r3, r2
	register uint32_t r6 __asm__("r6") = call_id;
     6bc:	266a      	movs	r6, #106	; 0x6a
	__asm__ volatile("svc %[svid]\n"
     6be:	df03      	svc	3
		printk("\n\r Thread Send");
     6c0:	4638      	mov	r0, r7
     6c2:	f005 f8e3 	bl	588c <printk>
		k_busy_wait(200000);					
     6c6:	f7ff ffad 	bl	624 <k_busy_wait.constprop.0>
		for(char i = 1; i<=10 ; i++)
     6ca:	f89d 3007 	ldrb.w	r3, [sp, #7]
     6ce:	3301      	adds	r3, #1
     6d0:	b2db      	uxtb	r3, r3
     6d2:	2b0a      	cmp	r3, #10
     6d4:	f88d 3007 	strb.w	r3, [sp, #7]
     6d8:	d8e5      	bhi.n	6a6 <Thread_send+0xa>
     6da:	e7e6      	b.n	6aa <Thread_send+0xe>
	return z_impl_k_msgq_put(msgq, data, timeout);
     6dc:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
     6e0:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
     6e4:	f10d 0107 	add.w	r1, sp, #7
     6e8:	4620      	mov	r0, r4
     6ea:	f002 fdf1 	bl	32d0 <z_impl_k_msgq_put>
     6ee:	e7e7      	b.n	6c0 <Thread_send+0x24>
     6f0:	200004b0 	.word	0x200004b0
     6f4:	0000777e 	.word	0x0000777e

000006f8 <main>:
//		k_msgq_purge(&my_msgq);
	}
	
}
void main(void)
{
     6f8:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
     6fc:	b08b      	sub	sp, #44	; 0x2c
	const char *a = "huynh tai";
	char argv_thread = 1;
     6fe:	2301      	movs	r3, #1
     700:	f88d 3013 	strb.w	r3, [sp, #19]
	uint32_t _value_stack_1 = 4;
	uint32_t _value_stack_2 = 5;
     704:	2204      	movs	r2, #4
     706:	2305      	movs	r3, #5
     708:	e9cd 2305 	strd	r2, r3, [sp, #20]
	/*-------------Thread-------------*/	
	k_tid_t my_tid_a = k_thread_create(&my_thread_data_a, my_stack_area_a,
                                 MY_STACK_SIZE,
                                 thread_a,
                                 a, &argv_thread, NULL,
                                 MY_PRIORITY, 0, K_NO_WAIT);
     70c:	f04f 0800 	mov.w	r8, #0
     710:	f04f 0900 	mov.w	r9, #0
	k_tid_t my_tid_a = k_thread_create(&my_thread_data_a, my_stack_area_a,
     714:	2607      	movs	r6, #7
     716:	f10d 0313 	add.w	r3, sp, #19
     71a:	e9cd 8902 	strd	r8, r9, [sp, #8]
     71e:	4a7c      	ldr	r2, [pc, #496]	; (910 <CONFIG_HEAP_MEM_POOL_SIZE+0x110>)
     720:	497c      	ldr	r1, [pc, #496]	; (914 <CONFIG_HEAP_MEM_POOL_SIZE+0x114>)
     722:	9300      	str	r3, [sp, #0]
     724:	487c      	ldr	r0, [pc, #496]	; (918 <CONFIG_HEAP_MEM_POOL_SIZE+0x118>)
     726:	4b7d      	ldr	r3, [pc, #500]	; (91c <CONFIG_HEAP_MEM_POOL_SIZE+0x11c>)
     728:	9601      	str	r6, [sp, #4]
     72a:	f004 fff1 	bl	5710 <k_thread_create.constprop.0>
	k_thread_name_set(my_tid_a, "thread_a");
	k_tid_t my_tid_b = k_thread_create(&my_thread_data_b, my_stack_area_b,
     72e:	2400      	movs	r4, #0
	k_thread_name_set(my_tid_a, "thread_a");
     730:	497b      	ldr	r1, [pc, #492]	; (920 <CONFIG_HEAP_MEM_POOL_SIZE+0x120>)
	k_tid_t my_tid_a = k_thread_create(&my_thread_data_a, my_stack_area_a,
     732:	4605      	mov	r5, r0
	k_thread_name_set(my_tid_a, "thread_a");
     734:	f005 f819 	bl	576a <k_thread_name_set>
	k_tid_t my_tid_b = k_thread_create(&my_thread_data_b, my_stack_area_b,
     738:	e9cd 8902 	strd	r8, r9, [sp, #8]
     73c:	4a79      	ldr	r2, [pc, #484]	; (924 <CONFIG_HEAP_MEM_POOL_SIZE+0x124>)
     73e:	497a      	ldr	r1, [pc, #488]	; (928 <CONFIG_HEAP_MEM_POOL_SIZE+0x128>)
     740:	487a      	ldr	r0, [pc, #488]	; (92c <CONFIG_HEAP_MEM_POOL_SIZE+0x12c>)
     742:	9601      	str	r6, [sp, #4]
     744:	4623      	mov	r3, r4
     746:	9400      	str	r4, [sp, #0]
     748:	f004 ffe2 	bl	5710 <k_thread_create.constprop.0>
                                 MY_STACK_SIZE,
                                 thread_b,
                                 NULL,NULL, NULL,
                                 MY_PRIORITY, 0, K_NO_WAIT);
	k_thread_name_set(my_tid_b, "thread_b");
     74c:	4978      	ldr	r1, [pc, #480]	; (930 <CONFIG_HEAP_MEM_POOL_SIZE+0x130>)
	/*-------------Thread Send-Receive----------------------*/
	k_tid_t my_tid_send = k_thread_create(&my_thread_data_send,my_stack_area_send,
                                 MY_STACK_SIZE,
                                 Thread_send,
                                 NULL, NULL, NULL,
                                 -4, 0, K_MSEC(100));
     74e:	f640 48cd 	movw	r8, #3277	; 0xccd
     752:	f04f 0900 	mov.w	r9, #0
	k_tid_t my_tid_b = k_thread_create(&my_thread_data_b, my_stack_area_b,
     756:	4607      	mov	r7, r0
	k_thread_name_set(my_tid_b, "thread_b");
     758:	f005 f807 	bl	576a <k_thread_name_set>
	k_tid_t my_tid_send = k_thread_create(&my_thread_data_send,my_stack_area_send,
     75c:	f06f 0303 	mvn.w	r3, #3
     760:	4a74      	ldr	r2, [pc, #464]	; (934 <CONFIG_HEAP_MEM_POOL_SIZE+0x134>)
     762:	4975      	ldr	r1, [pc, #468]	; (938 <CONFIG_HEAP_MEM_POOL_SIZE+0x138>)
     764:	4875      	ldr	r0, [pc, #468]	; (93c <CONFIG_HEAP_MEM_POOL_SIZE+0x13c>)
     766:	e9cd 4300 	strd	r4, r3, [sp]
     76a:	e9cd 8902 	strd	r8, r9, [sp, #8]
     76e:	4623      	mov	r3, r4
     770:	f004 ffce 	bl	5710 <k_thread_create.constprop.0>
	k_thread_name_set(my_tid_send, "Thread_send");
     774:	4972      	ldr	r1, [pc, #456]	; (940 <CONFIG_HEAP_MEM_POOL_SIZE+0x140>)
     776:	f004 fff8 	bl	576a <k_thread_name_set>
	k_tid_t my_tid_receive = k_thread_create(&my_thread_data_receive,my_stack_area_receive,
     77a:	f06f 0302 	mvn.w	r3, #2
     77e:	4a71      	ldr	r2, [pc, #452]	; (944 <CONFIG_HEAP_MEM_POOL_SIZE+0x144>)
     780:	4971      	ldr	r1, [pc, #452]	; (948 <CONFIG_HEAP_MEM_POOL_SIZE+0x148>)
     782:	4872      	ldr	r0, [pc, #456]	; (94c <CONFIG_HEAP_MEM_POOL_SIZE+0x14c>)
     784:	e9cd 4300 	strd	r4, r3, [sp]
     788:	e9cd 8902 	strd	r8, r9, [sp, #8]
     78c:	4623      	mov	r3, r4
     78e:	f004 ffbf 	bl	5710 <k_thread_create.constprop.0>
                                 MY_STACK_SIZE,
                                 Thread_receive,
                                 NULL, NULL, NULL,
                                 -3, 0, K_MSEC(100));
	k_thread_name_set(my_tid_receive, "Thread_receive");	
     792:	496f      	ldr	r1, [pc, #444]	; (950 <CONFIG_HEAP_MEM_POOL_SIZE+0x150>)
     794:	f004 ffe9 	bl	576a <k_thread_name_set>
	/*----------------------------------*/



	/*-------------Workqueue--------------*/
	k_work_q_start(&my_work_q, my_stack_workqueue,MY_STACK_SIZE, MY_PRIORITY); //create Workqueue
     798:	496e      	ldr	r1, [pc, #440]	; (954 <CONFIG_HEAP_MEM_POOL_SIZE+0x154>)
     79a:	486f      	ldr	r0, [pc, #444]	; (958 <CONFIG_HEAP_MEM_POOL_SIZE+0x158>)
     79c:	4633      	mov	r3, r6
     79e:	f44f 7200 	mov.w	r2, #512	; 0x200
     7a2:	f004 fab5 	bl	4d10 <k_work_q_start>
	*work = (struct k_work)Z_WORK_INITIALIZER(handler);
     7a6:	4b6d      	ldr	r3, [pc, #436]	; (95c <CONFIG_HEAP_MEM_POOL_SIZE+0x15c>)
     7a8:	4a6d      	ldr	r2, [pc, #436]	; (960 <CONFIG_HEAP_MEM_POOL_SIZE+0x160>)
	/*-----------------------------------*/



	/*----------TIMING---------------*/
	k_timer_init(&my_timer, my_expiry_function, NULL);
     7aa:	496e      	ldr	r1, [pc, #440]	; (964 <CONFIG_HEAP_MEM_POOL_SIZE+0x164>)
     7ac:	486e      	ldr	r0, [pc, #440]	; (968 <CONFIG_HEAP_MEM_POOL_SIZE+0x168>)
     7ae:	601c      	str	r4, [r3, #0]
     7b0:	e9c3 2401 	strd	r2, r4, [r3, #4]
     7b4:	4622      	mov	r2, r4
     7b6:	f006 fa01 	bl	6bbc <k_timer_init>
     7ba:	f004 ff6b 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
     7be:	2800      	cmp	r0, #0
     7c0:	f000 8091 	beq.w	8e6 <CONFIG_HEAP_MEM_POOL_SIZE+0xe6>
	register uint32_t ret __asm__("r0") = arg1;
     7c4:	4868      	ldr	r0, [pc, #416]	; (968 <CONFIG_HEAP_MEM_POOL_SIZE+0x168>)
	register uint32_t r1 __asm__("r1") = arg2;
     7c6:	f640 41cd 	movw	r1, #3277	; 0xccd
	register uint32_t r2 __asm__("r2") = arg3;
     7ca:	4622      	mov	r2, r4
	register uint32_t r3 __asm__("r3") = arg4;
     7cc:	f44f 4380 	mov.w	r3, #16384	; 0x4000
	register uint32_t r6 __asm__("r6") = call_id;
     7d0:	269f      	movs	r6, #159	; 0x9f
	__asm__ volatile("svc %[svid]\n"
     7d2:	df03      	svc	3
//	k_mem_slab_init(&my_slab, my_slab_buffer, 400, 6);
//	k_mem_slab_alloc(&my_slab,&block_slab,K_NO_WAIT);
//	memset(block_slab,'0',400);
	/*---------------------------------------*/
	/*------------Stack-------------------------*/
	k_stack_init(&my_stack, my_stack_array, 10);
     7d4:	4965      	ldr	r1, [pc, #404]	; (96c <CONFIG_HEAP_MEM_POOL_SIZE+0x16c>)
     7d6:	4866      	ldr	r0, [pc, #408]	; (970 <CONFIG_HEAP_MEM_POOL_SIZE+0x170>)
     7d8:	220a      	movs	r2, #10
     7da:	f006 f8e1 	bl	69a0 <k_stack_init>
	k_stack_push(&my_stack,(uint32_t)&_value_stack_1);
     7de:	a805      	add	r0, sp, #20
     7e0:	f7ff fee2 	bl	5a8 <k_stack_push.constprop.0>
	k_stack_push(&my_stack,(uint32_t)&_value_stack_2);
     7e4:	a806      	add	r0, sp, #24
     7e6:	f7ff fedf 	bl	5a8 <k_stack_push.constprop.0>
	/*--------------Message Queue-----------*/
	k_msgq_init(&my_msgq, _buff_queue, sizeof(char), 9);
     7ea:	4862      	ldr	r0, [pc, #392]	; (974 <CONFIG_HEAP_MEM_POOL_SIZE+0x174>)
     7ec:	2309      	movs	r3, #9
     7ee:	2201      	movs	r2, #1
     7f0:	a907      	add	r1, sp, #28
     7f2:	f005 fe26 	bl	6442 <k_msgq_init>
	struct device *dev;
	struct device *dev_led0;
	bool led_is_on = true;
	int ret;
	/*-----Configure nRF52832 from Library nrf52.h-------------*/
	NRF_P0->PIN_CNF[14] = (3 << 16) | (3 << 2);
     7f6:	f04f 43a0 	mov.w	r3, #1342177280	; 0x50000000
     7fa:	4a5f      	ldr	r2, [pc, #380]	; (978 <CONFIG_HEAP_MEM_POOL_SIZE+0x178>)
     7fc:	f8c3 2738 	str.w	r2, [r3, #1848]	; 0x738
    NRF_P0->PIN_CNF[15] = (3 << 16) | (3 << 2);
     800:	f8c3 273c 	str.w	r2, [r3, #1852]	; 0x73c
    NRF_P0->PIN_CNF[16] = (3 << 16) | (3 << 2);
     804:	f8c3 2740 	str.w	r2, [r3, #1856]	; 0x740
    NRF_P0->PIN_CNF[13] = (3 << 16) | (3 << 2); 
     808:	f8c3 2734 	str.w	r2, [r3, #1844]	; 0x734
	//NRF_P0->DIRSET = 0x001E0000;
    NRF_P0->PIN_CNF[6] = 0x03;
     80c:	2203      	movs	r2, #3
     80e:	f8c3 2718 	str.w	r2, [r3, #1816]	; 0x718
    NRF_P0->PIN_CNF[7] = 0;
     812:	2200      	movs	r2, #0
     814:	f8c3 271c 	str.w	r2, [r3, #1820]	; 0x71c
    // Configure GPIOTE
    //EVENTS
    NRF_GPIOTE->INTENSET = (1 << 0);                          // Enable INTERRUPTION EVENT_IN[0]
     818:	4b58      	ldr	r3, [pc, #352]	; (97c <CONFIG_HEAP_MEM_POOL_SIZE+0x17c>)
    //NRF_GPIOTE->CONFIG[0] = (1 << 0) | (13 << 8) | (2 << 16); // Configure EVENT_IN[0]
    //NRF_GPIOTE->CONFIG[5] = (1 << 0) | (14 << 8) | (2 << 16); // Configure EVENT_IN[0]
    NRF_GPIOTE->CONFIG[6] = (1 << 0) | (15 << 8) | (2 << 16); // Configure EVENT_IN[0]
     81a:	4a59      	ldr	r2, [pc, #356]	; (980 <CONFIG_HEAP_MEM_POOL_SIZE+0x180>)
    NRF_GPIOTE->INTENSET = (1 << 0);                          // Enable INTERRUPTION EVENT_IN[0]
     81c:	2401      	movs	r4, #1
     81e:	f8c3 4304 	str.w	r4, [r3, #772]	; 0x304
    NRF_GPIOTE->CONFIG[6] = (1 << 0) | (15 << 8) | (2 << 16); // Configure EVENT_IN[0]
     822:	f8c3 2528 	str.w	r2, [r3, #1320]	; 0x528
    NRF_GPIOTE->CONFIG[7] = (1 << 0) | (16 << 8) | (2 << 16); // Configure EVENT_IN[0]
     826:	f502 7280 	add.w	r2, r2, #256	; 0x100
     82a:	f8c3 252c 	str.w	r2, [r3, #1324]	; 0x52c
    // TASKS
    //NRF_GPIOTE->CONFIG[1] = (3 << 0) | (17 << 8) | (3 << 16) | (1 << 20);
    //NRF_GPIOTE->CONFIG[2] = (3 << 0) | (18 << 8) | (3 << 16) | (1 << 20);
    NRF_GPIOTE->CONFIG[3] = (3 << 0) | (19 << 8) | (3 << 16) | (1 << 20);
     82e:	f502 1288 	add.w	r2, r2, #1114112	; 0x110000
     832:	f202 3202 	addw	r2, r2, #770	; 0x302
     836:	f8c3 251c 	str.w	r2, [r3, #1308]	; 0x51c
    NRF_GPIOTE->CONFIG[4] = (3 << 0) | (20 << 8) | (3 << 16) | (1 << 20);
     83a:	f502 7280 	add.w	r2, r2, #256	; 0x100
     83e:	f8c3 2520 	str.w	r2, [r3, #1312]	; 0x520
    //NRF_PPI->CHENSET = (15 << 0);
    //NRF_PPI->CH[0].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[0];
    //NRF_PPI->CH[0].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[1];
    //NRF_PPI->CH[1].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[5];
    //NRF_PPI->CH[1].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[2];
    NRF_PPI->CH[2].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[6];
     842:	f503 33c8 	add.w	r3, r3, #102400	; 0x19000
     846:	4a4f      	ldr	r2, [pc, #316]	; (984 <CONFIG_HEAP_MEM_POOL_SIZE+0x184>)
     848:	f8c3 2520 	str.w	r2, [r3, #1312]	; 0x520
    NRF_PPI->CH[2].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[3];
     84c:	f5a2 7286 	sub.w	r2, r2, #268	; 0x10c
     850:	f8c3 2524 	str.w	r2, [r3, #1316]	; 0x524
    NRF_PPI->CH[3].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[7];
     854:	f502 7288 	add.w	r2, r2, #272	; 0x110
     858:	f8c3 2528 	str.w	r2, [r3, #1320]	; 0x528
    NRF_PPI->CH[3].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[4];
     85c:	f5a2 7286 	sub.w	r2, r2, #268	; 0x10c
     860:	f8c3 252c 	str.w	r2, [r3, #1324]	; 0x52c
    NRF_PPI->CHG[0] = (15 << 0);
     864:	220f      	movs	r2, #15
     866:	f8c3 2800 	str.w	r2, [r3, #2048]	; 0x800
    NRF_PPI->TASKS_CHG[0].EN = 1;
     86a:	601c      	str	r4, [r3, #0]
	/*---------------------------------------------------------------*/
	dev = device_get_binding(LED1);
     86c:	f7ff fe8a 	bl	584 <device_get_binding.constprop.0>
	if (dev == NULL) {
     870:	4606      	mov	r6, r0
     872:	2800      	cmp	r0, #0
     874:	d048      	beq.n	908 <CONFIG_HEAP_MEM_POOL_SIZE+0x108>
		return;
	}

	ret = gpio_pin_configure(dev, PIN, GPIO_OUTPUT_ACTIVE | FLAGS);
     876:	2112      	movs	r1, #18
     878:	f004 ff26 	bl	56c8 <gpio_pin_configure.constprop.0>
	if (ret < 0) {
     87c:	2800      	cmp	r0, #0
     87e:	db43      	blt.n	908 <CONFIG_HEAP_MEM_POOL_SIZE+0x108>
		return;
	}
	dev_led0 = device_get_binding(LED1);
     880:	f7ff fe80 	bl	584 <device_get_binding.constprop.0>
	if (dev_led0 == NULL) {
     884:	4680      	mov	r8, r0
     886:	2800      	cmp	r0, #0
     888:	d03e      	beq.n	908 <CONFIG_HEAP_MEM_POOL_SIZE+0x108>
		return;
	}

	ret = gpio_pin_configure(dev_led0, PIN0, GPIO_OUTPUT_ACTIVE | FLAGS);
     88a:	2111      	movs	r1, #17
     88c:	f004 ff1c 	bl	56c8 <gpio_pin_configure.constprop.0>
	if (ret < 0) {
     890:	2800      	cmp	r0, #0
     892:	db39      	blt.n	908 <CONFIG_HEAP_MEM_POOL_SIZE+0x108>
		return;
	}
	k_thread_suspend(my_tid_b);
     894:	4638      	mov	r0, r7
     896:	f004 ff9a 	bl	57ce <k_thread_suspend>
	k_thread_suspend(my_tid_a);
     89a:	4628      	mov	r0, r5
     89c:	f004 ff97 	bl	57ce <k_thread_suspend>

	(void)cfg;
	__ASSERT((cfg->port_pin_mask & (gpio_port_pins_t)BIT(pin)) != 0U,
		 "Unsupported pin");

	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
     8a0:	68f3      	ldr	r3, [r6, #12]
     8a2:	681b      	ldr	r3, [r3, #0]
//	memset(buff,'0',1000);
	while (1) {

		gpio_pin_set(dev, PIN, (int)led_is_on);
     8a4:	4625      	mov	r5, r4
		value = (value != 0) ? 0 : 1;
     8a6:	f413 2f80 	tst.w	r3, #262144	; 0x40000
     8aa:	f084 0401 	eor.w	r4, r4, #1
     8ae:	bf0c      	ite	eq
     8b0:	462b      	moveq	r3, r5
     8b2:	4623      	movne	r3, r4
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     8b4:	f44f 2180 	mov.w	r1, #262144	; 0x40000
     8b8:	4630      	mov	r0, r6
	if (value != 0)	{
     8ba:	b1fb      	cbz	r3, 8fc <CONFIG_HEAP_MEM_POOL_SIZE+0xfc>
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     8bc:	f004 ff65 	bl	578a <gpio_port_set_bits_raw>
	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
     8c0:	f8d8 300c 	ldr.w	r3, [r8, #12]
     8c4:	681b      	ldr	r3, [r3, #0]
		value = (value != 0) ? 0 : 1;
     8c6:	f413 3f00 	tst.w	r3, #131072	; 0x20000
     8ca:	bf08      	it	eq
     8cc:	4625      	moveq	r5, r4
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     8ce:	f44f 3100 	mov.w	r1, #131072	; 0x20000
     8d2:	4640      	mov	r0, r8
	if (value != 0)	{
     8d4:	b1ad      	cbz	r5, 902 <CONFIG_HEAP_MEM_POOL_SIZE+0x102>
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     8d6:	f004 ff58 	bl	578a <gpio_port_set_bits_raw>
	return k_sleep(Z_TIMEOUT_MS(ms));
     8da:	2100      	movs	r1, #0
     8dc:	f44f 4000 	mov.w	r0, #32768	; 0x8000
     8e0:	f004 fee2 	bl	56a8 <k_sleep>
     8e4:	e7dc      	b.n	8a0 <CONFIG_HEAP_MEM_POOL_SIZE+0xa0>
	z_impl_k_timer_start(timer, duration, period);
     8e6:	f44f 4280 	mov.w	r2, #16384	; 0x4000
     8ea:	2300      	movs	r3, #0
     8ec:	e9cd 2300 	strd	r2, r3, [sp]
     8f0:	481d      	ldr	r0, [pc, #116]	; (968 <CONFIG_HEAP_MEM_POOL_SIZE+0x168>)
     8f2:	4642      	mov	r2, r8
     8f4:	464b      	mov	r3, r9
     8f6:	f004 fc07 	bl	5108 <z_impl_k_timer_start>
     8fa:	e76b      	b.n	7d4 <main+0xdc>
		ret = gpio_port_clear_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     8fc:	f004 ff56 	bl	57ac <gpio_port_clear_bits_raw>
     900:	e7de      	b.n	8c0 <CONFIG_HEAP_MEM_POOL_SIZE+0xc0>
     902:	f004 ff53 	bl	57ac <gpio_port_clear_bits_raw>
     906:	e7e8      	b.n	8da <CONFIG_HEAP_MEM_POOL_SIZE+0xda>
	//	k_thread_suspend(my_tid_a);
		//k_thread_abort(my_tid_a);		
	//	k_thread_resume(my_tid_a);k_thread_resume(my_tid_a);
	}

}
     908:	b00b      	add	sp, #44	; 0x2c
     90a:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
     90e:	bf00      	nop
     910:	00000559 	.word	0x00000559
     914:	20002400 	.word	0x20002400
     918:	20000000 	.word	0x20000000
     91c:	0000778d 	.word	0x0000778d
     920:	00007797 	.word	0x00007797
     924:	00000531 	.word	0x00000531
     928:	20002600 	.word	0x20002600
     92c:	200000a0 	.word	0x200000a0
     930:	000077a0 	.word	0x000077a0
     934:	0000069d 	.word	0x0000069d
     938:	20002800 	.word	0x20002800
     93c:	200001e0 	.word	0x200001e0
     940:	000077a9 	.word	0x000077a9
     944:	00000649 	.word	0x00000649
     948:	20002a00 	.word	0x20002a00
     94c:	20000140 	.word	0x20000140
     950:	000077b5 	.word	0x000077b5
     954:	20002c00 	.word	0x20002c00
     958:	200002b8 	.word	0x200002b8
     95c:	20000518 	.word	0x20000518
     960:	000005cd 	.word	0x000005cd
     964:	00000501 	.word	0x00000501
     968:	20000280 	.word	0x20000280
     96c:	200004f0 	.word	0x200004f0
     970:	200004d8 	.word	0x200004d8
     974:	200004b0 	.word	0x200004b0
     978:	0003000c 	.word	0x0003000c
     97c:	40006000 	.word	0x40006000
     980:	00020f01 	.word	0x00020f01
     984:	40006118 	.word	0x40006118

00000988 <print_digits>:
}
#endif /* CONFIG_PRINTK */

static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
			 bool pad_before, char pad_char, int min_width)
{
     988:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
     98c:	b087      	sub	sp, #28
     98e:	460f      	mov	r7, r1
     990:	4619      	mov	r1, r3
	char buf[DIGITS_BUFLEN];
	int i;

	/* Print it backwards into the end of the buffer, low digits first */
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
		buf[i] = "0123456789abcdef"[num % base];
     992:	9b10      	ldr	r3, [sp, #64]	; 0x40
{
     994:	f89d b044 	ldrb.w	fp, [sp, #68]	; 0x44
     998:	f89d a048 	ldrb.w	sl, [sp, #72]	; 0x48
		buf[i] = "0123456789abcdef"[num % base];
     99c:	4c1f      	ldr	r4, [pc, #124]	; (a1c <print_digits+0x94>)
{
     99e:	4606      	mov	r6, r0
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     9a0:	2514      	movs	r5, #20
{
     9a2:	4610      	mov	r0, r2
		buf[i] = "0123456789abcdef"[num % base];
     9a4:	4698      	mov	r8, r3
     9a6:	ea4f 79e3 	mov.w	r9, r3, asr #31
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     9aa:	ea50 0301 	orrs.w	r3, r0, r1
     9ae:	d119      	bne.n	9e4 <print_digits+0x5c>
		num /= base;
	}

	if (i == DIGITS_BUFLEN - 1) {
     9b0:	2d14      	cmp	r5, #20
		buf[i] = '0';
	} else {
		i++;
	}

	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     9b2:	9c13      	ldr	r4, [sp, #76]	; 0x4c
		i++;
     9b4:	bf14      	ite	ne
     9b6:	3501      	addne	r5, #1
		buf[i] = '0';
     9b8:	2330      	moveq	r3, #48	; 0x30
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     9ba:	442c      	add	r4, r5
		buf[i] = '0';
     9bc:	bf08      	it	eq
     9be:	f88d 3014 	strbeq.w	r3, [sp, #20]
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     9c2:	2c15      	cmp	r4, #21
     9c4:	d01b      	beq.n	9fe <print_digits+0x76>
     9c6:	3c15      	subs	r4, #21

	for (/**/; pad > 0 && pad_before; pad--) {
     9c8:	2c00      	cmp	r4, #0
     9ca:	dc1a      	bgt.n	a02 <print_digits+0x7a>
		out(pad_char, ctx);
	}
	for (/**/; i < DIGITS_BUFLEN; i++) {
		out(buf[i], ctx);
     9cc:	f81d 0005 	ldrb.w	r0, [sp, r5]
     9d0:	4639      	mov	r1, r7
	for (/**/; i < DIGITS_BUFLEN; i++) {
     9d2:	3501      	adds	r5, #1
		out(buf[i], ctx);
     9d4:	47b0      	blx	r6
	for (/**/; i < DIGITS_BUFLEN; i++) {
     9d6:	2d15      	cmp	r5, #21
     9d8:	d1f8      	bne.n	9cc <print_digits+0x44>
	}
	for (/**/; pad > 0; pad--) {
     9da:	2c00      	cmp	r4, #0
     9dc:	dc19      	bgt.n	a12 <print_digits+0x8a>
		out(pad_char, ctx);
	}
}
     9de:	b007      	add	sp, #28
     9e0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		buf[i] = "0123456789abcdef"[num % base];
     9e4:	4642      	mov	r2, r8
     9e6:	464b      	mov	r3, r9
     9e8:	f7ff fbf8 	bl	1dc <__aeabi_uldivmod>
     9ec:	5ca2      	ldrb	r2, [r4, r2]
     9ee:	f80d 2005 	strb.w	r2, [sp, r5]
     9f2:	4684      	mov	ip, r0
     9f4:	460b      	mov	r3, r1
		num /= base;
     9f6:	4660      	mov	r0, ip
     9f8:	4619      	mov	r1, r3
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     9fa:	3d01      	subs	r5, #1
     9fc:	e7d5      	b.n	9aa <print_digits+0x22>
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     9fe:	2400      	movs	r4, #0
	for (/**/; i < DIGITS_BUFLEN; i++) {
     a00:	e7e4      	b.n	9cc <print_digits+0x44>
	for (/**/; pad > 0 && pad_before; pad--) {
     a02:	f1bb 0f00 	cmp.w	fp, #0
     a06:	d0e1      	beq.n	9cc <print_digits+0x44>
		out(pad_char, ctx);
     a08:	4639      	mov	r1, r7
     a0a:	4650      	mov	r0, sl
     a0c:	47b0      	blx	r6
	for (/**/; pad > 0 && pad_before; pad--) {
     a0e:	3c01      	subs	r4, #1
     a10:	e7da      	b.n	9c8 <print_digits+0x40>
		out(pad_char, ctx);
     a12:	4639      	mov	r1, r7
     a14:	4650      	mov	r0, sl
     a16:	47b0      	blx	r6
	for (/**/; pad > 0; pad--) {
     a18:	3c01      	subs	r4, #1
     a1a:	e7de      	b.n	9da <print_digits+0x52>
     a1c:	000077c4 	.word	0x000077c4

00000a20 <char_out>:

static int char_out(int c, void *ctx_p)
{
	struct out_context *ctx = ctx_p;

	ctx->count++;
     a20:	680b      	ldr	r3, [r1, #0]
     a22:	3301      	adds	r3, #1
     a24:	600b      	str	r3, [r1, #0]
	return _char_out(c);
     a26:	4b01      	ldr	r3, [pc, #4]	; (a2c <char_out+0xc>)
     a28:	681b      	ldr	r3, [r3, #0]
     a2a:	4718      	bx	r3
     a2c:	20002e00 	.word	0x20002e00

00000a30 <__printk_hook_install>:
	_char_out = fn;
     a30:	4b01      	ldr	r3, [pc, #4]	; (a38 <__printk_hook_install+0x8>)
     a32:	6018      	str	r0, [r3, #0]
}
     a34:	4770      	bx	lr
     a36:	bf00      	nop
     a38:	20002e00 	.word	0x20002e00

00000a3c <z_vprintk>:
{
     a3c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	char length_mod = 0;
     a40:	2600      	movs	r6, #0
{
     a42:	b087      	sub	sp, #28
     a44:	4605      	mov	r5, r0
     a46:	468b      	mov	fp, r1
     a48:	461c      	mov	r4, r3
	while (*fmt) {
     a4a:	f102 39ff 	add.w	r9, r2, #4294967295	; 0xffffffff
	int min_width = -1;
     a4e:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
	enum pad_type padding = PAD_NONE;
     a52:	4637      	mov	r7, r6
			might_format = 0;
     a54:	2300      	movs	r3, #0
					break;
     a56:	e007      	b.n	a68 <z_vprintk+0x2c>
		if (!might_format) {
     a58:	b96b      	cbnz	r3, a76 <z_vprintk+0x3a>
			if (*fmt != '%') {
     a5a:	2825      	cmp	r0, #37	; 0x25
     a5c:	f000 80fc 	beq.w	c58 <z_vprintk+0x21c>
				out((int)*fmt, ctx);
     a60:	4659      	mov	r1, fp
     a62:	9304      	str	r3, [sp, #16]
     a64:	47a8      	blx	r5
     a66:	9b04      	ldr	r3, [sp, #16]
	while (*fmt) {
     a68:	f819 0f01 	ldrb.w	r0, [r9, #1]!
     a6c:	2800      	cmp	r0, #0
     a6e:	d1f3      	bne.n	a58 <z_vprintk+0x1c>
}
     a70:	b007      	add	sp, #28
     a72:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			switch (*fmt) {
     a76:	287a      	cmp	r0, #122	; 0x7a
     a78:	d80a      	bhi.n	a90 <z_vprintk+0x54>
     a7a:	2862      	cmp	r0, #98	; 0x62
     a7c:	d810      	bhi.n	aa0 <z_vprintk+0x64>
     a7e:	2830      	cmp	r0, #48	; 0x30
     a80:	d052      	beq.n	b28 <z_vprintk+0xec>
     a82:	d845      	bhi.n	b10 <z_vprintk+0xd4>
     a84:	2825      	cmp	r0, #37	; 0x25
     a86:	f000 80e5 	beq.w	c54 <z_vprintk+0x218>
     a8a:	282d      	cmp	r0, #45	; 0x2d
     a8c:	f000 80ea 	beq.w	c64 <z_vprintk+0x228>
					out((int)'%', ctx);
     a90:	4659      	mov	r1, fp
     a92:	2025      	movs	r0, #37	; 0x25
     a94:	47a8      	blx	r5
					out((int)*fmt, ctx);
     a96:	f899 0000 	ldrb.w	r0, [r9]
     a9a:	4659      	mov	r1, fp
     a9c:	47a8      	blx	r5
     a9e:	e7d9      	b.n	a54 <z_vprintk+0x18>
     aa0:	f1a0 0263 	sub.w	r2, r0, #99	; 0x63
     aa4:	2a17      	cmp	r2, #23
     aa6:	d8f3      	bhi.n	a90 <z_vprintk+0x54>
     aa8:	a101      	add	r1, pc, #4	; (adr r1, ab0 <z_vprintk+0x74>)
     aaa:	f851 f022 	ldr.w	pc, [r1, r2, lsl #2]
     aae:	bf00      	nop
     ab0:	00000c4d 	.word	0x00000c4d
     ab4:	00000b71 	.word	0x00000b71
     ab8:	00000a91 	.word	0x00000a91
     abc:	00000a91 	.word	0x00000a91
     ac0:	00000a91 	.word	0x00000a91
     ac4:	00000b53 	.word	0x00000b53
     ac8:	00000b71 	.word	0x00000b71
     acc:	00000a91 	.word	0x00000a91
     ad0:	00000a91 	.word	0x00000a91
     ad4:	00000b53 	.word	0x00000b53
     ad8:	00000a91 	.word	0x00000a91
     adc:	00000a91 	.word	0x00000a91
     ae0:	00000a91 	.word	0x00000a91
     ae4:	00000bd5 	.word	0x00000bd5
     ae8:	00000a91 	.word	0x00000a91
     aec:	00000a91 	.word	0x00000a91
     af0:	00000c17 	.word	0x00000c17
     af4:	00000a91 	.word	0x00000a91
     af8:	00000b71 	.word	0x00000b71
     afc:	00000a91 	.word	0x00000a91
     b00:	00000a91 	.word	0x00000a91
     b04:	00000b19 	.word	0x00000b19
     b08:	00000a91 	.word	0x00000a91
     b0c:	00000b53 	.word	0x00000b53
			switch (*fmt) {
     b10:	2839      	cmp	r0, #57	; 0x39
     b12:	d915      	bls.n	b40 <z_vprintk+0x104>
     b14:	2858      	cmp	r0, #88	; 0x58
     b16:	d1bb      	bne.n	a90 <z_vprintk+0x54>
				if (*fmt == 'p') {
     b18:	f899 3000 	ldrb.w	r3, [r9]
     b1c:	2b70      	cmp	r3, #112	; 0x70
     b1e:	d163      	bne.n	be8 <z_vprintk+0x1ac>
					x = va_arg(ap, unsigned int);
     b20:	f854 2b04 	ldr.w	r2, [r4], #4
     b24:	2300      	movs	r3, #0
     b26:	e06a      	b.n	bfe <z_vprintk+0x1c2>
				if (min_width < 0 && padding == PAD_NONE) {
     b28:	f1b8 0f00 	cmp.w	r8, #0
     b2c:	da0b      	bge.n	b46 <z_vprintk+0x10a>
     b2e:	2f00      	cmp	r7, #0
     b30:	f000 809a 	beq.w	c68 <z_vprintk+0x22c>
					min_width = *fmt - '0';
     b34:	f1a0 0830 	sub.w	r8, r0, #48	; 0x30
					padding = PAD_SPACE_BEFORE;
     b38:	2f00      	cmp	r7, #0
     b3a:	bf08      	it	eq
     b3c:	2702      	moveq	r7, #2
     b3e:	e793      	b.n	a68 <z_vprintk+0x2c>
				if (min_width < 0) {
     b40:	f1b8 0f00 	cmp.w	r8, #0
     b44:	dbf6      	blt.n	b34 <z_vprintk+0xf8>
					min_width = 10 * min_width + *fmt - '0';
     b46:	220a      	movs	r2, #10
     b48:	fb02 0808 	mla	r8, r2, r8, r0
     b4c:	f1a8 0830 	sub.w	r8, r8, #48	; 0x30
     b50:	e7f2      	b.n	b38 <z_vprintk+0xfc>
				if (*fmt == 'h' && length_mod == 'h') {
     b52:	2868      	cmp	r0, #104	; 0x68
     b54:	d103      	bne.n	b5e <z_vprintk+0x122>
     b56:	2e68      	cmp	r6, #104	; 0x68
     b58:	d106      	bne.n	b68 <z_vprintk+0x12c>
					length_mod = 'H';
     b5a:	2648      	movs	r6, #72	; 0x48
     b5c:	e784      	b.n	a68 <z_vprintk+0x2c>
				} else if (*fmt == 'l' && length_mod == 'l') {
     b5e:	286c      	cmp	r0, #108	; 0x6c
     b60:	d102      	bne.n	b68 <z_vprintk+0x12c>
     b62:	2e6c      	cmp	r6, #108	; 0x6c
     b64:	f000 8082 	beq.w	c6c <z_vprintk+0x230>
				} else if (length_mod == 0) {
     b68:	2e00      	cmp	r6, #0
     b6a:	d191      	bne.n	a90 <z_vprintk+0x54>
     b6c:	4606      	mov	r6, r0
     b6e:	e77b      	b.n	a68 <z_vprintk+0x2c>
				if (length_mod == 'z') {
     b70:	2e7a      	cmp	r6, #122	; 0x7a
     b72:	d103      	bne.n	b7c <z_vprintk+0x140>
					d = va_arg(ap, int);
     b74:	f854 2b04 	ldr.w	r2, [r4], #4
     b78:	17d3      	asrs	r3, r2, #31
     b7a:	e008      	b.n	b8e <z_vprintk+0x152>
				} else if (length_mod == 'l') {
     b7c:	2e6c      	cmp	r6, #108	; 0x6c
     b7e:	d0f9      	beq.n	b74 <z_vprintk+0x138>
				} else if (length_mod == 'L') {
     b80:	2e4c      	cmp	r6, #76	; 0x4c
     b82:	d1f7      	bne.n	b74 <z_vprintk+0x138>
					long long lld = va_arg(ap, long long);
     b84:	3407      	adds	r4, #7
     b86:	f024 0407 	bic.w	r4, r4, #7
					d = (printk_val_t) lld;
     b8a:	e8f4 2302 	ldrd	r2, r3, [r4], #8
				if (*fmt != 'u' && negative(d)) {
     b8e:	2875      	cmp	r0, #117	; 0x75
     b90:	d00f      	beq.n	bb2 <z_vprintk+0x176>
     b92:	2a00      	cmp	r2, #0
     b94:	f173 0100 	sbcs.w	r1, r3, #0
     b98:	da0b      	bge.n	bb2 <z_vprintk+0x176>
					out((int)'-', ctx);
     b9a:	4659      	mov	r1, fp
     b9c:	202d      	movs	r0, #45	; 0x2d
     b9e:	e9cd 2304 	strd	r2, r3, [sp, #16]
     ba2:	47a8      	blx	r5
					d = -d;
     ba4:	e9dd 2304 	ldrd	r2, r3, [sp, #16]
     ba8:	4252      	negs	r2, r2
     baa:	eb63 0343 	sbc.w	r3, r3, r3, lsl #1
					min_width--;
     bae:	f108 38ff 	add.w	r8, r8, #4294967295	; 0xffffffff
	print_digits(out, ctx, num, 10, padding != PAD_SPACE_AFTER,
     bb2:	1ef9      	subs	r1, r7, #3
     bb4:	bf18      	it	ne
     bb6:	2101      	movne	r1, #1
     bb8:	2f01      	cmp	r7, #1
     bba:	bf0c      	ite	eq
     bbc:	2030      	moveq	r0, #48	; 0x30
     bbe:	2020      	movne	r0, #32
     bc0:	e9cd 0802 	strd	r0, r8, [sp, #8]
     bc4:	9101      	str	r1, [sp, #4]
     bc6:	210a      	movs	r1, #10
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
     bc8:	9100      	str	r1, [sp, #0]
     bca:	4628      	mov	r0, r5
     bcc:	4659      	mov	r1, fp
     bce:	f7ff fedb 	bl	988 <print_digits>
     bd2:	e73f      	b.n	a54 <z_vprintk+0x18>
				out('0', ctx);
     bd4:	4659      	mov	r1, fp
     bd6:	2030      	movs	r0, #48	; 0x30
     bd8:	47a8      	blx	r5
				out('x', ctx);
     bda:	4659      	mov	r1, fp
     bdc:	2078      	movs	r0, #120	; 0x78
     bde:	47a8      	blx	r5
				min_width = sizeof(void *) * 2;
     be0:	f04f 0808 	mov.w	r8, #8
				padding = PAD_ZERO_BEFORE;
     be4:	2701      	movs	r7, #1
     be6:	e797      	b.n	b18 <z_vprintk+0xdc>
				} else if (length_mod == 'l') {
     be8:	2e6c      	cmp	r6, #108	; 0x6c
     bea:	d099      	beq.n	b20 <z_vprintk+0xe4>
				} else if (length_mod == 'L') {
     bec:	2e4c      	cmp	r6, #76	; 0x4c
     bee:	d197      	bne.n	b20 <z_vprintk+0xe4>
					x = va_arg(ap, unsigned long long);
     bf0:	1de3      	adds	r3, r4, #7
     bf2:	f023 0307 	bic.w	r3, r3, #7
     bf6:	461c      	mov	r4, r3
     bf8:	685b      	ldr	r3, [r3, #4]
     bfa:	f854 2b08 	ldr.w	r2, [r4], #8
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
     bfe:	1ef9      	subs	r1, r7, #3
     c00:	bf18      	it	ne
     c02:	2101      	movne	r1, #1
     c04:	2f01      	cmp	r7, #1
     c06:	bf0c      	ite	eq
     c08:	2030      	moveq	r0, #48	; 0x30
     c0a:	2020      	movne	r0, #32
     c0c:	9101      	str	r1, [sp, #4]
     c0e:	e9cd 0802 	strd	r0, r8, [sp, #8]
     c12:	2110      	movs	r1, #16
     c14:	e7d8      	b.n	bc8 <z_vprintk+0x18c>
				char *s = va_arg(ap, char *);
     c16:	46a2      	mov	sl, r4
     c18:	f85a 3b04 	ldr.w	r3, [sl], #4
				while (*s) {
     c1c:	461c      	mov	r4, r3
     c1e:	4621      	mov	r1, r4
     c20:	f814 0b01 	ldrb.w	r0, [r4], #1
     c24:	b940      	cbnz	r0, c38 <z_vprintk+0x1fc>
				if (padding == PAD_SPACE_AFTER) {
     c26:	2f03      	cmp	r7, #3
     c28:	d122      	bne.n	c70 <z_vprintk+0x234>
					int remaining = min_width - (s - start);
     c2a:	1acc      	subs	r4, r1, r3
     c2c:	eba8 0404 	sub.w	r4, r8, r4
					while (remaining-- > 0) {
     c30:	2c00      	cmp	r4, #0
     c32:	dc06      	bgt.n	c42 <z_vprintk+0x206>
				char *s = va_arg(ap, char *);
     c34:	4654      	mov	r4, sl
     c36:	e70d      	b.n	a54 <z_vprintk+0x18>
					out((int)(*s++), ctx);
     c38:	4659      	mov	r1, fp
     c3a:	9304      	str	r3, [sp, #16]
     c3c:	47a8      	blx	r5
     c3e:	9b04      	ldr	r3, [sp, #16]
     c40:	e7ed      	b.n	c1e <z_vprintk+0x1e2>
						out(' ', ctx);
     c42:	4659      	mov	r1, fp
     c44:	2020      	movs	r0, #32
     c46:	47a8      	blx	r5
     c48:	3c01      	subs	r4, #1
     c4a:	e7f1      	b.n	c30 <z_vprintk+0x1f4>
				out(c, ctx);
     c4c:	f854 0b04 	ldr.w	r0, [r4], #4
     c50:	4659      	mov	r1, fp
     c52:	e723      	b.n	a9c <z_vprintk+0x60>
				out((int)'%', ctx);
     c54:	4659      	mov	r1, fp
     c56:	e721      	b.n	a9c <z_vprintk+0x60>
				length_mod = 0;
     c58:	461e      	mov	r6, r3
				padding = PAD_NONE;
     c5a:	461f      	mov	r7, r3
				min_width = -1;
     c5c:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
				might_format = 1;
     c60:	2301      	movs	r3, #1
     c62:	e701      	b.n	a68 <z_vprintk+0x2c>
			switch (*fmt) {
     c64:	2703      	movs	r7, #3
     c66:	e6ff      	b.n	a68 <z_vprintk+0x2c>
					padding = PAD_ZERO_BEFORE;
     c68:	2701      	movs	r7, #1
     c6a:	e6fd      	b.n	a68 <z_vprintk+0x2c>
					length_mod = 'L';
     c6c:	264c      	movs	r6, #76	; 0x4c
     c6e:	e6fb      	b.n	a68 <z_vprintk+0x2c>
				char *s = va_arg(ap, char *);
     c70:	4654      	mov	r4, sl
			might_format = 0;
     c72:	4603      	mov	r3, r0
     c74:	e6f8      	b.n	a68 <z_vprintk+0x2c>
     c76:	bf00      	nop

00000c78 <z_impl_k_str_out>:
#endif
}
#endif /* CONFIG_USERSPACE */

void z_impl_k_str_out(char *c, size_t n)
{
     c78:	b570      	push	{r4, r5, r6, lr}
#ifdef CONFIG_PRINTK_SYNC
	k_spinlock_key_t key = k_spin_lock(&lock);
#endif

	for (i = 0; i < n; i++) {
		_char_out(c[i]);
     c7a:	4e05      	ldr	r6, [pc, #20]	; (c90 <z_impl_k_str_out+0x18>)
     c7c:	4604      	mov	r4, r0
     c7e:	1845      	adds	r5, r0, r1
	for (i = 0; i < n; i++) {
     c80:	42ac      	cmp	r4, r5
     c82:	d100      	bne.n	c86 <z_impl_k_str_out+0xe>
	}

#ifdef CONFIG_PRINTK_SYNC
	k_spin_unlock(&lock, key);
#endif
}
     c84:	bd70      	pop	{r4, r5, r6, pc}
		_char_out(c[i]);
     c86:	6833      	ldr	r3, [r6, #0]
     c88:	f814 0b01 	ldrb.w	r0, [r4], #1
     c8c:	4798      	blx	r3
	for (i = 0; i < n; i++) {
     c8e:	e7f7      	b.n	c80 <z_impl_k_str_out+0x8>
     c90:	20002e00 	.word	0x20002e00

00000c94 <vprintk>:
{
     c94:	b530      	push	{r4, r5, lr}
     c96:	b08b      	sub	sp, #44	; 0x2c
     c98:	4604      	mov	r4, r0
     c9a:	460d      	mov	r5, r1
 * @return true if the CPU is currently running with user permissions
 */
static inline bool _is_user_context(void)
{
#ifdef CONFIG_USERSPACE
	return arch_is_user_context();
     c9c:	f004 fdc5 	bl	582a <arch_is_user_context>
	if (_is_user_context()) {
     ca0:	b188      	cbz	r0, cc6 <vprintk+0x32>
		struct buf_out_context ctx = { 0 };
     ca2:	2228      	movs	r2, #40	; 0x28
     ca4:	2100      	movs	r1, #0
     ca6:	4668      	mov	r0, sp
     ca8:	f005 facb 	bl	6242 <memset>
		z_vprintk(buf_char_out, &ctx, fmt, ap);
     cac:	462b      	mov	r3, r5
     cae:	480a      	ldr	r0, [pc, #40]	; (cd8 <vprintk+0x44>)
     cb0:	4622      	mov	r2, r4
     cb2:	4669      	mov	r1, sp
     cb4:	f7ff fec2 	bl	a3c <z_vprintk>
		if (ctx.buf_count) {
     cb8:	9b01      	ldr	r3, [sp, #4]
     cba:	b113      	cbz	r3, cc2 <vprintk+0x2e>
			buf_flush(&ctx);
     cbc:	4668      	mov	r0, sp
     cbe:	f004 fdc0 	bl	5842 <buf_flush>
}
     cc2:	b00b      	add	sp, #44	; 0x2c
     cc4:	bd30      	pop	{r4, r5, pc}
		struct out_context ctx = { 0 };
     cc6:	9000      	str	r0, [sp, #0]
		z_vprintk(char_out, &ctx, fmt, ap);
     cc8:	460b      	mov	r3, r1
     cca:	4804      	ldr	r0, [pc, #16]	; (cdc <vprintk+0x48>)
     ccc:	4622      	mov	r2, r4
     cce:	4669      	mov	r1, sp
     cd0:	f7ff feb4 	bl	a3c <z_vprintk>
}
     cd4:	e7f5      	b.n	cc2 <vprintk+0x2e>
     cd6:	bf00      	nop
     cd8:	0000586b 	.word	0x0000586b
     cdc:	00000a21 	.word	0x00000a21

00000ce0 <z_mrsh_k_str_out>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_str_out(char * c, size_t n);
uintptr_t z_mrsh_k_str_out(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     ce0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
     ce2:	4d0e      	ldr	r5, [pc, #56]	; (d1c <z_mrsh_k_str_out+0x3c>)
     ce4:	9a08      	ldr	r2, [sp, #32]
     ce6:	68ab      	ldr	r3, [r5, #8]
     ce8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_str_out(char *c, size_t n)
{
	Z_OOPS(Z_SYSCALL_MEMORY_READ(c, n));
     cec:	2200      	movs	r2, #0
{
     cee:	4606      	mov	r6, r0
     cf0:	460f      	mov	r7, r1
     cf2:	f005 fa59 	bl	61a8 <arch_buffer_validate>
     cf6:	4604      	mov	r4, r0
     cf8:	b130      	cbz	r0, d08 <z_mrsh_k_str_out+0x28>
     cfa:	f004 fd96 	bl	582a <arch_is_user_context>
     cfe:	68ab      	ldr	r3, [r5, #8]
     d00:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
     d04:	f005 fa22 	bl	614c <arch_syscall_oops>
	z_impl_k_str_out((char *)c, n);
     d08:	4630      	mov	r0, r6
     d0a:	4639      	mov	r1, r7
     d0c:	f7ff ffb4 	bl	c78 <z_impl_k_str_out>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_str_out(*(char **)&arg0, *(size_t*)&arg1)
;
	_current->syscall_frame = NULL;
     d10:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
     d12:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
     d14:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
     d18:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
     d1a:	bf00      	nop
     d1c:	20000664 	.word	0x20000664

00000d20 <process_event>:
 * regions.
 */
static void process_event(struct onoff_manager *mgr,
			  int evt,
			  k_spinlock_key_t key)
{
     d20:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	sys_slist_t clients;
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     d24:	f8b0 9018 	ldrh.w	r9, [r0, #24]
	__ASSERT_NO_MSG(evt != EVT_NOP);

	/* If this is a nested call record the event for processing in
	 * the top invocation.
	 */
	if (processing) {
     d28:	f019 0808 	ands.w	r8, r9, #8
{
     d2c:	4604      	mov	r4, r0
	if (processing) {
     d2e:	d00d      	beq.n	d4c <process_event+0x2c>
		if (evt == EVT_COMPLETE) {
     d30:	2901      	cmp	r1, #1
			mgr->flags |= ONOFF_FLAG_COMPLETE;
     d32:	bf0c      	ite	eq
     d34:	f049 0910 	orreq.w	r9, r9, #16
		} else {
			__ASSERT_NO_MSG(evt == EVT_RECHECK);

			mgr->flags |= ONOFF_FLAG_RECHECK;
     d38:	f049 0920 	orrne.w	r9, r9, #32
     d3c:	f8a0 9018 	strh.w	r9, [r0, #24]
	__asm__ volatile(
		"cpsie i;"
		"isb"
		: : : "memory");
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__asm__ volatile(
     d40:	f382 8811 	msr	BASEPRI, r2
     d44:	f3bf 8f6f 	isb	sy
		state = mgr->flags & ONOFF_STATE_MASK;
	} while (evt != EVT_NOP);

out:
	k_spin_unlock(&mgr->lock, key);
}
     d48:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     d4c:	f009 0907 	and.w	r9, r9, #7
		if (evt == EVT_RECHECK) {
     d50:	2902      	cmp	r1, #2
     d52:	d107      	bne.n	d64 <process_event+0x44>
			evt = process_recheck(mgr);
     d54:	4620      	mov	r0, r4
     d56:	f004 fda6 	bl	58a6 <process_recheck>
		if (evt == EVT_NOP) {
     d5a:	2800      	cmp	r0, #0
     d5c:	d0f0      	beq.n	d40 <process_event+0x20>
		if (evt == EVT_COMPLETE) {
     d5e:	2801      	cmp	r0, #1
     d60:	8b23      	ldrh	r3, [r4, #24]
     d62:	d150      	bne.n	e06 <process_event+0xe6>
			res = mgr->last_res;
     d64:	6967      	ldr	r7, [r4, #20]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     d66:	8b21      	ldrh	r1, [r4, #24]
	if (res < 0) {
     d68:	2f00      	cmp	r7, #0
     d6a:	da15      	bge.n	d98 <process_event+0x78>
		*clients = mgr->clients;
     d6c:	6825      	ldr	r5, [r4, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     d6e:	f021 0107 	bic.w	r1, r1, #7
 * @param list A pointer on the list to initialize
 */
static inline void sys_slist_init(sys_slist_t *list)
{
	list->head = NULL;
	list->tail = NULL;
     d72:	e9c4 8800 	strd	r8, r8, [r4]
     d76:	f041 0101 	orr.w	r1, r1, #1
	mgr->flags = (state & ONOFF_STATE_MASK)
     d7a:	8321      	strh	r1, [r4, #24]
		onoff_transition_fn transit = NULL;
     d7c:	2600      	movs	r6, #0
		bool do_monitors = (state != (mgr->flags & ONOFF_STATE_MASK))
     d7e:	8b21      	ldrh	r1, [r4, #24]
     d80:	f001 0a07 	and.w	sl, r1, #7
				   && !sys_slist_is_empty(&mgr->monitors);
     d84:	45ca      	cmp	sl, r9
     d86:	d002      	beq.n	d8e <process_event+0x6e>
		if (do_monitors
     d88:	68a3      	ldr	r3, [r4, #8]
     d8a:	2b00      	cmp	r3, #0
     d8c:	d15c      	bne.n	e48 <process_event+0x128>
		    || !sys_slist_is_empty(&clients)
     d8e:	b90d      	cbnz	r5, d94 <process_event+0x74>
		    || (transit != NULL)) {
     d90:	2e00      	cmp	r6, #0
     d92:	d074      	beq.n	e7e <process_event+0x15e>
     d94:	2300      	movs	r3, #0
     d96:	e058      	b.n	e4a <process_event+0x12a>
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     d98:	f001 0307 	and.w	r3, r1, #7
		   || (state == ONOFF_STATE_RESETTING)) {
     d9c:	1f58      	subs	r0, r3, #5
	} else if ((state == ONOFF_STATE_TO_ON)
     d9e:	2801      	cmp	r0, #1
     da0:	d820      	bhi.n	de4 <process_event+0xc4>
		*clients = mgr->clients;
     da2:	f021 0107 	bic.w	r1, r1, #7
		if (state == ONOFF_STATE_TO_ON) {
     da6:	2b06      	cmp	r3, #6
		*clients = mgr->clients;
     da8:	6825      	ldr	r5, [r4, #0]
	list->head = NULL;
     daa:	b289      	uxth	r1, r1
	list->tail = NULL;
     dac:	e9c4 8800 	strd	r8, r8, [r4]
		if (state == ONOFF_STATE_TO_ON) {
     db0:	d10c      	bne.n	dcc <process_event+0xac>
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
     db2:	2d00      	cmp	r5, #0
     db4:	462b      	mov	r3, r5
     db6:	bf38      	it	cc
     db8:	2300      	movcc	r3, #0
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
     dba:	b12b      	cbz	r3, dc8 <process_event+0xa8>
				mgr->refs += 1U;
     dbc:	8b60      	ldrh	r0, [r4, #26]
 *
 * @return a pointer on the next node (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_next_no_check(sys_snode_t *node);

Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
     dbe:	681b      	ldr	r3, [r3, #0]
     dc0:	3001      	adds	r0, #1
     dc2:	8360      	strh	r0, [r4, #26]
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
     dc4:	2b00      	cmp	r3, #0
     dc6:	d1f8      	bne.n	dba <process_event+0x9a>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     dc8:	f041 0102 	orr.w	r1, r1, #2
	mgr->flags = (state & ONOFF_STATE_MASK)
     dcc:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
     dce:	4620      	mov	r0, r4
     dd0:	f004 fd69 	bl	58a6 <process_recheck>
     dd4:	4606      	mov	r6, r0
     dd6:	2800      	cmp	r0, #0
     dd8:	d0d1      	beq.n	d7e <process_event+0x5e>
			mgr->flags |= ONOFF_FLAG_RECHECK;
     dda:	8b23      	ldrh	r3, [r4, #24]
     ddc:	f043 0320 	orr.w	r3, r3, #32
     de0:	8323      	strh	r3, [r4, #24]
     de2:	e7cb      	b.n	d7c <process_event+0x5c>
	} else if (state == ONOFF_STATE_TO_OFF) {
     de4:	2b04      	cmp	r3, #4
     de6:	d10c      	bne.n	e02 <process_event+0xe2>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     de8:	f021 0107 	bic.w	r1, r1, #7
     dec:	b289      	uxth	r1, r1
	mgr->flags = (state & ONOFF_STATE_MASK)
     dee:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
     df0:	4620      	mov	r0, r4
     df2:	f004 fd58 	bl	58a6 <process_recheck>
     df6:	4605      	mov	r5, r0
     df8:	2800      	cmp	r0, #0
     dfa:	d0bf      	beq.n	d7c <process_event+0x5c>
			mgr->flags |= ONOFF_FLAG_RECHECK;
     dfc:	f041 0120 	orr.w	r1, r1, #32
     e00:	8321      	strh	r1, [r4, #24]
     e02:	2500      	movs	r5, #0
     e04:	e7ba      	b.n	d7c <process_event+0x5c>
		} else if (evt == EVT_START) {
     e06:	2803      	cmp	r0, #3
     e08:	d109      	bne.n	e1e <process_event+0xfe>
			transit = mgr->transitions->start;
     e0a:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     e0c:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->start;
     e10:	680e      	ldr	r6, [r1, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     e12:	f043 0306 	orr.w	r3, r3, #6
	mgr->flags = (state & ONOFF_STATE_MASK)
     e16:	8323      	strh	r3, [r4, #24]
}
     e18:	2500      	movs	r5, #0
		res = 0;
     e1a:	462f      	mov	r7, r5
     e1c:	e7af      	b.n	d7e <process_event+0x5e>
		} else if (evt == EVT_STOP) {
     e1e:	2804      	cmp	r0, #4
     e20:	d106      	bne.n	e30 <process_event+0x110>
			transit = mgr->transitions->stop;
     e22:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     e24:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->stop;
     e28:	684e      	ldr	r6, [r1, #4]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     e2a:	f043 0304 	orr.w	r3, r3, #4
     e2e:	e7f2      	b.n	e16 <process_event+0xf6>
		} else if (evt == EVT_RESET) {
     e30:	2805      	cmp	r0, #5
     e32:	d106      	bne.n	e42 <process_event+0x122>
			transit = mgr->transitions->reset;
     e34:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     e36:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->reset;
     e3a:	688e      	ldr	r6, [r1, #8]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     e3c:	f043 0305 	orr.w	r3, r3, #5
     e40:	e7e9      	b.n	e16 <process_event+0xf6>
     e42:	2500      	movs	r5, #0
		onoff_transition_fn transit = NULL;
     e44:	462e      	mov	r6, r5
     e46:	e7e8      	b.n	e1a <process_event+0xfa>
				   && !sys_slist_is_empty(&mgr->monitors);
     e48:	2301      	movs	r3, #1
			uint32_t flags = mgr->flags | ONOFF_FLAG_PROCESSING;
     e4a:	f041 0108 	orr.w	r1, r1, #8
			mgr->flags = flags;
     e4e:	8321      	strh	r1, [r4, #24]
     e50:	f382 8811 	msr	BASEPRI, r2
     e54:	f3bf 8f6f 	isb	sy
			if (do_monitors) {
     e58:	bb03      	cbnz	r3, e9c <process_event+0x17c>
			if (!sys_slist_is_empty(&clients)) {
     e5a:	2d00      	cmp	r5, #0
     e5c:	d140      	bne.n	ee0 <process_event+0x1c0>
			if (transit != NULL) {
     e5e:	b116      	cbz	r6, e66 <process_event+0x146>
				transit(mgr, transition_complete);
     e60:	4925      	ldr	r1, [pc, #148]	; (ef8 <process_event+0x1d8>)
     e62:	4620      	mov	r0, r4
     e64:	47b0      	blx	r6
	__asm__ volatile(
     e66:	f04f 0320 	mov.w	r3, #32
     e6a:	f3ef 8211 	mrs	r2, BASEPRI
     e6e:	f383 8811 	msr	BASEPRI, r3
     e72:	f3bf 8f6f 	isb	sy
			mgr->flags &= ~ONOFF_FLAG_PROCESSING;
     e76:	8b23      	ldrh	r3, [r4, #24]
     e78:	f023 0308 	bic.w	r3, r3, #8
     e7c:	8323      	strh	r3, [r4, #24]
		if ((mgr->flags & ONOFF_FLAG_COMPLETE) != 0) {
     e7e:	8b23      	ldrh	r3, [r4, #24]
     e80:	06d9      	lsls	r1, r3, #27
     e82:	d531      	bpl.n	ee8 <process_event+0x1c8>
			mgr->flags &= ~ONOFF_FLAG_COMPLETE;
     e84:	f023 0310 	bic.w	r3, r3, #16
     e88:	8323      	strh	r3, [r4, #24]
			evt = EVT_COMPLETE;
     e8a:	2101      	movs	r1, #1
		state = mgr->flags & ONOFF_STATE_MASK;
     e8c:	f8b4 9018 	ldrh.w	r9, [r4, #24]
     e90:	f009 0907 	and.w	r9, r9, #7
	} while (evt != EVT_NOP);
     e94:	2900      	cmp	r1, #0
     e96:	f47f af5b 	bne.w	d50 <process_event+0x30>
out:
     e9a:	e751      	b.n	d40 <process_event+0x20>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
     e9c:	68a1      	ldr	r1, [r4, #8]
     e9e:	2900      	cmp	r1, #0
     ea0:	d0db      	beq.n	e5a <process_event+0x13a>
	return node->next;
     ea2:	680b      	ldr	r3, [r1, #0]
		mon->callback(mgr, mon, state, res);
     ea4:	f8d1 b004 	ldr.w	fp, [r1, #4]
     ea8:	2b00      	cmp	r3, #0
     eaa:	bf38      	it	cc
     eac:	2300      	movcc	r3, #0
     eae:	4699      	mov	r9, r3
     eb0:	4652      	mov	r2, sl
     eb2:	463b      	mov	r3, r7
     eb4:	4620      	mov	r0, r4
     eb6:	47d8      	blx	fp
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
     eb8:	f1b9 0f00 	cmp.w	r9, #0
     ebc:	d0cd      	beq.n	e5a <process_event+0x13a>
     ebe:	f8d9 3000 	ldr.w	r3, [r9]
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
     ec2:	4649      	mov	r1, r9
     ec4:	e7ee      	b.n	ea4 <process_event+0x184>
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
     ec6:	4639      	mov	r1, r7
     ec8:	f10b 0004 	add.w	r0, fp, #4
 *
 * @return A pointer to the first node of the list
 */
static inline sys_snode_t *sys_slist_get_not_empty(sys_slist_t *list);

Z_GENLIST_GET_NOT_EMPTY(slist, snode)
     ecc:	682d      	ldr	r5, [r5, #0]
     ece:	f004 fc9f 	bl	5810 <sys_notify_finalize>
	if (cb) {
     ed2:	4681      	mov	r9, r0
     ed4:	b120      	cbz	r0, ee0 <process_event+0x1c0>
		cb(mgr, cli, state, res);
     ed6:	463b      	mov	r3, r7
     ed8:	4652      	mov	r2, sl
     eda:	4659      	mov	r1, fp
     edc:	4620      	mov	r0, r4
     ede:	47c8      	blx	r9
     ee0:	46ab      	mov	fp, r5
	while (!sys_slist_is_empty(list)) {
     ee2:	2d00      	cmp	r5, #0
     ee4:	d1ef      	bne.n	ec6 <process_event+0x1a6>
     ee6:	e7ba      	b.n	e5e <process_event+0x13e>
		} else if ((mgr->flags & ONOFF_FLAG_RECHECK) != 0) {
     ee8:	f013 0120 	ands.w	r1, r3, #32
			mgr->flags &= ~ONOFF_FLAG_RECHECK;
     eec:	bf1e      	ittt	ne
     eee:	f023 0320 	bicne.w	r3, r3, #32
     ef2:	8323      	strhne	r3, [r4, #24]
			evt = EVT_RECHECK;
     ef4:	2102      	movne	r1, #2
     ef6:	e7c9      	b.n	e8c <process_event+0x16c>
     ef8:	000058fd 	.word	0x000058fd

00000efc <z_mrsh_z_sys_mutex_kernel_lock>:
#include <syscalls/mutex.h>

extern int z_vrfy_z_sys_mutex_kernel_lock(struct sys_mutex * mutex, k_timeout_t timeout);
uintptr_t z_mrsh_z_sys_mutex_kernel_lock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     efc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
     efe:	4c0e      	ldr	r4, [pc, #56]	; (f38 <z_mrsh_z_sys_mutex_kernel_lock+0x3c>)
     f00:	68a3      	ldr	r3, [r4, #8]
{
     f02:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
     f04:	9a08      	ldr	r2, [sp, #32]
     f06:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
     f0a:	460f      	mov	r7, r1
{
	/* sys_mutex memory is never touched, just used to lookup the
	 * underlying k_mutex, but we don't want threads using mutexes
	 * that are outside their memory domain
	 */
	return Z_SYSCALL_MEMORY_WRITE(addr, sizeof(struct sys_mutex));
     f0c:	2201      	movs	r2, #1
     f0e:	2104      	movs	r1, #4
     f10:	4605      	mov	r5, r0
     f12:	f005 f949 	bl	61a8 <arch_buffer_validate>
     f16:	b140      	cbz	r0, f2a <z_mrsh_z_sys_mutex_kernel_lock+0x2e>
     f18:	f004 ffec 	bl	5ef4 <arch_is_user_context>

static inline int z_vrfy_z_sys_mutex_kernel_lock(struct sys_mutex *mutex,
						 k_timeout_t timeout)
{
	if (check_sys_mutex_addr(mutex)) {
		return -EACCES;
     f1c:	f06f 000c 	mvn.w	r0, #12
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_z_sys_mutex_kernel_lock(*(struct sys_mutex **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
     f20:	68a3      	ldr	r3, [r4, #8]
     f22:	2200      	movs	r2, #0
     f24:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
     f28:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	}

	return z_impl_z_sys_mutex_kernel_lock(mutex, timeout);
     f2a:	463a      	mov	r2, r7
     f2c:	4633      	mov	r3, r6
     f2e:	4628      	mov	r0, r5
     f30:	f004 ffea 	bl	5f08 <z_impl_z_sys_mutex_kernel_lock>
     f34:	e7f4      	b.n	f20 <z_mrsh_z_sys_mutex_kernel_lock+0x24>
     f36:	bf00      	nop
     f38:	20000664 	.word	0x20000664

00000f3c <z_impl_z_sys_mutex_kernel_unlock>:
}
#include <syscalls/z_sys_mutex_kernel_lock_mrsh.c>

int z_impl_z_sys_mutex_kernel_unlock(struct sys_mutex *mutex)
{
     f3c:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	obj = z_object_find(mutex);
     f40:	f7ff f8cc 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_SYS_MUTEX) {
     f44:	b1c0      	cbz	r0, f78 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
     f46:	7983      	ldrb	r3, [r0, #6]
     f48:	2b0e      	cmp	r3, #14
     f4a:	d115      	bne.n	f78 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
	return obj->data.mutex;
     f4c:	6882      	ldr	r2, [r0, #8]
	struct k_mutex *kernel_mutex = get_k_mutex(mutex);

	if (kernel_mutex == NULL || kernel_mutex->lock_count == 0) {
     f4e:	b19a      	cbz	r2, f78 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
     f50:	68d3      	ldr	r3, [r2, #12]
     f52:	b18b      	cbz	r3, f78 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
		return -EINVAL;
	}

	if (kernel_mutex->owner != _current) {
     f54:	4b0b      	ldr	r3, [pc, #44]	; (f84 <z_impl_z_sys_mutex_kernel_unlock+0x48>)
     f56:	6891      	ldr	r1, [r2, #8]
     f58:	689b      	ldr	r3, [r3, #8]
     f5a:	4299      	cmp	r1, r3
     f5c:	d10f      	bne.n	f7e <z_impl_z_sys_mutex_kernel_unlock+0x42>
	ret = arch_is_user_context();
     f5e:	f004 ffc9 	bl	5ef4 <arch_is_user_context>
	if (z_syscall_trap()) {
     f62:	b128      	cbz	r0, f70 <z_impl_z_sys_mutex_kernel_unlock+0x34>
	register uint32_t ret __asm__("r0") = arg1;
     f64:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
     f66:	266d      	movs	r6, #109	; 0x6d
	__asm__ volatile("svc %[svid]\n"
     f68:	df03      	svc	3
		return -EPERM;
	}

	k_mutex_unlock(kernel_mutex);
	return 0;
     f6a:	2000      	movs	r0, #0
}
     f6c:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return z_impl_k_mutex_unlock(mutex);
     f70:	4610      	mov	r0, r2
     f72:	f002 fc37 	bl	37e4 <z_impl_k_mutex_unlock>
     f76:	e7f8      	b.n	f6a <z_impl_z_sys_mutex_kernel_unlock+0x2e>
		return -EINVAL;
     f78:	f06f 0015 	mvn.w	r0, #21
     f7c:	e7f6      	b.n	f6c <z_impl_z_sys_mutex_kernel_unlock+0x30>
		return -EPERM;
     f7e:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
     f82:	e7f3      	b.n	f6c <z_impl_z_sys_mutex_kernel_unlock+0x30>
     f84:	20000664 	.word	0x20000664

00000f88 <z_mrsh_z_sys_mutex_kernel_unlock>:
#include <syscalls/mutex.h>

extern int z_vrfy_z_sys_mutex_kernel_unlock(struct sys_mutex * mutex);
uintptr_t z_mrsh_z_sys_mutex_kernel_unlock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     f88:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
     f8a:	4c0c      	ldr	r4, [pc, #48]	; (fbc <z_mrsh_z_sys_mutex_kernel_unlock+0x34>)
     f8c:	9a06      	ldr	r2, [sp, #24]
     f8e:	68a3      	ldr	r3, [r4, #8]
	return Z_SYSCALL_MEMORY_WRITE(addr, sizeof(struct sys_mutex));
     f90:	2104      	movs	r1, #4
     f92:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
     f96:	2201      	movs	r2, #1
{
     f98:	4605      	mov	r5, r0
     f9a:	f005 f905 	bl	61a8 <arch_buffer_validate>
     f9e:	b140      	cbz	r0, fb2 <z_mrsh_z_sys_mutex_kernel_unlock+0x2a>
	return arch_is_user_context();
     fa0:	f004 ffa8 	bl	5ef4 <arch_is_user_context>

static inline int z_vrfy_z_sys_mutex_kernel_unlock(struct sys_mutex *mutex)
{
	if (check_sys_mutex_addr(mutex)) {
		return -EACCES;
     fa4:	f06f 000c 	mvn.w	r0, #12
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_z_sys_mutex_kernel_unlock(*(struct sys_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
     fa8:	68a3      	ldr	r3, [r4, #8]
     faa:	2200      	movs	r2, #0
     fac:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
     fb0:	bd38      	pop	{r3, r4, r5, pc}
	}

	return z_impl_z_sys_mutex_kernel_unlock(mutex);
     fb2:	4628      	mov	r0, r5
     fb4:	f7ff ffc2 	bl	f3c <z_impl_z_sys_mutex_kernel_unlock>
     fb8:	e7f6      	b.n	fa8 <z_mrsh_z_sys_mutex_kernel_unlock+0x20>
     fba:	bf00      	nop
     fbc:	20000664 	.word	0x20000664

00000fc0 <console_out>:
		return c;
	}

#endif  /* CONFIG_UART_CONSOLE_DEBUG_SERVER_HOOKS */

	if ('\n' == c) {
     fc0:	280a      	cmp	r0, #10
{
     fc2:	b538      	push	{r3, r4, r5, lr}
     fc4:	4d06      	ldr	r5, [pc, #24]	; (fe0 <console_out+0x20>)
     fc6:	4604      	mov	r4, r0
	if ('\n' == c) {
     fc8:	d103      	bne.n	fd2 <console_out+0x12>
		uart_poll_out(uart_console_dev, '\r');
     fca:	6828      	ldr	r0, [r5, #0]
     fcc:	210d      	movs	r1, #13
     fce:	f004 ffbc 	bl	5f4a <uart_poll_out>
	}
	uart_poll_out(uart_console_dev, c);
     fd2:	6828      	ldr	r0, [r5, #0]
     fd4:	b2e1      	uxtb	r1, r4
     fd6:	f004 ffb8 	bl	5f4a <uart_poll_out>

	return c;
}
     fda:	4620      	mov	r0, r4
     fdc:	bd38      	pop	{r3, r4, r5, pc}
     fde:	bf00      	nop
     fe0:	20000528 	.word	0x20000528

00000fe4 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(struct device *arg)
{
     fe4:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
static inline bool arch_is_user_context(void)
{
	uint32_t value;

	/* check for handler mode */
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
     fe8:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
     fec:	b98b      	cbnz	r3, 1012 <uart_console_init+0x2e>
		return false;
	}

	/* if not handler mode, return mode information */
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
     fee:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
     ff2:	07db      	lsls	r3, r3, #31
     ff4:	d50d      	bpl.n	1012 <uart_console_init+0x2e>
	register uint32_t ret __asm__("r0") = arg1;
     ff6:	4809      	ldr	r0, [pc, #36]	; (101c <uart_console_init+0x38>)
	register uint32_t r6 __asm__("r6") = call_id;
     ff8:	2627      	movs	r6, #39	; 0x27
	__asm__ volatile("svc %[svid]\n"
     ffa:	df03      	svc	3

	ARG_UNUSED(arg);

	uart_console_dev = device_get_binding(CONFIG_UART_CONSOLE_ON_DEV_NAME);
     ffc:	4b08      	ldr	r3, [pc, #32]	; (1020 <uart_console_init+0x3c>)
     ffe:	6018      	str	r0, [r3, #0]
	__stdout_hook_install(console_out);
    1000:	4808      	ldr	r0, [pc, #32]	; (1024 <uart_console_init+0x40>)
    1002:	f001 f855 	bl	20b0 <__stdout_hook_install>
	__printk_hook_install(console_out);
    1006:	4807      	ldr	r0, [pc, #28]	; (1024 <uart_console_init+0x40>)
    1008:	f7ff fd12 	bl	a30 <__printk_hook_install>
#endif

	uart_console_hook_install();

	return 0;
}
    100c:	2000      	movs	r0, #0
    100e:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	return z_impl_device_get_binding(name);
    1012:	4802      	ldr	r0, [pc, #8]	; (101c <uart_console_init+0x38>)
    1014:	f001 fff6 	bl	3004 <z_impl_device_get_binding>
    1018:	e7f0      	b.n	ffc <uart_console_init+0x18>
    101a:	bf00      	nop
    101c:	000077d5 	.word	0x000077d5
    1020:	20000528 	.word	0x20000528
    1024:	00000fc1 	.word	0x00000fc1

00001028 <onoff_stop>:
	return (clock_control_subsys_t)offset;
}

static void onoff_stop(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
    1028:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	struct nrf_clock_control_data *data =
    102c:	4f0e      	ldr	r7, [pc, #56]	; (1068 <onoff_stop+0x40>)
    102e:	68fa      	ldr	r2, [r7, #12]
	size_t offset = (size_t)(mgr - data->mgr);
    1030:	1a84      	subs	r4, r0, r2
    1032:	10a3      	asrs	r3, r4, #2
    1034:	4c0d      	ldr	r4, [pc, #52]	; (106c <onoff_stop+0x44>)
    1036:	435c      	muls	r4, r3
{
    1038:	4605      	mov	r5, r0
    103a:	b2e4      	uxtb	r4, r4
	err = set_off_state(&subdata->flags, ctx);
    103c:	200c      	movs	r0, #12
    103e:	fb00 2004 	mla	r0, r0, r4, r2
{
    1042:	460e      	mov	r6, r1
	err = set_off_state(&subdata->flags, ctx);
    1044:	2140      	movs	r1, #64	; 0x40
    1046:	4408      	add	r0, r1
    1048:	f004 ffac 	bl	5fa4 <set_off_state>
	if (err < 0) {
    104c:	1e01      	subs	r1, r0, #0
    104e:	db05      	blt.n	105c <onoff_stop+0x34>
	get_sub_config(dev, type)->stop();
    1050:	687b      	ldr	r3, [r7, #4]
    1052:	eb03 04c4 	add.w	r4, r3, r4, lsl #3
    1056:	6863      	ldr	r3, [r4, #4]
    1058:	4798      	blx	r3
	return 0;
    105a:	2100      	movs	r1, #0
	int res;

	res = stop(DEVICE_GET(clock_nrf), get_subsys(mgr), CTX_ONOFF);
	notify(mgr, res);
    105c:	4628      	mov	r0, r5
    105e:	4633      	mov	r3, r6
}
    1060:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	notify(mgr, res);
    1064:	4718      	bx	r3
    1066:	bf00      	nop
    1068:	20002e20 	.word	0x20002e20
    106c:	b6db6db7 	.word	0xb6db6db7

00001070 <onoff_start>:
	notify(mgr, 0);
}

static void onoff_start(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
    1070:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	struct nrf_clock_control_data *data =
    1074:	f8df 8050 	ldr.w	r8, [pc, #80]	; 10c8 <onoff_start+0x58>
    1078:	f8d8 600c 	ldr.w	r6, [r8, #12]
	size_t offset = (size_t)(mgr - data->mgr);
    107c:	1b84      	subs	r4, r0, r6
    107e:	10a3      	asrs	r3, r4, #2
    1080:	4c0f      	ldr	r4, [pc, #60]	; (10c0 <onoff_start+0x50>)
    1082:	435c      	muls	r4, r3
    1084:	b2e4      	uxtb	r4, r4
	err = set_starting_state(&subdata->flags, ctx);
    1086:	250c      	movs	r5, #12
    1088:	4365      	muls	r5, r4
{
    108a:	4681      	mov	r9, r0
	err = set_starting_state(&subdata->flags, ctx);
    108c:	f105 0040 	add.w	r0, r5, #64	; 0x40
{
    1090:	460f      	mov	r7, r1
	err = set_starting_state(&subdata->flags, ctx);
    1092:	4430      	add	r0, r6
    1094:	2140      	movs	r1, #64	; 0x40
    1096:	f004 ff9e 	bl	5fd6 <set_starting_state>
	if (err < 0) {
    109a:	1e01      	subs	r1, r0, #0
    109c:	db0a      	blt.n	10b4 <onoff_start+0x44>
	subdata->cb = data->cb;
    109e:	4a09      	ldr	r2, [pc, #36]	; (10c4 <onoff_start+0x54>)
    10a0:	1973      	adds	r3, r6, r5
	subdata->user_data = data->user_data;
    10a2:	e9c3 270e 	strd	r2, r7, [r3, #56]	; 0x38
	 get_sub_config(dev, type)->start();
    10a6:	f8d8 3004 	ldr.w	r3, [r8, #4]
    10aa:	f853 3034 	ldr.w	r3, [r3, r4, lsl #3]
	err = async_start(DEVICE_GET(clock_nrf), get_subsys(mgr),
			  &data, CTX_ONOFF);
	if (err < 0) {
		notify(mgr, err);
	}
}
    10ae:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	 get_sub_config(dev, type)->start();
    10b2:	4718      	bx	r3
		notify(mgr, err);
    10b4:	4648      	mov	r0, r9
    10b6:	463b      	mov	r3, r7
}
    10b8:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
		notify(mgr, err);
    10bc:	4718      	bx	r3
    10be:	bf00      	nop
    10c0:	b6db6db7 	.word	0xb6db6db7
    10c4:	00006039 	.word	0x00006039
    10c8:	20002e20 	.word	0x20002e20

000010cc <clk_init>:
	static const struct onoff_transitions transitions = {
		.start = onoff_start,
		.stop = onoff_stop
	};

	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
    10cc:	2200      	movs	r2, #0
{
    10ce:	b570      	push	{r4, r5, r6, lr}
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
    10d0:	2101      	movs	r1, #1
{
    10d2:	4604      	mov	r4, r0
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
    10d4:	4610      	mov	r0, r2
    10d6:	f000 fafb 	bl	16d0 <z_arm_irq_priority_set>
		    nrf_power_clock_isr, 0, 0);

	irq_enable(DT_INST_IRQN(0));
    10da:	2000      	movs	r0, #0
    10dc:	f000 fae8 	bl	16b0 <arch_irq_enable>
    return false;
}

NRF_STATIC_INLINE void nrf_clock_lf_src_set(NRF_CLOCK_Type * p_reg, nrf_clock_lfclk_t source)
{
    p_reg->LFCLKSRC = (uint32_t)(source);
    10e0:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
	clock_irqs_enable();

	for (enum clock_control_nrf_type i = 0;
		i < CLOCK_CONTROL_NRF_TYPE_COUNT; i++) {
		struct nrf_clock_control_sub_data *subdata =
						get_sub_data(dev, i);
    10e4:	68e6      	ldr	r6, [r4, #12]

		err = onoff_manager_init(get_onoff_manager(dev, i),
    10e6:	490c      	ldr	r1, [pc, #48]	; (1118 <clk_init+0x4c>)
    p_reg->INTENSET = mask;
    10e8:	2203      	movs	r2, #3
    p_reg->LFCLKSRC = (uint32_t)(source);
    10ea:	2501      	movs	r5, #1
    10ec:	f8c3 5518 	str.w	r5, [r3, #1304]	; 0x518
    10f0:	4630      	mov	r0, r6
    p_reg->INTENSET = mask;
    10f2:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
    10f6:	f004 fc0f 	bl	5918 <onoff_manager_init>
					 &transitions);
		if (err < 0) {
    10fa:	2800      	cmp	r0, #0
    10fc:	db0a      	blt.n	1114 <clk_init+0x48>
			return err;
		}

		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
    10fe:	6435      	str	r5, [r6, #64]	; 0x40
						get_sub_data(dev, i);
    1100:	68e4      	ldr	r4, [r4, #12]
		err = onoff_manager_init(get_onoff_manager(dev, i),
    1102:	4905      	ldr	r1, [pc, #20]	; (1118 <clk_init+0x4c>)
    1104:	f104 001c 	add.w	r0, r4, #28
    1108:	f004 fc06 	bl	5918 <onoff_manager_init>
		if (err < 0) {
    110c:	2800      	cmp	r0, #0
		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
    110e:	bfa4      	itt	ge
    1110:	64e5      	strge	r5, [r4, #76]	; 0x4c
	}

	return 0;
    1112:	2000      	movge	r0, #0
}
    1114:	bd70      	pop	{r4, r5, r6, pc}
    1116:	bf00      	nop
    1118:	0000724c 	.word	0x0000724c

0000111c <clkstarted_handle.constprop.0>:
static void clkstarted_handle(struct device *dev,
    111c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	struct nrf_clock_control_sub_data *sub_data = get_sub_data(dev, type);
    1120:	4e0b      	ldr	r6, [pc, #44]	; (1150 <clkstarted_handle.constprop.0+0x34>)
static void clkstarted_handle(struct device *dev,
    1122:	4601      	mov	r1, r0
	clock_control_cb_t callback = sub_data->cb;
    1124:	230c      	movs	r3, #12
	struct nrf_clock_control_sub_data *sub_data = get_sub_data(dev, type);
    1126:	68f0      	ldr	r0, [r6, #12]
	clock_control_cb_t callback = sub_data->cb;
    1128:	434b      	muls	r3, r1
    112a:	18c4      	adds	r4, r0, r3
	void *user_data = sub_data->user_data;
    112c:	e9d4 570e 	ldrd	r5, r7, [r4, #56]	; 0x38
	sub_data->cb = NULL;
    1130:	2200      	movs	r2, #0
	set_on_state(&sub_data->flags);
    1132:	3340      	adds	r3, #64	; 0x40
	sub_data->cb = NULL;
    1134:	63a2      	str	r2, [r4, #56]	; 0x38
	set_on_state(&sub_data->flags);
    1136:	4418      	add	r0, r3
    1138:	f004 ff6b 	bl	6012 <set_on_state>
	if (callback) {
    113c:	b12d      	cbz	r5, 114a <clkstarted_handle.constprop.0+0x2e>
		callback(dev, (clock_control_subsys_t)type, user_data);
    113e:	463a      	mov	r2, r7
    1140:	4630      	mov	r0, r6
    1142:	462b      	mov	r3, r5
}
    1144:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		callback(dev, (clock_control_subsys_t)type, user_data);
    1148:	4718      	bx	r3
}
    114a:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    114e:	bf00      	nop
    1150:	20002e20 	.word	0x20002e20

00001154 <generic_hfclk_start>:
{
    1154:	b508      	push	{r3, lr}
    1156:	f04f 0320 	mov.w	r3, #32
    115a:	f3ef 8111 	mrs	r1, BASEPRI
    115e:	f383 8811 	msr	BASEPRI, r3
    1162:	f3bf 8f6f 	isb	sy
	hfclk_users |= HF_USER_GENERIC;
    1166:	4a13      	ldr	r2, [pc, #76]	; (11b4 <generic_hfclk_start+0x60>)
    1168:	6813      	ldr	r3, [r2, #0]
    116a:	f043 0002 	orr.w	r0, r3, #2
	if (hfclk_users & HF_USER_BT) {
    116e:	f013 0301 	ands.w	r3, r3, #1
	hfclk_users |= HF_USER_GENERIC;
    1172:	6010      	str	r0, [r2, #0]
	if (hfclk_users & HF_USER_BT) {
    1174:	d00e      	beq.n	1194 <generic_hfclk_start+0x40>
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
    1176:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    117a:	f8d2 340c 	ldr.w	r3, [r2, #1036]	; 0x40c
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
    117e:	f8d2 240c 	ldr.w	r2, [r2, #1036]	; 0x40c
		if (type == NRF_CLOCK_HFCLK_HIGH_ACCURACY) {
    1182:	f013 0301 	ands.w	r3, r3, #1
    1186:	d005      	beq.n	1194 <generic_hfclk_start+0x40>
	struct nrf_clock_control_data *data =
    1188:	4b0b      	ldr	r3, [pc, #44]	; (11b8 <generic_hfclk_start+0x64>)
	return &data->subsys[CLOCK_CONTROL_NRF_TYPE_HFCLK].flags;
    118a:	68d8      	ldr	r0, [r3, #12]
			set_on_state(get_hf_flags());
    118c:	3040      	adds	r0, #64	; 0x40
    118e:	f004 ff40 	bl	6012 <set_on_state>
			already_started = true;
    1192:	2301      	movs	r3, #1
	__asm__ volatile(
    1194:	f381 8811 	msr	BASEPRI, r1
    1198:	f3bf 8f6f 	isb	sy
	if (already_started) {
    119c:	b123      	cbz	r3, 11a8 <generic_hfclk_start+0x54>
}
    119e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		clkstarted_handle(DEVICE_GET(clock_nrf),
    11a2:	2000      	movs	r0, #0
    11a4:	f7ff bfba 	b.w	111c <clkstarted_handle.constprop.0>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    11a8:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    11ac:	2201      	movs	r2, #1
    11ae:	601a      	str	r2, [r3, #0]
}
    11b0:	bd08      	pop	{r3, pc}
    11b2:	bf00      	nop
    11b4:	2000058c 	.word	0x2000058c
    11b8:	20002e20 	.word	0x20002e20

000011bc <lfclk_stop>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    11bc:	4b05      	ldr	r3, [pc, #20]	; (11d4 <lfclk_stop+0x18>)
    11be:	2200      	movs	r2, #0
    11c0:	601a      	str	r2, [r3, #0]
{
    11c2:	b082      	sub	sp, #8
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    11c4:	681b      	ldr	r3, [r3, #0]
    11c6:	9301      	str	r3, [sp, #4]
    (void)dummy;
    11c8:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    11ca:	4b03      	ldr	r3, [pc, #12]	; (11d8 <lfclk_stop+0x1c>)
    11cc:	2201      	movs	r2, #1
    11ce:	601a      	str	r2, [r3, #0]
}
    11d0:	b002      	add	sp, #8
    11d2:	4770      	bx	lr
    11d4:	40000104 	.word	0x40000104
    11d8:	4000000c 	.word	0x4000000c

000011dc <generic_hfclk_stop>:
 * @return Previous value of @a target.
 */
#ifdef CONFIG_ATOMIC_OPERATIONS_BUILTIN
static inline atomic_val_t atomic_and(atomic_t *target, atomic_val_t value)
{
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    11dc:	4a0d      	ldr	r2, [pc, #52]	; (1214 <generic_hfclk_stop+0x38>)
    11de:	f3bf 8f5b 	dmb	ish
{
    11e2:	b082      	sub	sp, #8
    11e4:	e852 3f00 	ldrex	r3, [r2]
    11e8:	f023 0102 	bic.w	r1, r3, #2
    11ec:	e842 1000 	strex	r0, r1, [r2]
    11f0:	2800      	cmp	r0, #0
    11f2:	d1f7      	bne.n	11e4 <generic_hfclk_stop+0x8>
    11f4:	f3bf 8f5b 	dmb	ish
	if (atomic_and(&hfclk_users, ~HF_USER_GENERIC) & HF_USER_BT) {
    11f8:	f013 0301 	ands.w	r3, r3, #1
    11fc:	d107      	bne.n	120e <generic_hfclk_stop+0x32>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    11fe:	4a06      	ldr	r2, [pc, #24]	; (1218 <generic_hfclk_stop+0x3c>)
    1200:	6013      	str	r3, [r2, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    1202:	6813      	ldr	r3, [r2, #0]
    1204:	9301      	str	r3, [sp, #4]
    (void)dummy;
    1206:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    1208:	4b04      	ldr	r3, [pc, #16]	; (121c <generic_hfclk_stop+0x40>)
    120a:	2201      	movs	r2, #1
    120c:	601a      	str	r2, [r3, #0]
}
    120e:	b002      	add	sp, #8
    1210:	4770      	bx	lr
    1212:	bf00      	nop
    1214:	2000058c 	.word	0x2000058c
    1218:	40000100 	.word	0x40000100
    121c:	40000004 	.word	0x40000004

00001220 <lfclk_start>:
{
    1220:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	if (!once) {
    1224:	4c0a      	ldr	r4, [pc, #40]	; (1250 <lfclk_start+0x30>)
    1226:	7822      	ldrb	r2, [r4, #0]
    1228:	b942      	cbnz	r2, 123c <lfclk_start+0x1c>
	ret = arch_is_user_context();
    122a:	f004 fea8 	bl	5f7e <arch_is_user_context>
	if (z_syscall_trap()) {
    122e:	b150      	cbz	r0, 1246 <lfclk_start+0x26>
	register uint32_t ret __asm__("r0") = arg1;
    1230:	f44f 70a5 	mov.w	r0, #330	; 0x14a
	register uint32_t r6 __asm__("r6") = call_id;
    1234:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    1236:	df03      	svc	3
		once = true;
    1238:	2301      	movs	r3, #1
    123a:	7023      	strb	r3, [r4, #0]
    123c:	4b05      	ldr	r3, [pc, #20]	; (1254 <lfclk_start+0x34>)
    123e:	2201      	movs	r2, #1
    1240:	601a      	str	r2, [r3, #0]
}
    1242:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	z_impl_k_busy_wait(usec_to_wait);
    1246:	f44f 70a5 	mov.w	r0, #330	; 0x14a
    124a:	f005 fc04 	bl	6a56 <z_impl_k_busy_wait>
    124e:	e7f3      	b.n	1238 <lfclk_start+0x18>
    1250:	20000fe0 	.word	0x20000fe0
    1254:	40000008 	.word	0x40000008

00001258 <api_blocking_start>:
{
    1258:	e92d 4170 	stmdb	sp!, {r4, r5, r6, r8, lr}
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    125c:	2301      	movs	r3, #1
{
    125e:	b089      	sub	sp, #36	; 0x24
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    1260:	2500      	movs	r5, #0
    1262:	e9cd 5306 	strd	r5, r3, [sp, #24]
	struct clock_control_async_data data = {
    1266:	4b0f      	ldr	r3, [pc, #60]	; (12a4 <api_blocking_start+0x4c>)
    1268:	9501      	str	r5, [sp, #4]
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    126a:	ac04      	add	r4, sp, #16
	err = api_start(dev, subsys, &data);
    126c:	aa01      	add	r2, sp, #4
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    126e:	e9cd 4404 	strd	r4, r4, [sp, #16]
	struct clock_control_async_data data = {
    1272:	e9cd 3402 	strd	r3, r4, [sp, #8]
	err = api_start(dev, subsys, &data);
    1276:	f004 ff18 	bl	60aa <api_start>
	if (err < 0) {
    127a:	2800      	cmp	r0, #0
    127c:	db08      	blt.n	1290 <api_blocking_start+0x38>
    127e:	f004 fe7e 	bl	5f7e <arch_is_user_context>
	if (z_syscall_trap()) {
    1282:	b140      	cbz	r0, 1296 <api_blocking_start+0x3e>
		return (int) arch_syscall_invoke3(*(uintptr_t *)&sem, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_SEM_TAKE);
    1284:	4620      	mov	r0, r4
	register uint32_t r1 __asm__("r1") = arg2;
    1286:	f44f 4180 	mov.w	r1, #16384	; 0x4000
	register uint32_t r2 __asm__("r2") = arg3;
    128a:	462a      	mov	r2, r5
	register uint32_t r6 __asm__("r6") = call_id;
    128c:	2687      	movs	r6, #135	; 0x87
	__asm__ volatile("svc %[svid]\n"
    128e:	df03      	svc	3
}
    1290:	b009      	add	sp, #36	; 0x24
    1292:	e8bd 8170 	ldmia.w	sp!, {r4, r5, r6, r8, pc}
	return z_impl_k_sem_take(sem, timeout);
    1296:	f44f 4280 	mov.w	r2, #16384	; 0x4000
    129a:	2300      	movs	r3, #0
    129c:	4620      	mov	r0, r4
    129e:	f003 f9ed 	bl	467c <z_impl_k_sem_take>
	return k_sem_take(&sem, K_MSEC(500));
    12a2:	e7f5      	b.n	1290 <api_blocking_start+0x38>
    12a4:	0000604b 	.word	0x0000604b

000012a8 <nrf_power_clock_isr>:
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    12a8:	4b18      	ldr	r3, [pc, #96]	; (130c <nrf_power_clock_isr+0x64>)
	}
#endif
}

void nrf_power_clock_isr(void *arg)
{
    12aa:	b507      	push	{r0, r1, r2, lr}
    12ac:	681a      	ldr	r2, [r3, #0]
	bool ret = nrf_clock_event_check(NRF_CLOCK, evt) &&
    12ae:	b1b2      	cbz	r2, 12de <nrf_power_clock_isr+0x36>
    return p_reg->INTENSET & mask;
    12b0:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    12b4:	f8d2 2304 	ldr.w	r2, [r2, #772]	; 0x304
	if (ret) {
    12b8:	07d0      	lsls	r0, r2, #31
    12ba:	d510      	bpl.n	12de <nrf_power_clock_isr+0x36>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    12bc:	2200      	movs	r2, #0
    12be:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    12c0:	681b      	ldr	r3, [r3, #0]
    12c2:	9300      	str	r3, [sp, #0]
    (void)dummy;
    12c4:	9b00      	ldr	r3, [sp, #0]
	struct device *dev = DEVICE_GET(clock_nrf);

	if (clock_event_check_and_clean(NRF_CLOCK_EVENT_HFCLKSTARTED,
					NRF_CLOCK_INT_HF_STARTED_MASK)) {
		struct nrf_clock_control_sub_data *data =
				get_sub_data(dev, CLOCK_CONTROL_NRF_TYPE_HFCLK);
    12c6:	4b12      	ldr	r3, [pc, #72]	; (1310 <nrf_power_clock_isr+0x68>)
		 * HFCLKSTARTED may be generated twice.
		 *
		 * Also software should be notified about clock being on only
		 * if generic request occured.
		 */
		if ((GET_STATUS(data->flags) == CLOCK_CONTROL_STATUS_STARTING)
    12c8:	68db      	ldr	r3, [r3, #12]
    12ca:	6c18      	ldr	r0, [r3, #64]	; 0x40
    12cc:	f010 0007 	ands.w	r0, r0, #7
    12d0:	d105      	bne.n	12de <nrf_power_clock_isr+0x36>
			&& (hfclk_users & HF_USER_GENERIC)) {
    12d2:	4b10      	ldr	r3, [pc, #64]	; (1314 <nrf_power_clock_isr+0x6c>)
    12d4:	681b      	ldr	r3, [r3, #0]
    12d6:	0799      	lsls	r1, r3, #30
    12d8:	d501      	bpl.n	12de <nrf_power_clock_isr+0x36>
			clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_HFCLK);
    12da:	f7ff ff1f 	bl	111c <clkstarted_handle.constprop.0>
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    12de:	4b0e      	ldr	r3, [pc, #56]	; (1318 <nrf_power_clock_isr+0x70>)
    12e0:	681a      	ldr	r2, [r3, #0]
	bool ret = nrf_clock_event_check(NRF_CLOCK, evt) &&
    12e2:	b182      	cbz	r2, 1306 <nrf_power_clock_isr+0x5e>
    return p_reg->INTENSET & mask;
    12e4:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    12e8:	f8d2 2304 	ldr.w	r2, [r2, #772]	; 0x304
	if (ret) {
    12ec:	0792      	lsls	r2, r2, #30
    12ee:	d50a      	bpl.n	1306 <nrf_power_clock_isr+0x5e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    12f0:	2200      	movs	r2, #0
    12f2:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    12f4:	681b      	ldr	r3, [r3, #0]
    12f6:	9301      	str	r3, [sp, #4]
    (void)dummy;
    12f8:	9b01      	ldr	r3, [sp, #4]
					NRF_CLOCK_INT_LF_STARTED_MASK)) {
		if (IS_ENABLED(
			CONFIG_CLOCK_CONTROL_NRF_K32SRC_RC_CALIBRATION)) {
			z_nrf_clock_calibration_lfclk_started();
		}
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    12fa:	2001      	movs	r0, #1
	usb_power_isr();

	if (IS_ENABLED(CONFIG_CLOCK_CONTROL_NRF_K32SRC_RC_CALIBRATION)) {
		z_nrf_clock_calibration_isr();
	}
}
    12fc:	b003      	add	sp, #12
    12fe:	f85d eb04 	ldr.w	lr, [sp], #4
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    1302:	f7ff bf0b 	b.w	111c <clkstarted_handle.constprop.0>
}
    1306:	b003      	add	sp, #12
    1308:	f85d fb04 	ldr.w	pc, [sp], #4
    130c:	40000100 	.word	0x40000100
    1310:	20002e20 	.word	0x20002e20
    1314:	2000058c 	.word	0x2000058c
    1318:	40000104 	.word	0x40000104

0000131c <z_nrf_clock_control_lf_on>:
{
    131c:	b510      	push	{r4, lr}
	return __atomic_exchange_n(target, value, __ATOMIC_SEQ_CST);
    131e:	4911      	ldr	r1, [pc, #68]	; (1364 <z_nrf_clock_control_lf_on+0x48>)
    1320:	f3bf 8f5b 	dmb	ish
    1324:	4604      	mov	r4, r0
    1326:	2201      	movs	r2, #1
    1328:	e851 3f00 	ldrex	r3, [r1]
    132c:	e841 2000 	strex	r0, r2, [r1]
    1330:	2800      	cmp	r0, #0
    1332:	d1f9      	bne.n	1328 <z_nrf_clock_control_lf_on+0xc>
    1334:	f3bf 8f5b 	dmb	ish
	if (atomic_set(&on, 1) == 0) {
    1338:	b943      	cbnz	r3, 134c <z_nrf_clock_control_lf_on+0x30>
				get_onoff_manager(DEVICE_GET(clock_nrf),
    133a:	490b      	ldr	r1, [pc, #44]	; (1368 <z_nrf_clock_control_lf_on+0x4c>)
	return &data->mgr[type];
    133c:	68c8      	ldr	r0, [r1, #12]
 */
static inline void sys_notify_init_spinwait(struct sys_notify *notify)
{
	__ASSERT_NO_MSG(notify != NULL);

	*notify = (struct sys_notify){
    133e:	490b      	ldr	r1, [pc, #44]	; (136c <z_nrf_clock_control_lf_on+0x50>)
		err = onoff_request(mgr, &cli);
    1340:	301c      	adds	r0, #28
    1342:	604b      	str	r3, [r1, #4]
    1344:	60cb      	str	r3, [r1, #12]
    1346:	608a      	str	r2, [r1, #8]
    1348:	f004 faf9 	bl	593e <onoff_request>
	switch (start_mode) {
    134c:	2c01      	cmp	r4, #1
    134e:	d006      	beq.n	135e <z_nrf_clock_control_lf_on+0x42>
    1350:	2c02      	cmp	r4, #2
    1352:	d106      	bne.n	1362 <z_nrf_clock_control_lf_on+0x46>
		lfclk_spinwait(CLOCK_CONTROL_NRF_K32SRC);
    1354:	2001      	movs	r0, #1
}
    1356:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		lfclk_spinwait(NRF_CLOCK_LFCLK_RC);
    135a:	f004 be85 	b.w	6068 <lfclk_spinwait>
    135e:	2000      	movs	r0, #0
    1360:	e7f9      	b.n	1356 <z_nrf_clock_control_lf_on+0x3a>
}
    1362:	bd10      	pop	{r4, pc}
    1364:	20000590 	.word	0x20000590
    1368:	20002e20 	.word	0x20002e20
    136c:	2000052c 	.word	0x2000052c

00001370 <handle_next_cycle_case>:
 * counter progresses during that time it means that 1 cycle elapsed and
 * interrupt is set pending.
 */
static void handle_next_cycle_case(uint32_t t)
{
	set_comparator(t + 2);
    1370:	1c82      	adds	r2, r0, #2

#ifndef NRF_DECLARE_ONLY

NRF_STATIC_INLINE  void nrf_rtc_cc_set(NRF_RTC_Type * p_reg, uint32_t ch, uint32_t cc_val)
{
    p_reg->CC[ch] = cc_val;
    1372:	4b08      	ldr	r3, [pc, #32]	; (1394 <handle_next_cycle_case+0x24>)
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    1374:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    1378:	f8c3 2540 	str.w	r2, [r3, #1344]	; 0x540
#endif
}

NRF_STATIC_INLINE uint32_t nrf_rtc_counter_get(NRF_RTC_Type const * p_reg)
{
     return p_reg->COUNTER;
    137c:	f8d3 2504 	ldr.w	r2, [r3, #1284]	; 0x504
	while (t != counter()) {
    1380:	4290      	cmp	r0, r2
    1382:	d100      	bne.n	1386 <handle_next_cycle_case+0x16>
		 * generated. Trigger interrupt.
		 */
		t = counter();
		set_comparator(t + 2);
	}
}
    1384:	4770      	bx	lr
    1386:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
		set_comparator(t + 2);
    138a:	1c82      	adds	r2, r0, #2
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    138c:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    1390:	e7f2      	b.n	1378 <handle_next_cycle_case+0x8>
    1392:	bf00      	nop
    1394:	40011000 	.word	0x40011000

00001398 <event_clear>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    1398:	4b04      	ldr	r3, [pc, #16]	; (13ac <event_clear+0x14>)
    139a:	2200      	movs	r2, #0
{
    139c:	b082      	sub	sp, #8
    139e:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    13a0:	681b      	ldr	r3, [r3, #0]
    13a2:	9301      	str	r3, [sp, #4]
    (void)dummy;
    13a4:	9b01      	ldr	r3, [sp, #4]
}
    13a6:	b002      	add	sp, #8
    13a8:	4770      	bx	lr
    13aa:	bf00      	nop
    13ac:	40011140 	.word	0x40011140

000013b0 <rtc_nrf_isr>:
 * probably better abstract that at some point (e.g. query and reset
 * it by pointer at runtime, maybe?) so we don't have this leaky
 * symbol.
 */
void rtc_nrf_isr(void *arg)
{
    13b0:	b508      	push	{r3, lr}
	ARG_UNUSED(arg);
	event_clear();
    13b2:	f7ff fff1 	bl	1398 <event_clear>
    return p_reg->CC[ch];
    13b6:	4b07      	ldr	r3, [pc, #28]	; (13d4 <rtc_nrf_isr+0x24>)

	uint32_t t = get_comparator();
	uint32_t dticks = counter_sub(t, last_count) / CYC_PER_TICK;
    13b8:	4a07      	ldr	r2, [pc, #28]	; (13d8 <rtc_nrf_isr+0x28>)
    13ba:	f8d3 0540 	ldr.w	r0, [r3, #1344]	; 0x540
    13be:	6813      	ldr	r3, [r2, #0]
	return (a - b) & COUNTER_MAX;
    13c0:	1ac0      	subs	r0, r0, r3
    13c2:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000

	last_count += dticks * CYC_PER_TICK;
    13c6:	4403      	add	r3, r0
    13c8:	6013      	str	r3, [r2, #0]
		 */
		set_absolute_alarm(last_count + CYC_PER_TICK);
	}

	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
}
    13ca:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
    13ce:	f003 bdc9 	b.w	4f64 <z_clock_announce>
    13d2:	bf00      	nop
    13d4:	40011000 	.word	0x40011000
    13d8:	20000594 	.word	0x20000594

000013dc <z_clock_driver_init>:

int z_clock_driver_init(struct device *device)
{
    13dc:	b538      	push	{r3, r4, r5, lr}
}

NRF_STATIC_INLINE void nrf_rtc_prescaler_set(NRF_RTC_Type * p_reg, uint32_t val)
{
    NRFX_ASSERT(val <= (RTC_PRESCALER_PRESCALER_Msk >> RTC_PRESCALER_PRESCALER_Pos));
    p_reg->PRESCALER = val;
    13de:	4d10      	ldr	r5, [pc, #64]	; (1420 <z_clock_driver_init+0x44>)
    13e0:	2400      	movs	r4, #0
    13e2:	f8c5 4508 	str.w	r4, [r5, #1288]	; 0x508
	ARG_UNUSED(device);

	/* TODO: replace with counter driver to access RTC */
	nrf_rtc_prescaler_set(RTC, 0);
	event_clear();
    13e6:	f7ff ffd7 	bl	1398 <event_clear>
 */
__STATIC_INLINE void __NVIC_ClearPendingIRQ(IRQn_Type IRQn)
{
  if ((int32_t)(IRQn) >= 0)
  {
    NVIC->ICPR[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    13ea:	4b0e      	ldr	r3, [pc, #56]	; (1424 <z_clock_driver_init+0x48>)
    13ec:	f44f 3200 	mov.w	r2, #131072	; 0x20000
    13f0:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
    p_reg->INTENSET = mask;
    13f4:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    13f8:	f8c5 3304 	str.w	r3, [r5, #772]	; 0x304
	NVIC_ClearPendingIRQ(RTC_IRQn);
	int_enable();

	IRQ_CONNECT(RTC_IRQn, 1, rtc_nrf_isr, 0, 0);
    13fc:	4622      	mov	r2, r4
    13fe:	2101      	movs	r1, #1
    1400:	2011      	movs	r0, #17
    1402:	f000 f965 	bl	16d0 <z_arm_irq_priority_set>
	irq_enable(RTC_IRQn);
    1406:	2011      	movs	r0, #17
    1408:	f000 f952 	bl	16b0 <arch_irq_enable>
    return (uint32_t)p_reg + task;
}

NRF_STATIC_INLINE void nrf_rtc_task_trigger(NRF_RTC_Type * p_reg, nrf_rtc_task_t task)
{
    *(__IO uint32_t *)((uint32_t)p_reg + task) = 1;
    140c:	4a06      	ldr	r2, [pc, #24]	; (1428 <z_clock_driver_init+0x4c>)
    140e:	2301      	movs	r3, #1
    1410:	6013      	str	r3, [r2, #0]

	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		set_comparator(counter() + CYC_PER_TICK);
	}

	z_nrf_clock_control_lf_on(NRF_LFCLK_START_MODE_NOWAIT);
    1412:	4620      	mov	r0, r4
    1414:	602b      	str	r3, [r5, #0]
    1416:	f7ff ff81 	bl	131c <z_nrf_clock_control_lf_on>

	return 0;
}
    141a:	4620      	mov	r0, r4
    141c:	bd38      	pop	{r3, r4, r5, pc}
    141e:	bf00      	nop
    1420:	40011000 	.word	0x40011000
    1424:	e000e100 	.word	0xe000e100
    1428:	40011008 	.word	0x40011008

0000142c <z_clock_set_timeout>:

void z_clock_set_timeout(int32_t ticks, bool idle)
{
    142c:	e92d 4178 	stmdb	sp!, {r3, r4, r5, r6, r8, lr}
	}

	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);

	uint32_t unannounced = counter_sub(counter(), last_count);
    1430:	4b30      	ldr	r3, [pc, #192]	; (14f4 <z_clock_set_timeout+0xc8>)
     return p_reg->COUNTER;
    1432:	4c31      	ldr	r4, [pc, #196]	; (14f8 <z_clock_set_timeout+0xcc>)
    1434:	6819      	ldr	r1, [r3, #0]
    1436:	f8d4 2504 	ldr.w	r2, [r4, #1284]	; 0x504
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    143a:	4d30      	ldr	r5, [pc, #192]	; (14fc <z_clock_set_timeout+0xd0>)
	return (a - b) & COUNTER_MAX;
    143c:	1a52      	subs	r2, r2, r1
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    143e:	f1b0 3fff 	cmp.w	r0, #4294967295	; 0xffffffff
    1442:	bf08      	it	eq
    1444:	4628      	moveq	r0, r5
	/* If we haven't announced for more than half the 24-bit wrap
	 * duration, then force an announce to avoid loss of a wrap
	 * event.  This can happen if new timeouts keep being set
	 * before the existing one triggers the interrupt.
	 */
	if (unannounced >= COUNTER_HALF_SPAN) {
    1446:	0216      	lsls	r6, r2, #8
	return (a - b) & COUNTER_MAX;
    1448:	f022 437f 	bic.w	r3, r2, #4278190080	; 0xff000000
	if (unannounced >= COUNTER_HALF_SPAN) {
    144c:	d43b      	bmi.n	14c6 <z_clock_set_timeout+0x9a>
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);
    144e:	3801      	subs	r0, #1
    1450:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    1454:	42a8      	cmp	r0, r5
    1456:	bfa8      	it	ge
    1458:	4628      	movge	r0, r5
	}

	/* Get the cycles from last_count to the tick boundary after
	 * the requested ticks have passed starting now.
	 */
	cyc = ticks * CYC_PER_TICK + 1 + unannounced;
    145a:	3301      	adds	r3, #1
    p_reg->INTENCLR = mask;
    145c:	f44f 3680 	mov.w	r6, #65536	; 0x10000
    1460:	4418      	add	r0, r3
    1462:	f8c4 6308 	str.w	r6, [r4, #776]	; 0x308
	 */
	if (cyc > MAX_CYCLES) {
		cyc = MAX_CYCLES;
	}

	cyc += last_count;
    1466:	42a8      	cmp	r0, r5
    1468:	bf94      	ite	ls
    146a:	180d      	addls	r5, r1, r0
    146c:	194d      	addhi	r5, r1, r5
     return p_reg->COUNTER;
    146e:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
    return p_reg->CC[ch];
    1472:	f8d4 1540 	ldr.w	r1, [r4, #1344]	; 0x540
	event_clear();
    1476:	f7ff ff8f 	bl	1398 <event_clear>
	return (a - b) & COUNTER_MAX;
    147a:	1a09      	subs	r1, r1, r0
    147c:	f021 417f 	bic.w	r1, r1, #4278190080	; 0xff000000
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    1480:	f020 437f 	bic.w	r3, r0, #4278190080	; 0xff000000
	if (counter_sub(prev_val, now) == 1) {
    1484:	2901      	cmp	r1, #1
    p_reg->CC[ch] = cc_val;
    1486:	f8c4 3540 	str.w	r3, [r4, #1344]	; 0x540
}

NRF_STATIC_INLINE void nrf_rtc_event_enable(NRF_RTC_Type * p_reg, uint32_t mask)
{
    p_reg->EVTENSET = mask;
    148a:	f8c4 6344 	str.w	r6, [r4, #836]	; 0x344
    148e:	d10b      	bne.n	14a8 <z_clock_set_timeout+0x7c>
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    1490:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    1494:	b9cb      	cbnz	r3, 14ca <z_clock_set_timeout+0x9e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    1496:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    149a:	07da      	lsls	r2, r3, #31
    149c:	d515      	bpl.n	14ca <z_clock_set_timeout+0x9e>
	register uint32_t ret __asm__("r0") = arg1;
    149e:	200f      	movs	r0, #15
	register uint32_t r6 __asm__("r6") = call_id;
    14a0:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    14a2:	df03      	svc	3
		event_clear();
    14a4:	f7ff ff78 	bl	1398 <event_clear>
    14a8:	4b15      	ldr	r3, [pc, #84]	; (1500 <z_clock_set_timeout+0xd4>)
    14aa:	f44f 3200 	mov.w	r2, #131072	; 0x20000
    14ae:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
     return p_reg->COUNTER;
    14b2:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    14b6:	1a2b      	subs	r3, r5, r0
    14b8:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
	if (diff == 1) {
    14bc:	2b01      	cmp	r3, #1
    14be:	d108      	bne.n	14d2 <z_clock_set_timeout+0xa6>
		handle_next_cycle_case(t);
    14c0:	f7ff ff56 	bl	1370 <handle_next_cycle_case>
    14c4:	e00f      	b.n	14e6 <z_clock_set_timeout+0xba>
		ticks = 0;
    14c6:	2000      	movs	r0, #0
    14c8:	e7c7      	b.n	145a <z_clock_set_timeout+0x2e>
	z_impl_k_busy_wait(usec_to_wait);
    14ca:	200f      	movs	r0, #15
    14cc:	f005 fac3 	bl	6a56 <z_impl_k_busy_wait>
    14d0:	e7e8      	b.n	14a4 <z_clock_set_timeout+0x78>
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    14d2:	f025 437f 	bic.w	r3, r5, #4278190080	; 0xff000000
    p_reg->CC[ch] = cc_val;
    14d6:	f8c4 3540 	str.w	r3, [r4, #1344]	; 0x540
     return p_reg->COUNTER;
    14da:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    14de:	1a2d      	subs	r5, r5, r0
    14e0:	3d02      	subs	r5, #2
	if (diff > MAX_CYCLES) {
    14e2:	022b      	lsls	r3, r5, #8
    14e4:	d4ec      	bmi.n	14c0 <z_clock_set_timeout+0x94>
    p_reg->INTENSET = mask;
    14e6:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    14ea:	f8c4 3304 	str.w	r3, [r4, #772]	; 0x304
	set_protected_absolute_alarm(cyc);
}
    14ee:	e8bd 8178 	ldmia.w	sp!, {r3, r4, r5, r6, r8, pc}
    14f2:	bf00      	nop
    14f4:	20000594 	.word	0x20000594
    14f8:	40011000 	.word	0x40011000
    14fc:	007fffff 	.word	0x007fffff
    1500:	e000e100 	.word	0xe000e100

00001504 <z_clock_elapsed>:
	__asm__ volatile(
    1504:	f04f 0220 	mov.w	r2, #32
    1508:	f3ef 8311 	mrs	r3, BASEPRI
    150c:	f382 8811 	msr	BASEPRI, r2
    1510:	f3bf 8f6f 	isb	sy
     return p_reg->COUNTER;
    1514:	4a06      	ldr	r2, [pc, #24]	; (1530 <z_clock_elapsed+0x2c>)
    1516:	f8d2 0504 	ldr.w	r0, [r2, #1284]	; 0x504
	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		return 0;
	}

	k_spinlock_key_t key = k_spin_lock(&lock);
	uint32_t ret = counter_sub(counter(), last_count) / CYC_PER_TICK;
    151a:	4a06      	ldr	r2, [pc, #24]	; (1534 <z_clock_elapsed+0x30>)
	return (a - b) & COUNTER_MAX;
    151c:	6812      	ldr	r2, [r2, #0]
    151e:	1a80      	subs	r0, r0, r2
    1520:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000
	__asm__ volatile(
    1524:	f383 8811 	msr	BASEPRI, r3
    1528:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&lock, key);
	return ret;
}
    152c:	4770      	bx	lr
    152e:	bf00      	nop
    1530:	40011000 	.word	0x40011000
    1534:	20000594 	.word	0x20000594

00001538 <_DoInit>:
*
*/
#define INIT()  do {                                            \
                  if (_SEGGER_RTT.acID[0] == '\0') { _DoInit(); }  \
                } while (0)
static void _DoInit(void) {
    1538:	b510      	push	{r4, lr}
  SEGGER_RTT_CB* p;
  //
  // Initialize control block
  //
  p = &_SEGGER_RTT;
  p->MaxNumUpBuffers    = SEGGER_RTT_MAX_NUM_UP_BUFFERS;
    153a:	4c11      	ldr	r4, [pc, #68]	; (1580 <_DoInit+0x48>)
  p->MaxNumDownBuffers  = SEGGER_RTT_MAX_NUM_DOWN_BUFFERS;
  //
  // Initialize up buffer 0
  //
  p->aUp[0].sName         = "Terminal";
    153c:	4a11      	ldr	r2, [pc, #68]	; (1584 <_DoInit+0x4c>)
    153e:	61a2      	str	r2, [r4, #24]
  p->MaxNumUpBuffers    = SEGGER_RTT_MAX_NUM_UP_BUFFERS;
    1540:	2303      	movs	r3, #3
  p->MaxNumDownBuffers  = SEGGER_RTT_MAX_NUM_DOWN_BUFFERS;
    1542:	e9c4 3304 	strd	r3, r3, [r4, #16]
  p->aUp[0].pBuffer       = _acUpBuffer;
    1546:	4b10      	ldr	r3, [pc, #64]	; (1588 <_DoInit+0x50>)
    1548:	61e3      	str	r3, [r4, #28]
  p->aUp[0].WrOff         = 0u;
  p->aUp[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
  //
  // Initialize down buffer 0
  //
  p->aDown[0].sName         = "Terminal";
    154a:	6622      	str	r2, [r4, #96]	; 0x60
  p->aUp[0].SizeOfBuffer  = sizeof(_acUpBuffer);
    154c:	f44f 6380 	mov.w	r3, #1024	; 0x400
  p->aDown[0].pBuffer       = _acDownBuffer;
    1550:	4a0e      	ldr	r2, [pc, #56]	; (158c <_DoInit+0x54>)
  //
  // Finish initialization of the control block.
  // Copy Id string in three steps to make sure "SEGGER RTT" is not found
  // in initializer memory (usually flash) by J-Link
  //
  strcpy(&p->acID[7], "RTT");
    1552:	490f      	ldr	r1, [pc, #60]	; (1590 <_DoInit+0x58>)
  p->aUp[0].SizeOfBuffer  = sizeof(_acUpBuffer);
    1554:	6223      	str	r3, [r4, #32]
  p->aDown[0].pBuffer       = _acDownBuffer;
    1556:	6662      	str	r2, [r4, #100]	; 0x64
  p->aUp[0].RdOff         = 0u;
    1558:	2300      	movs	r3, #0
  p->aDown[0].SizeOfBuffer  = sizeof(_acDownBuffer);
    155a:	2210      	movs	r2, #16
  strcpy(&p->acID[7], "RTT");
    155c:	1de0      	adds	r0, r4, #7
  p->aUp[0].RdOff         = 0u;
    155e:	62a3      	str	r3, [r4, #40]	; 0x28
  p->aUp[0].WrOff         = 0u;
    1560:	6263      	str	r3, [r4, #36]	; 0x24
  p->aUp[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
    1562:	62e3      	str	r3, [r4, #44]	; 0x2c
  p->aDown[0].RdOff         = 0u;
    1564:	6723      	str	r3, [r4, #112]	; 0x70
  p->aDown[0].WrOff         = 0u;
    1566:	66e3      	str	r3, [r4, #108]	; 0x6c
  p->aDown[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
    1568:	6763      	str	r3, [r4, #116]	; 0x74
  p->aDown[0].SizeOfBuffer  = sizeof(_acDownBuffer);
    156a:	66a2      	str	r2, [r4, #104]	; 0x68
  strcpy(&p->acID[7], "RTT");
    156c:	f004 fe28 	bl	61c0 <strcpy>
  strcpy(&p->acID[0], "SEGGER");
    1570:	4908      	ldr	r1, [pc, #32]	; (1594 <_DoInit+0x5c>)
    1572:	4620      	mov	r0, r4
    1574:	f004 fe24 	bl	61c0 <strcpy>
  p->acID[6] = ' ';
    1578:	2320      	movs	r3, #32
    157a:	71a3      	strb	r3, [r4, #6]
}
    157c:	bd10      	pop	{r4, pc}
    157e:	bf00      	nop
    1580:	20000598 	.word	0x20000598
    1584:	000077ec 	.word	0x000077ec
    1588:	20000ff1 	.word	0x20000ff1
    158c:	20000fe1 	.word	0x20000fe1
    1590:	000077f5 	.word	0x000077f5
    1594:	000077f9 	.word	0x000077f9

00001598 <arch_swap>:
#ifdef CONFIG_EXECUTION_BENCHMARKING
	read_timer_start_of_swap();
#endif

	/* store off key and return value */
	_current->arch.basepri = key;
    1598:	4a0a      	ldr	r2, [pc, #40]	; (15c4 <arch_swap+0x2c>)
	_current->arch.swap_return_value = _k_neg_eagain;
    159a:	490b      	ldr	r1, [pc, #44]	; (15c8 <arch_swap+0x30>)
	_current->arch.basepri = key;
    159c:	6893      	ldr	r3, [r2, #8]
	_current->arch.swap_return_value = _k_neg_eagain;
    159e:	6809      	ldr	r1, [r1, #0]
    15a0:	f8c3 1090 	str.w	r1, [r3, #144]	; 0x90

#if defined(CONFIG_CPU_CORTEX_M)
	/* set pending bit to make sure we will take a PendSV exception */
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    15a4:	4909      	ldr	r1, [pc, #36]	; (15cc <arch_swap+0x34>)
	_current->arch.basepri = key;
    15a6:	f8c3 008c 	str.w	r0, [r3, #140]	; 0x8c
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    15aa:	684b      	ldr	r3, [r1, #4]
    15ac:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
    15b0:	604b      	str	r3, [r1, #4]
    15b2:	2300      	movs	r3, #0
    15b4:	f383 8811 	msr	BASEPRI, r3
    15b8:	f3bf 8f6f 	isb	sy
#endif

	/* Context switch is performed here. Returning implies the
	 * thread has been context-switched-in again.
	 */
	return _current->arch.swap_return_value;
    15bc:	6893      	ldr	r3, [r2, #8]
}
    15be:	f8d3 0090 	ldr.w	r0, [r3, #144]	; 0x90
    15c2:	4770      	bx	lr
    15c4:	20000664 	.word	0x20000664
    15c8:	000072d0 	.word	0x000072d0
    15cc:	e000ed00 	.word	0xe000ed00

000015d0 <z_arm_pendsv>:
    pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_TRACING */

    /* load _kernel into r1 and current k_thread into r2 */
    ldr r1, =_kernel
    15d0:	4919      	ldr	r1, [pc, #100]	; (1638 <z_arm_pendsv+0x68>)
    ldr r2, [r1, #_kernel_offset_to_current]
    15d2:	688a      	ldr	r2, [r1, #8]

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
    15d4:	f04f 0038 	mov.w	r0, #56	; 0x38
    add r0, r2
    15d8:	4410      	add	r0, r2

    /* save callee-saved + psp in thread */
#if defined(CONFIG_CPU_CORTEX_M)
    mrs ip, PSP
    15da:	f3ef 8c09 	mrs	ip, PSP
    mov r6, r11
    mov r7, ip
    /* store r8-12 */
    stmea r0!, {r3-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    stmia r0, {v1-v8, ip}
    15de:	e880 1ff0 	stmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}

    /* Protect the kernel state while we play with the thread lists */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    15e2:	2020      	movs	r0, #32
    msr BASEPRI, r0
    15e4:	f380 8811 	msr	BASEPRI, r0
    isb /* Make the effect of disabling interrupts be realized immediately */
    15e8:	f3bf 8f6f 	isb	sy
     * the new thread is context-switched in since all decisions
     * to pend PendSV have been taken with the current kernel
     * state and this is what we're handling currently.
     */
#if defined(CONFIG_CPU_CORTEX_M)
    ldr v4, =_SCS_ICSR
    15ec:	4f13      	ldr	r7, [pc, #76]	; (163c <z_arm_pendsv+0x6c>)
    ldr v3, =_SCS_ICSR_UNPENDSV
    15ee:	f04f 6600 	mov.w	r6, #134217728	; 0x8000000
#endif

    /* _kernel is still in r1 */

    /* fetch the thread to run from the ready queue cache */
    ldr r2, [r1, #_kernel_offset_to_ready_q_cache]
    15f2:	6a4a      	ldr	r2, [r1, #36]	; 0x24

    str r2, [r1, #_kernel_offset_to_current]
    15f4:	608a      	str	r2, [r1, #8]
     * has been handled.
     */

    /* _SCS_ICSR is still in v4 and _SCS_ICSR_UNPENDSV in v3 */
#if defined(CONFIG_CPU_CORTEX_M)
    str v3, [v4, #0]
    15f6:	603e      	str	r6, [r7, #0]

    ldr r0, [r4]
    movs.n r3, #0
    str r3, [r4]
#else
    ldr r0, [r2, #_thread_offset_to_basepri]
    15f8:	f8d2 008c 	ldr.w	r0, [r2, #140]	; 0x8c
    movs r3, #0
    15fc:	2300      	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
    15fe:	f8c2 308c 	str.w	r3, [r2, #140]	; 0x8c
    /* restore r4-r7, go back 9*4 bytes to the start of the stored block */
    subs r0, #36
    ldmia r0!, {r4-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* restore BASEPRI for the incoming thread */
    msr BASEPRI, r0
    1602:	f380 8811 	msr	BASEPRI, r0
    isb
#endif

#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
    /* Re-program dynamic memory map */
    push {r2,lr}
    1606:	b504      	push	{r2, lr}
    mov r0, r2 /* _current thread */
    1608:	4610      	mov	r0, r2
    bl z_arm_configure_dynamic_mpu_regions
    160a:	f000 fbd5 	bl	1db8 <z_arm_configure_dynamic_mpu_regions>
    pop {r2,lr}
    160e:	e8bd 4004 	ldmia.w	sp!, {r2, lr}
#endif

#ifdef CONFIG_USERSPACE
    /* restore mode */
    ldr r0, [r2, #_thread_offset_to_mode]
    1612:	f8d2 0094 	ldr.w	r0, [r2, #148]	; 0x94
    mrs r3, CONTROL
    1616:	f3ef 8314 	mrs	r3, CONTROL
    bic r3, #1
    161a:	f023 0301 	bic.w	r3, r3, #1
    orr r3, r0
    161e:	ea43 0300 	orr.w	r3, r3, r0
    msr CONTROL, r3
    1622:	f383 8814 	msr	CONTROL, r3

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    1626:	f3bf 8f6f 	isb	sy

#endif

    /* load callee-saved + psp from thread */
    add r0, r2, #_thread_offset_to_callee_saved
    162a:	f102 0038 	add.w	r0, r2, #56	; 0x38
    ldmia r0, {v1-v8, ip}
    162e:	e890 1ff0 	ldmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
    msr PSP, ip
    1632:	f38c 8809 	msr	PSP, ip

    /*
     * Cortex-M: return from PendSV exception
     * Cortex-R: return to the caller (_IntExit or z_arm_svc)
     */
    bx lr
    1636:	4770      	bx	lr
    ldr r1, =_kernel
    1638:	20000664 	.word	0x20000664
    ldr v4, =_SCS_ICSR
    163c:	e000ed04 	.word	0xe000ed04

00001640 <z_arm_svc>:
  bne _stack_frame_endif
_stack_frame_msp:
  mrs r0, MSP
_stack_frame_endif:
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst lr, #0x4    /* did we come from thread mode ? */
    1640:	f01e 0f04 	tst.w	lr, #4
    ite eq  /* if zero (equal), came from handler mode */
    1644:	bf0c      	ite	eq
        mrseq r0, MSP   /* handler mode, stack frame is on MSP */
    1646:	f3ef 8008 	mrseq	r0, MSP
        mrsne r0, PSP   /* thread mode, stack frame is on PSP */
    164a:	f3ef 8009 	mrsne	r0, PSP
#endif


    /* Figure out what SVC call number was invoked */

    ldr r1, [r0, #24]   /* grab address of PC from stack frame */
    164e:	6981      	ldr	r1, [r0, #24]
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    subs r1, r1, #2
    ldrb r1, [r1]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldrb r1, [r1, #-2]
    1650:	f811 1c02 	ldrb.w	r1, [r1, #-2]
    * 1: irq_offload (if configured)
    * 2: kernel panic or oops (software generated fatal exception)
    * 3: System call (if user mode supported)
    */
#if defined(CONFIG_USERSPACE)
    mrs r2, CONTROL
    1654:	f3ef 8214 	mrs	r2, CONTROL

    cmp r1, #3
    1658:	2903      	cmp	r1, #3
    beq _do_syscall
    165a:	d008      	beq.n	166e <_do_syscall>
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    movs r3, #0x1
    tst r2, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst r2, #0x1
    165c:	f012 0f01 	tst.w	r2, #1
#endif
    bne _oops
    1660:	d101      	bne.n	1666 <_oops>

#endif /* CONFIG_USERSPACE */

    cmp r1, #2
    1662:	2902      	cmp	r1, #2
    beq _oops
    1664:	d0ff      	beq.n	1666 <_oops>

00001666 <_oops>:
    /* exception return is done in z_arm_int_exit() */
    b z_arm_int_exit
#endif

_oops:
    push {r0, lr}
    1666:	b501      	push	{r0, lr}
    bl z_do_kernel_oops
    1668:	f004 fd64 	bl	6134 <z_do_kernel_oops>
    /* return from SVC exception is done here */
    pop {r0, pc}
    166c:	bd01      	pop	{r0, pc}

0000166e <_do_syscall>:
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    movs r3, #24
    ldr r1, [r0, r3]   /* grab address of PC from stack frame */
    mov r8, r1
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r8, [r0, #24]   /* grab address of PC from stack frame */
    166e:	f8d0 8018 	ldr.w	r8, [r0, #24]
#endif
    ldr r1, =z_arm_do_syscall
    1672:	490d      	ldr	r1, [pc, #52]	; (16a8 <valid_syscall_id+0x24>)
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    str r1, [r0, r3]   /* overwrite the PC to point to z_arm_do_syscall */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    str r1, [r0, #24]   /* overwrite the PC to point to z_arm_do_syscall */
    1674:	6181      	str	r1, [r0, #24]
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    ldr r3, =K_SYSCALL_LIMIT
    cmp r6, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* validate syscall limit */
    ldr ip, =K_SYSCALL_LIMIT
    1676:	f44f 7c86 	mov.w	ip, #268	; 0x10c
    cmp r6, ip
    167a:	4566      	cmp	r6, ip
#endif
    /* The supplied syscall_id must be lower than the limit
     * (Requires unsigned integer comparison)
     */
    blo valid_syscall_id
    167c:	d302      	bcc.n	1684 <valid_syscall_id>

    /* bad syscall id.  Set arg1 to bad id and set call_id to SYSCALL_BAD */
    str r6, [r0]
    167e:	6006      	str	r6, [r0, #0]
    ldr r6, =K_SYSCALL_BAD
    1680:	f240 160b 	movw	r6, #267	; 0x10b

00001684 <valid_syscall_id>:

    /* Bad syscalls treated as valid syscalls with ID K_SYSCALL_BAD. */

valid_syscall_id:
    ldr r0, =_kernel
    1684:	4809      	ldr	r0, [pc, #36]	; (16ac <valid_syscall_id+0x28>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1686:	6880      	ldr	r0, [r0, #8]
    dsb
    /* set mode to privileged, r2 still contains value from CONTROL */
    movs r3, #1
    bics r2, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r1, [r0, #_thread_offset_to_mode]
    1688:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    bic r1, #1
    168c:	f021 0101 	bic.w	r1, r1, #1
    /* Store (privileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    1690:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
    dsb
    1694:	f3bf 8f4f 	dsb	sy
    /* set mode to privileged, r2 still contains value from CONTROL */
    bic r2, #1
    1698:	f022 0201 	bic.w	r2, r2, #1
#endif
    msr CONTROL, r2
    169c:	f382 8814 	msr	CONTROL, r2

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    16a0:	f3bf 8f6f 	isb	sy
    ldr r1, [r0, #_thread_offset_to_stack_info_start]    /* stack_info.start */
    msr PSPLIM, r1
#endif /* CONFIG_BUILTIN_STACK_GUARD */

    /* return from SVC to the modified LR - z_arm_do_syscall */
    bx lr
    16a4:	4770      	bx	lr
    16a6:	0000      	.short	0x0000
    ldr r1, =z_arm_do_syscall
    16a8:	0000193d 	.word	0x0000193d
    ldr r0, =_kernel
    16ac:	20000664 	.word	0x20000664

000016b0 <arch_irq_enable>:
#define REG_FROM_IRQ(irq) (irq / NUM_IRQS_PER_REG)
#define BIT_FROM_IRQ(irq) (irq % NUM_IRQS_PER_REG)

void arch_irq_enable(unsigned int irq)
{
	NVIC_EnableIRQ((IRQn_Type)irq);
    16b0:	b243      	sxtb	r3, r0
  if ((int32_t)(IRQn) >= 0)
    16b2:	2b00      	cmp	r3, #0
    16b4:	db08      	blt.n	16c8 <arch_irq_enable+0x18>
    NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    16b6:	2201      	movs	r2, #1
    16b8:	f000 001f 	and.w	r0, r0, #31
    16bc:	fa02 f000 	lsl.w	r0, r2, r0
    16c0:	095b      	lsrs	r3, r3, #5
    16c2:	4a02      	ldr	r2, [pc, #8]	; (16cc <arch_irq_enable+0x1c>)
    16c4:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
}
    16c8:	4770      	bx	lr
    16ca:	bf00      	nop
    16cc:	e000e100 	.word	0xe000e100

000016d0 <z_arm_irq_priority_set>:
	 */
	__ASSERT(prio <= (BIT(NUM_IRQ_PRIO_BITS) - 1),
		 "invalid priority %d! values must be less than %lu\n",
		 prio - _IRQ_PRIO_OFFSET,
		 BIT(NUM_IRQ_PRIO_BITS) - (_IRQ_PRIO_OFFSET));
	NVIC_SetPriority((IRQn_Type)irq, prio);
    16d0:	b243      	sxtb	r3, r0
  \param [in]  priority  Priority to set.
  \note    The priority cannot be set for every processor exception.
 */
__STATIC_INLINE void __NVIC_SetPriority(IRQn_Type IRQn, uint32_t priority)
{
  if ((int32_t)(IRQn) >= 0)
    16d2:	2b00      	cmp	r3, #0
  {
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    16d4:	bfa8      	it	ge
    16d6:	f103 4360 	addge.w	r3, r3, #3758096384	; 0xe0000000
	prio += _IRQ_PRIO_OFFSET;
    16da:	f101 0101 	add.w	r1, r1, #1
  }
  else
  {
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    16de:	bfb8      	it	lt
    16e0:	4b06      	ldrlt	r3, [pc, #24]	; (16fc <z_arm_irq_priority_set+0x2c>)
    16e2:	ea4f 1141 	mov.w	r1, r1, lsl #5
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    16e6:	bfac      	ite	ge
    16e8:	f503 4361 	addge.w	r3, r3, #57600	; 0xe100
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    16ec:	f000 000f 	andlt.w	r0, r0, #15
    16f0:	b2c9      	uxtb	r1, r1
    16f2:	bfb4      	ite	lt
    16f4:	5419      	strblt	r1, [r3, r0]
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    16f6:	f883 1300 	strbge.w	r1, [r3, #768]	; 0x300
}
    16fa:	4770      	bx	lr
    16fc:	e000ed14 	.word	0xe000ed14

00001700 <arch_user_mode_enter>:
					void *p1, void *p2, void *p3)
{

	/* Set up privileged stack before entering user mode */
	_current->arch.priv_stack_start =
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    1700:	4c0c      	ldr	r4, [pc, #48]	; (1734 <arch_user_mode_enter+0x34>)
{
    1702:	4698      	mov	r8, r3
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    1704:	68a3      	ldr	r3, [r4, #8]
{
    1706:	b583      	push	{r0, r1, r7, lr}
    1708:	4605      	mov	r5, r0
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    170a:	f8d3 0080 	ldr.w	r0, [r3, #128]	; 0x80
{
    170e:	4617      	mov	r7, r2
    1710:	460e      	mov	r6, r1
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    1712:	f005 fb75 	bl	6e00 <z_priv_stack_find>
	_current->arch.priv_stack_start =
    1716:	68a4      	ldr	r4, [r4, #8]
#else
	_current->arch.priv_stack_start += MPU_GUARD_ALIGN_AND_SIZE;
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */
#endif /* CONFIG_MPU_STACK_GUARD */

	z_arm_userspace_enter(user_entry, p1, p2, p3,
    1718:	e9d4 321b 	ldrd	r3, r2, [r4, #108]	; 0x6c
    171c:	1a9b      	subs	r3, r3, r2
	_current->arch.priv_stack_start =
    171e:	f8c4 0098 	str.w	r0, [r4, #152]	; 0x98
	z_arm_userspace_enter(user_entry, p1, p2, p3,
    1722:	9301      	str	r3, [sp, #4]
    1724:	6ea3      	ldr	r3, [r4, #104]	; 0x68
    1726:	9300      	str	r3, [sp, #0]
    1728:	463a      	mov	r2, r7
    172a:	4643      	mov	r3, r8
    172c:	4631      	mov	r1, r6
    172e:	4628      	mov	r0, r5
    1730:	f000 f8c2 	bl	18b8 <z_arm_userspace_enter>
    1734:	20000664 	.word	0x20000664

00001738 <arch_new_thread>:
{
    1738:	b530      	push	{r4, r5, lr}
	if ((thread->base.user_options & K_USER) != 0) {
    173a:	7b01      	ldrb	r1, [r0, #12]
	iframe->a1 = (uint32_t)entry;
    173c:	f842 3c20 	str.w	r3, [r2, #-32]
	iframe->a2 = (uint32_t)p1;
    1740:	9b03      	ldr	r3, [sp, #12]
    1742:	f842 3c1c 	str.w	r3, [r2, #-28]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    1746:	4d0e      	ldr	r5, [pc, #56]	; (1780 <arch_new_thread+0x48>)
	iframe->a3 = (uint32_t)p2;
    1748:	9b04      	ldr	r3, [sp, #16]
    174a:	f842 3c18 	str.w	r3, [r2, #-24]
	if ((thread->base.user_options & K_USER) != 0) {
    174e:	f011 0f04 	tst.w	r1, #4
	iframe->a4 = (uint32_t)p3;
    1752:	9b05      	ldr	r3, [sp, #20]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    1754:	490b      	ldr	r1, [pc, #44]	; (1784 <arch_new_thread+0x4c>)
	iframe->a4 = (uint32_t)p3;
    1756:	f842 3c14 	str.w	r3, [r2, #-20]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    175a:	bf18      	it	ne
    175c:	4629      	movne	r1, r5
	iframe->xpsr =
    175e:	f04f 7380 	mov.w	r3, #16777216	; 0x1000000
    1762:	f842 3c04 	str.w	r3, [r2, #-4]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
    1766:	f1a2 0420 	sub.w	r4, r2, #32
	thread->arch.basepri = 0;
    176a:	2300      	movs	r3, #0
	iframe->pc &= 0xfffffffe;
    176c:	f021 0101 	bic.w	r1, r1, #1
    1770:	f842 1c08 	str.w	r1, [r2, #-8]
	thread->arch.priv_stack_start = 0;
    1774:	e9c0 3325 	strd	r3, r3, [r0, #148]	; 0x94
	thread->callee_saved.psp = (uint32_t)iframe;
    1778:	6584      	str	r4, [r0, #88]	; 0x58
	thread->arch.basepri = 0;
    177a:	f8c0 308c 	str.w	r3, [r0, #140]	; 0x8c
}
    177e:	bd30      	pop	{r4, r5, pc}
    1780:	00001701 	.word	0x00001701
    1784:	000059df 	.word	0x000059df

00001788 <z_check_thread_stack_fail>:
 * @return The lowest allowed stack frame pointer, if error is a
 *         thread stack corruption, otherwise return 0.
 */
uint32_t z_check_thread_stack_fail(const uint32_t fault_addr, const uint32_t psp)
{
	const struct k_thread *thread = _current;
    1788:	4b10      	ldr	r3, [pc, #64]	; (17cc <z_check_thread_stack_fail+0x44>)
    178a:	689b      	ldr	r3, [r3, #8]
{
    178c:	b510      	push	{r4, lr}
    178e:	4604      	mov	r4, r0

	if (!thread) {
    1790:	b1bb      	cbz	r3, 17c2 <z_check_thread_stack_fail+0x3a>
#else
	uint32_t guard_len = MPU_GUARD_ALIGN_AND_SIZE;
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */

#if defined(CONFIG_USERSPACE)
	if (thread->arch.priv_stack_start) {
    1792:	f8d3 0098 	ldr.w	r0, [r3, #152]	; 0x98
    1796:	b168      	cbz	r0, 17b4 <z_check_thread_stack_fail+0x2c>
 */
__STATIC_FORCEINLINE uint32_t __get_CONTROL(void)
{
  uint32_t result;

  __ASM volatile ("MRS %0, control" : "=r" (result) );
    1798:	f3ef 8214 	mrs	r2, CONTROL
		/* User thread */
		if ((__get_CONTROL() & CONTROL_nPRIV_Msk) == 0) {
    179c:	f012 0201 	ands.w	r2, r2, #1
    17a0:	d105      	bne.n	17ae <z_check_thread_stack_fail+0x26>
			/* User thread in privilege mode */
			if (IS_MPU_GUARD_VIOLATION(
    17a2:	3416      	adds	r4, #22
    17a4:	d10f      	bne.n	17c6 <z_check_thread_stack_fail+0x3e>
		/* Thread stack corruption */
		return thread->stack_info.start;
	}
#endif /* CONFIG_USERSPACE */

	return 0;
    17a6:	4288      	cmp	r0, r1
    17a8:	bf98      	it	ls
    17aa:	2000      	movls	r0, #0
}
    17ac:	bd10      	pop	{r4, pc}
			if (psp < (uint32_t)thread->stack_obj) {
    17ae:	f8d3 0080 	ldr.w	r0, [r3, #128]	; 0x80
    17b2:	e7f8      	b.n	17a6 <z_check_thread_stack_fail+0x1e>
		if (IS_MPU_GUARD_VIOLATION(thread->stack_info.start -
    17b4:	3416      	adds	r4, #22
    17b6:	d1f9      	bne.n	17ac <z_check_thread_stack_fail+0x24>
    17b8:	6e9b      	ldr	r3, [r3, #104]	; 0x68
    17ba:	428b      	cmp	r3, r1
    17bc:	bf88      	it	hi
    17be:	4618      	movhi	r0, r3
    17c0:	e7f4      	b.n	17ac <z_check_thread_stack_fail+0x24>
	return 0;
    17c2:	4618      	mov	r0, r3
    17c4:	e7f2      	b.n	17ac <z_check_thread_stack_fail+0x24>
    17c6:	4610      	mov	r0, r2
    17c8:	e7f0      	b.n	17ac <z_check_thread_stack_fail+0x24>
    17ca:	bf00      	nop
    17cc:	20000664 	.word	0x20000664

000017d0 <arch_switch_to_main_thread>:
}
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */

void arch_switch_to_main_thread(struct k_thread *main_thread, char *stack_ptr,
				k_thread_entry_t _main)
{
    17d0:	b508      	push	{r3, lr}
    17d2:	4604      	mov	r4, r0
    17d4:	460e      	mov	r6, r1
    17d6:	4615      	mov	r5, r2
	 * to set up access permissions for fixed memory sections, such
	 * as Application Memory or No-Cacheable SRAM area.
	 *
	 * This function is invoked once, upon system initialization.
	 */
	z_arm_configure_static_mpu_regions();
    17d8:	f000 fad2 	bl	1d80 <z_arm_configure_static_mpu_regions>
#endif
	_current = main_thread;
    17dc:	4b08      	ldr	r3, [pc, #32]	; (1800 <arch_switch_to_main_thread+0x30>)
#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
	/*
	 * If stack protection is enabled, make sure to set it
	 * before jumping to thread entry function
	 */
	z_arm_configure_dynamic_mpu_regions(main_thread);
    17de:	4620      	mov	r0, r4
	_current = main_thread;
    17e0:	609c      	str	r4, [r3, #8]
	z_arm_configure_dynamic_mpu_regions(main_thread);
    17e2:	f000 fae9 	bl	1db8 <z_arm_configure_dynamic_mpu_regions>

	/*
	 * Set PSP to the highest address of the main stack
	 * before enabling interrupts and jumping to main.
	 */
	__asm__ volatile (
    17e6:	4628      	mov	r0, r5
    17e8:	f386 8809 	msr	PSP, r6
    17ec:	2100      	movs	r1, #0
    17ee:	b663      	cpsie	if
    17f0:	f381 8811 	msr	BASEPRI, r1
    17f4:	f3bf 8f6f 	isb	sy
    17f8:	2200      	movs	r2, #0
    17fa:	2300      	movs	r3, #0
    17fc:	f004 f8ef 	bl	59de <z_thread_entry>
	:
	: "r" (_main), "r" (stack_ptr)
	: "r0" /* not to be overwritten by msr PSP, %1 */
	);

	CODE_UNREACHABLE;
    1800:	20000664 	.word	0x20000664

00001804 <z_arm_cpu_idle_init>:
 * void z_arm_cpu_idle_init(void);
 */

SECTION_FUNC(TEXT, z_arm_cpu_idle_init)
#if defined(CONFIG_CPU_CORTEX_M)
	ldr	r1, =_SCB_SCR
    1804:	4901      	ldr	r1, [pc, #4]	; (180c <z_arm_cpu_idle_init+0x8>)
	movs.n	r2, #_SCR_INIT_BITS
    1806:	2210      	movs	r2, #16
	str	r2, [r1]
    1808:	600a      	str	r2, [r1, #0]
#endif
	bx	lr
    180a:	4770      	bx	lr
	ldr	r1, =_SCB_SCR
    180c:	e000ed10 	.word	0xe000ed10

00001810 <arch_cpu_idle>:
	 * before entering low power state.
	 *
	 * Set PRIMASK before configuring BASEPRI to prevent interruption
	 * before wake-up.
	 */
	cpsid	i
    1810:	b672      	cpsid	i

	/*
	 * Set wake-up interrupt priority to the lowest and synchronise to
	 * ensure that this is visible to the WFI instruction.
	 */
	eors.n	r0, r0
    1812:	4040      	eors	r0, r0
	msr	BASEPRI, r0
    1814:	f380 8811 	msr	BASEPRI, r0
	isb
    1818:	f3bf 8f6f 	isb	sy

	/*
	 * Wait for all memory transactions to complete before entering low
	 * power state.
	 */
	dsb
    181c:	f3bf 8f4f 	dsb	sy

	/* Enter low power state */
	wfi
    1820:	bf30      	wfi

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
    1822:	b662      	cpsie	i
	isb
    1824:	f3bf 8f6f 	isb	sy

	bx	lr
    1828:	4770      	bx	lr
    182a:	bf00      	nop

0000182c <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
    182c:	bf30      	wfi
    b z_SysNmiOnReset
    182e:	f7ff bffd 	b.w	182c <z_SysNmiOnReset>
    1832:	bf00      	nop

00001834 <z_arm_prep_c>:
#else
#define VECTOR_ADDRESS CONFIG_SRAM_BASE_ADDRESS
#endif
static inline void relocate_vector_table(void)
{
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    1834:	4a0e      	ldr	r2, [pc, #56]	; (1870 <z_arm_prep_c+0x3c>)
 * This routine prepares for the execution of and runs C code.
 *
 * @return N/A
 */
void z_arm_prep_c(void)
{
    1836:	b508      	push	{r3, lr}
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    1838:	4b0e      	ldr	r3, [pc, #56]	; (1874 <z_arm_prep_c+0x40>)
    183a:	f022 027f 	bic.w	r2, r2, #127	; 0x7f
    183e:	609a      	str	r2, [r3, #8]
  \details Acts as a special kind of Data Memory Barrier.
           It completes when all explicit memory accesses before this instruction complete.
 */
__STATIC_FORCEINLINE void __DSB(void)
{
  __ASM volatile ("dsb 0xF":::"memory");
    1840:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    1844:	f3bf 8f6f 	isb	sy
	SCB->CPACR &= (~(CPACR_CP10_Msk | CPACR_CP11_Msk));
    1848:	f8d3 2088 	ldr.w	r2, [r3, #136]	; 0x88
    184c:	f422 0270 	bic.w	r2, r2, #15728640	; 0xf00000
    1850:	f8c3 2088 	str.w	r2, [r3, #136]	; 0x88
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    1854:	f3ef 8314 	mrs	r3, CONTROL
	__set_CONTROL(__get_CONTROL() & (~(CONTROL_FPCA_Msk)));
    1858:	f023 0304 	bic.w	r3, r3, #4
  __ASM volatile ("MSR control, %0" : : "r" (control) : "memory");
    185c:	f383 8814 	msr	CONTROL, r3
	relocate_vector_table();
#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
    1860:	f001 fc32 	bl	30c8 <z_bss_zero>
	z_data_copy();
    1864:	f001 fc3a 	bl	30dc <z_data_copy>
#if defined(CONFIG_ARMV7_R) && defined(CONFIG_INIT_STACKS)
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
    1868:	f000 fa58 	bl	1d1c <z_arm_interrupt_init>
	z_cstart();
    186c:	f001 fc80 	bl	3170 <z_cstart>
    1870:	00000000 	.word	0x00000000
    1874:	e000ed00 	.word	0xe000ed00

00001878 <_isr_wrapper>:
 * @return N/A
 */
SECTION_FUNC(TEXT, _isr_wrapper)

#if defined(CONFIG_CPU_CORTEX_M)
	push {r0,lr}		/* r0, lr are now the first items on the stack */
    1878:	b501      	push	{r0, lr}
	 * Disable interrupts to prevent nesting while exiting idle state. This
	 * is only necessary for the Cortex-M because it is the only ARM
	 * architecture variant that automatically enables interrupts when
	 * entering an ISR.
	 */
	cpsid i  /* PRIMASK = 1 */
    187a:	b672      	cpsid	i
#endif

	/* is this a wakeup from idle ? */
	ldr r2, =_kernel
    187c:	4a0b      	ldr	r2, [pc, #44]	; (18ac <_isr_wrapper+0x34>)
	/* requested idle duration, in ticks */
	ldr r0, [r2, #_kernel_offset_to_idle]
    187e:	6a10      	ldr	r0, [r2, #32]
	cmp r0, #0
    1880:	2800      	cmp	r0, #0
	str r1, [r2, #_kernel_offset_to_idle]
	bl z_sys_power_save_idle_exit
_idle_state_cleared:

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	ittt ne
    1882:	bf1e      	ittt	ne
	movne	r1, #0
    1884:	2100      	movne	r1, #0
		/* clear kernel idle state */
		strne	r1, [r2, #_kernel_offset_to_idle]
    1886:	6211      	strne	r1, [r2, #32]
		blne	z_sys_power_save_idle_exit
    1888:	f004 fdcf 	blne	642a <z_sys_power_save_idle_exit>
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
	cpsie i		/* re-enable interrupts (PRIMASK = 0) */
    188c:	b662      	cpsie	i
#endif

#endif /* CONFIG_SYS_POWER_MANAGEMENT */

#if defined(CONFIG_CPU_CORTEX_M)
	mrs r0, IPSR	/* get exception number */
    188e:	f3ef 8005 	mrs	r0, IPSR
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	ldr r1, =16
	subs r0, r1	/* get IRQ number */
	lsls r0, #3	/* table is 8-byte wide */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	sub r0, r0, #16	/* get IRQ number */
    1892:	f1a0 0010 	sub.w	r0, r0, #16
	lsl r0, r0, #3	/* table is 8-byte wide */
    1896:	ea4f 00c0 	mov.w	r0, r0, lsl #3
	 * interface function.
	 */
	cpsie i
#endif /* !CONFIG_CPU_CORTEX_M */

	ldr r1, =_sw_isr_table
    189a:	4905      	ldr	r1, [pc, #20]	; (18b0 <_isr_wrapper+0x38>)
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
    189c:	4401      	add	r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
    189e:	c909      	ldmia	r1!, {r0, r3}
#ifdef CONFIG_EXECUTION_BENCHMARKING
	push {r0, r3}	/* Save r0 and r3 into stack */
	bl read_timer_end_of_isr
	pop {r0, r3}	/* Restore r0 and r3 regs */
#endif /* CONFIG_EXECUTION_BENCHMARKING */
	blx r3		/* call ISR */
    18a0:	4798      	blx	r3

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	pop {r0, r3}
	mov lr, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	pop {r0, lr}
    18a2:	e8bd 4001 	ldmia.w	sp!, {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
    18a6:	4903      	ldr	r1, [pc, #12]	; (18b4 <_isr_wrapper+0x3c>)
	bx r1
    18a8:	4708      	bx	r1
    18aa:	0000      	.short	0x0000
	ldr r2, =_kernel
    18ac:	20000664 	.word	0x20000664
	ldr r1, =_sw_isr_table
    18b0:	000070e4 	.word	0x000070e4
	ldr r1, =z_arm_int_exit
    18b4:	00001d01 	.word	0x00001d01

000018b8 <z_arm_userspace_enter>:
 * z_arm_userspace_enter(user_entry, p1, p2, p3,
 *                        stack_info.start, stack_info.size);
 */
SECTION_FUNC(TEXT,z_arm_userspace_enter)
    /* move user_entry to lr */
    mov lr, r0
    18b8:	4686      	mov	lr, r0

    /* prepare to set stack to privileged stack */
    ldr r0, =_kernel
    18ba:	481e      	ldr	r0, [pc, #120]	; (1934 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    18bc:	6880      	ldr	r0, [r0, #8]
    ldr r1, =CONFIG_PRIVILEGED_STACK_SIZE
    add r0, r0, r1
    /* Restore p1 from ip */
    mov r1, ip
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r0, [r0, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    18be:	f8d0 0098 	ldr.w	r0, [r0, #152]	; 0x98
    ldr ip, =CONFIG_PRIVILEGED_STACK_SIZE
    18c2:	f44f 6c80 	mov.w	ip, #1024	; 0x400
    add r0, r0, ip
    18c6:	4460      	add	r0, ip

    /* store current stack pointer to ip
     * the current stack pointer is needed to retrieve
     * stack_info.start and stack_info.size
     */
    mov ip, sp
    18c8:	46ec      	mov	ip, sp
     * modifying PSP via MSR instruction is not subject to stack limit
     * checking, so we do not need to clear PSPLIM before setting PSP.
     * The operation is safe since, by design, the privileged stack is
     * located in memory higher than the default (user) thread stack.
     */
    msr PSP, r0
    18ca:	f380 8809 	msr	PSP, r0
    ldr r0, [r0, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    msr PSPLIM, r0
#endif

    /* push args to stack */
    push {r1,r2,r3,lr}
    18ce:	b50e      	push	{r1, r2, r3, lr}
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    mov r1, ip
    push {r0,r1}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    push {r0,ip}
    18d0:	e92d 1001 	stmdb	sp!, {r0, ip}
     *
     * Note that the risk for overflow is higher if using the normal thread
     * stack, since we do not control how much stack is actually left, when
     * user invokes z_arm_userspace_enter().
     */
    ldr r0, =_kernel
    18d4:	4817      	ldr	r0, [pc, #92]	; (1934 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    18d6:	6880      	ldr	r0, [r0, #8]
    bl z_arm_configure_dynamic_mpu_regions
    18d8:	f000 fa6e 	bl	1db8 <z_arm_configure_dynamic_mpu_regions>
    ldr r3, [r3, #4]
    mov ip, r3

    push {r0,r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r0,ip}
    18dc:	e8bd 1001 	ldmia.w	sp!, {r0, ip}

    /* load up stack info from user stack */
    ldr r0, [ip]
    18e0:	f8dc 0000 	ldr.w	r0, [ip]
    ldr ip, [ip, #4]
    18e4:	f8dc c004 	ldr.w	ip, [ip, #4]

    push {r0,ip}
    18e8:	e92d 1001 	stmdb	sp!, {r0, ip}
#endif

    /* clear the user stack area to clean out privileged data */
    /* from right past the guard right up to the end */
    mov r2, ip
    18ec:	4662      	mov	r2, ip
#ifdef CONFIG_INIT_STACKS
    ldr r1,=0xaaaaaaaa
#else
    eors.n r1, r1
    18ee:	4049      	eors	r1, r1
#endif
    bl memset
    18f0:	f004 fca7 	bl	6242 <memset>

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    pop {r0, r1}
    mov ip, r1
#elif (defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE))
    pop {r0,ip}
    18f4:	e8bd 1001 	ldmia.w	sp!, {r0, ip}
#endif

    /* r0 contains user stack start, ip contains user stack size */
    add r0, r0, ip   /* calculate top of stack */
    18f8:	4460      	add	r0, ip
    mov ip, r4
    pop {r1,r2,r3,r4}
    mov lr, r4
    mov r4, ip
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r1,r2,r3,lr}
    18fa:	e8bd 400e 	ldmia.w	sp!, {r1, r2, r3, lr}

    pop {r0, ip}
#endif

    /* set stack to user stack */
    msr PSP, r0
    18fe:	f380 8809 	msr	PSP, r0
    msr BASEPRI, ip
    isb
#endif

    /* restore r0 */
    mov r0, lr
    1902:	4670      	mov	r0, lr
    mov ip, r3
    /* Store (unprivileged) mode in thread's mode state variable */
    ldr r2, =_thread_offset_to_mode
    str r1, [r0, r2]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    push {r0, r1}
    1904:	b403      	push	{r0, r1}
    ldr r0, =_kernel
    1906:	480b      	ldr	r0, [pc, #44]	; (1934 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1908:	6880      	ldr	r0, [r0, #8]
    ldr r1, [r0, #_thread_offset_to_mode]
    190a:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    orrs r1, r1, #1
    190e:	f051 0101 	orrs.w	r1, r1, #1
    mrs ip, CONTROL
    1912:	f3ef 8c14 	mrs	ip, CONTROL
    orrs ip, ip, #1
    1916:	f05c 0c01 	orrs.w	ip, ip, #1
    /* Store (unprivileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    191a:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
#endif
    dsb
    191e:	f3bf 8f4f 	dsb	sy
    msr CONTROL, ip
    1922:	f38c 8814 	msr	CONTROL, ip

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    1926:	f3bf 8f6f 	isb	sy
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    pop {r0, r1, r2, r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r0, r1}
    192a:	bc03      	pop	{r0, r1}
    push {r0, r1}
    ldr r0, =z_thread_entry
    mov ip, r0
    pop {r0, r1}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr ip, =z_thread_entry
    192c:	f8df c008 	ldr.w	ip, [pc, #8]	; 1938 <z_arm_userspace_enter+0x80>
#endif
    bx ip
    1930:	4760      	bx	ip
    1932:	0000      	.short	0x0000
    ldr r0, =_kernel
    1934:	20000664 	.word	0x20000664
    ldr ip, =z_thread_entry
    1938:	000059df 	.word	0x000059df

0000193c <z_arm_do_syscall>:
    pop {r0, r1}

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)

    /* setup privileged stack */
    ldr ip, =_kernel
    193c:	f8df c088 	ldr.w	ip, [pc, #136]	; 19c8 <dispatch_syscall+0x5a>
    ldr ip, [ip, #_kernel_offset_to_current]
    1940:	f8dc c008 	ldr.w	ip, [ip, #8]
    ldr ip, [ip, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    1944:	f8dc c098 	ldr.w	ip, [ip, #152]	; 0x98
    add ip, #CONFIG_PRIVILEGED_STACK_SIZE
    1948:	f50c 6c80 	add.w	ip, ip, #1024	; 0x400

    /* Store current SP and LR at the beginning of the priv stack */
    subs ip, #8
    194c:	f1bc 0c08 	subs.w	ip, ip, #8
    str sp, [ip, #0]
    1950:	f8cc d000 	str.w	sp, [ip]
    str lr, [ip, #4]
    1954:	f8cc e004 	str.w	lr, [ip, #4]
#endif

    /* switch to privileged stack */
    msr PSP, ip
    1958:	f38c 8809 	msr	PSP, ip
    mov lr, r0
    /* Restore r0 */
    mov r0, ip

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr ip, =K_SYSCALL_BAD
    195c:	f240 1c0b 	movw	ip, #267	; 0x10b
    cmp r6, ip
    1960:	4566      	cmp	r6, ip
    bne valid_syscall
    1962:	d103      	bne.n	196c <valid_syscall>

    /* BAD SYSCALL path */
    /* fixup stack frame on the privileged stack, adding ssf */
    mov ip, sp
    1964:	46ec      	mov	ip, sp
    push {r4,r5,ip,lr}
    1966:	e92d 5030 	stmdb	sp!, {r4, r5, ip, lr}
    b dispatch_syscall
    196a:	e000      	b.n	196e <dispatch_syscall>

0000196c <valid_syscall>:

valid_syscall:
    /* push args to complete stack frame */
    push {r4,r5}
    196c:	b430      	push	{r4, r5}

0000196e <dispatch_syscall>:

dispatch_syscall:
    ldr ip, =_k_syscall_table
    196e:	f8df c05c 	ldr.w	ip, [pc, #92]	; 19cc <dispatch_syscall+0x5e>
    lsl r6, #2
    1972:	ea4f 0686 	mov.w	r6, r6, lsl #2
    add ip, r6
    1976:	44b4      	add	ip, r6
    ldr ip, [ip]	/* load table address */
    1978:	f8dc c000 	ldr.w	ip, [ip]
    /* execute function from dispatch table */
    blx ip
    197c:	47e0      	blx	ip

    /* restore LR */
    ldr lr, [sp,#12]
    197e:	f8dd e00c 	ldr.w	lr, [sp, #12]
    /* Restore r0 */
    mov r0, ip

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* set stack back to unprivileged stack */
    ldr ip, [sp,#8]
    1982:	f8dd c008 	ldr.w	ip, [sp, #8]
    msr PSP, ip
    1986:	f38c 8809 	msr	PSP, ip
    /* Restore interrupt lock status */
    msr BASEPRI, r2
    isb
#endif

    push {r0, r1}
    198a:	b403      	push	{r0, r1}
    mrs r2, CONTROL
    orrs r2, r2, r3
    msr CONTROL, r2
    pop {r2, r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r0, =_kernel
    198c:	480e      	ldr	r0, [pc, #56]	; (19c8 <dispatch_syscall+0x5a>)
    ldr r0, [r0, #_kernel_offset_to_current]
    198e:	6880      	ldr	r0, [r0, #8]
    ldr r1, [r0, #_thread_offset_to_mode]
    1990:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    orrs r1, r1, #1
    1994:	f051 0101 	orrs.w	r1, r1, #1
    /* Store (unprivileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    1998:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
    dsb
    199c:	f3bf 8f4f 	dsb	sy
    /* drop privileges by setting bit 0 in CONTROL */
    mrs ip, CONTROL
    19a0:	f3ef 8c14 	mrs	ip, CONTROL
    orrs ip, ip, #1
    19a4:	f05c 0c01 	orrs.w	ip, ip, #1
    msr CONTROL, ip
    19a8:	f38c 8814 	msr	CONTROL, ip

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    19ac:	f3bf 8f6f 	isb	sy
    pop {r0, r1}
    19b0:	bc03      	pop	{r0, r1}

    /* Zero out volatile (caller-saved) registers so as to not leak state from
     * kernel mode. The C calling convention for the syscall handler will
     * restore the others to original values.
     */
    mov r1, #0
    19b2:	f04f 0100 	mov.w	r1, #0
    mov r2, #0
    19b6:	f04f 0200 	mov.w	r2, #0
    mov r3, #0
    19ba:	f04f 0300 	mov.w	r3, #0

    /*
     * return back to original function that called SVC, add 1 to force thumb
     * mode
     */
    mov ip, r8
    19be:	46c4      	mov	ip, r8
    orrs ip, ip, #1
    19c0:	f05c 0c01 	orrs.w	ip, ip, #1

#endif
    bx ip
    19c4:	4760      	bx	ip
    19c6:	0000      	.short	0x0000
    ldr ip, =_kernel
    19c8:	20000664 	.word	0x20000664
    ldr ip, =_k_syscall_table
    19cc:	000072d4 	.word	0x000072d4

000019d0 <arch_user_string_nlen>:

/*
 * size_t arch_user_string_nlen(const char *s, size_t maxsize, int *err_arg)
 */
SECTION_FUNC(TEXT, arch_user_string_nlen)
    push {r0, r1, r2, r4, r5, lr}
    19d0:	b537      	push	{r0, r1, r2, r4, r5, lr}

    /* sp+4 is error value, init to -1 */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    ldr r3, =-1
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    mov.w r3, #-1
    19d2:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
#endif
    str	r3, [sp, #4]
    19d6:	9301      	str	r3, [sp, #4]

    /* Perform string length calculation */
    movs r3, #0		/* r3 is the counter */
    19d8:	2300      	movs	r3, #0

000019da <z_arm_user_string_nlen_fault_start>:

strlen_loop:
z_arm_user_string_nlen_fault_start:
    /* r0 contains the string. r5 = *(r0 + r3]). This could fault. */
    ldrb r5, [r0, r3]
    19da:	5cc5      	ldrb	r5, [r0, r3]

000019dc <z_arm_user_string_nlen_fault_end>:
z_arm_user_string_nlen_fault_end:
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cmp r5, #0
    beq strlen_done
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    cbz	r5, strlen_done
    19dc:	b11d      	cbz	r5, 19e6 <strlen_done>
#endif
    cmp	r3, r1
    19de:	428b      	cmp	r3, r1
    beq.n strlen_done
    19e0:	d001      	beq.n	19e6 <strlen_done>

    adds r3, #1
    19e2:	3301      	adds	r3, #1
    b.n	strlen_loop
    19e4:	e7f9      	b.n	19da <z_arm_user_string_nlen_fault_start>

000019e6 <strlen_done>:

strlen_done:
    /* Move length calculation from r3 to r0 (return value register) */
    mov	r0, r3
    19e6:	4618      	mov	r0, r3

    /* Clear error value since we succeeded */
    movs r1, #0
    19e8:	2100      	movs	r1, #0
    str	r1, [sp, #4]
    19ea:	9101      	str	r1, [sp, #4]

000019ec <z_arm_user_string_nlen_fixup>:

z_arm_user_string_nlen_fixup:
    /* Write error value to err pointer parameter */
    ldr	r1, [sp, #4]
    19ec:	9901      	ldr	r1, [sp, #4]
    str	r1, [r2, #0]
    19ee:	6011      	str	r1, [r2, #0]

    add	sp, #12
    19f0:	b003      	add	sp, #12
    pop	{r4, r5, pc}
    19f2:	bd30      	pop	{r4, r5, pc}

000019f4 <__start>:
 * search for a __start symbol instead, so create that alias here.
 */
SECTION_SUBSEC_FUNC(TEXT,_reset_section,__start)

#if defined(CONFIG_PLATFORM_SPECIFIC_INIT)
    bl z_platform_init
    19f4:	f004 fc55 	bl	62a2 <z_platform_init>

    /* lock interrupts: will get unlocked when switch to main task */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    19f8:	2020      	movs	r0, #32
    msr BASEPRI, r0
    19fa:	f380 8811 	msr	BASEPRI, r0

    /*
     * Set PSP and use it to boot without using MSP, so that it
     * gets set to z_interrupt_stacks during initialization.
     */
    ldr r0, =z_interrupt_stacks
    19fe:	4808      	ldr	r0, [pc, #32]	; (1a20 <__start+0x2c>)
    ldr r1, =CONFIG_ISR_STACK_SIZE
    1a00:	f44f 6100 	mov.w	r1, #2048	; 0x800
    adds r0, r0, r1
    1a04:	1840      	adds	r0, r0, r1
    msr PSP, r0
    1a06:	f380 8809 	msr	PSP, r0
    mrs r0, CONTROL
    1a0a:	f3ef 8014 	mrs	r0, CONTROL
    movs r1, #2
    1a0e:	2102      	movs	r1, #2
    orrs r0, r1 /* CONTROL_SPSEL_Msk */
    1a10:	4308      	orrs	r0, r1
    msr CONTROL, r0
    1a12:	f380 8814 	msr	CONTROL, r0
    /*
     * When changing the stack pointer, software must use an ISB instruction
     * immediately after the MSR instruction. This ensures that instructions
     * after the ISB instruction execute using the new stack pointer.
     */
    isb
    1a16:	f3bf 8f6f 	isb	sy
    /*
     * 'bl' jumps the furthest of the branch instructions that are
     * supported on all platforms. So it is used when jumping to z_arm_prep_c
     * (even though we do not intend to return).
     */
    bl z_arm_prep_c
    1a1a:	f7ff ff0b 	bl	1834 <z_arm_prep_c>
    1a1e:	0000      	.short	0x0000
    ldr r0, =z_interrupt_stacks
    1a20:	20001540 	.word	0x20001540

00001a24 <z_arm_bus_fault>:
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
SECTION_SUBSEC_FUNC(TEXT,__fault,z_arm_exc_spurious)

	mrs r0, MSP
    1a24:	f3ef 8008 	mrs	r0, MSP
	mrs r1, PSP
    1a28:	f3ef 8109 	mrs	r1, PSP
	mov r2, lr /* EXC_RETURN */
    1a2c:	4672      	mov	r2, lr

	push {r0, lr}
    1a2e:	b501      	push	{r0, lr}

	bl z_arm_fault
    1a30:	f000 f8dc 	bl	1bec <z_arm_fault>

	pop {r0, pc}
    1a34:	bd01      	pop	{r0, pc}
    1a36:	bf00      	nop

00001a38 <mem_manage_fault>:
 *
 * @return error code to identify the fatal error reason
 */
static uint32_t mem_manage_fault(z_arch_esf_t *esf, int from_hard_fault,
			      bool *recoverable)
{
    1a38:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	uint32_t mmfar = -EINVAL;

	PR_FAULT_INFO("***** MPU FAULT *****");

	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    1a3a:	4c2a      	ldr	r4, [pc, #168]	; (1ae4 <mem_manage_fault+0xac>)
{
    1a3c:	4605      	mov	r5, r0
    1a3e:	4616      	mov	r6, r2
	return arch_is_user_context();
    1a40:	f004 fb99 	bl	6176 <arch_is_user_context>
	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    1a44:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1a46:	06d8      	lsls	r0, r3, #27
    1a48:	d501      	bpl.n	1a4e <mem_manage_fault+0x16>
    1a4a:	f004 fb94 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  Stacking error (context area might be"
			" not valid)");
	}
	if ((SCB->CFSR & SCB_CFSR_MUNSTKERR_Msk) != 0) {
    1a4e:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1a50:	071a      	lsls	r2, r3, #28
    1a52:	d501      	bpl.n	1a58 <mem_manage_fault+0x20>
    1a54:	f004 fb8f 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  Unstacking error");
	}
	if ((SCB->CFSR & SCB_CFSR_DACCVIOL_Msk) != 0) {
    1a58:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1a5a:	079b      	lsls	r3, r3, #30
    1a5c:	d530      	bpl.n	1ac0 <mem_manage_fault+0x88>
    1a5e:	f004 fb8a 	bl	6176 <arch_is_user_context>
		 * The MMFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another higher
		 * priority exception might change the MMFAR value.
		 */
		mmfar = SCB->MMFAR;
    1a62:	6b62      	ldr	r2, [r4, #52]	; 0x34

		if ((SCB->CFSR & SCB_CFSR_MMARVALID_Msk) != 0) {
    1a64:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1a66:	0618      	lsls	r0, r3, #24
    1a68:	d506      	bpl.n	1a78 <mem_manage_fault+0x40>
    1a6a:	f004 fb84 	bl	6176 <arch_is_user_context>
			PR_EXC("  MMFAR Address: 0x%x", mmfar);
			if (from_hard_fault) {
    1a6e:	b119      	cbz	r1, 1a78 <mem_manage_fault+0x40>
				/* clear SCB_MMAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_MMARVALID_Msk;
    1a70:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1a72:	f023 0380 	bic.w	r3, r3, #128	; 0x80
    1a76:	62a3      	str	r3, [r4, #40]	; 0x28
			}
		}
	}
	if ((SCB->CFSR & SCB_CFSR_IACCVIOL_Msk) != 0) {
    1a78:	491a      	ldr	r1, [pc, #104]	; (1ae4 <mem_manage_fault+0xac>)
    1a7a:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a7c:	07db      	lsls	r3, r3, #31
    1a7e:	d501      	bpl.n	1a84 <mem_manage_fault+0x4c>
    1a80:	f004 fb79 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  Instruction Access Violation");
	}
#if defined(CONFIG_ARMV7_M_ARMV8_M_FP)
	if ((SCB->CFSR & SCB_CFSR_MLSPERR_Msk) != 0) {
    1a84:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a86:	069c      	lsls	r4, r3, #26
    1a88:	d501      	bpl.n	1a8e <mem_manage_fault+0x56>
    1a8a:	f004 fb74 	bl	6176 <arch_is_user_context>
	 * if the memory violation error is a stack corruption.
	 *
	 * By design, being a Stacking MemManage fault is a necessary
	 * and sufficient condition for a thread stack corruption.
	 */
	if (SCB->CFSR & SCB_CFSR_MSTKERR_Msk) {
    1a8e:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a90:	06d8      	lsls	r0, r3, #27
    1a92:	d418      	bmi.n	1ac6 <mem_manage_fault+0x8e>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    1a94:	2000      	movs	r0, #0
		"Stacking error without stack guard / User-mode support\n");
#endif /* CONFIG_MPU_STACK_GUARD || CONFIG_USERSPACE */
	}

	/* clear MMFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;
    1a96:	4a13      	ldr	r2, [pc, #76]	; (1ae4 <mem_manage_fault+0xac>)
    1a98:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1a9a:	f043 03ff 	orr.w	r3, r3, #255	; 0xff
    1a9e:	6293      	str	r3, [r2, #40]	; 0x28
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1aa0:	4b11      	ldr	r3, [pc, #68]	; (1ae8 <mem_manage_fault+0xb0>)
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1aa2:	69aa      	ldr	r2, [r5, #24]
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1aa4:	f023 0301 	bic.w	r3, r3, #1
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1aa8:	4293      	cmp	r3, r2
    1aaa:	d819      	bhi.n	1ae0 <mem_manage_fault+0xa8>
    1aac:	4b0f      	ldr	r3, [pc, #60]	; (1aec <mem_manage_fault+0xb4>)
    1aae:	f023 0301 	bic.w	r3, r3, #1
    1ab2:	4293      	cmp	r3, r2
    1ab4:	d914      	bls.n	1ae0 <mem_manage_fault+0xa8>
			esf->basic.pc = (uint32_t)(exceptions[i].fixup);
    1ab6:	4b0e      	ldr	r3, [pc, #56]	; (1af0 <mem_manage_fault+0xb8>)
    1ab8:	61ab      	str	r3, [r5, #24]
			return true;
    1aba:	2301      	movs	r3, #1

	/* Assess whether system shall ignore/recover from this MPU fault. */
	*recoverable = memory_fault_recoverable(esf);
    1abc:	7033      	strb	r3, [r6, #0]

	return reason;
}
    1abe:	bd70      	pop	{r4, r5, r6, pc}
	uint32_t mmfar = -EINVAL;
    1ac0:	f06f 0215 	mvn.w	r2, #21
    1ac4:	e7d8      	b.n	1a78 <mem_manage_fault+0x40>
		if (SCB->ICSR & SCB_ICSR_RETTOBASE_Msk) {
    1ac6:	684b      	ldr	r3, [r1, #4]
    1ac8:	051b      	lsls	r3, r3, #20
    1aca:	d5e3      	bpl.n	1a94 <mem_manage_fault+0x5c>
			uint32_t min_stack_ptr = z_check_thread_stack_fail(mmfar,
    1acc:	4629      	mov	r1, r5
    1ace:	4610      	mov	r0, r2
    1ad0:	f7ff fe5a 	bl	1788 <z_check_thread_stack_fail>
			if (min_stack_ptr) {
    1ad4:	2800      	cmp	r0, #0
    1ad6:	d0dd      	beq.n	1a94 <mem_manage_fault+0x5c>
  __ASM volatile ("MSR psp, %0" : : "r" (topOfProcStack) : );
    1ad8:	f380 8809 	msr	PSP, r0
				reason = K_ERR_STACK_CHK_FAIL;
    1adc:	2002      	movs	r0, #2
    1ade:	e7da      	b.n	1a96 <mem_manage_fault+0x5e>
	return false;
    1ae0:	2300      	movs	r3, #0
    1ae2:	e7eb      	b.n	1abc <mem_manage_fault+0x84>
    1ae4:	e000ed00 	.word	0xe000ed00
    1ae8:	000019db 	.word	0x000019db
    1aec:	000019dd 	.word	0x000019dd
    1af0:	000019ed 	.word	0x000019ed

00001af4 <usage_fault.isra.0>:
 *
 * See z_arm_fault_dump() for example.
 *
 * @return error code to identify the fatal error reason
 */
static uint32_t usage_fault(const z_arch_esf_t *esf)
    1af4:	b508      	push	{r3, lr}
    1af6:	f004 fb3e 	bl	6176 <arch_is_user_context>
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** USAGE FAULT *****");

	/* bits are sticky: they stack and must be reset */
	if ((SCB->CFSR & SCB_CFSR_DIVBYZERO_Msk) != 0) {
    1afa:	4a14      	ldr	r2, [pc, #80]	; (1b4c <usage_fault.isra.0+0x58>)
    1afc:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1afe:	0198      	lsls	r0, r3, #6
    1b00:	d501      	bpl.n	1b06 <usage_fault.isra.0+0x12>
    1b02:	f004 fb38 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  Division by zero");
	}
	if ((SCB->CFSR & SCB_CFSR_UNALIGNED_Msk) != 0) {
    1b06:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1b08:	01d9      	lsls	r1, r3, #7
    1b0a:	d501      	bpl.n	1b10 <usage_fault.isra.0+0x1c>
    1b0c:	f004 fb33 	bl	6176 <arch_is_user_context>
		 */
		reason = K_ERR_STACK_CHK_FAIL;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
	}
#endif /* CONFIG_ARMV8_M_MAINLINE */
	if ((SCB->CFSR & SCB_CFSR_NOCP_Msk) != 0) {
    1b10:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1b12:	031b      	lsls	r3, r3, #12
    1b14:	d501      	bpl.n	1b1a <usage_fault.isra.0+0x26>
    1b16:	f004 fb2e 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  No coprocessor instructions");
	}
	if ((SCB->CFSR & SCB_CFSR_INVPC_Msk) != 0) {
    1b1a:	4a0c      	ldr	r2, [pc, #48]	; (1b4c <usage_fault.isra.0+0x58>)
    1b1c:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1b1e:	0358      	lsls	r0, r3, #13
    1b20:	d501      	bpl.n	1b26 <usage_fault.isra.0+0x32>
    1b22:	f004 fb28 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  Illegal load of EXC_RETURN into PC");
	}
	if ((SCB->CFSR & SCB_CFSR_INVSTATE_Msk) != 0) {
    1b26:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1b28:	0399      	lsls	r1, r3, #14
    1b2a:	d501      	bpl.n	1b30 <usage_fault.isra.0+0x3c>
    1b2c:	f004 fb23 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  Illegal use of the EPSR");
	}
	if ((SCB->CFSR & SCB_CFSR_UNDEFINSTR_Msk) != 0) {
    1b30:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1b32:	03db      	lsls	r3, r3, #15
    1b34:	d501      	bpl.n	1b3a <usage_fault.isra.0+0x46>
    1b36:	f004 fb1e 	bl	6176 <arch_is_user_context>
		PR_FAULT_INFO("  Attempt to execute undefined instruction");
	}

	/* clear UFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    1b3a:	4a04      	ldr	r2, [pc, #16]	; (1b4c <usage_fault.isra.0+0x58>)
    1b3c:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1b3e:	ea6f 4303 	mvn.w	r3, r3, lsl #16
    1b42:	ea6f 4313 	mvn.w	r3, r3, lsr #16
    1b46:	6293      	str	r3, [r2, #40]	; 0x28

	return reason;
}
    1b48:	2000      	movs	r0, #0
    1b4a:	bd08      	pop	{r3, pc}
    1b4c:	e000ed00 	.word	0xe000ed00

00001b50 <bus_fault>:
{
    1b50:	b538      	push	{r3, r4, r5, lr}
	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    1b52:	4c22      	ldr	r4, [pc, #136]	; (1bdc <bus_fault+0x8c>)
{
    1b54:	4605      	mov	r5, r0
    1b56:	f004 fb0e 	bl	6176 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    1b5a:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1b5c:	04d8      	lsls	r0, r3, #19
    1b5e:	d501      	bpl.n	1b64 <bus_fault+0x14>
    1b60:	f004 fb09 	bl	6176 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_UNSTKERR_Msk) {
    1b64:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1b66:	051b      	lsls	r3, r3, #20
    1b68:	d501      	bpl.n	1b6e <bus_fault+0x1e>
    1b6a:	f004 fb04 	bl	6176 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_PRECISERR_Msk) {
    1b6e:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1b70:	0598      	lsls	r0, r3, #22
    1b72:	d50c      	bpl.n	1b8e <bus_fault+0x3e>
    1b74:	f004 faff 	bl	6176 <arch_is_user_context>
		STORE_xFAR(bfar, SCB->BFAR);
    1b78:	6ba3      	ldr	r3, [r4, #56]	; 0x38
		if ((SCB->CFSR & SCB_CFSR_BFARVALID_Msk) != 0) {
    1b7a:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1b7c:	041b      	lsls	r3, r3, #16
    1b7e:	d506      	bpl.n	1b8e <bus_fault+0x3e>
    1b80:	f004 faf9 	bl	6176 <arch_is_user_context>
			if (from_hard_fault) {
    1b84:	b119      	cbz	r1, 1b8e <bus_fault+0x3e>
				SCB->CFSR &= ~SCB_CFSR_BFARVALID_Msk;
    1b86:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1b88:	f423 4300 	bic.w	r3, r3, #32768	; 0x8000
    1b8c:	62a3      	str	r3, [r4, #40]	; 0x28
	if (SCB->CFSR & SCB_CFSR_IMPRECISERR_Msk) {
    1b8e:	4913      	ldr	r1, [pc, #76]	; (1bdc <bus_fault+0x8c>)
    1b90:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1b92:	055c      	lsls	r4, r3, #21
    1b94:	d501      	bpl.n	1b9a <bus_fault+0x4a>
    1b96:	f004 faee 	bl	6176 <arch_is_user_context>
	if ((SCB->CFSR & SCB_CFSR_IBUSERR_Msk) != 0) {
    1b9a:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1b9c:	05d8      	lsls	r0, r3, #23
    1b9e:	d516      	bpl.n	1bce <bus_fault+0x7e>
    1ba0:	f004 fae9 	bl	6176 <arch_is_user_context>
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
    1ba4:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1ba6:	f443 437f 	orr.w	r3, r3, #65280	; 0xff00
    1baa:	628b      	str	r3, [r1, #40]	; 0x28
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1bac:	4b0c      	ldr	r3, [pc, #48]	; (1be0 <bus_fault+0x90>)
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1bae:	69a9      	ldr	r1, [r5, #24]
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1bb0:	f023 0301 	bic.w	r3, r3, #1
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1bb4:	428b      	cmp	r3, r1
    1bb6:	d80e      	bhi.n	1bd6 <bus_fault+0x86>
    1bb8:	4b0a      	ldr	r3, [pc, #40]	; (1be4 <bus_fault+0x94>)
    1bba:	f023 0301 	bic.w	r3, r3, #1
    1bbe:	428b      	cmp	r3, r1
    1bc0:	d909      	bls.n	1bd6 <bus_fault+0x86>
			esf->basic.pc = (uint32_t)(exceptions[i].fixup);
    1bc2:	4b09      	ldr	r3, [pc, #36]	; (1be8 <bus_fault+0x98>)
    1bc4:	61ab      	str	r3, [r5, #24]
			return true;
    1bc6:	2301      	movs	r3, #1
	*recoverable = memory_fault_recoverable(esf);
    1bc8:	7013      	strb	r3, [r2, #0]
}
    1bca:	2000      	movs	r0, #0
    1bcc:	bd38      	pop	{r3, r4, r5, pc}
	} else if (SCB->CFSR & SCB_CFSR_LSPERR_Msk) {
    1bce:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1bd0:	049b      	lsls	r3, r3, #18
    1bd2:	d4e5      	bmi.n	1ba0 <bus_fault+0x50>
    1bd4:	e7e6      	b.n	1ba4 <bus_fault+0x54>
	return false;
    1bd6:	2300      	movs	r3, #0
    1bd8:	e7f6      	b.n	1bc8 <bus_fault+0x78>
    1bda:	bf00      	nop
    1bdc:	e000ed00 	.word	0xe000ed00
    1be0:	000019db 	.word	0x000019db
    1be4:	000019dd 	.word	0x000019dd
    1be8:	000019ed 	.word	0x000019ed

00001bec <z_arm_fault>:
 * @param psp PSP value immediately after the exception occurred
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 *
 */
void z_arm_fault(uint32_t msp, uint32_t psp, uint32_t exc_return)
{
    1bec:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    1bee:	4b3c      	ldr	r3, [pc, #240]	; (1ce0 <z_arm_fault+0xf4>)
    1bf0:	685c      	ldr	r4, [r3, #4]
{
    1bf2:	b08a      	sub	sp, #40	; 0x28
    1bf4:	460d      	mov	r5, r1
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    1bf6:	f3c4 0408 	ubfx	r4, r4, #0, #9
    1bfa:	2600      	movs	r6, #0
    1bfc:	f386 8811 	msr	BASEPRI, r6
    1c00:	f3bf 8f6f 	isb	sy
	if ((exc_return & EXC_RETURN_INDICATOR_PREFIX) !=
    1c04:	f002 437f 	and.w	r3, r2, #4278190080	; 0xff000000
    1c08:	f1b3 4f7f 	cmp.w	r3, #4278190080	; 0xff000000
    1c0c:	d105      	bne.n	1c1a <z_arm_fault+0x2e>
	if ((exc_return & EXC_RETURN_MODE_THREAD) &&
    1c0e:	f002 030c 	and.w	r3, r2, #12
    1c12:	2b08      	cmp	r3, #8
    1c14:	d103      	bne.n	1c1e <z_arm_fault+0x32>
    1c16:	f004 faae 	bl	6176 <arch_is_user_context>
		return NULL;
    1c1a:	4635      	mov	r5, r6
    1c1c:	e003      	b.n	1c26 <z_arm_fault+0x3a>
		if (exc_return & EXC_RETURN_MODE_THREAD) {
    1c1e:	0712      	lsls	r2, r2, #28
    1c20:	d401      	bmi.n	1c26 <z_arm_fault+0x3a>
			ptr_esf = (z_arch_esf_t *)msp;
    1c22:	4605      	mov	r5, r0
			*nested_exc = true;
    1c24:	2601      	movs	r6, #1
	*recoverable = false;
    1c26:	2200      	movs	r2, #0
    1c28:	1ee3      	subs	r3, r4, #3
    1c2a:	f88d 2007 	strb.w	r2, [sp, #7]
	switch (fault) {
    1c2e:	2b03      	cmp	r3, #3
    1c30:	d80c      	bhi.n	1c4c <z_arm_fault+0x60>
    1c32:	e8df f003 	tbb	[pc, r3]
    1c36:	4802      	.short	0x4802
    1c38:	454c      	.short	0x454c
    1c3a:	f004 fa9c 	bl	6176 <arch_is_user_context>
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    1c3e:	4b28      	ldr	r3, [pc, #160]	; (1ce0 <z_arm_fault+0xf4>)
	*recoverable = false;
    1c40:	f88d 2007 	strb.w	r2, [sp, #7]
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    1c44:	6adc      	ldr	r4, [r3, #44]	; 0x2c
    1c46:	f014 0402 	ands.w	r4, r4, #2
    1c4a:	d003      	beq.n	1c54 <z_arm_fault+0x68>
    1c4c:	f004 fa93 	bl	6176 <arch_is_user_context>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    1c50:	2400      	movs	r4, #0
}
    1c52:	e00e      	b.n	1c72 <z_arm_fault+0x86>
	} else if ((SCB->HFSR & SCB_HFSR_FORCED_Msk) != 0) {
    1c54:	6adb      	ldr	r3, [r3, #44]	; 0x2c
    1c56:	005b      	lsls	r3, r3, #1
    1c58:	d50b      	bpl.n	1c72 <z_arm_fault+0x86>
    1c5a:	f004 fa8c 	bl	6176 <arch_is_user_context>
		if (SCB_MMFSR != 0) {
    1c5e:	4b21      	ldr	r3, [pc, #132]	; (1ce4 <z_arm_fault+0xf8>)
    1c60:	781b      	ldrb	r3, [r3, #0]
    1c62:	b1f3      	cbz	r3, 1ca2 <z_arm_fault+0xb6>
			reason = mem_manage_fault(esf, 1, recoverable);
    1c64:	f10d 0207 	add.w	r2, sp, #7
    1c68:	2101      	movs	r1, #1
		reason = mem_manage_fault(esf, 0, recoverable);
    1c6a:	4628      	mov	r0, r5
    1c6c:	f7ff fee4 	bl	1a38 <mem_manage_fault>
		reason = usage_fault(esf);
    1c70:	4604      	mov	r4, r0
	 esf = get_esf(msp, psp, exc_return, &nested_exc);
	__ASSERT(esf != NULL,
		"ESF could not be retrieved successfully. Shall never occur.");

	reason = fault_handle(esf, fault, &recoverable);
	if (recoverable) {
    1c72:	f89d 3007 	ldrb.w	r3, [sp, #7]
    1c76:	b993      	cbnz	r3, 1c9e <z_arm_fault+0xb2>
		return;
	}

	/* Copy ESF */
	memcpy(&esf_copy, esf, sizeof(z_arch_esf_t));
    1c78:	2220      	movs	r2, #32
    1c7a:	4629      	mov	r1, r5
    1c7c:	a802      	add	r0, sp, #8
    1c7e:	f004 fab5 	bl	61ec <memcpy>
	/* Overwrite stacked IPSR to mark a nested exception,
	 * or a return to Thread mode. Note that this may be
	 * required, if the retrieved ESF contents are invalid
	 * due to, for instance, a stacking error.
	 */
	if (nested_exc) {
    1c82:	9b09      	ldr	r3, [sp, #36]	; 0x24
    1c84:	b33e      	cbz	r6, 1cd6 <z_arm_fault+0xea>
		if ((esf_copy.basic.xpsr & IPSR_ISR_Msk) == 0) {
    1c86:	f3c3 0208 	ubfx	r2, r3, #0, #9
    1c8a:	b922      	cbnz	r2, 1c96 <z_arm_fault+0xaa>
			esf_copy.basic.xpsr |= IPSR_ISR_Msk;
    1c8c:	ea6f 2353 	mvn.w	r3, r3, lsr #9
    1c90:	ea6f 2343 	mvn.w	r3, r3, lsl #9
		}
	} else {
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    1c94:	9309      	str	r3, [sp, #36]	; 0x24
	}

	z_arm_fatal_error(reason, &esf_copy);
    1c96:	a902      	add	r1, sp, #8
    1c98:	4620      	mov	r0, r4
    1c9a:	f004 fa3b 	bl	6114 <z_arm_fatal_error>
}
    1c9e:	b00a      	add	sp, #40	; 0x28
    1ca0:	bd70      	pop	{r4, r5, r6, pc}
		} else if (SCB_BFSR != 0) {
    1ca2:	4b11      	ldr	r3, [pc, #68]	; (1ce8 <z_arm_fault+0xfc>)
    1ca4:	781b      	ldrb	r3, [r3, #0]
    1ca6:	b133      	cbz	r3, 1cb6 <z_arm_fault+0xca>
			reason = bus_fault(esf, 1, recoverable);
    1ca8:	f10d 0207 	add.w	r2, sp, #7
    1cac:	2101      	movs	r1, #1
		reason = bus_fault(esf, 0, recoverable);
    1cae:	4628      	mov	r0, r5
    1cb0:	f7ff ff4e 	bl	1b50 <bus_fault>
    1cb4:	e7dc      	b.n	1c70 <z_arm_fault+0x84>
		} else if (SCB_UFSR != 0) {
    1cb6:	4b0d      	ldr	r3, [pc, #52]	; (1cec <z_arm_fault+0x100>)
    1cb8:	881b      	ldrh	r3, [r3, #0]
    1cba:	b29b      	uxth	r3, r3
    1cbc:	2b00      	cmp	r3, #0
    1cbe:	d0d8      	beq.n	1c72 <z_arm_fault+0x86>
		reason = usage_fault(esf);
    1cc0:	f7ff ff18 	bl	1af4 <usage_fault.isra.0>
    1cc4:	e7d4      	b.n	1c70 <z_arm_fault+0x84>
		reason = mem_manage_fault(esf, 0, recoverable);
    1cc6:	f10d 0207 	add.w	r2, sp, #7
    1cca:	2100      	movs	r1, #0
    1ccc:	e7cd      	b.n	1c6a <z_arm_fault+0x7e>
		reason = bus_fault(esf, 0, recoverable);
    1cce:	f10d 0207 	add.w	r2, sp, #7
    1cd2:	2100      	movs	r1, #0
    1cd4:	e7eb      	b.n	1cae <z_arm_fault+0xc2>
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    1cd6:	f423 73ff 	bic.w	r3, r3, #510	; 0x1fe
    1cda:	f023 0301 	bic.w	r3, r3, #1
    1cde:	e7d9      	b.n	1c94 <z_arm_fault+0xa8>
    1ce0:	e000ed00 	.word	0xe000ed00
    1ce4:	e000ed28 	.word	0xe000ed28
    1ce8:	e000ed29 	.word	0xe000ed29
    1cec:	e000ed2a 	.word	0xe000ed2a

00001cf0 <z_arm_fault_init>:
 */
void z_arm_fault_init(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	SCB->CCR |= SCB_CCR_DIV_0_TRP_Msk;
    1cf0:	4a02      	ldr	r2, [pc, #8]	; (1cfc <z_arm_fault_init+0xc>)
    1cf2:	6953      	ldr	r3, [r2, #20]
    1cf4:	f043 0310 	orr.w	r3, r3, #16
    1cf8:	6153      	str	r3, [r2, #20]
	 * Stack to attempt to descend into secure region, in which case a
	 * Secure Hard Fault will occur and we can track the fault from there.
	 */
	SCB->CCR |= SCB_CCR_STKOFHFNMIGN_Msk;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
}
    1cfa:	4770      	bx	lr
    1cfc:	e000ed00 	.word	0xe000ed00

00001d00 <z_arm_exc_exit>:
 */

SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)

#ifdef CONFIG_PREEMPT_ENABLED
	ldr r3, =_kernel
    1d00:	4b04      	ldr	r3, [pc, #16]	; (1d14 <_EXIT_EXC+0x2>)

	ldr r1, [r3, #_kernel_offset_to_current]
    1d02:	6899      	ldr	r1, [r3, #8]
	ldr r0, [r3, #_kernel_offset_to_ready_q_cache]
    1d04:	6a58      	ldr	r0, [r3, #36]	; 0x24
	cmp r0, r1
    1d06:	4288      	cmp	r0, r1
	beq _EXIT_EXC
    1d08:	d003      	beq.n	1d12 <_EXIT_EXC>

	/* context switch required, pend the PendSV exception */
	ldr r1, =_SCS_ICSR
    1d0a:	4903      	ldr	r1, [pc, #12]	; (1d18 <_EXIT_EXC+0x6>)
	ldr r2, =_SCS_ICSR_PENDSV
    1d0c:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
	str r2, [r1]
    1d10:	600a      	str	r2, [r1, #0]

00001d12 <_EXIT_EXC>:
#else
	pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_STACK_SENTINEL */

	bx lr
    1d12:	4770      	bx	lr
	ldr r3, =_kernel
    1d14:	20000664 	.word	0x20000664
	ldr r1, =_SCS_ICSR
    1d18:	e000ed04 	.word	0xe000ed04

00001d1c <z_arm_interrupt_init>:
    1d1c:	4804      	ldr	r0, [pc, #16]	; (1d30 <z_arm_interrupt_init+0x14>)
 * @return N/A
 */

void z_arm_interrupt_init(void)
{
	int irq = 0;
    1d1e:	2300      	movs	r3, #0
    1d20:	2120      	movs	r1, #32
    1d22:	18c2      	adds	r2, r0, r3

	for (; irq < CONFIG_NUM_IRQS; irq++) {
    1d24:	3301      	adds	r3, #1
    1d26:	2b27      	cmp	r3, #39	; 0x27
    1d28:	f882 1300 	strb.w	r1, [r2, #768]	; 0x300
    1d2c:	d1f9      	bne.n	1d22 <z_arm_interrupt_init+0x6>
		NVIC_SetPriority((IRQn_Type)irq, _IRQ_PRIO_OFFSET);
	}
}
    1d2e:	4770      	bx	lr
    1d30:	e000e100 	.word	0xe000e100

00001d34 <z_impl_k_thread_abort>:
#include <sys/__assert.h>

extern void z_thread_single_abort(struct k_thread *thread);

void z_impl_k_thread_abort(k_tid_t thread)
{
    1d34:	b538      	push	{r3, r4, r5, lr}
    1d36:	4604      	mov	r4, r0
	__asm__ volatile(
    1d38:	f04f 0320 	mov.w	r3, #32
    1d3c:	f3ef 8511 	mrs	r5, BASEPRI
    1d40:	f383 8811 	msr	BASEPRI, r3
    1d44:	f3bf 8f6f 	isb	sy
	key = irq_lock();

	__ASSERT(!(thread->base.user_options & K_ESSENTIAL),
		 "essential thread aborted");

	z_thread_single_abort(thread);
    1d48:	f002 f8fe 	bl	3f48 <z_thread_single_abort>
	z_thread_monitor_exit(thread);

	if (_current == thread) {
    1d4c:	4b0a      	ldr	r3, [pc, #40]	; (1d78 <z_impl_k_thread_abort+0x44>)
    1d4e:	689b      	ldr	r3, [r3, #8]
    1d50:	42a3      	cmp	r3, r4
    1d52:	d10b      	bne.n	1d6c <z_impl_k_thread_abort+0x38>
		if ((SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk) == 0) {
    1d54:	4b09      	ldr	r3, [pc, #36]	; (1d7c <z_impl_k_thread_abort+0x48>)
    1d56:	685a      	ldr	r2, [r3, #4]
    1d58:	f3c2 0208 	ubfx	r2, r2, #0, #9
    1d5c:	b912      	cbnz	r2, 1d64 <z_impl_k_thread_abort+0x30>
	int ret;
	z_check_stack_sentinel();
#ifndef CONFIG_ARM
	sys_trace_thread_switched_out();
#endif
	ret = arch_swap(key);
    1d5e:	4628      	mov	r0, r5
    1d60:	f7ff fc1a 	bl	1598 <arch_swap>
			(void)z_swap_irqlock(key);
			CODE_UNREACHABLE;
		} else {
			SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    1d64:	685a      	ldr	r2, [r3, #4]
    1d66:	f042 5280 	orr.w	r2, r2, #268435456	; 0x10000000
    1d6a:	605a      	str	r2, [r3, #4]
		}
	}

	/* The abort handler might have altered the ready queue. */
	z_reschedule_irqlock(key);
    1d6c:	4628      	mov	r0, r5
}
    1d6e:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule_irqlock(key);
    1d72:	f004 bce6 	b.w	6742 <z_reschedule_irqlock>
    1d76:	bf00      	nop
    1d78:	20000664 	.word	0x20000664
    1d7c:	e000ed00 	.word	0xe000ed00

00001d80 <z_arm_configure_static_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_static_mpu_regions(void)
{
    1d80:	b51f      	push	{r0, r1, r2, r3, r4, lr}
		.size = (uint32_t)&_nocache_ram_size,
		.attr = K_MEM_PARTITION_P_RW_U_NA_NOCACHE,
		};
#endif /* CONFIG_NOCACHE_MEMORY */
#if defined(CONFIG_ARCH_HAS_RAMFUNC_SUPPORT)
		const struct k_mem_partition ramfunc_region =
    1d82:	4b08      	ldr	r3, [pc, #32]	; (1da4 <z_arm_configure_static_mpu_regions+0x24>)
    1d84:	9301      	str	r3, [sp, #4]
    1d86:	4b08      	ldr	r3, [pc, #32]	; (1da8 <z_arm_configure_static_mpu_regions+0x28>)
    1d88:	9302      	str	r3, [sp, #8]
    1d8a:	4b08      	ldr	r3, [pc, #32]	; (1dac <z_arm_configure_static_mpu_regions+0x2c>)
    1d8c:	9303      	str	r3, [sp, #12]

	/* Define a constant array of k_mem_partition objects
	 * to hold the configuration of the respective static
	 * MPU regions.
	 */
	const struct k_mem_partition *static_regions[] = {
    1d8e:	ab01      	add	r3, sp, #4
    1d90:	9300      	str	r3, [sp, #0]
	/* Configure the static MPU regions within firmware SRAM boundaries.
	 * Start address of the image is given by _image_ram_start. The end
	 * of the firmware SRAM area is marked by __kernel_ram_end, taking
	 * into account the unused SRAM area, as well.
	 */
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    1d92:	4a07      	ldr	r2, [pc, #28]	; (1db0 <z_arm_configure_static_mpu_regions+0x30>)
    1d94:	4b07      	ldr	r3, [pc, #28]	; (1db4 <z_arm_configure_static_mpu_regions+0x34>)
    1d96:	2101      	movs	r1, #1
    1d98:	4668      	mov	r0, sp
    1d9a:	f000 f93d 	bl	2018 <arm_core_mpu_configure_static_mpu_regions>
	};

	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
		ARRAY_SIZE(dyn_region_areas));
#endif /* CONFIG_MPU_REQUIRES_NON_OVERLAPPING_REGIONS */
}
    1d9e:	b005      	add	sp, #20
    1da0:	f85d fb04 	ldr.w	pc, [sp], #4
    1da4:	20000000 	.word	0x20000000
    1da8:	00000000 	.word	0x00000000
    1dac:	060b0000 	.word	0x060b0000
    1db0:	20000000 	.word	0x20000000
    1db4:	20010000 	.word	0x20010000

00001db8 <z_arm_configure_dynamic_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_dynamic_mpu_regions(struct k_thread *thread)
{
    1db8:	b570      	push	{r4, r5, r6, lr}
    1dba:	4604      	mov	r4, r0
    1dbc:	b094      	sub	sp, #80	; 0x50
    1dbe:	f004 f9e4 	bl	618a <arch_is_user_context>
#if defined(CONFIG_USERSPACE)
	struct k_mem_partition thread_stack;

	/* Memory domain */
	LOG_DBG("configure thread %p's domain", thread);
	struct k_mem_domain *mem_domain = thread->mem_domain_info.mem_domain;
    1dc2:	6fe1      	ldr	r1, [r4, #124]	; 0x7c

	if (mem_domain) {
    1dc4:	b1d1      	cbz	r1, 1dfc <z_arm_configure_dynamic_mpu_regions+0x44>
    1dc6:	f004 f9e0 	bl	618a <arch_is_user_context>
		LOG_DBG("configure domain: %p", mem_domain);
		uint32_t num_partitions = mem_domain->num_partitions;
    1dca:	f891 50c8 	ldrb.w	r5, [r1, #200]	; 0xc8
    1dce:	f004 f9dc 	bl	618a <arch_is_user_context>
		struct k_mem_partition partition;
		int i;

		LOG_DBG("configure domain: %p", mem_domain);

		for (i = 0; i < CONFIG_MAX_DOMAIN_PARTITIONS; i++) {
    1dd2:	460a      	mov	r2, r1
    1dd4:	f101 06c0 	add.w	r6, r1, #192	; 0xc0
	uint8_t region_num = 0U;
    1dd8:	2100      	movs	r1, #0
			partition = mem_domain->partitions[i];
			if (partition.size == 0) {
    1dda:	6853      	ldr	r3, [r2, #4]
    1ddc:	b15b      	cbz	r3, 1df6 <z_arm_configure_dynamic_mpu_regions+0x3e>
    1dde:	f004 f9d4 	bl	618a <arch_is_user_context>
			}
			LOG_DBG("set region 0x%lx 0x%x",
				partition.start, partition.size);
			__ASSERT(region_num < _MAX_DYNAMIC_MPU_REGIONS_NUM,
				"Out-of-bounds error for dynamic region map.");
			dynamic_regions[region_num] =
    1de2:	ab14      	add	r3, sp, #80	; 0x50
    1de4:	eb03 0381 	add.w	r3, r3, r1, lsl #2
				&mem_domain->partitions[i];

			region_num++;
			num_partitions--;
			if (num_partitions == 0U) {
    1de8:	3d01      	subs	r5, #1
			region_num++;
    1dea:	f101 0101 	add.w	r1, r1, #1
			dynamic_regions[region_num] =
    1dee:	f843 2c44 	str.w	r2, [r3, #-68]
			region_num++;
    1df2:	b2c9      	uxtb	r1, r1
			if (num_partitions == 0U) {
    1df4:	d002      	beq.n	1dfc <z_arm_configure_dynamic_mpu_regions+0x44>
		for (i = 0; i < CONFIG_MAX_DOMAIN_PARTITIONS; i++) {
    1df6:	320c      	adds	r2, #12
    1df8:	4296      	cmp	r6, r2
    1dfa:	d1ee      	bne.n	1dda <z_arm_configure_dynamic_mpu_regions+0x22>
    1dfc:	f004 f9c5 	bl	618a <arch_is_user_context>
			}
		}
	}
	/* Thread user stack */
	LOG_DBG("configure user thread %p's context", thread);
	if (thread->arch.priv_stack_start) {
    1e00:	f8d4 3098 	ldr.w	r3, [r4, #152]	; 0x98
    1e04:	b183      	cbz	r3, 1e28 <z_arm_configure_dynamic_mpu_regions+0x70>
		/* K_USER thread stack needs a region */
		uint32_t base = (uint32_t)thread->stack_obj;
		uint32_t size = thread->stack_info.size +
    1e06:	e9d4 031a 	ldrd	r0, r3, [r4, #104]	; 0x68
		uint32_t base = (uint32_t)thread->stack_obj;
    1e0a:	f8d4 2080 	ldr.w	r2, [r4, #128]	; 0x80
		uint32_t size = thread->stack_info.size +
    1e0e:	4403      	add	r3, r0
    1e10:	1a9b      	subs	r3, r3, r2
			(thread->stack_info.start - base);

		__ASSERT(region_num < _MAX_DYNAMIC_MPU_REGIONS_NUM,
			"Out-of-bounds error for dynamic region map.");
		thread_stack = (const struct k_mem_partition)
    1e12:	e9cd 2300 	strd	r2, r3, [sp]
    1e16:	4b07      	ldr	r3, [pc, #28]	; (1e34 <z_arm_configure_dynamic_mpu_regions+0x7c>)
    1e18:	9302      	str	r3, [sp, #8]
			{base, size, K_MEM_PARTITION_P_RW_U_RW};

		dynamic_regions[region_num] = &thread_stack;
    1e1a:	ab14      	add	r3, sp, #80	; 0x50
    1e1c:	eb03 0381 	add.w	r3, r3, r1, lsl #2

		region_num++;
    1e20:	3101      	adds	r1, #1
		dynamic_regions[region_num] = &thread_stack;
    1e22:	f843 dc44 	str.w	sp, [r3, #-68]
		region_num++;
    1e26:	b2c9      	uxtb	r1, r1

	region_num++;
#endif /* CONFIG_MPU_STACK_GUARD */

	/* Configure the dynamic MPU regions */
	arm_core_mpu_configure_dynamic_mpu_regions(
    1e28:	a803      	add	r0, sp, #12
    1e2a:	f000 f91b 	bl	2064 <arm_core_mpu_configure_dynamic_mpu_regions>
		(const struct k_mem_partition **)dynamic_regions,
		region_num);
}
    1e2e:	b014      	add	sp, #80	; 0x50
    1e30:	bd70      	pop	{r4, r5, r6, pc}
    1e32:	bf00      	nop
    1e34:	130b0000 	.word	0x130b0000

00001e38 <arch_mem_domain_thread_add>:
	return ARM_CORE_MPU_MAX_DOMAIN_PARTITIONS_GET(available_regions);
}

void arch_mem_domain_thread_add(struct k_thread *thread)
{
	if (_current != thread) {
    1e38:	4b03      	ldr	r3, [pc, #12]	; (1e48 <arch_mem_domain_thread_add+0x10>)
    1e3a:	689b      	ldr	r3, [r3, #8]
    1e3c:	4283      	cmp	r3, r0
    1e3e:	d101      	bne.n	1e44 <arch_mem_domain_thread_add+0xc>

	/* Request to configure memory domain for a thread.
	 * This triggers re-programming of the entire dynamic
	 * memory map.
	 */
	z_arm_configure_dynamic_mpu_regions(thread);
    1e40:	f7ff bfba 	b.w	1db8 <z_arm_configure_dynamic_mpu_regions>
}
    1e44:	4770      	bx	lr
    1e46:	bf00      	nop
    1e48:	20000664 	.word	0x20000664

00001e4c <is_enabled_region>:
    1e4c:	f04f 0320 	mov.w	r3, #32
    1e50:	f3ef 8211 	mrs	r2, BASEPRI
    1e54:	f383 8811 	msr	BASEPRI, r3
    1e58:	f3bf 8f6f 	isb	sy
	/* Lock IRQs to ensure RNR value is correct when reading RASR. */
	unsigned int key;
	uint32_t rasr;

	key = irq_lock();
	MPU->RNR = index;
    1e5c:	4b04      	ldr	r3, [pc, #16]	; (1e70 <is_enabled_region+0x24>)
    1e5e:	6098      	str	r0, [r3, #8]
	rasr = MPU->RASR;
    1e60:	6918      	ldr	r0, [r3, #16]
	__asm__ volatile(
    1e62:	f382 8811 	msr	BASEPRI, r2
    1e66:	f3bf 8f6f 	isb	sy
	irq_unlock(key);

	return (rasr & MPU_RASR_ENABLE_Msk) ? 1 : 0;
}
    1e6a:	f000 0001 	and.w	r0, r0, #1
    1e6e:	4770      	bx	lr
    1e70:	e000ed90 	.word	0xe000ed90

00001e74 <mpu_configure_region>:
/* This internal function programs an MPU region
 * of a given configuration at a given MPU index.
 */
static int mpu_configure_region(const uint8_t index,
	const struct k_mem_partition *new_region)
{
    1e74:	b538      	push	{r3, r4, r5, lr}
    1e76:	4604      	mov	r4, r0
    1e78:	f004 f998 	bl	61ac <arch_is_user_context>

	LOG_DBG("Configure MPU region at index 0x%x", index);

	/* Populate internal ARM MPU region configuration structure. */
	region_conf.base = new_region->start;
	get_region_attr_from_k_mem_partition_info(&region_conf.attr,
    1e7c:	e9d1 5300 	ldrd	r5, r3, [r1]
	if (size <= 32U) {
    1e80:	2b20      	cmp	r3, #32
    1e82:	6889      	ldr	r1, [r1, #8]
    1e84:	d912      	bls.n	1eac <mpu_configure_region+0x38>
	if (size > (1UL << 31)) {
    1e86:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
    1e8a:	d811      	bhi.n	1eb0 <mpu_configure_region+0x3c>
	return ((32 - __builtin_clz(size - 1) - 2 + 1) << MPU_RASR_SIZE_Pos) &
    1e8c:	3b01      	subs	r3, #1
    1e8e:	fab3 f383 	clz	r3, r3
    1e92:	f1c3 031f 	rsb	r3, r3, #31
    1e96:	005b      	lsls	r3, r3, #1
	if (index > (get_num_regions() - 1)) {
    1e98:	2c07      	cmp	r4, #7
	p_attr->rasr = attr->rasr_attr | size_to_mpu_rasr_size(size);
    1e9a:	ea41 0103 	orr.w	r1, r1, r3
    1e9e:	d909      	bls.n	1eb4 <mpu_configure_region+0x40>
    1ea0:	f004 f984 	bl	61ac <arch_is_user_context>
		return -EINVAL;
    1ea4:	f06f 0415 	mvn.w	r4, #21
		&new_region->attr, new_region->start, new_region->size);

	/* Allocate and program region */
	return region_allocate_and_init(index,
		(const struct arm_mpu_region *)&region_conf);
}
    1ea8:	4620      	mov	r0, r4
    1eaa:	bd38      	pop	{r3, r4, r5, pc}
		return REGION_32B;
    1eac:	2308      	movs	r3, #8
    1eae:	e7f3      	b.n	1e98 <mpu_configure_region+0x24>
		return REGION_4G;
    1eb0:	233e      	movs	r3, #62	; 0x3e
    1eb2:	e7f1      	b.n	1e98 <mpu_configure_region+0x24>
    1eb4:	f004 f97a 	bl	61ac <arch_is_user_context>
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1eb8:	f025 051f 	bic.w	r5, r5, #31
	MPU->RNR = index;
    1ebc:	4805      	ldr	r0, [pc, #20]	; (1ed4 <mpu_configure_region+0x60>)
				| MPU_RBAR_VALID_Msk | index;
    1ebe:	4325      	orrs	r5, r4
    1ec0:	f045 0510 	orr.w	r5, r5, #16
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1ec4:	f041 0101 	orr.w	r1, r1, #1
	MPU->RNR = index;
    1ec8:	6084      	str	r4, [r0, #8]
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1eca:	60c5      	str	r5, [r0, #12]
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1ecc:	6101      	str	r1, [r0, #16]
    1ece:	f004 f96d 	bl	61ac <arch_is_user_context>
	return region_allocate_and_init(index,
    1ed2:	e7e9      	b.n	1ea8 <mpu_configure_region+0x34>
    1ed4:	e000ed90 	.word	0xe000ed90

00001ed8 <arm_core_mpu_enable>:
void arm_core_mpu_enable(void)
{
	/* Enable MPU and use the default memory map as a
	 * background region for privileged software access.
	 */
	MPU->CTRL = MPU_CTRL_ENABLE_Msk | MPU_CTRL_PRIVDEFENA_Msk;
    1ed8:	4b03      	ldr	r3, [pc, #12]	; (1ee8 <arm_core_mpu_enable+0x10>)
    1eda:	2205      	movs	r2, #5
    1edc:	605a      	str	r2, [r3, #4]
  __ASM volatile ("dsb 0xF":::"memory");
    1ede:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    1ee2:	f3bf 8f6f 	isb	sy

	/* Make sure that all the registers are set before proceeding */
	__DSB();
	__ISB();
}
    1ee6:	4770      	bx	lr
    1ee8:	e000ed90 	.word	0xe000ed90

00001eec <arm_core_mpu_disable>:
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
    1eec:	f3bf 8f5f 	dmb	sy
{
	/* Force any outstanding transfers to complete before disabling MPU */
	__DMB();

	/* Disable MPU */
	MPU->CTRL = 0;
    1ef0:	4b01      	ldr	r3, [pc, #4]	; (1ef8 <arm_core_mpu_disable+0xc>)
    1ef2:	2200      	movs	r2, #0
    1ef4:	605a      	str	r2, [r3, #4]
}
    1ef6:	4770      	bx	lr
    1ef8:	e000ed90 	.word	0xe000ed90

00001efc <arm_mpu_init>:
 */
static int arm_mpu_init(struct device *arg)
{
	uint32_t r_index;

	if (mpu_config.num_regions > get_num_regions()) {
    1efc:	4915      	ldr	r1, [pc, #84]	; (1f54 <arm_mpu_init+0x58>)
{
    1efe:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (mpu_config.num_regions > get_num_regions()) {
    1f00:	680c      	ldr	r4, [r1, #0]
    1f02:	2c08      	cmp	r4, #8
    1f04:	d822      	bhi.n	1f4c <arm_mpu_init+0x50>
	MPU->RNR = index;
    1f06:	4d14      	ldr	r5, [pc, #80]	; (1f58 <arm_mpu_init+0x5c>)
    1f08:	f004 f950 	bl	61ac <arch_is_user_context>
	/* Architecture-specific configuration */
	mpu_init();

	/* Program fixed regions configured at SOC definition. */
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    1f0c:	260c      	movs	r6, #12
	arm_core_mpu_disable();
    1f0e:	f7ff ffed 	bl	1eec <arm_core_mpu_disable>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    1f12:	2200      	movs	r2, #0
    1f14:	4294      	cmp	r4, r2
    1f16:	d105      	bne.n	1f24 <arm_mpu_init+0x28>
	}

	/* Update the number of programmed MPU regions. */
	static_regions_num = mpu_config.num_regions;
    1f18:	4b10      	ldr	r3, [pc, #64]	; (1f5c <arm_mpu_init+0x60>)
    1f1a:	701c      	strb	r4, [r3, #0]


	arm_core_mpu_enable();
    1f1c:	f7ff ffdc 	bl	1ed8 <arm_core_mpu_enable>
	__ASSERT(
		(MPU->TYPE & MPU_TYPE_DREGION_Msk) >> MPU_TYPE_DREGION_Pos ==
		NUM_MPU_REGIONS,
		"Invalid number of MPU regions\n");
#endif /* CORTEX_M0PLUS || CPU_CORTEX_M3 || CPU_CORTEX_M4 */
	return 0;
    1f20:	2000      	movs	r0, #0
}
    1f22:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    1f24:	fb06 f302 	mul.w	r3, r6, r2
    1f28:	6848      	ldr	r0, [r1, #4]
    1f2a:	60aa      	str	r2, [r5, #8]
    1f2c:	18c7      	adds	r7, r0, r3
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1f2e:	58c3      	ldr	r3, [r0, r3]
    1f30:	f023 031f 	bic.w	r3, r3, #31
				| MPU_RBAR_VALID_Msk | index;
    1f34:	4313      	orrs	r3, r2
    1f36:	f043 0310 	orr.w	r3, r3, #16
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1f3a:	60eb      	str	r3, [r5, #12]
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1f3c:	68bb      	ldr	r3, [r7, #8]
    1f3e:	f043 0301 	orr.w	r3, r3, #1
    1f42:	612b      	str	r3, [r5, #16]
    1f44:	f004 f932 	bl	61ac <arch_is_user_context>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    1f48:	3201      	adds	r2, #1
    1f4a:	e7e3      	b.n	1f14 <arm_mpu_init+0x18>
		return -1;
    1f4c:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    1f50:	e7e7      	b.n	1f22 <arm_mpu_init+0x26>
    1f52:	bf00      	nop
    1f54:	00007258 	.word	0x00007258
    1f58:	e000ed90 	.word	0xe000ed90
    1f5c:	200013f1 	.word	0x200013f1

00001f60 <arm_core_mpu_get_max_available_dyn_regions>:
	return get_num_regions() - static_regions_num;
    1f60:	4b02      	ldr	r3, [pc, #8]	; (1f6c <arm_core_mpu_get_max_available_dyn_regions+0xc>)
    1f62:	7818      	ldrb	r0, [r3, #0]
}
    1f64:	f1c0 0008 	rsb	r0, r0, #8
    1f68:	4770      	bx	lr
    1f6a:	bf00      	nop
    1f6c:	200013f1 	.word	0x200013f1

00001f70 <arm_core_mpu_buffer_validate>:
{
    1f70:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    1f74:	2900      	cmp	r1, #0
	/* Lock IRQs to ensure RNR value is correct when reading RBAR, RASR. */
	unsigned int key;
	uint32_t rbar, rasr;

	key = irq_lock();
	MPU->RNR = r_index;
    1f76:	4e27      	ldr	r6, [pc, #156]	; (2014 <arm_core_mpu_buffer_validate+0xa4>)
	r_addr_start = rbar & MPU_RBAR_ADDR_Msk;
	r_size_lshift = ((rasr & MPU_RASR_SIZE_Msk) >>
			MPU_RASR_SIZE_Pos) + 1;
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;

	size = size == 0 ? 0 : size - 1;
    1f78:	f101 35ff 	add.w	r5, r1, #4294967295	; 0xffffffff
    1f7c:	4604      	mov	r4, r0
    1f7e:	4617      	mov	r7, r2
static inline int mpu_buffer_validate(void *addr, size_t size, int write)
{
	int32_t r_index;

	/* Iterate all mpu regions in reversed order */
	for (r_index = get_num_regions() - 1; r_index >= 0;  r_index--) {
    1f80:	bf08      	it	eq
    1f82:	2500      	moveq	r5, #0
    1f84:	2107      	movs	r1, #7
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;
    1f86:	f04f 0801 	mov.w	r8, #1
		if (!is_enabled_region(r_index) ||
    1f8a:	4608      	mov	r0, r1
    1f8c:	f7ff ff5e 	bl	1e4c <is_enabled_region>
    1f90:	2800      	cmp	r0, #0
    1f92:	d037      	beq.n	2004 <arm_core_mpu_buffer_validate+0x94>
	__asm__ volatile(
    1f94:	f04f 0320 	mov.w	r3, #32
    1f98:	f3ef 8011 	mrs	r0, BASEPRI
    1f9c:	f383 8811 	msr	BASEPRI, r3
    1fa0:	f3bf 8f6f 	isb	sy
	MPU->RNR = r_index;
    1fa4:	60b1      	str	r1, [r6, #8]
	rbar = MPU->RBAR;
    1fa6:	68f2      	ldr	r2, [r6, #12]
	rasr = MPU->RASR;
    1fa8:	6933      	ldr	r3, [r6, #16]
	__asm__ volatile(
    1faa:	f380 8811 	msr	BASEPRI, r0
    1fae:	f3bf 8f6f 	isb	sy
	return __builtin_add_overflow(a, b, result);
}

static inline bool u32_add_overflow(uint32_t a, uint32_t b, uint32_t *result)
{
	return __builtin_add_overflow(a, b, result);
    1fb2:	1960      	adds	r0, r4, r5
    1fb4:	d226      	bcs.n	2004 <arm_core_mpu_buffer_validate+0x94>
	r_addr_start = rbar & MPU_RBAR_ADDR_Msk;
    1fb6:	f022 021f 	bic.w	r2, r2, #31
	if ((start >= r_addr_start) && (end <= r_addr_end)) {
    1fba:	4294      	cmp	r4, r2
    1fbc:	d322      	bcc.n	2004 <arm_core_mpu_buffer_validate+0x94>
	r_size_lshift = ((rasr & MPU_RASR_SIZE_Msk) >>
    1fbe:	f3c3 0344 	ubfx	r3, r3, #1, #5
    1fc2:	3301      	adds	r3, #1
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;
    1fc4:	fa08 f303 	lsl.w	r3, r8, r3
    1fc8:	3a01      	subs	r2, #1
    1fca:	4413      	add	r3, r2
	if ((start >= r_addr_start) && (end <= r_addr_end)) {
    1fcc:	4283      	cmp	r3, r0
    1fce:	d319      	bcc.n	2004 <arm_core_mpu_buffer_validate+0x94>
	__asm__ volatile(
    1fd0:	f04f 0320 	mov.w	r3, #32
    1fd4:	f3ef 8211 	mrs	r2, BASEPRI
    1fd8:	f383 8811 	msr	BASEPRI, r3
    1fdc:	f3bf 8f6f 	isb	sy
	MPU->RNR = r_index;
    1fe0:	60b1      	str	r1, [r6, #8]
	rasr = MPU->RASR;
    1fe2:	6933      	ldr	r3, [r6, #16]
	__asm__ volatile(
    1fe4:	f382 8811 	msr	BASEPRI, r2
    1fe8:	f3bf 8f6f 	isb	sy
	return (rasr & MPU_RASR_AP_Msk) >> MPU_RASR_AP_Pos;
    1fec:	0e19      	lsrs	r1, r3, #24
    1fee:	f3c3 6302 	ubfx	r3, r3, #24, #3
	if (write) {
    1ff2:	b167      	cbz	r7, 200e <arm_core_mpu_buffer_validate+0x9e>
		return r_ap == P_RW_U_RW;
    1ff4:	3b03      	subs	r3, #3
    1ff6:	4259      	negs	r1, r3
    1ff8:	4159      	adcs	r1, r3
		/* For ARM MPU, higher region number takes priority.
		 * Since we iterate all mpu regions in reversed order, so
		 * we can stop the iteration immediately once we find the
		 * matched region that grants permission or denies access.
		 */
		if (is_user_accessible_region(r_index, write)) {
    1ffa:	fab1 f181 	clz	r1, r1
    1ffe:	0949      	lsrs	r1, r1, #5
    2000:	4249      	negs	r1, r1
	return mpu_buffer_validate(addr, size, write);
    2002:	e001      	b.n	2008 <arm_core_mpu_buffer_validate+0x98>
	for (r_index = get_num_regions() - 1; r_index >= 0;  r_index--) {
    2004:	3901      	subs	r1, #1
    2006:	d2c0      	bcs.n	1f8a <arm_core_mpu_buffer_validate+0x1a>
}
    2008:	4608      	mov	r0, r1
    200a:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return r_ap & MPU_USER_READ_ACCESSIBLE_Msk;
    200e:	f001 0102 	and.w	r1, r1, #2
    2012:	e7f2      	b.n	1ffa <arm_core_mpu_buffer_validate+0x8a>
    2014:	e000ed90 	.word	0xe000ed90

00002018 <arm_core_mpu_configure_static_mpu_regions>:
{
    2018:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
static int mpu_configure_static_mpu_regions(const struct k_mem_partition
	*static_regions[], const uint8_t regions_num,
	const uint32_t background_area_base,
	const uint32_t background_area_end)
{
	int mpu_reg_index = static_regions_num;
    201a:	4c11      	ldr	r4, [pc, #68]	; (2060 <arm_core_mpu_configure_static_mpu_regions+0x48>)
    201c:	4607      	mov	r7, r0
	int reg_index = start_reg_index;
    201e:	7820      	ldrb	r0, [r4, #0]
{
    2020:	460e      	mov	r6, r1
	for (i = 0; i < regions_num; i++) {
    2022:	2500      	movs	r5, #0
    2024:	42b5      	cmp	r5, r6
    2026:	da11      	bge.n	204c <arm_core_mpu_configure_static_mpu_regions+0x34>
		if (regions[i]->size == 0U) {
    2028:	f857 1025 	ldr.w	r1, [r7, r5, lsl #2]
    202c:	684b      	ldr	r3, [r1, #4]
    202e:	b1ab      	cbz	r3, 205c <arm_core_mpu_configure_static_mpu_regions+0x44>
		((part->size & (part->size - 1)) == 0U)
    2030:	1e5a      	subs	r2, r3, #1
		&&
    2032:	4213      	tst	r3, r2
    2034:	d10c      	bne.n	2050 <arm_core_mpu_configure_static_mpu_regions+0x38>
		&&
    2036:	2b1f      	cmp	r3, #31
    2038:	d90a      	bls.n	2050 <arm_core_mpu_configure_static_mpu_regions+0x38>
		((part->start & (part->size - 1)) == 0U);
    203a:	680b      	ldr	r3, [r1, #0]
		&&
    203c:	421a      	tst	r2, r3
    203e:	d107      	bne.n	2050 <arm_core_mpu_configure_static_mpu_regions+0x38>
		reg_index = mpu_configure_region(reg_index, regions[i]);
    2040:	b2c0      	uxtb	r0, r0
    2042:	f7ff ff17 	bl	1e74 <mpu_configure_region>
		if (reg_index == -EINVAL) {
    2046:	f110 0f16 	cmn.w	r0, #22
    204a:	d106      	bne.n	205a <arm_core_mpu_configure_static_mpu_regions+0x42>
	ARG_UNUSED(background_area_end);

	mpu_reg_index = mpu_configure_regions(static_regions,
		regions_num, mpu_reg_index, true);

	static_regions_num = mpu_reg_index;
    204c:	7020      	strb	r0, [r4, #0]
}
    204e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    2050:	f004 f8ac 	bl	61ac <arch_is_user_context>
			return -EINVAL;
    2054:	f06f 0015 	mvn.w	r0, #21
    2058:	e7f8      	b.n	204c <arm_core_mpu_configure_static_mpu_regions+0x34>
		reg_index++;
    205a:	3001      	adds	r0, #1
	for (i = 0; i < regions_num; i++) {
    205c:	3501      	adds	r5, #1
    205e:	e7e1      	b.n	2024 <arm_core_mpu_configure_static_mpu_regions+0xc>
    2060:	200013f1 	.word	0x200013f1

00002064 <arm_core_mpu_configure_dynamic_mpu_regions>:
{
    2064:	b538      	push	{r3, r4, r5, lr}
 * performed, the error signal is propagated to the caller of the function.
 */
static int mpu_configure_dynamic_mpu_regions(const struct k_mem_partition
	*dynamic_regions[], uint8_t regions_num)
{
	int mpu_reg_index = static_regions_num;
    2066:	4b10      	ldr	r3, [pc, #64]	; (20a8 <arm_core_mpu_configure_dynamic_mpu_regions+0x44>)
    2068:	4605      	mov	r5, r0
	int reg_index = start_reg_index;
    206a:	7818      	ldrb	r0, [r3, #0]
{
    206c:	460c      	mov	r4, r1
	for (i = 0; i < regions_num; i++) {
    206e:	2200      	movs	r2, #0
    2070:	42a2      	cmp	r2, r4
    2072:	db07      	blt.n	2084 <arm_core_mpu_configure_dynamic_mpu_regions+0x20>
	 */

	mpu_reg_index = mpu_configure_regions(dynamic_regions,
		regions_num, mpu_reg_index, false);

	if (mpu_reg_index != -EINVAL) {
    2074:	f110 0f16 	cmn.w	r0, #22
    2078:	d003      	beq.n	2082 <arm_core_mpu_configure_dynamic_mpu_regions+0x1e>
/** Clear and disable the given MPU region.
* \param rnr Region number to be cleared.
*/
__STATIC_INLINE void ARM_MPU_ClrRegion(uint32_t rnr)
{
  MPU->RNR = rnr;
    207a:	4a0c      	ldr	r2, [pc, #48]	; (20ac <arm_core_mpu_configure_dynamic_mpu_regions+0x48>)
  MPU->RASR = 0U;
    207c:	2100      	movs	r1, #0

		/* Disable the non-programmed MPU regions. */
		for (int i = mpu_reg_index; i < get_num_regions(); i++) {
    207e:	2807      	cmp	r0, #7
    2080:	dd0d      	ble.n	209e <arm_core_mpu_configure_dynamic_mpu_regions+0x3a>
}
    2082:	bd38      	pop	{r3, r4, r5, pc}
		if (regions[i]->size == 0U) {
    2084:	f855 1022 	ldr.w	r1, [r5, r2, lsl #2]
    2088:	684b      	ldr	r3, [r1, #4]
    208a:	b133      	cbz	r3, 209a <arm_core_mpu_configure_dynamic_mpu_regions+0x36>
		reg_index = mpu_configure_region(reg_index, regions[i]);
    208c:	b2c0      	uxtb	r0, r0
    208e:	f7ff fef1 	bl	1e74 <mpu_configure_region>
		if (reg_index == -EINVAL) {
    2092:	f110 0f16 	cmn.w	r0, #22
    2096:	d0f4      	beq.n	2082 <arm_core_mpu_configure_dynamic_mpu_regions+0x1e>
		reg_index++;
    2098:	3001      	adds	r0, #1
	for (i = 0; i < regions_num; i++) {
    209a:	3201      	adds	r2, #1
    209c:	e7e8      	b.n	2070 <arm_core_mpu_configure_dynamic_mpu_regions+0xc>
  MPU->RNR = rnr;
    209e:	6090      	str	r0, [r2, #8]
  MPU->RASR = 0U;
    20a0:	6111      	str	r1, [r2, #16]
    20a2:	3001      	adds	r0, #1
    20a4:	e7eb      	b.n	207e <arm_core_mpu_configure_dynamic_mpu_regions+0x1a>
    20a6:	bf00      	nop
    20a8:	200013f1 	.word	0x200013f1
    20ac:	e000ed90 	.word	0xe000ed90

000020b0 <__stdout_hook_install>:

static int (*_stdout_hook)(int) = _stdout_hook_default;

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
    20b0:	4b01      	ldr	r3, [pc, #4]	; (20b8 <__stdout_hook_install+0x8>)
    20b2:	6018      	str	r0, [r3, #0]
}
    20b4:	4770      	bx	lr
    20b6:	bf00      	nop
    20b8:	20002e04 	.word	0x20002e04

000020bc <z_impl_zephyr_fputc>:

int z_impl_zephyr_fputc(int c, FILE *stream)
{
	return (stdout == stream) ? _stdout_hook(c) : EOF;
    20bc:	2902      	cmp	r1, #2
    20be:	d102      	bne.n	20c6 <z_impl_zephyr_fputc+0xa>
    20c0:	4b02      	ldr	r3, [pc, #8]	; (20cc <z_impl_zephyr_fputc+0x10>)
    20c2:	681b      	ldr	r3, [r3, #0]
    20c4:	4718      	bx	r3
}
    20c6:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    20ca:	4770      	bx	lr
    20cc:	20002e04 	.word	0x20002e04

000020d0 <z_mrsh_zephyr_fputc>:
#include <syscalls/libc-hooks.h>

extern int z_vrfy_zephyr_fputc(int c, FILE * stream);
uintptr_t z_mrsh_zephyr_fputc(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    20d0:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    20d2:	4c06      	ldr	r4, [pc, #24]	; (20ec <z_mrsh_zephyr_fputc+0x1c>)
    20d4:	9a04      	ldr	r2, [sp, #16]
    20d6:	68a3      	ldr	r3, [r4, #8]
    20d8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_zephyr_fputc(int c, FILE *stream)
{
	return z_impl_zephyr_fputc(c, stream);
    20dc:	f7ff ffee 	bl	20bc <z_impl_zephyr_fputc>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_zephyr_fputc(*(int*)&arg0, *(FILE **)&arg1)
;
	_current->syscall_frame = NULL;
    20e0:	68a3      	ldr	r3, [r4, #8]
    20e2:	2200      	movs	r2, #0
    20e4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    20e8:	bd10      	pop	{r4, pc}
    20ea:	bf00      	nop
    20ec:	20000664 	.word	0x20000664

000020f0 <z_impl_zephyr_fwrite>:
{
	size_t i;
	size_t j;
	const unsigned char *p;

	if ((stream != stdout) || (nitems == 0) || (size == 0)) {
    20f0:	2b02      	cmp	r3, #2
{
    20f2:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    20f6:	4606      	mov	r6, r0
    20f8:	460c      	mov	r4, r1
    20fa:	4615      	mov	r5, r2
	if ((stream != stdout) || (nitems == 0) || (size == 0)) {
    20fc:	d115      	bne.n	212a <z_impl_zephyr_fwrite+0x3a>
    20fe:	b1b2      	cbz	r2, 212e <z_impl_zephyr_fwrite+0x3e>
    2100:	b181      	cbz	r1, 2124 <z_impl_zephyr_fwrite+0x34>
	p = ptr;
	i = nitems;
	do {
		j = size;
		do {
			if (_stdout_hook((int) *p++) == EOF) {
    2102:	f8df 9030 	ldr.w	r9, [pc, #48]	; 2134 <z_impl_zephyr_fwrite+0x44>
    2106:	4617      	mov	r7, r2
		j = size;
    2108:	46b0      	mov	r8, r6
    210a:	4426      	add	r6, r4
			if (_stdout_hook((int) *p++) == EOF) {
    210c:	f8d9 3000 	ldr.w	r3, [r9]
    2110:	f818 0b01 	ldrb.w	r0, [r8], #1
    2114:	4798      	blx	r3
    2116:	3001      	adds	r0, #1
    2118:	d003      	beq.n	2122 <z_impl_zephyr_fwrite+0x32>
				goto done;
			}
			j--;
		} while (j > 0);
    211a:	4546      	cmp	r6, r8
    211c:	d1f6      	bne.n	210c <z_impl_zephyr_fwrite+0x1c>

		i--;
	} while (i > 0);
    211e:	3f01      	subs	r7, #1
    2120:	d1f2      	bne.n	2108 <z_impl_zephyr_fwrite+0x18>

done:
	return (nitems - i);
    2122:	1bec      	subs	r4, r5, r7
}
    2124:	4620      	mov	r0, r4
    2126:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
		return 0;
    212a:	2400      	movs	r4, #0
    212c:	e7fa      	b.n	2124 <z_impl_zephyr_fwrite+0x34>
    212e:	4614      	mov	r4, r2
    2130:	e7f8      	b.n	2124 <z_impl_zephyr_fwrite+0x34>
    2132:	bf00      	nop
    2134:	20002e04 	.word	0x20002e04

00002138 <z_mrsh_zephyr_fwrite>:
#include <syscalls/libc-hooks.h>

extern size_t z_vrfy_zephyr_fwrite(const void *_MLIBC_RESTRICT ptr, size_t size, size_t nitems, FILE *_MLIBC_RESTRICT stream);
uintptr_t z_mrsh_zephyr_fwrite(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2138:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    213c:	4f12      	ldr	r7, [pc, #72]	; (2188 <z_mrsh_zephyr_fwrite+0x50>)
{
    213e:	469a      	mov	sl, r3
	_current->syscall_frame = ssf;
    2140:	68bb      	ldr	r3, [r7, #8]
{
    2142:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
    2144:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    2146:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return __builtin_mul_overflow(a, b, result);
}

static inline bool size_mul_overflow(size_t a, size_t b, size_t *result)
{
	return __builtin_mul_overflow(a, b, result);
    214a:	fba6 3401 	umull	r3, r4, r6, r1
{
    214e:	4680      	mov	r8, r0
    2150:	460d      	mov	r5, r1
    2152:	46b9      	mov	r9, r7
    2154:	b92c      	cbnz	r4, 2162 <z_mrsh_zephyr_fwrite+0x2a>
static inline size_t z_vrfy_zephyr_fwrite(const void *_MLIBC_RESTRICT ptr,
					  size_t size, size_t nitems,
					  FILE *_MLIBC_RESTRICT stream)
{

	Z_OOPS(Z_SYSCALL_MEMORY_ARRAY_READ(ptr, nitems, size));
    2156:	4622      	mov	r2, r4
    2158:	4619      	mov	r1, r3
    215a:	f004 f825 	bl	61a8 <arch_buffer_validate>
    215e:	4604      	mov	r4, r0
    2160:	b138      	cbz	r0, 2172 <z_mrsh_zephyr_fwrite+0x3a>
    2162:	f004 f891 	bl	6288 <arch_is_user_context>
    2166:	f8d9 3008 	ldr.w	r3, [r9, #8]
    216a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    216e:	f003 ffed 	bl	614c <arch_syscall_oops>
	return z_impl_zephyr_fwrite((const void *_MLIBC_RESTRICT)ptr, size,
    2172:	4653      	mov	r3, sl
    2174:	4632      	mov	r2, r6
    2176:	4629      	mov	r1, r5
    2178:	4640      	mov	r0, r8
    217a:	f7ff ffb9 	bl	20f0 <z_impl_zephyr_fwrite>
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	size_t ret = z_vrfy_zephyr_fwrite(*(const void *_MLIBC_RESTRICT*)&arg0, *(size_t*)&arg1, *(size_t*)&arg2, *(FILE *_MLIBC_RESTRICT*)&arg3)
;
	_current->syscall_frame = NULL;
    217e:	68bb      	ldr	r3, [r7, #8]
    2180:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2184:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    2188:	20000664 	.word	0x20000664

0000218c <nordicsemi_nrf52_init>:
	__asm__ volatile(
    218c:	f04f 0320 	mov.w	r3, #32
    2190:	f3ef 8211 	mrs	r2, BASEPRI
    2194:	f383 8811 	msr	BASEPRI, r3
    2198:	f3bf 8f6f 	isb	sy

	key = irq_lock();

#ifdef CONFIG_NRF_ENABLE_ICACHE
	/* Enable the instruction cache */
	NRF_NVMC->ICACHECNF = NVMC_ICACHECNF_CACHEEN_Msk;
    219c:	4906      	ldr	r1, [pc, #24]	; (21b8 <nordicsemi_nrf52_init+0x2c>)
    219e:	2301      	movs	r3, #1
    21a0:	f8c1 3540 	str.w	r3, [r1, #1344]	; 0x540
#endif

#if NRF_POWER_HAS_DCDCEN
NRF_STATIC_INLINE void nrf_power_dcdcen_set(NRF_POWER_Type * p_reg, bool enable)
{
    p_reg->DCDCEN = (enable ? POWER_DCDCEN_DCDCEN_Enabled : POWER_DCDCEN_DCDCEN_Disabled) <<
    21a4:	f04f 4180 	mov.w	r1, #1073741824	; 0x40000000
    21a8:	f8c1 3578 	str.w	r3, [r1, #1400]	; 0x578
	__asm__ volatile(
    21ac:	f382 8811 	msr	BASEPRI, r2
    21b0:	f3bf 8f6f 	isb	sy
	NMI_INIT();

	irq_unlock(key);

	return 0;
}
    21b4:	2000      	movs	r0, #0
    21b6:	4770      	bx	lr
    21b8:	4001e000 	.word	0x4001e000

000021bc <arch_busy_wait>:

#else // NRFX_CHECK(NRFX_DELAY_DWT_BASED)

NRF_STATIC_INLINE void nrfx_coredep_delay_us(uint32_t time_us)
{
    if (time_us == 0)
    21bc:	b120      	cbz	r0, 21c8 <arch_busy_wait+0xc>
    };

    typedef void (* delay_func_t)(uint32_t);
    const delay_func_t delay_cycles =
        // Set LSB to 1 to execute the code in the Thumb mode.
        (delay_func_t)((((uint32_t)delay_machine_code) | 1));
    21be:	4b03      	ldr	r3, [pc, #12]	; (21cc <arch_busy_wait+0x10>)
    uint32_t cycles = time_us * NRFX_DELAY_CPU_FREQ_MHZ;
    delay_cycles(cycles);
    21c0:	0180      	lsls	r0, r0, #6
    21c2:	f043 0301 	orr.w	r3, r3, #1
    21c6:	4718      	bx	r3

void arch_busy_wait(uint32_t time_us)
{
	nrfx_coredep_delay_us(time_us);
}
    21c8:	4770      	bx	lr
    21ca:	bf00      	nop
    21cc:	00007220 	.word	0x00007220

000021d0 <gpio_nrfx_init>:
}

#define GPIOTE_NODE DT_INST(0, nordic_nrf_gpiote)

static int gpio_nrfx_init(struct device *port)
{
    21d0:	b508      	push	{r3, lr}
	static bool gpio_initialized;

	if (!gpio_initialized) {
    21d2:	4b09      	ldr	r3, [pc, #36]	; (21f8 <gpio_nrfx_init+0x28>)
    21d4:	781a      	ldrb	r2, [r3, #0]
    21d6:	b96a      	cbnz	r2, 21f4 <gpio_nrfx_init+0x24>
		gpio_initialized = true;
    21d8:	2101      	movs	r1, #1
    21da:	7019      	strb	r1, [r3, #0]
		IRQ_CONNECT(DT_IRQN(GPIOTE_NODE), DT_IRQ(GPIOTE_NODE, priority),
    21dc:	2006      	movs	r0, #6
    21de:	2105      	movs	r1, #5
    21e0:	f7ff fa76 	bl	16d0 <z_arm_irq_priority_set>
			    gpiote_event_handler, NULL, 0);

		irq_enable(DT_IRQN(GPIOTE_NODE));
    21e4:	2006      	movs	r0, #6
    21e6:	f7ff fa63 	bl	16b0 <arch_irq_enable>
    return ((uint32_t)p_reg + event);
}

NRF_STATIC_INLINE void nrf_gpiote_int_enable(NRF_GPIOTE_Type * p_reg, uint32_t mask)
{
    p_reg->INTENSET = mask;
    21ea:	4b04      	ldr	r3, [pc, #16]	; (21fc <gpio_nrfx_init+0x2c>)
    21ec:	f04f 4200 	mov.w	r2, #2147483648	; 0x80000000
    21f0:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
		nrf_gpiote_int_enable(NRF_GPIOTE, NRF_GPIOTE_INT_PORT_MASK);
	}

	return 0;
}
    21f4:	2000      	movs	r0, #0
    21f6:	bd08      	pop	{r3, pc}
    21f8:	200013f2 	.word	0x200013f2
    21fc:	40006000 	.word	0x40006000

00002200 <gpio_nrfx_config>:
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    2200:	4b2b      	ldr	r3, [pc, #172]	; (22b0 <gpio_nrfx_config+0xb0>)
{
    2202:	b5f0      	push	{r4, r5, r6, r7, lr}
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    2204:	6846      	ldr	r6, [r0, #4]
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    2206:	482b      	ldr	r0, [pc, #172]	; (22b4 <gpio_nrfx_config+0xb4>)
    2208:	4013      	ands	r3, r2
    220a:	4283      	cmp	r3, r0
    220c:	d040      	beq.n	2290 <gpio_nrfx_config+0x90>
    220e:	d80d      	bhi.n	222c <gpio_nrfx_config+0x2c>
    2210:	2b06      	cmp	r3, #6
    2212:	d015      	beq.n	2240 <gpio_nrfx_config+0x40>
    2214:	d805      	bhi.n	2222 <gpio_nrfx_config+0x22>
    2216:	b19b      	cbz	r3, 2240 <gpio_nrfx_config+0x40>
    2218:	2b02      	cmp	r3, #2
    221a:	d03b      	beq.n	2294 <gpio_nrfx_config+0x94>
    221c:	f06f 0015 	mvn.w	r0, #21
    2220:	e035      	b.n	228e <gpio_nrfx_config+0x8e>
    2222:	f5b3 1f80 	cmp.w	r3, #1048576	; 0x100000
    2226:	d1f9      	bne.n	221c <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_H0S1;
    2228:	2301      	movs	r3, #1
    222a:	e009      	b.n	2240 <gpio_nrfx_config+0x40>
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    222c:	4822      	ldr	r0, [pc, #136]	; (22b8 <gpio_nrfx_config+0xb8>)
    222e:	4283      	cmp	r3, r0
    2230:	d032      	beq.n	2298 <gpio_nrfx_config+0x98>
    2232:	f5b3 0fa0 	cmp.w	r3, #5242880	; 0x500000
    2236:	d031      	beq.n	229c <gpio_nrfx_config+0x9c>
    2238:	f5b3 0f80 	cmp.w	r3, #4194304	; 0x400000
    223c:	d1ee      	bne.n	221c <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_S0H1;
    223e:	2302      	movs	r3, #2
	if ((flags & GPIO_PULL_UP) != 0) {
    2240:	06d0      	lsls	r0, r2, #27
		pull = NRF_GPIO_PIN_NOPULL;
    2242:	bf54      	ite	pl
    2244:	f3c2 1540 	ubfxpl	r5, r2, #5, #1
		pull = NRF_GPIO_PIN_PULLUP;
    2248:	2503      	movmi	r5, #3
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    224a:	f482 7480 	eor.w	r4, r2, #256	; 0x100
	if ((flags & GPIO_OUTPUT) != 0) {
    224e:	0597      	lsls	r7, r2, #22
	dir = ((flags & GPIO_OUTPUT) != 0)
    2250:	f3c2 2040 	ubfx	r0, r2, #9, #1
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    2254:	f3c4 2400 	ubfx	r4, r4, #8, #1
	if ((flags & GPIO_OUTPUT) != 0) {
    2258:	d507      	bpl.n	226a <gpio_nrfx_config+0x6a>
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    225a:	f412 6f00 	tst.w	r2, #2048	; 0x800
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    225e:	6877      	ldr	r7, [r6, #4]
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    2260:	d01e      	beq.n	22a0 <gpio_nrfx_config+0xa0>
			nrf_gpio_port_out_set(reg, BIT(pin));
    2262:	2201      	movs	r2, #1
    2264:	408a      	lsls	r2, r1
}


NRF_STATIC_INLINE void nrf_gpio_port_out_set(NRF_GPIO_Type * p_reg, uint32_t set_mask)
{
    p_reg->OUTSET = set_mask;
    2266:	f8c7 2508 	str.w	r2, [r7, #1288]	; 0x508
	nrf_gpio_cfg(NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin),
    226a:	7a32      	ldrb	r2, [r6, #8]
    226c:	f001 011f 	and.w	r1, r1, #31
    2270:	ea41 1142 	orr.w	r1, r1, r2, lsl #5
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    2274:	ea40 0244 	orr.w	r2, r0, r4, lsl #1
    2278:	ea42 2303 	orr.w	r3, r2, r3, lsl #8
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    227c:	f501 71e0 	add.w	r1, r1, #448	; 0x1c0
    2280:	f04f 42a0 	mov.w	r2, #1342177280	; 0x50000000
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    2284:	ea43 0385 	orr.w	r3, r3, r5, lsl #2
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    2288:	f842 3021 	str.w	r3, [r2, r1, lsl #2]
	return 0;
    228c:	2000      	movs	r0, #0
}
    228e:	bdf0      	pop	{r4, r5, r6, r7, pc}
		drive = NRF_GPIO_PIN_H0D1;
    2290:	2307      	movs	r3, #7
    2292:	e7d5      	b.n	2240 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0S1;
    2294:	2304      	movs	r3, #4
    2296:	e7d3      	b.n	2240 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0H1;
    2298:	2305      	movs	r3, #5
    229a:	e7d1      	b.n	2240 <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_H0H1;
    229c:	2303      	movs	r3, #3
    229e:	e7cf      	b.n	2240 <gpio_nrfx_config+0x40>
		} else if ((flags & GPIO_OUTPUT_INIT_LOW) != 0) {
    22a0:	0552      	lsls	r2, r2, #21
			nrf_gpio_port_out_clear(reg, BIT(pin));
    22a2:	bf42      	ittt	mi
    22a4:	2201      	movmi	r2, #1
    22a6:	408a      	lslmi	r2, r1
}


NRF_STATIC_INLINE void nrf_gpio_port_out_clear(NRF_GPIO_Type * p_reg, uint32_t clr_mask)
{
    p_reg->OUTCLR = clr_mask;
    22a8:	f8c7 250c 	strmi.w	r2, [r7, #1292]	; 0x50c
}
    22ac:	e7dd      	b.n	226a <gpio_nrfx_config+0x6a>
    22ae:	bf00      	nop
    22b0:	00f00006 	.word	0x00f00006
    22b4:	00100006 	.word	0x00100006
    22b8:	00400002 	.word	0x00400002

000022bc <gpio_nrfx_pin_interrupt_configure>:
{
    22bc:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
	struct gpio_nrfx_data *data = get_port_data(port);
    22be:	68c4      	ldr	r4, [r0, #12]
	uint32_t abs_pin = NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin);
    22c0:	6840      	ldr	r0, [r0, #4]
    22c2:	7a00      	ldrb	r0, [r0, #8]
    22c4:	f001 051f 	and.w	r5, r1, #31
	if ((mode == GPIO_INT_MODE_EDGE) &&
    22c8:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    22cc:	ea45 1540 	orr.w	r5, r5, r0, lsl #5
    22d0:	d10a      	bne.n	22e8 <gpio_nrfx_pin_interrupt_configure+0x2c>
    return (nrf_gpio_pin_dir_t)((reg->PIN_CNF[pin_number] &
    22d2:	f505 70e0 	add.w	r0, r5, #448	; 0x1c0
    22d6:	f04f 46a0 	mov.w	r6, #1342177280	; 0x50000000
    22da:	f856 0020 	ldr.w	r0, [r6, r0, lsl #2]
    22de:	07c7      	lsls	r7, r0, #31
    22e0:	d507      	bpl.n	22f2 <gpio_nrfx_pin_interrupt_configure+0x36>
		return -ENOTSUP;
    22e2:	f06f 0022 	mvn.w	r0, #34	; 0x22
    22e6:	e0b4      	b.n	2452 <gpio_nrfx_pin_interrupt_configure+0x196>
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    22e8:	f5b2 5f00 	cmp.w	r2, #8192	; 0x2000
    22ec:	68e0      	ldr	r0, [r4, #12]
    22ee:	f000 80b2 	beq.w	2456 <gpio_nrfx_pin_interrupt_configure+0x19a>
    22f2:	68e6      	ldr	r6, [r4, #12]
    22f4:	2001      	movs	r0, #1
    22f6:	4088      	lsls	r0, r1
    22f8:	4330      	orrs	r0, r6
    22fa:	6966      	ldr	r6, [r4, #20]
    22fc:	60e0      	str	r0, [r4, #12]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    22fe:	2001      	movs	r0, #1
    2300:	4088      	lsls	r0, r1
    2302:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    2306:	69a2      	ldr	r2, [r4, #24]
    2308:	bf0c      	ite	eq
    230a:	4306      	orreq	r6, r0
    230c:	4386      	bicne	r6, r0
	WRITE_BIT(data->double_edge, pin, trig == GPIO_INT_TRIG_BOTH);
    230e:	f5b3 2fc0 	cmp.w	r3, #393216	; 0x60000
    2312:	bf0c      	ite	eq
    2314:	4302      	orreq	r2, r0
    2316:	4382      	bicne	r2, r0
    2318:	61a2      	str	r2, [r4, #24]
    231a:	6922      	ldr	r2, [r4, #16]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    231c:	6166      	str	r6, [r4, #20]
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    231e:	f5b3 2f80 	cmp.w	r3, #262144	; 0x40000
    2322:	bf0c      	ite	eq
    2324:	4310      	orreq	r0, r2
    2326:	ea22 0000 	bicne.w	r0, r2, r0
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_int_enable_check(NRF_GPIOTE_Type const * p_reg, uint32_t mask)
{
    return p_reg->INTENSET & mask;
    232a:	4a5b      	ldr	r2, [pc, #364]	; (2498 <gpio_nrfx_pin_interrupt_configure+0x1dc>)
    232c:	6120      	str	r0, [r4, #16]
    232e:	f8d2 0304 	ldr.w	r0, [r2, #772]	; 0x304
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    2332:	2300      	movs	r3, #0
    2334:	b2c0      	uxtb	r0, r0
                        ((polarity << GPIOTE_CONFIG_POLARITY_Pos) & GPIOTE_CONFIG_POLARITY_Msk);
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_event_pin_get(NRF_GPIOTE_Type const * p_reg, uint32_t idx)
{
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    2336:	f503 76a2 	add.w	r6, r3, #324	; 0x144
    233a:	f852 6026 	ldr.w	r6, [r2, r6, lsl #2]
    233e:	f3c6 2604 	ubfx	r6, r6, #8, #5
		if ((nrf_gpiote_event_pin_get(NRF_GPIOTE, i) == abs_pin)
    2342:	42b5      	cmp	r5, r6
    2344:	f040 808c 	bne.w	2460 <gpio_nrfx_pin_interrupt_configure+0x1a4>
		    && (intenset & BIT(i))) {
    2348:	fa20 f603 	lsr.w	r6, r0, r3
    234c:	07f6      	lsls	r6, r6, #31
    234e:	f140 8087 	bpl.w	2460 <gpio_nrfx_pin_interrupt_configure+0x1a4>
			(void)atomic_and(mask, ~BIT(i));
    2352:	2001      	movs	r0, #1
    2354:	4098      	lsls	r0, r3
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    2356:	4e51      	ldr	r6, [pc, #324]	; (249c <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    2358:	f3bf 8f5b 	dmb	ish
    235c:	43c7      	mvns	r7, r0
    235e:	e856 cf00 	ldrex	ip, [r6]
    2362:	ea0c 0c07 	and.w	ip, ip, r7
    2366:	e846 ce00 	strex	lr, ip, [r6]
    236a:	f1be 0f00 	cmp.w	lr, #0
    236e:	d1f6      	bne.n	235e <gpio_nrfx_pin_interrupt_configure+0xa2>
    2370:	f3bf 8f5b 	dmb	ish
   p_reg->CONFIG[idx] &= ~GPIOTE_CONFIG_MODE_Event;
    2374:	009b      	lsls	r3, r3, #2
    2376:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    237a:	f503 43c0 	add.w	r3, r3, #24576	; 0x6000
    237e:	f8d3 6510 	ldr.w	r6, [r3, #1296]	; 0x510
    2382:	f026 0601 	bic.w	r6, r6, #1
    2386:	f8c3 6510 	str.w	r6, [r3, #1296]	; 0x510
    p_reg->INTENCLR = mask;
    238a:	f8c2 0308 	str.w	r0, [r2, #776]	; 0x308
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    238e:	00aa      	lsls	r2, r5, #2
    2390:	f102 42a0 	add.w	r2, r2, #1342177280	; 0x50000000
	if (data->pin_int_en & BIT(pin)) {
    2394:	68e0      	ldr	r0, [r4, #12]
    2396:	f8d2 3700 	ldr.w	r3, [r2, #1792]	; 0x700
    239a:	40c8      	lsrs	r0, r1
    239c:	f423 3340 	bic.w	r3, r3, #196608	; 0x30000
    23a0:	f010 0001 	ands.w	r0, r0, #1
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    23a4:	f8c2 3700 	str.w	r3, [r2, #1792]	; 0x700
    23a8:	d053      	beq.n	2452 <gpio_nrfx_pin_interrupt_configure+0x196>
		if (data->trig_edge & BIT(pin)) {
    23aa:	6960      	ldr	r0, [r4, #20]
    23ac:	40c8      	lsrs	r0, r1
    23ae:	f010 0001 	ands.w	r0, r0, #1
    23b2:	d060      	beq.n	2476 <gpio_nrfx_pin_interrupt_configure+0x1ba>
			if (data->double_edge & BIT(pin)) {
    23b4:	69a3      	ldr	r3, [r4, #24]
	return __atomic_fetch_or(target, value, __ATOMIC_SEQ_CST);
    23b6:	4a39      	ldr	r2, [pc, #228]	; (249c <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    23b8:	40cb      	lsrs	r3, r1
    23ba:	07db      	lsls	r3, r3, #31
			} else if ((data->int_active_level & BIT(pin)) != 0U) {
    23bc:	bf5f      	itttt	pl
    23be:	6923      	ldrpl	r3, [r4, #16]
    23c0:	fa23 f101 	lsrpl.w	r1, r3, r1
    23c4:	f001 0101 	andpl.w	r1, r1, #1
    23c8:	f1c1 0102 	rsbpl	r1, r1, #2
    23cc:	bf54      	ite	pl
    23ce:	b2c9      	uxtbpl	r1, r1
				pol = NRF_GPIOTE_POLARITY_TOGGLE;
    23d0:	2103      	movmi	r1, #3
    23d2:	2300      	movs	r3, #0
		atomic_val_t prev = atomic_or(mask, BIT(channel));
    23d4:	2601      	movs	r6, #1
    23d6:	fa06 f403 	lsl.w	r4, r6, r3
    23da:	f3bf 8f5b 	dmb	ish
    23de:	e852 0f00 	ldrex	r0, [r2]
    23e2:	ea40 0704 	orr.w	r7, r0, r4
    23e6:	e842 7c00 	strex	ip, r7, [r2]
    23ea:	f1bc 0f00 	cmp.w	ip, #0
    23ee:	d1f6      	bne.n	23de <gpio_nrfx_pin_interrupt_configure+0x122>
    23f0:	f3bf 8f5b 	dmb	ish
		if ((prev & BIT(channel)) == 0) {
    23f4:	40d8      	lsrs	r0, r3
    23f6:	f010 0001 	ands.w	r0, r0, #1
    23fa:	d136      	bne.n	246a <gpio_nrfx_pin_interrupt_configure+0x1ae>
  p_reg->CONFIG[idx] &= ~(GPIOTE_CONFIG_PORT_PIN_Msk | GPIOTE_CONFIG_POLARITY_Msk);
    23fc:	009a      	lsls	r2, r3, #2
    23fe:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    2402:	f502 42c0 	add.w	r2, r2, #24576	; 0x6000
			nrf_gpiote_event_t evt =
    2406:	3340      	adds	r3, #64	; 0x40
    2408:	f8d2 6510 	ldr.w	r6, [r2, #1296]	; 0x510
    240c:	f426 3647 	bic.w	r6, r6, #203776	; 0x31c00
    2410:	f426 7640 	bic.w	r6, r6, #768	; 0x300
    2414:	009b      	lsls	r3, r3, #2
    2416:	f8c2 6510 	str.w	r6, [r2, #1296]	; 0x510
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    241a:	022d      	lsls	r5, r5, #8
    return ((uint32_t)p_reg + event);
    241c:	b29b      	uxth	r3, r3
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    241e:	f8d2 6510 	ldr.w	r6, [r2, #1296]	; 0x510
    2422:	f405 55f8 	and.w	r5, r5, #7936	; 0x1f00
    return ((uint32_t)p_reg + event);
    2426:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    242a:	f503 43c0 	add.w	r3, r3, #24576	; 0x6000
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    242e:	ea45 4501 	orr.w	r5, r5, r1, lsl #16
    2432:	4335      	orrs	r5, r6
    2434:	f8c2 5510 	str.w	r5, [r2, #1296]	; 0x510
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2438:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    243a:	681b      	ldr	r3, [r3, #0]
    243c:	9301      	str	r3, [sp, #4]
    (void)dummy;
    243e:	9b01      	ldr	r3, [sp, #4]
   p_reg->CONFIG[idx] |= GPIOTE_CONFIG_MODE_Event;
    2440:	f8d2 3510 	ldr.w	r3, [r2, #1296]	; 0x510
    2444:	f043 0301 	orr.w	r3, r3, #1
    2448:	f8c2 3510 	str.w	r3, [r2, #1296]	; 0x510
    p_reg->INTENSET = mask;
    244c:	4b12      	ldr	r3, [pc, #72]	; (2498 <gpio_nrfx_pin_interrupt_configure+0x1dc>)
    244e:	f8c3 4304 	str.w	r4, [r3, #772]	; 0x304
}
    2452:	b003      	add	sp, #12
    2454:	bdf0      	pop	{r4, r5, r6, r7, pc}
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    2456:	2601      	movs	r6, #1
    2458:	408e      	lsls	r6, r1
    245a:	ea20 0006 	bic.w	r0, r0, r6
    245e:	e74c      	b.n	22fa <gpio_nrfx_pin_interrupt_configure+0x3e>
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    2460:	3301      	adds	r3, #1
    2462:	2b08      	cmp	r3, #8
    2464:	f47f af67 	bne.w	2336 <gpio_nrfx_pin_interrupt_configure+0x7a>
    2468:	e791      	b.n	238e <gpio_nrfx_pin_interrupt_configure+0xd2>
	for (uint8_t channel = 0; channel < GPIOTE_CH_NUM; ++channel) {
    246a:	3301      	adds	r3, #1
    246c:	2b08      	cmp	r3, #8
    246e:	d1b2      	bne.n	23d6 <gpio_nrfx_pin_interrupt_configure+0x11a>
	return -ENODEV;
    2470:	f06f 0012 	mvn.w	r0, #18
    2474:	e7ed      	b.n	2452 <gpio_nrfx_pin_interrupt_configure+0x196>
	if ((BIT(pin) & data->int_active_level) != 0U) {
    2476:	6923      	ldr	r3, [r4, #16]
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    2478:	f8d2 5700 	ldr.w	r5, [r2, #1792]	; 0x700
    247c:	fa23 f101 	lsr.w	r1, r3, r1
    2480:	f001 0101 	and.w	r1, r1, #1
    2484:	f1c1 0103 	rsb	r1, r1, #3
    2488:	f425 3340 	bic.w	r3, r5, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    248c:	ea43 4101 	orr.w	r1, r3, r1, lsl #16
    2490:	f8c2 1700 	str.w	r1, [r2, #1792]	; 0x700
}
    2494:	e7dd      	b.n	2452 <gpio_nrfx_pin_interrupt_configure+0x196>
    2496:	bf00      	nop
    2498:	40006000 	.word	0x40006000
    249c:	2000065c 	.word	0x2000065c

000024a0 <gpiote_event_handler>:
{
    24a0:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    24a2:	494e      	ldr	r1, [pc, #312]	; (25dc <gpiote_event_handler+0x13c>)
    24a4:	680d      	ldr	r5, [r1, #0]
	if (port_event) {
    24a6:	2d00      	cmp	r5, #0
    24a8:	d061      	beq.n	256e <gpiote_event_handler+0xce>
	struct gpio_nrfx_data *data = get_port_data(port);
    24aa:	4b4d      	ldr	r3, [pc, #308]	; (25e0 <gpiote_event_handler+0x140>)
    24ac:	68da      	ldr	r2, [r3, #12]
	const struct gpio_nrfx_cfg *cfg = get_port_cfg(port);
    24ae:	f8d3 c004 	ldr.w	ip, [r3, #4]
	uint32_t out = data->pin_int_en;
    24b2:	68d3      	ldr	r3, [r2, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    24b4:	e9d2 0405 	ldrd	r0, r4, [r2, #20]
    24b8:	4320      	orrs	r0, r4
    24ba:	ea23 0300 	bic.w	r3, r3, r0
	uint32_t port_in = nrf_gpio_port_in_read(cfg->port);
    24be:	f8dc 0004 	ldr.w	r0, [ip, #4]
	uint32_t pin_states = ~(port_in ^ data->int_active_level);
    24c2:	6912      	ldr	r2, [r2, #16]
    return p_reg->IN;
    24c4:	f8d0 4510 	ldr.w	r4, [r0, #1296]	; 0x510
    24c8:	4054      	eors	r4, r2
	uint32_t out = pin_states & level_pins;
    24ca:	ea23 0404 	bic.w	r4, r3, r4
	uint32_t bit = 1U << pin;
    24ce:	2001      	movs	r0, #1
	uint32_t pin = 0U;
    24d0:	2600      	movs	r6, #0
	while (level_pins) {
    24d2:	2b00      	cmp	r3, #0
    24d4:	d135      	bne.n	2542 <gpiote_event_handler+0xa2>
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    24d6:	600b      	str	r3, [r1, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    24d8:	680b      	ldr	r3, [r1, #0]
    24da:	9300      	str	r3, [sp, #0]
    (void)dummy;
    24dc:	9b00      	ldr	r3, [sp, #0]
    return p_reg->INTENSET & mask;
    24de:	4841      	ldr	r0, [pc, #260]	; (25e4 <gpiote_event_handler+0x144>)
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    24e0:	2300      	movs	r3, #0
		if (nrf_gpiote_int_enable_check(NRF_GPIOTE, BIT(i)) &&
    24e2:	2601      	movs	r6, #1
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    24e4:	461f      	mov	r7, r3
    return p_reg->INTENSET & mask;
    24e6:	f8d0 2304 	ldr.w	r2, [r0, #772]	; 0x304
    24ea:	fa06 f103 	lsl.w	r1, r6, r3
    24ee:	4211      	tst	r1, r2
    24f0:	d013      	beq.n	251a <gpiote_event_handler+0x7a>
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    24f2:	009a      	lsls	r2, r3, #2
    24f4:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    24f8:	f502 42c2 	add.w	r2, r2, #24832	; 0x6100
    24fc:	6811      	ldr	r1, [r2, #0]
    24fe:	b161      	cbz	r1, 251a <gpiote_event_handler+0x7a>
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    2500:	f503 71a2 	add.w	r1, r3, #324	; 0x144
    2504:	f850 1021 	ldr.w	r1, [r0, r1, lsl #2]
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2508:	6017      	str	r7, [r2, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    250a:	6812      	ldr	r2, [r2, #0]
    250c:	9201      	str	r2, [sp, #4]
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    250e:	f3c1 2104 	ubfx	r1, r1, #8, #5
			fired_triggers[abs_pin / 32U] |= BIT(abs_pin % 32);
    2512:	fa06 f101 	lsl.w	r1, r6, r1
    (void)dummy;
    2516:	9a01      	ldr	r2, [sp, #4]
    2518:	430c      	orrs	r4, r1
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    251a:	3301      	adds	r3, #1
    251c:	2b08      	cmp	r3, #8
    251e:	d1e2      	bne.n	24e6 <gpiote_event_handler+0x46>
	if (fired_triggers[0]) {
    2520:	bb3c      	cbnz	r4, 2572 <gpiote_event_handler+0xd2>
	if (port_event) {
    2522:	b165      	cbz	r5, 253e <gpiote_event_handler+0x9e>
	const struct gpio_nrfx_data *data = get_port_data(port);
    2524:	4b2e      	ldr	r3, [pc, #184]	; (25e0 <gpiote_event_handler+0x140>)
    2526:	68d8      	ldr	r0, [r3, #12]
	const struct gpio_nrfx_cfg *cfg = get_port_cfg(port);
    2528:	685e      	ldr	r6, [r3, #4]
	uint32_t out = data->pin_int_en;
    252a:	68c1      	ldr	r1, [r0, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    252c:	e9d0 3205 	ldrd	r3, r2, [r0, #20]
    2530:	4313      	orrs	r3, r2
    2532:	ea21 0103 	bic.w	r1, r1, r3
	uint32_t bit = 1U << pin;
    2536:	2401      	movs	r4, #1
	uint32_t pin = 0U;
    2538:	2500      	movs	r5, #0
	while (level_pins) {
    253a:	2900      	cmp	r1, #0
    253c:	d131      	bne.n	25a2 <gpiote_event_handler+0x102>
}
    253e:	b003      	add	sp, #12
    2540:	bdf0      	pop	{r4, r5, r6, r7, pc}
		if (level_pins & bit) {
    2542:	4203      	tst	r3, r0
    2544:	d010      	beq.n	2568 <gpiote_event_handler+0xc8>
			uint32_t abs_pin = NRF_GPIO_PIN_MAP(cfg->port_num, pin);
    2546:	f89c 7008 	ldrb.w	r7, [ip, #8]
    254a:	f006 021f 	and.w	r2, r6, #31
    254e:	ea42 1247 	orr.w	r2, r2, r7, lsl #5
    2552:	0092      	lsls	r2, r2, #2
    2554:	f102 42a0 	add.w	r2, r2, #1342177280	; 0x50000000
			level_pins &= ~bit;
    2558:	ea23 0300 	bic.w	r3, r3, r0
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    255c:	f8d2 7700 	ldr.w	r7, [r2, #1792]	; 0x700
    2560:	f427 3740 	bic.w	r7, r7, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    2564:	f8c2 7700 	str.w	r7, [r2, #1792]	; 0x700
		++pin;
    2568:	3601      	adds	r6, #1
		bit <<= 1;
    256a:	0040      	lsls	r0, r0, #1
    256c:	e7b1      	b.n	24d2 <gpiote_event_handler+0x32>
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    256e:	462c      	mov	r4, r5
    2570:	e7b5      	b.n	24de <gpiote_event_handler+0x3e>
	struct gpio_nrfx_data *data = get_port_data(port);
    2572:	4f1b      	ldr	r7, [pc, #108]	; (25e0 <gpiote_event_handler+0x140>)
					struct device *port,
					uint32_t pins)
{
	struct gpio_callback *cb, *tmp;

	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    2574:	68fb      	ldr	r3, [r7, #12]
    2576:	6859      	ldr	r1, [r3, #4]
    2578:	2900      	cmp	r1, #0
    257a:	d0d2      	beq.n	2522 <gpiote_event_handler+0x82>
	return node->next;
    257c:	680e      	ldr	r6, [r1, #0]
    257e:	2e00      	cmp	r6, #0
    2580:	bf38      	it	cc
    2582:	2600      	movcc	r6, #0
		if (cb->pin_mask & pins) {
    2584:	688a      	ldr	r2, [r1, #8]
    2586:	4022      	ands	r2, r4
    2588:	d002      	beq.n	2590 <gpiote_event_handler+0xf0>
			__ASSERT(cb->handler, "No callback handler!");
			cb->handler(port, cb, cb->pin_mask & pins);
    258a:	684b      	ldr	r3, [r1, #4]
    258c:	4638      	mov	r0, r7
    258e:	4798      	blx	r3
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    2590:	2e00      	cmp	r6, #0
    2592:	d0c6      	beq.n	2522 <gpiote_event_handler+0x82>
    2594:	6833      	ldr	r3, [r6, #0]
    2596:	2b00      	cmp	r3, #0
    2598:	bf38      	it	cc
    259a:	2300      	movcc	r3, #0
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    259c:	4631      	mov	r1, r6
    259e:	461e      	mov	r6, r3
    25a0:	e7f0      	b.n	2584 <gpiote_event_handler+0xe4>
		if (level_pins & bit) {
    25a2:	420c      	tst	r4, r1
    25a4:	d017      	beq.n	25d6 <gpiote_event_handler+0x136>
			uint32_t abs_pin = NRF_GPIO_PIN_MAP(cfg->port_num, pin);
    25a6:	7a32      	ldrb	r2, [r6, #8]
    25a8:	f005 031f 	and.w	r3, r5, #31
    25ac:	ea43 1342 	orr.w	r3, r3, r2, lsl #5
    25b0:	009b      	lsls	r3, r3, #2
	if ((BIT(pin) & data->int_active_level) != 0U) {
    25b2:	6902      	ldr	r2, [r0, #16]
    25b4:	f103 43a0 	add.w	r3, r3, #1342177280	; 0x50000000
    25b8:	40ea      	lsrs	r2, r5
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    25ba:	f8d3 7700 	ldr.w	r7, [r3, #1792]	; 0x700
    25be:	f002 0201 	and.w	r2, r2, #1
    25c2:	f1c2 0203 	rsb	r2, r2, #3
    25c6:	f427 3740 	bic.w	r7, r7, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    25ca:	ea47 4202 	orr.w	r2, r7, r2, lsl #16
    25ce:	f8c3 2700 	str.w	r2, [r3, #1792]	; 0x700
			level_pins &= ~bit;
    25d2:	ea21 0104 	bic.w	r1, r1, r4
		++pin;
    25d6:	3501      	adds	r5, #1
		bit <<= 1;
    25d8:	0064      	lsls	r4, r4, #1
    25da:	e7ae      	b.n	253a <gpiote_event_handler+0x9a>
    25dc:	4000617c 	.word	0x4000617c
    25e0:	20002e50 	.word	0x20002e50
    25e4:	40006000 	.word	0x40006000

000025e8 <z_mrsh_gpio_config>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
uintptr_t z_mrsh_gpio_config(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    25e8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    25ec:	f8df 804c 	ldr.w	r8, [pc, #76]	; 263c <z_mrsh_gpio_config+0x54>
    25f0:	f8d8 3008 	ldr.w	r3, [r8, #8]
{
    25f4:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    25f6:	9a08      	ldr	r2, [sp, #32]
    25f8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_config(*(struct device **)&arg0, *(gpio_pin_t*)&arg1, *(gpio_flags_t*)&arg2)
    25fc:	b2ce      	uxtb	r6, r1
{
    25fe:	4604      	mov	r4, r0
#include <syscall_handler.h>

static inline int z_vrfy_gpio_config(struct device *port,
				     gpio_pin_t pin, gpio_flags_t flags)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, pin_configure));
    2600:	f7fd fd6c 	bl	dc <z_object_find>
					 enum k_objects otype,
					 enum _obj_init_check init)
{
	int ret;

	ret = z_object_validate(ko, otype, init);
    2604:	2200      	movs	r2, #0
    2606:	211b      	movs	r1, #27
    2608:	f002 ff96 	bl	5538 <z_object_validate>
    260c:	4642      	mov	r2, r8
    260e:	4605      	mov	r5, r0
    2610:	b130      	cbz	r0, 2620 <z_mrsh_gpio_config+0x38>
    2612:	f003 fe9a 	bl	634a <arch_is_user_context>
    2616:	6893      	ldr	r3, [r2, #8]
    2618:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    261c:	f003 fd96 	bl	614c <arch_syscall_oops>
    2620:	68a3      	ldr	r3, [r4, #8]
    2622:	681b      	ldr	r3, [r3, #0]
    2624:	2b00      	cmp	r3, #0
    2626:	d0f4      	beq.n	2612 <z_mrsh_gpio_config+0x2a>
	return api->pin_configure(port, pin, flags);
    2628:	463a      	mov	r2, r7
    262a:	4631      	mov	r1, r6
    262c:	4620      	mov	r0, r4
    262e:	4798      	blx	r3
;
	_current->syscall_frame = NULL;
    2630:	f8d8 3008 	ldr.w	r3, [r8, #8]
    2634:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2638:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    263c:	20000664 	.word	0x20000664

00002640 <z_mrsh_gpio_port_get_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_get_raw(struct device * port, gpio_port_value_t * value);
uintptr_t z_mrsh_gpio_port_get_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2640:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2642:	4e17      	ldr	r6, [pc, #92]	; (26a0 <z_mrsh_gpio_port_get_raw+0x60>)
    2644:	9a08      	ldr	r2, [sp, #32]
    2646:	68b3      	ldr	r3, [r6, #8]
    2648:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    264c:	460d      	mov	r5, r1
    264e:	4604      	mov	r4, r0
#include <syscalls/gpio_config_mrsh.c>

static inline int z_vrfy_gpio_port_get_raw(struct device *port,
					   gpio_port_value_t *value)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_get_raw));
    2650:	f7fd fd44 	bl	dc <z_object_find>
    2654:	2200      	movs	r2, #0
    2656:	211b      	movs	r1, #27
    2658:	f002 ff6e 	bl	5538 <z_object_validate>
    265c:	4632      	mov	r2, r6
    265e:	b178      	cbz	r0, 2680 <z_mrsh_gpio_port_get_raw+0x40>
    2660:	f003 fe73 	bl	634a <arch_is_user_context>
    2664:	6893      	ldr	r3, [r2, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(value, sizeof(gpio_port_value_t)));
    2666:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    266a:	f003 fd6f 	bl	614c <arch_syscall_oops>
	return api->port_get_raw(port, value);
    266e:	68a3      	ldr	r3, [r4, #8]
    2670:	4629      	mov	r1, r5
    2672:	685b      	ldr	r3, [r3, #4]
    2674:	4620      	mov	r0, r4
    2676:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_get_raw(*(struct device **)&arg0, *(gpio_port_value_t **)&arg1)
;
	_current->syscall_frame = NULL;
    2678:	68b3      	ldr	r3, [r6, #8]
    267a:	f8c3 7084 	str.w	r7, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    267e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_get_raw));
    2680:	68a3      	ldr	r3, [r4, #8]
    2682:	685b      	ldr	r3, [r3, #4]
    2684:	2b00      	cmp	r3, #0
    2686:	d0eb      	beq.n	2660 <z_mrsh_gpio_port_get_raw+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(value, sizeof(gpio_port_value_t)));
    2688:	2201      	movs	r2, #1
    268a:	2104      	movs	r1, #4
    268c:	4628      	mov	r0, r5
    268e:	f003 fd8b 	bl	61a8 <arch_buffer_validate>
    2692:	4607      	mov	r7, r0
    2694:	2800      	cmp	r0, #0
    2696:	d0ea      	beq.n	266e <z_mrsh_gpio_port_get_raw+0x2e>
    2698:	f003 fe57 	bl	634a <arch_is_user_context>
    269c:	68b3      	ldr	r3, [r6, #8]
    269e:	e7e2      	b.n	2666 <z_mrsh_gpio_port_get_raw+0x26>
    26a0:	20000664 	.word	0x20000664

000026a4 <z_mrsh_gpio_port_set_masked_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_set_masked_raw(struct device * port, gpio_port_pins_t mask, gpio_port_value_t value);
uintptr_t z_mrsh_gpio_port_set_masked_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    26a4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    26a8:	f8df 804c 	ldr.w	r8, [pc, #76]	; 26f8 <z_mrsh_gpio_port_set_masked_raw+0x54>
    26ac:	f8d8 3008 	ldr.w	r3, [r8, #8]
{
    26b0:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    26b2:	9a08      	ldr	r2, [sp, #32]
    26b4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    26b8:	460e      	mov	r6, r1
    26ba:	4604      	mov	r4, r0
#include <syscalls/gpio_port_get_raw_mrsh.c>

static inline int z_vrfy_gpio_port_set_masked_raw(struct device *port,
		gpio_port_pins_t mask, gpio_port_value_t value)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_set_masked_raw));
    26bc:	f7fd fd0e 	bl	dc <z_object_find>
    26c0:	2200      	movs	r2, #0
    26c2:	211b      	movs	r1, #27
    26c4:	f002 ff38 	bl	5538 <z_object_validate>
    26c8:	4642      	mov	r2, r8
    26ca:	4605      	mov	r5, r0
    26cc:	b130      	cbz	r0, 26dc <z_mrsh_gpio_port_set_masked_raw+0x38>
    26ce:	f003 fe3c 	bl	634a <arch_is_user_context>
    26d2:	6893      	ldr	r3, [r2, #8]
    26d4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    26d8:	f003 fd38 	bl	614c <arch_syscall_oops>
    26dc:	68a3      	ldr	r3, [r4, #8]
    26de:	689b      	ldr	r3, [r3, #8]
    26e0:	2b00      	cmp	r3, #0
    26e2:	d0f4      	beq.n	26ce <z_mrsh_gpio_port_set_masked_raw+0x2a>
	return api->port_set_masked_raw(port, mask, value);
    26e4:	463a      	mov	r2, r7
    26e6:	4631      	mov	r1, r6
    26e8:	4620      	mov	r0, r4
    26ea:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_set_masked_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1, *(gpio_port_value_t*)&arg2)
;
	_current->syscall_frame = NULL;
    26ec:	f8d8 3008 	ldr.w	r3, [r8, #8]
    26f0:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    26f4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    26f8:	20000664 	.word	0x20000664

000026fc <z_mrsh_gpio_port_set_bits_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_set_bits_raw(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_set_bits_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    26fc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    26fe:	4f11      	ldr	r7, [pc, #68]	; (2744 <z_mrsh_gpio_port_set_bits_raw+0x48>)
    2700:	9a08      	ldr	r2, [sp, #32]
    2702:	68bb      	ldr	r3, [r7, #8]
    2704:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2708:	460e      	mov	r6, r1
    270a:	4604      	mov	r4, r0
#include <syscalls/gpio_port_set_masked_raw_mrsh.c>

static inline int z_vrfy_gpio_port_set_bits_raw(struct device *port,
						gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_set_bits_raw));
    270c:	f7fd fce6 	bl	dc <z_object_find>
    2710:	2200      	movs	r2, #0
    2712:	211b      	movs	r1, #27
    2714:	f002 ff10 	bl	5538 <z_object_validate>
    2718:	463a      	mov	r2, r7
    271a:	4605      	mov	r5, r0
    271c:	b130      	cbz	r0, 272c <z_mrsh_gpio_port_set_bits_raw+0x30>
    271e:	f003 fe14 	bl	634a <arch_is_user_context>
    2722:	6893      	ldr	r3, [r2, #8]
    2724:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2728:	f003 fd10 	bl	614c <arch_syscall_oops>
    272c:	68a3      	ldr	r3, [r4, #8]
    272e:	68db      	ldr	r3, [r3, #12]
    2730:	2b00      	cmp	r3, #0
    2732:	d0f4      	beq.n	271e <z_mrsh_gpio_port_set_bits_raw+0x22>
	return api->port_set_bits_raw(port, pins);
    2734:	4631      	mov	r1, r6
    2736:	4620      	mov	r0, r4
    2738:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_set_bits_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    273a:	68bb      	ldr	r3, [r7, #8]
    273c:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2740:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    2742:	bf00      	nop
    2744:	20000664 	.word	0x20000664

00002748 <z_mrsh_gpio_port_clear_bits_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_clear_bits_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2748:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    274a:	4f11      	ldr	r7, [pc, #68]	; (2790 <z_mrsh_gpio_port_clear_bits_raw+0x48>)
    274c:	9a08      	ldr	r2, [sp, #32]
    274e:	68bb      	ldr	r3, [r7, #8]
    2750:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2754:	460e      	mov	r6, r1
    2756:	4604      	mov	r4, r0
#include <syscalls/gpio_port_set_bits_raw_mrsh.c>

static inline int z_vrfy_gpio_port_clear_bits_raw(struct device *port,
						  gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_clear_bits_raw));
    2758:	f7fd fcc0 	bl	dc <z_object_find>
    275c:	2200      	movs	r2, #0
    275e:	211b      	movs	r1, #27
    2760:	f002 feea 	bl	5538 <z_object_validate>
    2764:	463a      	mov	r2, r7
    2766:	4605      	mov	r5, r0
    2768:	b130      	cbz	r0, 2778 <z_mrsh_gpio_port_clear_bits_raw+0x30>
    276a:	f003 fdee 	bl	634a <arch_is_user_context>
    276e:	6893      	ldr	r3, [r2, #8]
    2770:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2774:	f003 fcea 	bl	614c <arch_syscall_oops>
    2778:	68a3      	ldr	r3, [r4, #8]
    277a:	691b      	ldr	r3, [r3, #16]
    277c:	2b00      	cmp	r3, #0
    277e:	d0f4      	beq.n	276a <z_mrsh_gpio_port_clear_bits_raw+0x22>
	return api->port_clear_bits_raw(port, pins);
    2780:	4631      	mov	r1, r6
    2782:	4620      	mov	r0, r4
    2784:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_clear_bits_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    2786:	68bb      	ldr	r3, [r7, #8]
    2788:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    278c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    278e:	bf00      	nop
    2790:	20000664 	.word	0x20000664

00002794 <z_mrsh_gpio_port_toggle_bits>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_toggle_bits(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_toggle_bits(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2794:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2796:	4f11      	ldr	r7, [pc, #68]	; (27dc <z_mrsh_gpio_port_toggle_bits+0x48>)
    2798:	9a08      	ldr	r2, [sp, #32]
    279a:	68bb      	ldr	r3, [r7, #8]
    279c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    27a0:	460e      	mov	r6, r1
    27a2:	4604      	mov	r4, r0
#include <syscalls/gpio_port_clear_bits_raw_mrsh.c>

static inline int z_vrfy_gpio_port_toggle_bits(struct device *port,
					       gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_toggle_bits));
    27a4:	f7fd fc9a 	bl	dc <z_object_find>
    27a8:	2200      	movs	r2, #0
    27aa:	211b      	movs	r1, #27
    27ac:	f002 fec4 	bl	5538 <z_object_validate>
    27b0:	463a      	mov	r2, r7
    27b2:	4605      	mov	r5, r0
    27b4:	b130      	cbz	r0, 27c4 <z_mrsh_gpio_port_toggle_bits+0x30>
    27b6:	f003 fdc8 	bl	634a <arch_is_user_context>
    27ba:	6893      	ldr	r3, [r2, #8]
    27bc:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    27c0:	f003 fcc4 	bl	614c <arch_syscall_oops>
    27c4:	68a3      	ldr	r3, [r4, #8]
    27c6:	695b      	ldr	r3, [r3, #20]
    27c8:	2b00      	cmp	r3, #0
    27ca:	d0f4      	beq.n	27b6 <z_mrsh_gpio_port_toggle_bits+0x22>
	return api->port_toggle_bits(port, pins);
    27cc:	4631      	mov	r1, r6
    27ce:	4620      	mov	r0, r4
    27d0:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_toggle_bits(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    27d2:	68bb      	ldr	r3, [r7, #8]
    27d4:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    27d8:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    27da:	bf00      	nop
    27dc:	20000664 	.word	0x20000664

000027e0 <z_mrsh_gpio_pin_interrupt_configure>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_pin_interrupt_configure(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
uintptr_t z_mrsh_gpio_pin_interrupt_configure(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    27e0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    27e4:	4d19      	ldr	r5, [pc, #100]	; (284c <z_mrsh_gpio_pin_interrupt_configure+0x6c>)
    27e6:	68ab      	ldr	r3, [r5, #8]
{
    27e8:	4614      	mov	r4, r2
	_current->syscall_frame = ssf;
    27ea:	9a08      	ldr	r2, [sp, #32]
    27ec:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_pin_interrupt_configure(*(struct device **)&arg0, *(gpio_pin_t*)&arg1, *(gpio_flags_t*)&arg2)
    27f0:	fa5f f881 	uxtb.w	r8, r1
{
    27f4:	4607      	mov	r7, r0

static inline int z_vrfy_gpio_pin_interrupt_configure(struct device *port,
						      gpio_pin_t pin,
						      gpio_flags_t flags)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, pin_interrupt_configure));
    27f6:	f7fd fc71 	bl	dc <z_object_find>
    27fa:	2200      	movs	r2, #0
    27fc:	211b      	movs	r1, #27
    27fe:	f002 fe9b 	bl	5538 <z_object_validate>
    2802:	b130      	cbz	r0, 2812 <z_mrsh_gpio_pin_interrupt_configure+0x32>
    2804:	f003 fda1 	bl	634a <arch_is_user_context>
    2808:	68ab      	ldr	r3, [r5, #8]
    280a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    280e:	f003 fc9d 	bl	614c <arch_syscall_oops>
    2812:	68bb      	ldr	r3, [r7, #8]
    2814:	699e      	ldr	r6, [r3, #24]
    2816:	2e00      	cmp	r6, #0
    2818:	d0f4      	beq.n	2804 <z_mrsh_gpio_pin_interrupt_configure+0x24>
	if (((flags & GPIO_INT_LEVELS_LOGICAL) != 0) &&
    281a:	0423      	lsls	r3, r4, #16
    281c:	d508      	bpl.n	2830 <z_mrsh_gpio_pin_interrupt_configure+0x50>
	    ((data->invert & (gpio_port_pins_t)BIT(pin)) != 0)) {
    281e:	68fa      	ldr	r2, [r7, #12]
    2820:	2301      	movs	r3, #1
    2822:	6812      	ldr	r2, [r2, #0]
    2824:	fa03 f308 	lsl.w	r3, r3, r8
	if (((flags & GPIO_INT_LEVELS_LOGICAL) != 0) &&
    2828:	4213      	tst	r3, r2
		flags ^= (GPIO_INT_LOW_0 | GPIO_INT_HIGH_1);
    282a:	bf18      	it	ne
    282c:	f484 24c0 	eorne.w	r4, r4, #393216	; 0x60000
	return api->pin_interrupt_configure(port, pin, mode, trig);
    2830:	f404 23c0 	and.w	r3, r4, #393216	; 0x60000
    2834:	f404 32b0 	and.w	r2, r4, #90112	; 0x16000
    2838:	4641      	mov	r1, r8
    283a:	4638      	mov	r0, r7
    283c:	47b0      	blx	r6
;
	_current->syscall_frame = NULL;
    283e:	68ab      	ldr	r3, [r5, #8]
    2840:	2200      	movs	r2, #0
    2842:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2846:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    284a:	bf00      	nop
    284c:	20000664 	.word	0x20000664

00002850 <z_mrsh_gpio_get_pending_int>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_get_pending_int(struct device * dev);
uintptr_t z_mrsh_gpio_get_pending_int(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2850:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    2852:	4e10      	ldr	r6, [pc, #64]	; (2894 <z_mrsh_gpio_get_pending_int+0x44>)
    2854:	9a06      	ldr	r2, [sp, #24]
    2856:	68b3      	ldr	r3, [r6, #8]
    2858:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    285c:	4604      	mov	r4, r0
}
#include <syscalls/gpio_pin_interrupt_configure_mrsh.c>

static inline int z_vrfy_gpio_get_pending_int(struct device *dev)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(dev, get_pending_int));
    285e:	f7fd fc3d 	bl	dc <z_object_find>
    2862:	2200      	movs	r2, #0
    2864:	211b      	movs	r1, #27
    2866:	f002 fe67 	bl	5538 <z_object_validate>
    286a:	4632      	mov	r2, r6
    286c:	4605      	mov	r5, r0
    286e:	b130      	cbz	r0, 287e <z_mrsh_gpio_get_pending_int+0x2e>
    2870:	f003 fd6b 	bl	634a <arch_is_user_context>
    2874:	6893      	ldr	r3, [r2, #8]
    2876:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    287a:	f003 fc67 	bl	614c <arch_syscall_oops>
    287e:	68a3      	ldr	r3, [r4, #8]
    2880:	6a1b      	ldr	r3, [r3, #32]
    2882:	2b00      	cmp	r3, #0
    2884:	d0f4      	beq.n	2870 <z_mrsh_gpio_get_pending_int+0x20>

	if (api->get_pending_int == NULL) {
		return -ENOTSUP;
	}

	return api->get_pending_int(dev);
    2886:	4620      	mov	r0, r4
    2888:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_get_pending_int(*(struct device **)&arg0)
;
	_current->syscall_frame = NULL;
    288a:	68b3      	ldr	r3, [r6, #8]
    288c:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2890:	bd70      	pop	{r4, r5, r6, pc}
    2892:	bf00      	nop
    2894:	20000664 	.word	0x20000664

00002898 <uart_nrfx_err_check>:
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_uart_errorsrc_get_and_clear(NRF_UART_Type * p_reg)
{
    uint32_t errsrc_mask = p_reg->ERRORSRC;
    2898:	4b02      	ldr	r3, [pc, #8]	; (28a4 <uart_nrfx_err_check+0xc>)
    289a:	f8d3 0480 	ldr.w	r0, [r3, #1152]	; 0x480
    p_reg->ERRORSRC = errsrc_mask;
    289e:	f8c3 0480 	str.w	r0, [r3, #1152]	; 0x480
/** Console I/O function */
static int uart_nrfx_err_check(struct device *dev)
{
	/* register bitfields maps to the defines in uart.h */
	return nrf_uart_errorsrc_get_and_clear(uart0_addr);
}
    28a2:	4770      	bx	lr
    28a4:	40002000 	.word	0x40002000

000028a8 <uart_nrfx_configure>:

static int uart_nrfx_configure(struct device *dev,
			       const struct uart_config *cfg)
{
    28a8:	b530      	push	{r4, r5, lr}
		break;
	default:
		return -ENOTSUP;
	}
#else
	if (cfg->stop_bits != UART_CFG_STOP_BITS_1) {
    28aa:	794b      	ldrb	r3, [r1, #5]
    28ac:	2b01      	cmp	r3, #1
    28ae:	d11e      	bne.n	28ee <uart_nrfx_configure+0x46>
		return -ENOTSUP;
	}
#endif

	if (cfg->data_bits != UART_CFG_DATA_BITS_8) {
    28b0:	798b      	ldrb	r3, [r1, #6]
    28b2:	2b03      	cmp	r3, #3
    28b4:	d11b      	bne.n	28ee <uart_nrfx_configure+0x46>
		return -ENOTSUP;
	}

	switch (cfg->flow_ctrl) {
    28b6:	79ca      	ldrb	r2, [r1, #7]
    28b8:	b10a      	cbz	r2, 28be <uart_nrfx_configure+0x16>
    28ba:	2a01      	cmp	r2, #1
    28bc:	d117      	bne.n	28ee <uart_nrfx_configure+0x46>
	}

#if defined(UART_CONFIG_PARITYTYPE_Msk)
	uart_cfg.paritytype = NRF_UART_PARITYTYPE_EVEN;
#endif
	switch (cfg->parity) {
    28be:	790c      	ldrb	r4, [r1, #4]
    28c0:	b114      	cbz	r4, 28c8 <uart_nrfx_configure+0x20>
    28c2:	2c02      	cmp	r4, #2
    28c4:	d113      	bne.n	28ee <uart_nrfx_configure+0x46>
    28c6:	240e      	movs	r4, #14
#endif
	default:
		return -ENOTSUP;
	}

	if (baudrate_set(dev, cfg->baudrate) != 0) {
    28c8:	680b      	ldr	r3, [r1, #0]
	switch (baudrate) {
    28ca:	f5b3 4f16 	cmp.w	r3, #38400	; 0x9600
    28ce:	d05f      	beq.n	2990 <uart_nrfx_configure+0xe8>
    28d0:	d82b      	bhi.n	292a <uart_nrfx_configure+0x82>
    28d2:	f5b3 5f16 	cmp.w	r3, #9600	; 0x2580
    28d6:	d05d      	beq.n	2994 <uart_nrfx_configure+0xec>
    28d8:	d814      	bhi.n	2904 <uart_nrfx_configure+0x5c>
    28da:	f5b3 6f96 	cmp.w	r3, #1200	; 0x4b0
    28de:	d05b      	beq.n	2998 <uart_nrfx_configure+0xf0>
    28e0:	d808      	bhi.n	28f4 <uart_nrfx_configure+0x4c>
    28e2:	f5b3 7f96 	cmp.w	r3, #300	; 0x12c
    28e6:	d05a      	beq.n	299e <uart_nrfx_configure+0xf6>
    28e8:	f5b3 7f16 	cmp.w	r3, #600	; 0x258
    28ec:	d05a      	beq.n	29a4 <uart_nrfx_configure+0xfc>
    28ee:	f06f 0022 	mvn.w	r0, #34	; 0x22
    28f2:	e04c      	b.n	298e <uart_nrfx_configure+0xe6>
    28f4:	f5b3 6f16 	cmp.w	r3, #2400	; 0x960
    28f8:	d057      	beq.n	29aa <uart_nrfx_configure+0x102>
    28fa:	f5b3 5f96 	cmp.w	r3, #4800	; 0x12c0
    28fe:	d1f6      	bne.n	28ee <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_4800;
    2900:	4b34      	ldr	r3, [pc, #208]	; (29d4 <uart_nrfx_configure+0x12c>)
    2902:	e039      	b.n	2978 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2904:	f5b3 4fe1 	cmp.w	r3, #28800	; 0x7080
    2908:	d052      	beq.n	29b0 <uart_nrfx_configure+0x108>
    290a:	d807      	bhi.n	291c <uart_nrfx_configure+0x74>
    290c:	f5b3 5f61 	cmp.w	r3, #14400	; 0x3840
    2910:	d050      	beq.n	29b4 <uart_nrfx_configure+0x10c>
    2912:	f5b3 4f96 	cmp.w	r3, #19200	; 0x4b00
    2916:	d1ea      	bne.n	28ee <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_19200;
    2918:	4b2f      	ldr	r3, [pc, #188]	; (29d8 <uart_nrfx_configure+0x130>)
    291a:	e02d      	b.n	2978 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    291c:	f647 2512 	movw	r5, #31250	; 0x7a12
    2920:	42ab      	cmp	r3, r5
    2922:	d1e4      	bne.n	28ee <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_31250;
    2924:	f44f 0300 	mov.w	r3, #8388608	; 0x800000
    2928:	e026      	b.n	2978 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    292a:	f5b3 3f61 	cmp.w	r3, #230400	; 0x38400
    292e:	d044      	beq.n	29ba <uart_nrfx_configure+0x112>
    2930:	d811      	bhi.n	2956 <uart_nrfx_configure+0xae>
    2932:	f5b3 3f96 	cmp.w	r3, #76800	; 0x12c00
    2936:	d042      	beq.n	29be <uart_nrfx_configure+0x116>
    2938:	d808      	bhi.n	294c <uart_nrfx_configure+0xa4>
    293a:	f64d 25c0 	movw	r5, #56000	; 0xdac0
    293e:	42ab      	cmp	r3, r5
    2940:	d03f      	beq.n	29c2 <uart_nrfx_configure+0x11a>
    2942:	f5b3 4f61 	cmp.w	r3, #57600	; 0xe100
    2946:	d1d2      	bne.n	28ee <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_57600;
    2948:	4b24      	ldr	r3, [pc, #144]	; (29dc <uart_nrfx_configure+0x134>)
    294a:	e015      	b.n	2978 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    294c:	f5b3 3fe1 	cmp.w	r3, #115200	; 0x1c200
    2950:	d1cd      	bne.n	28ee <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_115200;
    2952:	4b23      	ldr	r3, [pc, #140]	; (29e0 <uart_nrfx_configure+0x138>)
    2954:	e010      	b.n	2978 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2956:	f5b3 2f61 	cmp.w	r3, #921600	; 0xe1000
    295a:	d035      	beq.n	29c8 <uart_nrfx_configure+0x120>
    295c:	d807      	bhi.n	296e <uart_nrfx_configure+0xc6>
    295e:	4d21      	ldr	r5, [pc, #132]	; (29e4 <uart_nrfx_configure+0x13c>)
    2960:	42ab      	cmp	r3, r5
    2962:	d033      	beq.n	29cc <uart_nrfx_configure+0x124>
    2964:	f5b3 2fe1 	cmp.w	r3, #460800	; 0x70800
    2968:	d1c1      	bne.n	28ee <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_460800;
    296a:	4b1f      	ldr	r3, [pc, #124]	; (29e8 <uart_nrfx_configure+0x140>)
    296c:	e004      	b.n	2978 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    296e:	4d1f      	ldr	r5, [pc, #124]	; (29ec <uart_nrfx_configure+0x144>)
    2970:	42ab      	cmp	r3, r5
    2972:	d1bc      	bne.n	28ee <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_1000000;
    2974:	f04f 5380 	mov.w	r3, #268435456	; 0x10000000
                    | (uint32_t)p_cfg->hwfc;
}

NRF_STATIC_INLINE void nrf_uart_baudrate_set(NRF_UART_Type * p_reg, nrf_uart_baudrate_t baudrate)
{
    p_reg->BAUDRATE = baudrate;
    2978:	4d1d      	ldr	r5, [pc, #116]	; (29f0 <uart_nrfx_configure+0x148>)
                    | (uint32_t)p_cfg->hwfc;
    297a:	4322      	orrs	r2, r4
    p_reg->BAUDRATE = baudrate;
    297c:	f8c5 3524 	str.w	r3, [r5, #1316]	; 0x524
    p_reg->CONFIG = (uint32_t)p_cfg->parity
    2980:	f8c5 256c 	str.w	r2, [r5, #1388]	; 0x56c
		return -ENOTSUP;
	}

	nrf_uart_configure(uart0_addr, &uart_cfg);

	get_dev_data(dev)->uart_config = *cfg;
    2984:	68c3      	ldr	r3, [r0, #12]
    2986:	c903      	ldmia	r1, {r0, r1}
    2988:	e883 0003 	stmia.w	r3, {r0, r1}

	return 0;
    298c:	2000      	movs	r0, #0
}
    298e:	bd30      	pop	{r4, r5, pc}
		nrf_baudrate = NRF_UART_BAUDRATE_38400;
    2990:	4b18      	ldr	r3, [pc, #96]	; (29f4 <uart_nrfx_configure+0x14c>)
    2992:	e7f1      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_9600;
    2994:	4b18      	ldr	r3, [pc, #96]	; (29f8 <uart_nrfx_configure+0x150>)
    2996:	e7ef      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_1200;
    2998:	f44f 239e 	mov.w	r3, #323584	; 0x4f000
    299c:	e7ec      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = 0x00014000;
    299e:	f44f 33a0 	mov.w	r3, #81920	; 0x14000
    29a2:	e7e9      	b.n	2978 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    29a4:	f44f 331c 	mov.w	r3, #159744	; 0x27000
    29a8:	e7e6      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_2400;
    29aa:	f44f 231d 	mov.w	r3, #643072	; 0x9d000
    29ae:	e7e3      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_28800;
    29b0:	4b12      	ldr	r3, [pc, #72]	; (29fc <uart_nrfx_configure+0x154>)
    29b2:	e7e1      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_14400;
    29b4:	f44f 136c 	mov.w	r3, #3866624	; 0x3b0000
    29b8:	e7de      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_230400;
    29ba:	4b11      	ldr	r3, [pc, #68]	; (2a00 <uart_nrfx_configure+0x158>)
    29bc:	e7dc      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_76800;
    29be:	4b11      	ldr	r3, [pc, #68]	; (2a04 <uart_nrfx_configure+0x15c>)
    29c0:	e7da      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_56000;
    29c2:	f44f 0365 	mov.w	r3, #15007744	; 0xe50000
    29c6:	e7d7      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_921600;
    29c8:	4b0f      	ldr	r3, [pc, #60]	; (2a08 <uart_nrfx_configure+0x160>)
    29ca:	e7d5      	b.n	2978 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_250000;
    29cc:	f04f 6380 	mov.w	r3, #67108864	; 0x4000000
    29d0:	e7d2      	b.n	2978 <uart_nrfx_configure+0xd0>
    29d2:	bf00      	nop
    29d4:	0013b000 	.word	0x0013b000
    29d8:	004ea000 	.word	0x004ea000
    29dc:	00ebf000 	.word	0x00ebf000
    29e0:	01d7e000 	.word	0x01d7e000
    29e4:	0003d090 	.word	0x0003d090
    29e8:	075f7000 	.word	0x075f7000
    29ec:	000f4240 	.word	0x000f4240
    29f0:	40002000 	.word	0x40002000
    29f4:	009d5000 	.word	0x009d5000
    29f8:	00275000 	.word	0x00275000
    29fc:	0075f000 	.word	0x0075f000
    2a00:	03afb000 	.word	0x03afb000
    2a04:	013a9000 	.word	0x013a9000
    2a08:	0ebed000 	.word	0x0ebed000

00002a0c <uart_nrfx_poll_in>:
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    2a0c:	4b08      	ldr	r3, [pc, #32]	; (2a30 <uart_nrfx_poll_in+0x24>)
    2a0e:	681a      	ldr	r2, [r3, #0]
{
    2a10:	b082      	sub	sp, #8
	if (!nrf_uart_event_check(uart0_addr, NRF_UART_EVENT_RXDRDY)) {
    2a12:	b152      	cbz	r2, 2a2a <uart_nrfx_poll_in+0x1e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    2a14:	2000      	movs	r0, #0
    2a16:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    2a18:	681b      	ldr	r3, [r3, #0]
    2a1a:	9301      	str	r3, [sp, #4]
    (void)dummy;
    2a1c:	9b01      	ldr	r3, [sp, #4]
    return p_reg->RXD;
    2a1e:	4b05      	ldr	r3, [pc, #20]	; (2a34 <uart_nrfx_poll_in+0x28>)
    2a20:	f8d3 3518 	ldr.w	r3, [r3, #1304]	; 0x518
    2a24:	700b      	strb	r3, [r1, #0]
}
    2a26:	b002      	add	sp, #8
    2a28:	4770      	bx	lr
		return -1;
    2a2a:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    2a2e:	e7fa      	b.n	2a26 <uart_nrfx_poll_in+0x1a>
    2a30:	40002108 	.word	0x40002108
    2a34:	40002000 	.word	0x40002000

00002a38 <uart_nrfx_poll_out>:
{
    2a38:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    2a3a:	460e      	mov	r6, r1
	if (!k_is_in_isr()) {
    2a3c:	f004 f805 	bl	6a4a <k_is_in_isr>
    2a40:	4d1b      	ldr	r5, [pc, #108]	; (2ab0 <uart_nrfx_poll_out+0x78>)
    2a42:	bb88      	cbnz	r0, 2aa8 <uart_nrfx_poll_out+0x70>
    2a44:	2464      	movs	r4, #100	; 0x64
	return __atomic_compare_exchange_n(target, &old_value, new_value,
    2a46:	2701      	movs	r7, #1
    2a48:	f3bf 8f5b 	dmb	ish
    2a4c:	e855 3f00 	ldrex	r3, [r5]
    2a50:	2b00      	cmp	r3, #0
    2a52:	d103      	bne.n	2a5c <uart_nrfx_poll_out+0x24>
    2a54:	e845 7200 	strex	r2, r7, [r5]
    2a58:	2a00      	cmp	r2, #0
    2a5a:	d1f7      	bne.n	2a4c <uart_nrfx_poll_out+0x14>
    2a5c:	f3bf 8f5b 	dmb	ish
		while (atomic_cas((atomic_t *) lock,
    2a60:	d007      	beq.n	2a72 <uart_nrfx_poll_out+0x3a>
	return z_impl_k_sleep(timeout);
    2a62:	2021      	movs	r0, #33	; 0x21
    2a64:	2100      	movs	r1, #0
    2a66:	3c01      	subs	r4, #1
    2a68:	f001 fc66 	bl	4338 <z_impl_k_sleep>
			if (--safety_cnt == 0) {
    2a6c:	f014 04ff 	ands.w	r4, r4, #255	; 0xff
    2a70:	d1ea      	bne.n	2a48 <uart_nrfx_poll_out+0x10>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    2a72:	4c10      	ldr	r4, [pc, #64]	; (2ab4 <uart_nrfx_poll_out+0x7c>)
    2a74:	2200      	movs	r2, #0
    2a76:	6022      	str	r2, [r4, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    2a78:	6822      	ldr	r2, [r4, #0]
    2a7a:	9201      	str	r2, [sp, #4]
    (void)dummy;
    2a7c:	9a01      	ldr	r2, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    2a7e:	4a0e      	ldr	r2, [pc, #56]	; (2ab8 <uart_nrfx_poll_out+0x80>)
    2a80:	2101      	movs	r1, #1
    2a82:	6011      	str	r1, [r2, #0]
    p_reg->TXD = txd;
    2a84:	f8c2 6514 	str.w	r6, [r2, #1300]	; 0x514
    2a88:	f44f 767a 	mov.w	r6, #1000	; 0x3e8
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    2a8c:	6823      	ldr	r3, [r4, #0]
	NRFX_WAIT_FOR(event_txdrdy_check(), 1000, 1, res);
    2a8e:	b923      	cbnz	r3, 2a9a <uart_nrfx_poll_out+0x62>
    2a90:	2001      	movs	r0, #1
    2a92:	f003 fc76 	bl	6382 <nrfx_busy_wait>
    2a96:	3e01      	subs	r6, #1
    2a98:	d1f8      	bne.n	2a8c <uart_nrfx_poll_out+0x54>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    2a9a:	4b08      	ldr	r3, [pc, #32]	; (2abc <uart_nrfx_poll_out+0x84>)
    2a9c:	2201      	movs	r2, #1
    2a9e:	601a      	str	r2, [r3, #0]
	*lock = 0;
    2aa0:	2300      	movs	r3, #0
    2aa2:	602b      	str	r3, [r5, #0]
}
    2aa4:	b003      	add	sp, #12
    2aa6:	bdf0      	pop	{r4, r5, r6, r7, pc}
		*lock = 1;
    2aa8:	2301      	movs	r3, #1
    2aaa:	602b      	str	r3, [r5, #0]
    2aac:	e7e1      	b.n	2a72 <uart_nrfx_poll_out+0x3a>
    2aae:	bf00      	nop
    2ab0:	20000660 	.word	0x20000660
    2ab4:	4000211c 	.word	0x4000211c
    2ab8:	40002008 	.word	0x40002008
    2abc:	4000200c 	.word	0x4000200c

00002ac0 <uart_nrfx_init>:
 * @param dev UART device struct
 *
 * @return 0 on success
 */
static int uart_nrfx_init(struct device *dev)
{
    2ac0:	b537      	push	{r0, r1, r2, r4, r5, lr}
    p_reg->OUTSET = set_mask;
    2ac2:	f04f 43a0 	mov.w	r3, #1342177280	; 0x50000000
    p_reg->ENABLE = UART_ENABLE_ENABLE_Disabled;
    2ac6:	4c17      	ldr	r4, [pc, #92]	; (2b24 <uart_nrfx_init+0x64>)
    2ac8:	2200      	movs	r2, #0
    2aca:	2140      	movs	r1, #64	; 0x40
    2acc:	f8c4 2500 	str.w	r2, [r4, #1280]	; 0x500
    p_reg->PSELRXD = pselrxd;
    2ad0:	2508      	movs	r5, #8
    2ad2:	f8c3 1508 	str.w	r1, [r3, #1288]	; 0x508
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    2ad6:	2103      	movs	r1, #3
    2ad8:	f8c3 1718 	str.w	r1, [r3, #1816]	; 0x718
    2adc:	f8c3 2720 	str.w	r2, [r3, #1824]	; 0x720
    2ae0:	f8c4 5514 	str.w	r5, [r4, #1300]	; 0x514
    p_reg->PSELTXD = pseltxd;
    2ae4:	2506      	movs	r5, #6
    2ae6:	f8c4 550c 	str.w	r5, [r4, #1292]	; 0x50c
    p_reg->OUTSET = set_mask;
    2aea:	2520      	movs	r5, #32
    2aec:	f8c3 5508 	str.w	r5, [r3, #1288]	; 0x508
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    2af0:	f8c3 1714 	str.w	r1, [r3, #1812]	; 0x714
    2af4:	f8c3 271c 	str.w	r2, [r3, #1820]	; 0x71c
    p_reg->PSELRTS = pselrts;
    2af8:	2305      	movs	r3, #5
    2afa:	f8c4 3508 	str.w	r3, [r4, #1288]	; 0x508
    p_reg->PSELCTS = pselcts;
    2afe:	2307      	movs	r3, #7
	}

	nrf_uart_hwfc_pins_set(uart0_addr, RTS_PIN, CTS_PIN);

	/* Set initial configuration */
	err = uart_nrfx_configure(dev, &get_dev_data(dev)->uart_config);
    2b00:	68c1      	ldr	r1, [r0, #12]
    2b02:	f8c4 3510 	str.w	r3, [r4, #1296]	; 0x510
    2b06:	f7ff fecf 	bl	28a8 <uart_nrfx_configure>
	if (err) {
    2b0a:	b948      	cbnz	r0, 2b20 <uart_nrfx_init+0x60>
    p_reg->ENABLE = UART_ENABLE_ENABLE_Enabled;
    2b0c:	2304      	movs	r3, #4
    2b0e:	f8c4 3500 	str.w	r3, [r4, #1280]	; 0x500
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    2b12:	4b05      	ldr	r3, [pc, #20]	; (2b28 <uart_nrfx_init+0x68>)
    2b14:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    2b16:	681b      	ldr	r3, [r3, #0]
    2b18:	9301      	str	r3, [sp, #4]
    (void)dummy;
    2b1a:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    2b1c:	2301      	movs	r3, #1
    2b1e:	6023      	str	r3, [r4, #0]
#if HW_FLOW_CONTROL_AVAILABLE
	k_delayed_work_init(&uart0_cb.tx_timeout_work, tx_timeout);
#endif
#endif
	return 0;
}
    2b20:	b003      	add	sp, #12
    2b22:	bd30      	pop	{r4, r5, pc}
    2b24:	40002000 	.word	0x40002000
    2b28:	40002108 	.word	0x40002108

00002b2c <z_mrsh_uart_err_check>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_err_check(struct device * dev);
uintptr_t z_mrsh_uart_err_check(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2b2c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    2b2e:	4e10      	ldr	r6, [pc, #64]	; (2b70 <z_mrsh_uart_err_check+0x44>)
    2b30:	9a06      	ldr	r2, [sp, #24]
    2b32:	68b3      	ldr	r3, [r6, #8]
    2b34:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2b38:	4604      	mov	r4, r0
	{							 \
		Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, op_)); \
		z_impl_uart_ ## op_(dev); \
	}

UART_SIMPLE(err_check)
    2b3a:	f7fd facf 	bl	dc <z_object_find>
    2b3e:	2200      	movs	r2, #0
    2b40:	2126      	movs	r1, #38	; 0x26
    2b42:	f002 fcf9 	bl	5538 <z_object_validate>
    2b46:	4632      	mov	r2, r6
    2b48:	4605      	mov	r5, r0
    2b4a:	b130      	cbz	r0, 2b5a <z_mrsh_uart_err_check+0x2e>
    2b4c:	f003 fc0f 	bl	636e <arch_is_user_context>
    2b50:	6893      	ldr	r3, [r2, #8]
    2b52:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2b56:	f003 faf9 	bl	614c <arch_syscall_oops>
    2b5a:	68a3      	ldr	r3, [r4, #8]
    2b5c:	689b      	ldr	r3, [r3, #8]
    2b5e:	2b00      	cmp	r3, #0
    2b60:	d0f4      	beq.n	2b4c <z_mrsh_uart_err_check+0x20>
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	if (api->err_check != NULL) {
		return api->err_check(dev);
    2b62:	4620      	mov	r0, r4
    2b64:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_err_check(*(struct device **)&arg0)
;
	_current->syscall_frame = NULL;
    2b66:	68b3      	ldr	r3, [r6, #8]
    2b68:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2b6c:	bd70      	pop	{r4, r5, r6, pc}
    2b6e:	bf00      	nop
    2b70:	20000664 	.word	0x20000664

00002b74 <z_mrsh_uart_poll_in>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_poll_in(struct device * dev, unsigned char * p_char);
uintptr_t z_mrsh_uart_poll_in(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2b74:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2b76:	4e17      	ldr	r6, [pc, #92]	; (2bd4 <z_mrsh_uart_poll_in+0x60>)
    2b78:	9a08      	ldr	r2, [sp, #32]
    2b7a:	68b3      	ldr	r3, [r6, #8]
    2b7c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2b80:	460d      	mov	r5, r1
    2b82:	4604      	mov	r4, r0
#include <syscalls/uart_err_check_mrsh.c>

static inline int z_vrfy_uart_poll_in(struct device *dev,
				      unsigned char *p_char)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_in));
    2b84:	f7fd faaa 	bl	dc <z_object_find>
    2b88:	2200      	movs	r2, #0
    2b8a:	2126      	movs	r1, #38	; 0x26
    2b8c:	f002 fcd4 	bl	5538 <z_object_validate>
    2b90:	4632      	mov	r2, r6
    2b92:	b178      	cbz	r0, 2bb4 <z_mrsh_uart_poll_in+0x40>
    2b94:	f003 fbeb 	bl	636e <arch_is_user_context>
    2b98:	6893      	ldr	r3, [r2, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(p_char, sizeof(unsigned char)));
    2b9a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2b9e:	f003 fad5 	bl	614c <arch_syscall_oops>
static inline int z_impl_uart_poll_in(struct device *dev, unsigned char *p_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	return api->poll_in(dev, p_char);
    2ba2:	68a3      	ldr	r3, [r4, #8]
    2ba4:	4629      	mov	r1, r5
    2ba6:	681b      	ldr	r3, [r3, #0]
    2ba8:	4620      	mov	r0, r4
    2baa:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_poll_in(*(struct device **)&arg0, *(unsigned char **)&arg1)
;
	_current->syscall_frame = NULL;
    2bac:	68b3      	ldr	r3, [r6, #8]
    2bae:	f8c3 7084 	str.w	r7, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2bb2:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_in));
    2bb4:	68a3      	ldr	r3, [r4, #8]
    2bb6:	681b      	ldr	r3, [r3, #0]
    2bb8:	2b00      	cmp	r3, #0
    2bba:	d0eb      	beq.n	2b94 <z_mrsh_uart_poll_in+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(p_char, sizeof(unsigned char)));
    2bbc:	2201      	movs	r2, #1
    2bbe:	4611      	mov	r1, r2
    2bc0:	4628      	mov	r0, r5
    2bc2:	f003 faf1 	bl	61a8 <arch_buffer_validate>
    2bc6:	4607      	mov	r7, r0
    2bc8:	2800      	cmp	r0, #0
    2bca:	d0ea      	beq.n	2ba2 <z_mrsh_uart_poll_in+0x2e>
    2bcc:	f003 fbcf 	bl	636e <arch_is_user_context>
    2bd0:	68b3      	ldr	r3, [r6, #8]
    2bd2:	e7e2      	b.n	2b9a <z_mrsh_uart_poll_in+0x26>
    2bd4:	20000664 	.word	0x20000664

00002bd8 <z_mrsh_uart_poll_out>:
#include <syscalls/uart.h>

extern void z_vrfy_uart_poll_out(struct device * dev, unsigned char out_char);
uintptr_t z_mrsh_uart_poll_out(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2bd8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2bda:	4f11      	ldr	r7, [pc, #68]	; (2c20 <z_mrsh_uart_poll_out+0x48>)
    2bdc:	9a08      	ldr	r2, [sp, #32]
    2bde:	68bb      	ldr	r3, [r7, #8]
    2be0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_uart_poll_out(*(struct device **)&arg0, *(unsigned char*)&arg1)
    2be4:	b2ce      	uxtb	r6, r1
{
    2be6:	4605      	mov	r5, r0
#include <syscalls/uart_poll_in_mrsh.c>

static inline void z_vrfy_uart_poll_out(struct device *dev,
					unsigned char out_char)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_out));
    2be8:	f7fd fa78 	bl	dc <z_object_find>
    2bec:	2200      	movs	r2, #0
    2bee:	2126      	movs	r1, #38	; 0x26
    2bf0:	f002 fca2 	bl	5538 <z_object_validate>
    2bf4:	463a      	mov	r2, r7
    2bf6:	4604      	mov	r4, r0
    2bf8:	b130      	cbz	r0, 2c08 <z_mrsh_uart_poll_out+0x30>
    2bfa:	f003 fbb8 	bl	636e <arch_is_user_context>
    2bfe:	6893      	ldr	r3, [r2, #8]
    2c00:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2c04:	f003 faa2 	bl	614c <arch_syscall_oops>
    2c08:	68ab      	ldr	r3, [r5, #8]
    2c0a:	685b      	ldr	r3, [r3, #4]
    2c0c:	2b00      	cmp	r3, #0
    2c0e:	d0f4      	beq.n	2bfa <z_mrsh_uart_poll_out+0x22>
						unsigned char out_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	api->poll_out(dev, out_char);
    2c10:	4628      	mov	r0, r5
    2c12:	4631      	mov	r1, r6
    2c14:	4798      	blx	r3
;
	_current->syscall_frame = NULL;
    2c16:	68bb      	ldr	r3, [r7, #8]
	return 0;
}
    2c18:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    2c1a:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    2c1e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    2c20:	20000664 	.word	0x20000664

00002c24 <z_mrsh_uart_config_get>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_config_get(struct device * dev, struct uart_config * cfg);
uintptr_t z_mrsh_uart_config_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2c24:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2c26:	4e1a      	ldr	r6, [pc, #104]	; (2c90 <z_mrsh_uart_config_get+0x6c>)
    2c28:	9a08      	ldr	r2, [sp, #32]
    2c2a:	68b3      	ldr	r3, [r6, #8]
    2c2c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2c30:	460d      	mov	r5, r1
    2c32:	4604      	mov	r4, r0
#include <syscalls/uart_poll_out_mrsh.c>

static inline int z_vrfy_uart_config_get(struct device *dev,
		struct uart_config *cfg)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2c34:	f7fd fa52 	bl	dc <z_object_find>
    2c38:	2200      	movs	r2, #0
    2c3a:	2126      	movs	r1, #38	; 0x26
    2c3c:	f002 fc7c 	bl	5538 <z_object_validate>
    2c40:	4637      	mov	r7, r6
    2c42:	b1a8      	cbz	r0, 2c70 <z_mrsh_uart_config_get+0x4c>
    2c44:	f003 fb93 	bl	636e <arch_is_user_context>
    2c48:	68bb      	ldr	r3, [r7, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(cfg, sizeof(struct uart_config)));
    2c4a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2c4e:	f003 fa7d 	bl	614c <arch_syscall_oops>
{
	const struct uart_driver_api *api =
				(const struct uart_driver_api *)dev->driver_api;

	if (api->config_get != NULL) {
		return api->config_get(dev, cfg);
    2c52:	4629      	mov	r1, r5
    2c54:	4620      	mov	r0, r4
    2c56:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_config_get(*(struct device **)&arg0, *(struct uart_config **)&arg1)
;
	_current->syscall_frame = NULL;
    2c58:	68bb      	ldr	r3, [r7, #8]
    2c5a:	2200      	movs	r2, #0
    2c5c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2c60:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (api->config_get != NULL) {
    2c62:	68a3      	ldr	r3, [r4, #8]
    2c64:	691b      	ldr	r3, [r3, #16]
    2c66:	2b00      	cmp	r3, #0
    2c68:	d1f3      	bne.n	2c52 <z_mrsh_uart_config_get+0x2e>
	}

	return -ENOTSUP;
    2c6a:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2c6e:	e7f3      	b.n	2c58 <z_mrsh_uart_config_get+0x34>
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2c70:	68a3      	ldr	r3, [r4, #8]
    2c72:	691b      	ldr	r3, [r3, #16]
    2c74:	2b00      	cmp	r3, #0
    2c76:	d0e5      	beq.n	2c44 <z_mrsh_uart_config_get+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(cfg, sizeof(struct uart_config)));
    2c78:	2201      	movs	r2, #1
    2c7a:	2108      	movs	r1, #8
    2c7c:	4628      	mov	r0, r5
    2c7e:	f003 fa93 	bl	61a8 <arch_buffer_validate>
    2c82:	2800      	cmp	r0, #0
    2c84:	d0ed      	beq.n	2c62 <z_mrsh_uart_config_get+0x3e>
    2c86:	f003 fb72 	bl	636e <arch_is_user_context>
    2c8a:	68b3      	ldr	r3, [r6, #8]
    2c8c:	e7dd      	b.n	2c4a <z_mrsh_uart_config_get+0x26>
    2c8e:	bf00      	nop
    2c90:	20000664 	.word	0x20000664

00002c94 <z_mrsh_uart_configure>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_configure(struct device * dev, const struct uart_config * cfg);
uintptr_t z_mrsh_uart_configure(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2c94:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2c96:	4e1a      	ldr	r6, [pc, #104]	; (2d00 <z_mrsh_uart_configure+0x6c>)
    2c98:	9a08      	ldr	r2, [sp, #32]
    2c9a:	68b3      	ldr	r3, [r6, #8]
    2c9c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2ca0:	460d      	mov	r5, r1
    2ca2:	4604      	mov	r4, r0
#include <syscalls/uart_config_get_mrsh.c>

static inline int z_vrfy_uart_configure(struct device *dev,
		const struct uart_config *cfg)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2ca4:	f7fd fa1a 	bl	dc <z_object_find>
    2ca8:	2200      	movs	r2, #0
    2caa:	2126      	movs	r1, #38	; 0x26
    2cac:	f002 fc44 	bl	5538 <z_object_validate>
    2cb0:	4637      	mov	r7, r6
    2cb2:	4602      	mov	r2, r0
    2cb4:	b1a8      	cbz	r0, 2ce2 <z_mrsh_uart_configure+0x4e>
    2cb6:	f003 fb5a 	bl	636e <arch_is_user_context>
    2cba:	68bb      	ldr	r3, [r7, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_READ(cfg, sizeof(struct uart_config)));
    2cbc:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2cc0:	f003 fa44 	bl	614c <arch_syscall_oops>
		return api->configure(dev, cfg);
    2cc4:	4629      	mov	r1, r5
    2cc6:	4620      	mov	r0, r4
    2cc8:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_configure(*(struct device **)&arg0, *(const struct uart_config **)&arg1)
;
	_current->syscall_frame = NULL;
    2cca:	68bb      	ldr	r3, [r7, #8]
    2ccc:	2200      	movs	r2, #0
    2cce:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2cd2:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (api->configure != NULL) {
    2cd4:	68a3      	ldr	r3, [r4, #8]
    2cd6:	68db      	ldr	r3, [r3, #12]
    2cd8:	2b00      	cmp	r3, #0
    2cda:	d1f3      	bne.n	2cc4 <z_mrsh_uart_configure+0x30>
	return -ENOTSUP;
    2cdc:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2ce0:	e7f3      	b.n	2cca <z_mrsh_uart_configure+0x36>
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2ce2:	68a3      	ldr	r3, [r4, #8]
    2ce4:	691b      	ldr	r3, [r3, #16]
    2ce6:	2b00      	cmp	r3, #0
    2ce8:	d0e5      	beq.n	2cb6 <z_mrsh_uart_configure+0x22>
	Z_OOPS(Z_SYSCALL_MEMORY_READ(cfg, sizeof(struct uart_config)));
    2cea:	2108      	movs	r1, #8
    2cec:	4628      	mov	r0, r5
    2cee:	f003 fa5b 	bl	61a8 <arch_buffer_validate>
    2cf2:	2800      	cmp	r0, #0
    2cf4:	d0ee      	beq.n	2cd4 <z_mrsh_uart_configure+0x40>
    2cf6:	f003 fb3a 	bl	636e <arch_is_user_context>
    2cfa:	68b3      	ldr	r3, [r6, #8]
    2cfc:	e7de      	b.n	2cbc <z_mrsh_uart_configure+0x28>
    2cfe:	bf00      	nop
    2d00:	20000664 	.word	0x20000664

00002d04 <nrf52_errata_108>:
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1;
            uint32_t var2;

            if (*(uint32_t *)0x10000130ul == 0xFFFFFFFF)
    2d04:	4b0b      	ldr	r3, [pc, #44]	; (2d34 <nrf52_errata_108+0x30>)
    2d06:	681b      	ldr	r3, [r3, #0]
    2d08:	1c5a      	adds	r2, r3, #1
            {
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2d0a:	bf05      	ittet	eq
    2d0c:	4b0a      	ldreq	r3, [pc, #40]	; (2d38 <nrf52_errata_108+0x34>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2d0e:	4a0b      	ldreq	r2, [pc, #44]	; (2d3c <nrf52_errata_108+0x38>)
            }
            else
            {
                var1 = *(uint32_t *)0x10000130ul;
                var2 = *(uint32_t *)0x10000134ul;
    2d10:	4a0b      	ldrne	r2, [pc, #44]	; (2d40 <nrf52_errata_108+0x3c>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2d12:	6810      	ldreq	r0, [r2, #0]
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2d14:	bf0a      	itet	eq
    2d16:	781b      	ldrbeq	r3, [r3, #0]
                var2 = *(uint32_t *)0x10000134ul;
    2d18:	6810      	ldrne	r0, [r2, #0]
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2d1a:	f3c0 1003 	ubfxeq	r0, r0, #4, #4
            }
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2d1e:	2b06      	cmp	r3, #6
    2d20:	d105      	bne.n	2d2e <nrf52_errata_108+0x2a>
            {
                switch(var2)
    2d22:	3803      	subs	r0, #3
    2d24:	2803      	cmp	r0, #3
    2d26:	bf8c      	ite	hi
    2d28:	2000      	movhi	r0, #0
    2d2a:	2001      	movls	r0, #1
    2d2c:	4770      	bx	lr
                    case 0x06ul:
                        return true;
                }
            }
        #endif
        return false;
    2d2e:	2000      	movs	r0, #0
    #endif
}
    2d30:	4770      	bx	lr
    2d32:	bf00      	nop
    2d34:	10000130 	.word	0x10000130
    2d38:	f0000fe0 	.word	0xf0000fe0
    2d3c:	f0000fe8 	.word	0xf0000fe8
    2d40:	10000134 	.word	0x10000134

00002d44 <nrf52_errata_16>:
    #ifndef NRF52_SERIES
        return false;
    #else
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2d44:	4b07      	ldr	r3, [pc, #28]	; (2d64 <nrf52_errata_16+0x20>)
    2d46:	781b      	ldrb	r3, [r3, #0]
            uint32_t var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2d48:	2b06      	cmp	r3, #6
    2d4a:	d109      	bne.n	2d60 <nrf52_errata_16+0x1c>
            uint32_t var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2d4c:	4b06      	ldr	r3, [pc, #24]	; (2d68 <nrf52_errata_16+0x24>)
    2d4e:	681b      	ldr	r3, [r3, #0]
    2d50:	f3c3 1303 	ubfx	r3, r3, #4, #4
    2d54:	3b03      	subs	r3, #3
    2d56:	2b03      	cmp	r3, #3
    2d58:	d802      	bhi.n	2d60 <nrf52_errata_16+0x1c>
    2d5a:	4a04      	ldr	r2, [pc, #16]	; (2d6c <nrf52_errata_16+0x28>)
    2d5c:	5cd0      	ldrb	r0, [r2, r3]
    2d5e:	4770      	bx	lr
                    case 0x06ul:
                        return false;
                }
            }
        #endif
        return false;
    2d60:	2000      	movs	r0, #0
    #endif
}
    2d62:	4770      	bx	lr
    2d64:	f0000fe0 	.word	0xf0000fe0
    2d68:	f0000fe8 	.word	0xf0000fe8
    2d6c:	00007817 	.word	0x00007817

00002d70 <SystemInit>:
{
    SystemCoreClock = __SYSTEM_CLOCK_64M;
}

void SystemInit(void)
{
    2d70:	b508      	push	{r3, lr}
        NRF_P0->PIN_CNF[20] = (GPIO_PIN_CNF_DRIVE_H0H1 << GPIO_PIN_CNF_DRIVE_Pos) | (GPIO_PIN_CNF_INPUT_Connect << GPIO_PIN_CNF_INPUT_Pos) | (GPIO_PIN_CNF_DIR_Output << GPIO_PIN_CNF_DIR_Pos);
    #endif
    
    /* Workaround for Errata 12 "COMP: Reference ladder not correctly calibrated" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_12()){
    2d72:	f7ff ffc7 	bl	2d04 <nrf52_errata_108>
    2d76:	b128      	cbz	r0, 2d84 <SystemInit+0x14>
        *(volatile uint32_t *)0x40013540 = (*(uint32_t *)0x10000324 & 0x00001F00) >> 8;
    2d78:	4b7e      	ldr	r3, [pc, #504]	; (2f74 <SystemInit+0x204>)
    2d7a:	4a7f      	ldr	r2, [pc, #508]	; (2f78 <SystemInit+0x208>)
    2d7c:	681b      	ldr	r3, [r3, #0]
    2d7e:	f3c3 2304 	ubfx	r3, r3, #8, #5
    2d82:	6013      	str	r3, [r2, #0]
    }
    
    /* Workaround for Errata 16 "System: RAM may be corrupt on wakeup from CPU IDLE" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_16()){
    2d84:	f7ff ffde 	bl	2d44 <nrf52_errata_16>
    2d88:	b110      	cbz	r0, 2d90 <SystemInit+0x20>
        *(volatile uint32_t *)0x4007C074 = 3131961357ul;
    2d8a:	4b7c      	ldr	r3, [pc, #496]	; (2f7c <SystemInit+0x20c>)
    2d8c:	4a7c      	ldr	r2, [pc, #496]	; (2f80 <SystemInit+0x210>)
    2d8e:	601a      	str	r2, [r3, #0]
    }

    /* Workaround for Errata 31 "CLOCK: Calibration values are not correctly loaded from FICR at reset" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_31()){
    2d90:	f7ff ffb8 	bl	2d04 <nrf52_errata_108>
    2d94:	b128      	cbz	r0, 2da2 <SystemInit+0x32>
        *(volatile uint32_t *)0x4000053C = ((*(volatile uint32_t *)0x10000244) & 0x0000E000) >> 13;
    2d96:	4b7b      	ldr	r3, [pc, #492]	; (2f84 <SystemInit+0x214>)
    2d98:	4a7b      	ldr	r2, [pc, #492]	; (2f88 <SystemInit+0x218>)
    2d9a:	681b      	ldr	r3, [r3, #0]
    2d9c:	f3c3 3342 	ubfx	r3, r3, #13, #3
    2da0:	6013      	str	r3, [r2, #0]
    }

    /* Workaround for Errata 32 "DIF: Debug session automatically enables TracePort pins" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_32()){
    2da2:	f7ff ffcf 	bl	2d44 <nrf52_errata_16>
    2da6:	b120      	cbz	r0, 2db2 <SystemInit+0x42>
        CoreDebug->DEMCR &= ~CoreDebug_DEMCR_TRCENA_Msk;
    2da8:	4a78      	ldr	r2, [pc, #480]	; (2f8c <SystemInit+0x21c>)
    2daa:	68d3      	ldr	r3, [r2, #12]
    2dac:	f023 7380 	bic.w	r3, r3, #16777216	; 0x1000000
    2db0:	60d3      	str	r3, [r2, #12]
    }

    /* Workaround for Errata 36 "CLOCK: Some registers are not reset when expected" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_36()){
    2db2:	f7ff ffa7 	bl	2d04 <nrf52_errata_108>
    2db6:	b140      	cbz	r0, 2dca <SystemInit+0x5a>
        NRF_CLOCK->EVENTS_DONE = 0;
    2db8:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    2dbc:	2200      	movs	r2, #0
    2dbe:	f8c3 210c 	str.w	r2, [r3, #268]	; 0x10c
        NRF_CLOCK->EVENTS_CTTO = 0;
    2dc2:	f8c3 2110 	str.w	r2, [r3, #272]	; 0x110
        NRF_CLOCK->CTIV = 0;
    2dc6:	f8c3 2538 	str.w	r2, [r3, #1336]	; 0x538
    }

    /* Workaround for Errata 37 "RADIO: Encryption engine is slow by default" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_37()){
    2dca:	f7ff ffbb 	bl	2d44 <nrf52_errata_16>
    2dce:	b110      	cbz	r0, 2dd6 <SystemInit+0x66>
        *(volatile uint32_t *)0x400005A0 = 0x3;
    2dd0:	4b6f      	ldr	r3, [pc, #444]	; (2f90 <SystemInit+0x220>)
    2dd2:	2203      	movs	r2, #3
    2dd4:	601a      	str	r2, [r3, #0]
    }

    /* Workaround for Errata 57 "NFCT: NFC Modulation amplitude" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_57()){
    2dd6:	f7ff ffb5 	bl	2d44 <nrf52_errata_16>
    2dda:	b140      	cbz	r0, 2dee <SystemInit+0x7e>
        *(volatile uint32_t *)0x40005610 = 0x00000005;
    2ddc:	4b6d      	ldr	r3, [pc, #436]	; (2f94 <SystemInit+0x224>)
    2dde:	2205      	movs	r2, #5
    2de0:	601a      	str	r2, [r3, #0]
        *(volatile uint32_t *)0x40005688 = 0x00000001;
    2de2:	2201      	movs	r2, #1
    2de4:	679a      	str	r2, [r3, #120]	; 0x78
        *(volatile uint32_t *)0x40005618 = 0x00000000;
    2de6:	2200      	movs	r2, #0
    2de8:	609a      	str	r2, [r3, #8]
        *(volatile uint32_t *)0x40005614 = 0x0000003F;
    2dea:	223f      	movs	r2, #63	; 0x3f
    2dec:	605a      	str	r2, [r3, #4]
         || defined (NRF52833_XXAA) || defined (DEVELOP_IN_NRF52833)\
         || defined (NRF52840_XXAA) || defined (DEVELOP_IN_NRF52840)
            uint32_t var1;
            uint32_t var2;

            if (*(uint32_t *)0x10000130ul == 0xFFFFFFFF)
    2dee:	4b6a      	ldr	r3, [pc, #424]	; (2f98 <SystemInit+0x228>)
    2df0:	681a      	ldr	r2, [r3, #0]
    2df2:	1c51      	adds	r1, r2, #1
            {
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2df4:	bf0b      	itete	eq
    2df6:	4b69      	ldreq	r3, [pc, #420]	; (2f9c <SystemInit+0x22c>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
            }
            else
            {
                var1 = *(uint32_t *)0x10000130ul;
                var2 = *(uint32_t *)0x10000134ul;
    2df8:	4b69      	ldrne	r3, [pc, #420]	; (2fa0 <SystemInit+0x230>)
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2dfa:	781a      	ldrbeq	r2, [r3, #0]
                var2 = *(uint32_t *)0x10000134ul;
    2dfc:	681b      	ldrne	r3, [r3, #0]
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2dfe:	bf02      	ittt	eq
    2e00:	3308      	addeq	r3, #8
    2e02:	681b      	ldreq	r3, [r3, #0]
    2e04:	f3c3 1303 	ubfxeq	r3, r3, #4, #4
            }
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2e08:	2a06      	cmp	r2, #6
    2e0a:	d14d      	bne.n	2ea8 <SystemInit+0x138>
            {
                switch(var2)
    2e0c:	3b03      	subs	r3, #3
    2e0e:	2b03      	cmp	r3, #3
    2e10:	d84a      	bhi.n	2ea8 <SystemInit+0x138>
    }

    /* Workaround for Errata 66 "TEMP: Linearity specification not met with default settings" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_66()){
    2e12:	4a64      	ldr	r2, [pc, #400]	; (2fa4 <SystemInit+0x234>)
    2e14:	5cd3      	ldrb	r3, [r2, r3]
    2e16:	2b00      	cmp	r3, #0
    2e18:	d046      	beq.n	2ea8 <SystemInit+0x138>
        NRF_TEMP->A0 = NRF_FICR->TEMP.A0;
    2e1a:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
    2e1e:	4b62      	ldr	r3, [pc, #392]	; (2fa8 <SystemInit+0x238>)
    2e20:	f8d2 1404 	ldr.w	r1, [r2, #1028]	; 0x404
    2e24:	f8c3 1520 	str.w	r1, [r3, #1312]	; 0x520
        NRF_TEMP->A1 = NRF_FICR->TEMP.A1;
    2e28:	f8d2 1408 	ldr.w	r1, [r2, #1032]	; 0x408
    2e2c:	f8c3 1524 	str.w	r1, [r3, #1316]	; 0x524
        NRF_TEMP->A2 = NRF_FICR->TEMP.A2;
    2e30:	f8d2 140c 	ldr.w	r1, [r2, #1036]	; 0x40c
    2e34:	f8c3 1528 	str.w	r1, [r3, #1320]	; 0x528
        NRF_TEMP->A3 = NRF_FICR->TEMP.A3;
    2e38:	f8d2 1410 	ldr.w	r1, [r2, #1040]	; 0x410
    2e3c:	f8c3 152c 	str.w	r1, [r3, #1324]	; 0x52c
        NRF_TEMP->A4 = NRF_FICR->TEMP.A4;
    2e40:	f8d2 1414 	ldr.w	r1, [r2, #1044]	; 0x414
    2e44:	f8c3 1530 	str.w	r1, [r3, #1328]	; 0x530
        NRF_TEMP->A5 = NRF_FICR->TEMP.A5;
    2e48:	f8d2 1418 	ldr.w	r1, [r2, #1048]	; 0x418
    2e4c:	f8c3 1534 	str.w	r1, [r3, #1332]	; 0x534
        NRF_TEMP->B0 = NRF_FICR->TEMP.B0;
    2e50:	f8d2 141c 	ldr.w	r1, [r2, #1052]	; 0x41c
    2e54:	f8c3 1540 	str.w	r1, [r3, #1344]	; 0x540
        NRF_TEMP->B1 = NRF_FICR->TEMP.B1;
    2e58:	f8d2 1420 	ldr.w	r1, [r2, #1056]	; 0x420
    2e5c:	f8c3 1544 	str.w	r1, [r3, #1348]	; 0x544
        NRF_TEMP->B2 = NRF_FICR->TEMP.B2;
    2e60:	f8d2 1424 	ldr.w	r1, [r2, #1060]	; 0x424
    2e64:	f8c3 1548 	str.w	r1, [r3, #1352]	; 0x548
        NRF_TEMP->B3 = NRF_FICR->TEMP.B3;
    2e68:	f8d2 1428 	ldr.w	r1, [r2, #1064]	; 0x428
    2e6c:	f8c3 154c 	str.w	r1, [r3, #1356]	; 0x54c
        NRF_TEMP->B4 = NRF_FICR->TEMP.B4;
    2e70:	f8d2 142c 	ldr.w	r1, [r2, #1068]	; 0x42c
    2e74:	f8c3 1550 	str.w	r1, [r3, #1360]	; 0x550
        NRF_TEMP->B5 = NRF_FICR->TEMP.B5;
    2e78:	f8d2 1430 	ldr.w	r1, [r2, #1072]	; 0x430
    2e7c:	f8c3 1554 	str.w	r1, [r3, #1364]	; 0x554
        NRF_TEMP->T0 = NRF_FICR->TEMP.T0;
    2e80:	f8d2 1434 	ldr.w	r1, [r2, #1076]	; 0x434
    2e84:	f8c3 1560 	str.w	r1, [r3, #1376]	; 0x560
        NRF_TEMP->T1 = NRF_FICR->TEMP.T1;
    2e88:	f8d2 1438 	ldr.w	r1, [r2, #1080]	; 0x438
    2e8c:	f8c3 1564 	str.w	r1, [r3, #1380]	; 0x564
        NRF_TEMP->T2 = NRF_FICR->TEMP.T2;
    2e90:	f8d2 143c 	ldr.w	r1, [r2, #1084]	; 0x43c
    2e94:	f8c3 1568 	str.w	r1, [r3, #1384]	; 0x568
        NRF_TEMP->T3 = NRF_FICR->TEMP.T3;
    2e98:	f8d2 1440 	ldr.w	r1, [r2, #1088]	; 0x440
    2e9c:	f8c3 156c 	str.w	r1, [r3, #1388]	; 0x56c
        NRF_TEMP->T4 = NRF_FICR->TEMP.T4;
    2ea0:	f8d2 2444 	ldr.w	r2, [r2, #1092]	; 0x444
    2ea4:	f8c3 2570 	str.w	r2, [r3, #1392]	; 0x570
    }

    /* Workaround for Errata 108 "RAM: RAM content cannot be trusted upon waking up from System ON Idle or System OFF mode" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_108()){
    2ea8:	f7ff ff2c 	bl	2d04 <nrf52_errata_108>
    2eac:	b128      	cbz	r0, 2eba <SystemInit+0x14a>
        *(volatile uint32_t *)0x40000EE4ul = *(volatile uint32_t *)0x10000258ul & 0x0000004Ful;
    2eae:	4b3f      	ldr	r3, [pc, #252]	; (2fac <SystemInit+0x23c>)
    2eb0:	4a3f      	ldr	r2, [pc, #252]	; (2fb0 <SystemInit+0x240>)
    2eb2:	681b      	ldr	r3, [r3, #0]
    2eb4:	f003 034f 	and.w	r3, r3, #79	; 0x4f
    2eb8:	6013      	str	r3, [r2, #0]
    }
    
    /* Workaround for Errata 136 "System: Bits in RESETREAS are set when they should not be" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_136()){
    2eba:	f7ff ff23 	bl	2d04 <nrf52_errata_108>
    2ebe:	b148      	cbz	r0, 2ed4 <SystemInit+0x164>
        if (NRF_POWER->RESETREAS & POWER_RESETREAS_RESETPIN_Msk){
    2ec0:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    2ec4:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2ec8:	07d2      	lsls	r2, r2, #31
            NRF_POWER->RESETREAS =  ~POWER_RESETREAS_RESETPIN_Msk;
    2eca:	bf44      	itt	mi
    2ecc:	f06f 0201 	mvnmi.w	r2, #1
    2ed0:	f8c3 2400 	strmi.w	r2, [r3, #1024]	; 0x400
    #ifndef NRF52_SERIES
        return false;
    #else
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1 = *(uint32_t *)0x10000130ul;
    2ed4:	4b30      	ldr	r3, [pc, #192]	; (2f98 <SystemInit+0x228>)
            uint32_t var2 = *(uint32_t *)0x10000134ul;
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2ed6:	681b      	ldr	r3, [r3, #0]
    2ed8:	2b06      	cmp	r3, #6
    2eda:	d10c      	bne.n	2ef6 <SystemInit+0x186>
            uint32_t var2 = *(uint32_t *)0x10000134ul;
    2edc:	4b30      	ldr	r3, [pc, #192]	; (2fa0 <SystemInit+0x230>)
    2ede:	681b      	ldr	r3, [r3, #0]
    2ee0:	3b03      	subs	r3, #3
    2ee2:	2b03      	cmp	r3, #3
    2ee4:	d807      	bhi.n	2ef6 <SystemInit+0x186>
        }
    }
    
    /* Workaround for Errata 182 "RADIO: Fixes for anomalies #102, #106, and #107 do not take effect" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_182()){
    2ee6:	4a33      	ldr	r2, [pc, #204]	; (2fb4 <SystemInit+0x244>)
    2ee8:	5cd3      	ldrb	r3, [r2, r3]
    2eea:	b123      	cbz	r3, 2ef6 <SystemInit+0x186>
        *(volatile uint32_t *) 0x4000173C |= (0x1 << 10);
    2eec:	4a32      	ldr	r2, [pc, #200]	; (2fb8 <SystemInit+0x248>)
    2eee:	6813      	ldr	r3, [r2, #0]
    2ef0:	f443 6380 	orr.w	r3, r3, #1024	; 0x400
    2ef4:	6013      	str	r3, [r2, #0]

    /* Configure GPIO pads as pPin Reset pin if Pin Reset capabilities desired. If CONFIG_GPIO_AS_PINRESET is not
      defined, pin reset will not be available. One GPIO (see Product Specification to see which one) will then be
      reserved for PinReset and not available as normal GPIO. */
    #if defined (CONFIG_GPIO_AS_PINRESET)
        if (((NRF_UICR->PSELRESET[0] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos)) ||
    2ef6:	f04f 2310 	mov.w	r3, #268439552	; 0x10001000
    2efa:	f8d3 2200 	ldr.w	r2, [r3, #512]	; 0x200
    2efe:	2a00      	cmp	r2, #0
    2f00:	db03      	blt.n	2f0a <SystemInit+0x19a>
            ((NRF_UICR->PSELRESET[1] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos))){
    2f02:	f8d3 3204 	ldr.w	r3, [r3, #516]	; 0x204
        if (((NRF_UICR->PSELRESET[0] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos)) ||
    2f06:	2b00      	cmp	r3, #0
    2f08:	da2f      	bge.n	2f6a <SystemInit+0x1fa>
            NRF_NVMC->CONFIG = NVMC_CONFIG_WEN_Wen << NVMC_CONFIG_WEN_Pos;
    2f0a:	4b2c      	ldr	r3, [pc, #176]	; (2fbc <SystemInit+0x24c>)
    2f0c:	2201      	movs	r2, #1
    2f0e:	f8c3 2504 	str.w	r2, [r3, #1284]	; 0x504
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2f12:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2f16:	2a00      	cmp	r2, #0
    2f18:	d0fb      	beq.n	2f12 <SystemInit+0x1a2>
            NRF_UICR->PSELRESET[0] = 21;
    2f1a:	f04f 2210 	mov.w	r2, #268439552	; 0x10001000
    2f1e:	2115      	movs	r1, #21
    2f20:	f8c2 1200 	str.w	r1, [r2, #512]	; 0x200
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2f24:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2f28:	2a00      	cmp	r2, #0
    2f2a:	d0fb      	beq.n	2f24 <SystemInit+0x1b4>
            NRF_UICR->PSELRESET[1] = 21;
    2f2c:	f04f 2310 	mov.w	r3, #268439552	; 0x10001000
    2f30:	2215      	movs	r2, #21
    2f32:	f8c3 2204 	str.w	r2, [r3, #516]	; 0x204
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2f36:	4b21      	ldr	r3, [pc, #132]	; (2fbc <SystemInit+0x24c>)
    2f38:	461a      	mov	r2, r3
    2f3a:	f8d3 1400 	ldr.w	r1, [r3, #1024]	; 0x400
    2f3e:	2900      	cmp	r1, #0
    2f40:	d0fb      	beq.n	2f3a <SystemInit+0x1ca>
            NRF_NVMC->CONFIG = NVMC_CONFIG_WEN_Ren << NVMC_CONFIG_WEN_Pos;
    2f42:	2100      	movs	r1, #0
    2f44:	f8c3 1504 	str.w	r1, [r3, #1284]	; 0x504
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2f48:	f8d2 3400 	ldr.w	r3, [r2, #1024]	; 0x400
    2f4c:	2b00      	cmp	r3, #0
    2f4e:	d0fb      	beq.n	2f48 <SystemInit+0x1d8>
  __ASM volatile ("dsb 0xF":::"memory");
    2f50:	f3bf 8f4f 	dsb	sy
__NO_RETURN __STATIC_INLINE void __NVIC_SystemReset(void)
{
  __DSB();                                                          /* Ensure all outstanding memory accesses included
                                                                       buffered write are completed before reset */
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
                           (SCB->AIRCR & SCB_AIRCR_PRIGROUP_Msk) |
    2f54:	491a      	ldr	r1, [pc, #104]	; (2fc0 <SystemInit+0x250>)
    2f56:	4b1b      	ldr	r3, [pc, #108]	; (2fc4 <SystemInit+0x254>)
    2f58:	68ca      	ldr	r2, [r1, #12]
    2f5a:	f402 62e0 	and.w	r2, r2, #1792	; 0x700
    2f5e:	4313      	orrs	r3, r2
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
    2f60:	60cb      	str	r3, [r1, #12]
    2f62:	f3bf 8f4f 	dsb	sy
                            SCB_AIRCR_SYSRESETREQ_Msk    );         /* Keep priority group unchanged */
  __DSB();                                                          /* Ensure completion of memory access */

  for(;;)                                                           /* wait until reset */
  {
    __NOP();
    2f66:	bf00      	nop
  for(;;)                                                           /* wait until reset */
    2f68:	e7fd      	b.n	2f66 <SystemInit+0x1f6>
    SystemCoreClock = __SYSTEM_CLOCK_64M;
    2f6a:	4b17      	ldr	r3, [pc, #92]	; (2fc8 <SystemInit+0x258>)
    2f6c:	4a17      	ldr	r2, [pc, #92]	; (2fcc <SystemInit+0x25c>)
    2f6e:	601a      	str	r2, [r3, #0]
            NVIC_SystemReset();
        }
    #endif

    SystemCoreClockUpdate();
}
    2f70:	bd08      	pop	{r3, pc}
    2f72:	bf00      	nop
    2f74:	10000324 	.word	0x10000324
    2f78:	40013540 	.word	0x40013540
    2f7c:	4007c074 	.word	0x4007c074
    2f80:	baadf00d 	.word	0xbaadf00d
    2f84:	10000244 	.word	0x10000244
    2f88:	4000053c 	.word	0x4000053c
    2f8c:	e000edf0 	.word	0xe000edf0
    2f90:	400005a0 	.word	0x400005a0
    2f94:	40005610 	.word	0x40005610
    2f98:	10000130 	.word	0x10000130
    2f9c:	f0000fe0 	.word	0xf0000fe0
    2fa0:	10000134 	.word	0x10000134
    2fa4:	0000780f 	.word	0x0000780f
    2fa8:	4000c000 	.word	0x4000c000
    2fac:	10000258 	.word	0x10000258
    2fb0:	40000ee4 	.word	0x40000ee4
    2fb4:	00007813 	.word	0x00007813
    2fb8:	4000173c 	.word	0x4000173c
    2fbc:	4001e000 	.word	0x4001e000
    2fc0:	e000ed00 	.word	0xe000ed00
    2fc4:	05fa0004 	.word	0x05fa0004
    2fc8:	20002e10 	.word	0x20002e10
    2fcc:	03d09000 	.word	0x03d09000

00002fd0 <z_sys_init_run_level>:
 * off and the next one begins.
 *
 * @param level init level to run.
 */
void z_sys_init_run_level(int32_t level)
{
    2fd0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2fd2:	4b0b      	ldr	r3, [pc, #44]	; (3000 <z_sys_init_run_level+0x30>)
    2fd4:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
    2fd8:	3001      	adds	r0, #1
			if (dev) {
				/* Initialization failed. Clear the API struct
				 * so that device_get_binding() will not succeed
				 * for it.
				 */
				dev->driver_api = NULL;
    2fda:	2700      	movs	r7, #0
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2fdc:	f853 6020 	ldr.w	r6, [r3, r0, lsl #2]
    2fe0:	42a6      	cmp	r6, r4
    2fe2:	d800      	bhi.n	2fe6 <z_sys_init_run_level+0x16>
			}
		}
	}
}
    2fe4:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		struct device *dev = entry->dev;
    2fe6:	6865      	ldr	r5, [r4, #4]
		if (dev != NULL) {
    2fe8:	b115      	cbz	r5, 2ff0 <z_sys_init_run_level+0x20>
			z_object_init(dev);
    2fea:	4628      	mov	r0, r5
    2fec:	f003 ff47 	bl	6e7e <z_object_init>
		retval = entry->init(dev);
    2ff0:	6823      	ldr	r3, [r4, #0]
    2ff2:	4628      	mov	r0, r5
    2ff4:	4798      	blx	r3
		if (retval != 0) {
    2ff6:	b108      	cbz	r0, 2ffc <z_sys_init_run_level+0x2c>
			if (dev) {
    2ff8:	b105      	cbz	r5, 2ffc <z_sys_init_run_level+0x2c>
				dev->driver_api = NULL;
    2ffa:	60af      	str	r7, [r5, #8]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2ffc:	3408      	adds	r4, #8
    2ffe:	e7ef      	b.n	2fe0 <z_sys_init_run_level+0x10>
    3000:	000072bc 	.word	0x000072bc

00003004 <z_impl_device_get_binding>:
	/* Split the search into two loops: in the common scenario, where
	 * device names are stored in ROM (and are referenced by the user
	 * with CONFIG_* macros), only cheap pointer comparisons will be
	 * performed. Reserve string comparisons for a fallback.
	 */
	for (dev = __device_start; dev != __device_end; dev++) {
    3004:	4b0f      	ldr	r3, [pc, #60]	; (3044 <z_impl_device_get_binding+0x40>)
{
    3006:	b570      	push	{r4, r5, r6, lr}
	for (dev = __device_start; dev != __device_end; dev++) {
    3008:	4c0f      	ldr	r4, [pc, #60]	; (3048 <z_impl_device_get_binding+0x44>)
{
    300a:	4605      	mov	r5, r0
    300c:	461e      	mov	r6, r3
	for (dev = __device_start; dev != __device_end; dev++) {
    300e:	429c      	cmp	r4, r3
    3010:	d104      	bne.n	301c <z_impl_device_get_binding+0x18>
		if (z_device_ready(dev) && (dev->name == name)) {
			return dev;
		}
	}

	for (dev = __device_start; dev != __device_end; dev++) {
    3012:	4c0d      	ldr	r4, [pc, #52]	; (3048 <z_impl_device_get_binding+0x44>)
    3014:	42b4      	cmp	r4, r6
    3016:	d108      	bne.n	302a <z_impl_device_get_binding+0x26>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
			return dev;
		}
	}

	return NULL;
    3018:	2400      	movs	r4, #0
    301a:	e010      	b.n	303e <z_impl_device_get_binding+0x3a>
		if (z_device_ready(dev) && (dev->name == name)) {
    301c:	68a2      	ldr	r2, [r4, #8]
    301e:	b112      	cbz	r2, 3026 <z_impl_device_get_binding+0x22>
    3020:	6822      	ldr	r2, [r4, #0]
    3022:	42aa      	cmp	r2, r5
    3024:	d00b      	beq.n	303e <z_impl_device_get_binding+0x3a>
	for (dev = __device_start; dev != __device_end; dev++) {
    3026:	3410      	adds	r4, #16
    3028:	e7f1      	b.n	300e <z_impl_device_get_binding+0xa>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    302a:	68a3      	ldr	r3, [r4, #8]
    302c:	b90b      	cbnz	r3, 3032 <z_impl_device_get_binding+0x2e>
	for (dev = __device_start; dev != __device_end; dev++) {
    302e:	3410      	adds	r4, #16
    3030:	e7f0      	b.n	3014 <z_impl_device_get_binding+0x10>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    3032:	6821      	ldr	r1, [r4, #0]
    3034:	4628      	mov	r0, r5
    3036:	f003 f8cd 	bl	61d4 <strcmp>
    303a:	2800      	cmp	r0, #0
    303c:	d1f7      	bne.n	302e <z_impl_device_get_binding+0x2a>
}
    303e:	4620      	mov	r0, r4
    3040:	bd70      	pop	{r4, r5, r6, pc}
    3042:	bf00      	nop
    3044:	20002e60 	.word	0x20002e60
    3048:	20002e20 	.word	0x20002e20

0000304c <z_mrsh_device_get_binding>:
#include <syscalls/device.h>

extern struct device * z_vrfy_device_get_binding(const char * name);
uintptr_t z_mrsh_device_get_binding(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    304c:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    304e:	4c0b      	ldr	r4, [pc, #44]	; (307c <z_mrsh_device_get_binding+0x30>)
{
    3050:	b08c      	sub	sp, #48	; 0x30
	_current->syscall_frame = ssf;
    3052:	68a3      	ldr	r3, [r4, #8]
    3054:	9a10      	ldr	r2, [sp, #64]	; 0x40
    3056:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    305a:	4601      	mov	r1, r0
#ifdef CONFIG_USERSPACE
static inline struct device *z_vrfy_device_get_binding(const char *name)
{
	char name_copy[Z_DEVICE_MAX_NAME_LEN];

	if (z_user_string_copy(name_copy, (char *)name, sizeof(name_copy))
    305c:	2230      	movs	r2, #48	; 0x30
    305e:	4668      	mov	r0, sp
    3060:	f003 ff35 	bl	6ece <z_user_string_copy>
    3064:	b940      	cbnz	r0, 3078 <z_mrsh_device_get_binding+0x2c>
	    != 0) {
		return 0;
	}

	return z_impl_device_get_binding(name_copy);
    3066:	4668      	mov	r0, sp
    3068:	f7ff ffcc 	bl	3004 <z_impl_device_get_binding>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	struct device * ret = z_vrfy_device_get_binding(*(const char **)&arg0)
;
	_current->syscall_frame = NULL;
    306c:	68a3      	ldr	r3, [r4, #8]
    306e:	2200      	movs	r2, #0
    3070:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3074:	b00c      	add	sp, #48	; 0x30
    3076:	bd10      	pop	{r4, pc}
		return 0;
    3078:	2000      	movs	r0, #0
    307a:	e7f7      	b.n	306c <z_mrsh_device_get_binding+0x20>
    307c:	20000664 	.word	0x20000664

00003080 <z_mrsh_z_errno>:

extern int * z_vrfy_z_errno();
uintptr_t z_mrsh_z_errno(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    3080:	4b03      	ldr	r3, [pc, #12]	; (3090 <z_mrsh_z_errno+0x10>)
    3082:	689b      	ldr	r3, [r3, #8]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int * ret = z_vrfy_z_errno()
;
	_current->syscall_frame = NULL;
    3084:	2200      	movs	r2, #0
	return (uintptr_t) ret;
}
    3086:	6e58      	ldr	r0, [r3, #100]	; 0x64
	_current->syscall_frame = NULL;
    3088:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
}
    308c:	4770      	bx	lr
    308e:	bf00      	nop
    3090:	20000664 	.word	0x20000664

00003094 <idle>:
#else
#define IDLE_YIELD_IF_COOP() do { } while (false)
#endif

void idle(void *unused1, void *unused2, void *unused3)
{
    3094:	b508      	push	{r3, lr}
	_kernel.idle = ticks;
    3096:	4d0b      	ldr	r5, [pc, #44]	; (30c4 <idle+0x30>)
	__asm__ volatile(
    3098:	f04f 0220 	mov.w	r2, #32
    309c:	f3ef 8311 	mrs	r3, BASEPRI
    30a0:	f382 8811 	msr	BASEPRI, r2
    30a4:	f3bf 8f6f 	isb	sy
	int32_t ticks = z_get_next_timeout_expiry();
    30a8:	f003 fd27 	bl	6afa <z_get_next_timeout_expiry>
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    30ac:	2101      	movs	r1, #1
    30ae:	2802      	cmp	r0, #2
	int32_t ticks = z_get_next_timeout_expiry();
    30b0:	4604      	mov	r4, r0
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    30b2:	bfd8      	it	le
    30b4:	4608      	movle	r0, r1
    30b6:	f003 fd30 	bl	6b1a <z_set_timeout_expiry>
	_kernel.idle = ticks;
    30ba:	622c      	str	r4, [r5, #32]
 *
 * @return N/A
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
    30bc:	f7fe fba8 	bl	1810 <arch_cpu_idle>
}
    30c0:	e7ea      	b.n	3098 <idle+0x4>
    30c2:	bf00      	nop
    30c4:	20000664 	.word	0x20000664

000030c8 <z_bss_zero>:
 *
 * @return N/A
 */
void z_bss_zero(void)
{
	(void)memset(__bss_start, 0, __bss_end - __bss_start);
    30c8:	4802      	ldr	r0, [pc, #8]	; (30d4 <z_bss_zero+0xc>)
    30ca:	4a03      	ldr	r2, [pc, #12]	; (30d8 <z_bss_zero+0x10>)
    30cc:	2100      	movs	r1, #0
    30ce:	1a12      	subs	r2, r2, r0
    30d0:	f003 b8b7 	b.w	6242 <memset>
    30d4:	20000000 	.word	0x20000000
    30d8:	200013f8 	.word	0x200013f8

000030dc <z_data_copy>:
 * @return N/A
 */
void z_data_copy(void)
{
	(void)memcpy(&__data_ram_start, &__data_rom_start,
		 __data_ram_end - __data_ram_start);
    30dc:	4809      	ldr	r0, [pc, #36]	; (3104 <z_data_copy+0x28>)
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    30de:	4a0a      	ldr	r2, [pc, #40]	; (3108 <z_data_copy+0x2c>)
    30e0:	490a      	ldr	r1, [pc, #40]	; (310c <z_data_copy+0x30>)
{
    30e2:	b508      	push	{r3, lr}
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    30e4:	1a12      	subs	r2, r2, r0
    30e6:	f003 f881 	bl	61ec <memcpy>
#ifdef CONFIG_ARCH_HAS_RAMFUNC_SUPPORT
	(void)memcpy(&_ramfunc_ram_start, &_ramfunc_rom_start,
    30ea:	4a09      	ldr	r2, [pc, #36]	; (3110 <z_data_copy+0x34>)
    30ec:	4909      	ldr	r1, [pc, #36]	; (3114 <z_data_copy+0x38>)
    30ee:	480a      	ldr	r0, [pc, #40]	; (3118 <z_data_copy+0x3c>)
    30f0:	f003 f87c 	bl	61ec <memcpy>
		count--;
	}
	__stack_chk_guard = guard_copy;
#else
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
		 _app_smem_end - _app_smem_start);
    30f4:	4809      	ldr	r0, [pc, #36]	; (311c <z_data_copy+0x40>)
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
    30f6:	4a0a      	ldr	r2, [pc, #40]	; (3120 <z_data_copy+0x44>)
    30f8:	490a      	ldr	r1, [pc, #40]	; (3124 <z_data_copy+0x48>)
#endif /* CONFIG_STACK_CANARIES */
#endif /* CONFIG_USERSPACE */
}
    30fa:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
    30fe:	1a12      	subs	r2, r2, r0
    3100:	f003 b874 	b.w	61ec <memcpy>
    3104:	20002e00 	.word	0x20002e00
    3108:	200049a8 	.word	0x200049a8
    310c:	00007974 	.word	0x00007974
    3110:	00000000 	.word	0x00000000
    3114:	00007974 	.word	0x00007974
    3118:	20000000 	.word	0x20000000
    311c:	20000000 	.word	0x20000000
    3120:	20000000 	.word	0x20000000
    3124:	00007974 	.word	0x00007974

00003128 <bg_thread_main>:
 * init functions, then invokes application's main() routine.
 *
 * @return N/A
 */
static void bg_thread_main(void *unused1, void *unused2, void *unused3)
{
    3128:	b508      	push	{r3, lr}
	static const unsigned int boot_delay = CONFIG_BOOT_DELAY;
#else
	static const unsigned int boot_delay;
#endif

	z_sys_post_kernel = true;
    312a:	4b0c      	ldr	r3, [pc, #48]	; (315c <bg_thread_main+0x34>)
    312c:	2201      	movs	r2, #1

	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    312e:	2002      	movs	r0, #2
	z_sys_post_kernel = true;
    3130:	701a      	strb	r2, [r3, #0]
	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    3132:	f7ff ff4d 	bl	2fd0 <z_sys_init_run_level>
		k_busy_wait(CONFIG_BOOT_DELAY * USEC_PER_MSEC);
	}

#if defined(CONFIG_BOOT_BANNER)
#ifdef BUILD_VERSION
	printk("*** Booting Zephyr OS build %s %s ***\n",
    3136:	4a0a      	ldr	r2, [pc, #40]	; (3160 <bg_thread_main+0x38>)
    3138:	490a      	ldr	r1, [pc, #40]	; (3164 <bg_thread_main+0x3c>)
    313a:	480b      	ldr	r0, [pc, #44]	; (3168 <bg_thread_main+0x40>)
    313c:	f002 fba6 	bl	588c <printk>
	__do_global_ctors_aux();
	__do_init_array_aux();
#endif

	/* Final init level before app starts */
	z_sys_init_run_level(_SYS_INIT_LEVEL_APPLICATION);
    3140:	2003      	movs	r0, #3
    3142:	f7ff ff45 	bl	2fd0 <z_sys_init_run_level>

	z_init_static_threads();
    3146:	f001 fd1f 	bl	4b88 <z_init_static_threads>
	z_timestamp_main = k_cycle_get_32();
#endif

	extern void main(void);

	main();
    314a:	f7fd fad5 	bl	6f8 <main>

	/* Mark nonessenrial since main() has no more work to do */
	z_main_thread.base.user_options &= ~K_ESSENTIAL;
    314e:	4a07      	ldr	r2, [pc, #28]	; (316c <bg_thread_main+0x44>)
    3150:	7b13      	ldrb	r3, [r2, #12]
    3152:	f023 0301 	bic.w	r3, r3, #1
    3156:	7313      	strb	r3, [r2, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
    3158:	bd08      	pop	{r3, pc}
    315a:	bf00      	nop
    315c:	200013f3 	.word	0x200013f3
    3160:	00007862 	.word	0x00007862
    3164:	0000781b 	.word	0x0000781b
    3168:	0000783c 	.word	0x0000783c
    316c:	20000408 	.word	0x20000408

00003170 <z_cstart>:
 * cleared/zeroed.
 *
 * @return Does not return
 */
FUNC_NORETURN void z_cstart(void)
{
    3170:	e92d 4880 	stmdb	sp!, {r7, fp, lr}
 *
 * @return N/A
 */
static ALWAYS_INLINE void z_arm_interrupt_stack_setup(void)
{
	uint32_t msp =
    3174:	f8df 90f4 	ldr.w	r9, [pc, #244]	; 326c <z_cstart+0xfc>
    3178:	b0af      	sub	sp, #188	; 0xbc
  __ASM volatile ("MSR msp, %0" : : "r" (topOfMainStack) : );
    317a:	f389 8808 	msr	MSP, r9
	 * for Cortex-M3 and Cortex-M4 (ARMv7-M) MCUs. For the rest
	 * of ARM Cortex-M processors this setting is enforced by
	 * default and it is not configurable.
	 */
#if defined(CONFIG_CPU_CORTEX_M3) || defined(CONFIG_CPU_CORTEX_M4)
	SCB->CCR |= SCB_CCR_STKALIGN_Msk;
    317e:	4d33      	ldr	r5, [pc, #204]	; (324c <z_cstart+0xdc>)
	_kernel.ready_q.cache = &z_main_thread;
    3180:	4e33      	ldr	r6, [pc, #204]	; (3250 <z_cstart+0xe0>)
    3182:	696b      	ldr	r3, [r5, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    3184:	f8df a0e8 	ldr.w	sl, [pc, #232]	; 3270 <z_cstart+0x100>
	z_setup_new_thread(thread, stack,
    3188:	4f32      	ldr	r7, [pc, #200]	; (3254 <z_cstart+0xe4>)
    318a:	f443 7300 	orr.w	r3, r3, #512	; 0x200
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    318e:	2400      	movs	r4, #0
    3190:	616b      	str	r3, [r5, #20]
    3192:	23e0      	movs	r3, #224	; 0xe0
    3194:	f885 3022 	strb.w	r3, [r5, #34]	; 0x22
    3198:	77ec      	strb	r4, [r5, #31]
    319a:	762c      	strb	r4, [r5, #24]
    319c:	766c      	strb	r4, [r5, #25]
    319e:	76ac      	strb	r4, [r5, #26]
#if defined(CONFIG_ARM_SECURE_FIRMWARE)
	NVIC_SetPriority(SecureFault_IRQn, _EXC_FAULT_PRIO);
#endif /* CONFIG_ARM_SECURE_FIRMWARE */

	/* Enable Usage, Mem, & Bus Faults */
	SCB->SHCSR |= SCB_SHCSR_USGFAULTENA_Msk | SCB_SHCSR_MEMFAULTENA_Msk |
    31a0:	6a6b      	ldr	r3, [r5, #36]	; 0x24
    31a2:	f443 23e0 	orr.w	r3, r3, #458752	; 0x70000
    31a6:	626b      	str	r3, [r5, #36]	; 0x24

static ALWAYS_INLINE void arch_kernel_init(void)
{
	z_arm_interrupt_stack_setup();
	z_arm_exc_setup();
	z_arm_fault_init();
    31a8:	f7fe fda2 	bl	1cf0 <z_arm_fault_init>
	z_arm_cpu_idle_init();
    31ac:	f7fe fb2a 	bl	1804 <z_arm_cpu_idle_init>
static ALWAYS_INLINE void z_arm_clear_faults(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* Reset all faults */
	SCB->CFSR = SCB_CFSR_USGFAULTSR_Msk |
    31b0:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    31b4:	62ab      	str	r3, [r5, #40]	; 0x28
		    SCB_CFSR_MEMFAULTSR_Msk |
		    SCB_CFSR_BUSFAULTSR_Msk;

	/* Clear all Hard Faults - HFSR is write-one-to-clear */
	SCB->HFSR = 0xffffffff;
    31b6:	62eb      	str	r3, [r5, #44]	; 0x2c
#endif
#ifdef CONFIG_USERSPACE
	dummy_thread->mem_domain_info.mem_domain = 0;
#endif

	_current_cpu->current = dummy_thread;
    31b8:	4d27      	ldr	r5, [pc, #156]	; (3258 <z_cstart+0xe8>)
	dummy_thread->mem_domain_info.mem_domain = 0;
    31ba:	9425      	str	r4, [sp, #148]	; 0x94
	dummy_thread->base.user_options = K_ESSENTIAL;
    31bc:	f240 1301 	movw	r3, #257	; 0x101
    31c0:	f8ad 3024 	strh.w	r3, [sp, #36]	; 0x24
	_current_cpu->current = dummy_thread;
    31c4:	ab06      	add	r3, sp, #24
    31c6:	60ab      	str	r3, [r5, #8]

	z_dummy_thread_init(&dummy_thread);
#endif

	/* perform basic hardware initialization */
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_1);
    31c8:	4620      	mov	r0, r4
	dummy_thread->stack_info.size = 0U;
    31ca:	e9cd 4420 	strd	r4, r4, [sp, #128]	; 0x80
    31ce:	f7ff feff 	bl	2fd0 <z_sys_init_run_level>
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_2);
    31d2:	2001      	movs	r0, #1
    31d4:	f7ff fefc 	bl	2fd0 <z_sys_init_run_level>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    31d8:	f04f 0b01 	mov.w	fp, #1
	z_sched_init();
    31dc:	f000 fff2 	bl	41c4 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    31e0:	4b1e      	ldr	r3, [pc, #120]	; (325c <z_cstart+0xec>)
	_kernel.ready_q.cache = &z_main_thread;
    31e2:	626e      	str	r6, [r5, #36]	; 0x24
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    31e4:	491e      	ldr	r1, [pc, #120]	; (3260 <z_cstart+0xf0>)
    31e6:	9305      	str	r3, [sp, #20]
    31e8:	f44f 6280 	mov.w	r2, #1024	; 0x400
    31ec:	4653      	mov	r3, sl
    31ee:	e9cd 4b03 	strd	r4, fp, [sp, #12]
    31f2:	e9cd 4401 	strd	r4, r4, [sp, #4]
    31f6:	9400      	str	r4, [sp, #0]
    31f8:	4630      	mov	r0, r6
    31fa:	f001 fbc7 	bl	498c <z_setup_new_thread>
	sys_trace_thread_resume(thread);
}

static inline void z_mark_thread_as_started(struct k_thread *thread)
{
	thread->base.thread_state &= ~_THREAD_PRESTART;
    31fe:	7b73      	ldrb	r3, [r6, #13]
    3200:	4680      	mov	r8, r0
    3202:	f023 0304 	bic.w	r3, r3, #4
	z_ready_thread(&z_main_thread);
    3206:	4630      	mov	r0, r6
    3208:	7373      	strb	r3, [r6, #13]
    320a:	f003 fad7 	bl	67bc <z_ready_thread>
	z_setup_new_thread(thread, stack,
    320e:	230f      	movs	r3, #15
    3210:	e9cd 4302 	strd	r4, r3, [sp, #8]
    3214:	4913      	ldr	r1, [pc, #76]	; (3264 <z_cstart+0xf4>)
    3216:	4b14      	ldr	r3, [pc, #80]	; (3268 <z_cstart+0xf8>)
    3218:	f44f 72a0 	mov.w	r2, #320	; 0x140
    321c:	e9cd b404 	strd	fp, r4, [sp, #16]
    3220:	e9cd 4400 	strd	r4, r4, [sp]
    3224:	4638      	mov	r0, r7
    3226:	f001 fbb1 	bl	498c <z_setup_new_thread>
    322a:	7b7b      	ldrb	r3, [r7, #13]
		_kernel.cpus[i].idle_thread = &z_idle_threads[i];
    322c:	60ef      	str	r7, [r5, #12]
    322e:	f023 0304 	bic.w	r3, r3, #4
    3232:	737b      	strb	r3, [r7, #13]
 * @return N/A
 */

static inline void sys_dlist_init(sys_dlist_t *list)
{
	list->head = (sys_dnode_t *)list;
    3234:	f105 0318 	add.w	r3, r5, #24
	list->tail = (sys_dnode_t *)list;
    3238:	e9c5 3306 	strd	r3, r3, [r5, #24]
		_kernel.cpus[i].id = i;
    323c:	752c      	strb	r4, [r5, #20]
		_kernel.cpus[i].irq_stack =
    323e:	f8c5 9004 	str.w	r9, [r5, #4]
	arch_switch_to_main_thread(&z_main_thread, stack_ptr, bg_thread_main);
    3242:	4652      	mov	r2, sl
    3244:	4641      	mov	r1, r8
    3246:	4630      	mov	r0, r6
    3248:	f7fe fac2 	bl	17d0 <arch_switch_to_main_thread>
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
    324c:	e000ed00 	.word	0xe000ed00
    3250:	20000408 	.word	0x20000408
    3254:	20000368 	.word	0x20000368
    3258:	20000664 	.word	0x20000664
    325c:	00007863 	.word	0x00007863
    3260:	20002000 	.word	0x20002000
    3264:	20001400 	.word	0x20001400
    3268:	00003095 	.word	0x00003095
    326c:	20001d40 	.word	0x20001d40
    3270:	00003129 	.word	0x00003129

00003274 <z_vrfy_k_msgq_alloc_init>:
}

#ifdef CONFIG_USERSPACE
int z_vrfy_k_msgq_alloc_init(struct k_msgq *q, size_t msg_size,
			    uint32_t max_msgs)
{
    3274:	b570      	push	{r4, r5, r6, lr}
    3276:	460d      	mov	r5, r1
    3278:	4616      	mov	r6, r2
    327a:	4604      	mov	r4, r0
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(q, K_OBJ_MSGQ));
    327c:	f7fc ff2e 	bl	dc <z_object_find>
    3280:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    3284:	2102      	movs	r1, #2
    3286:	f002 f957 	bl	5538 <z_object_validate>
    328a:	b138      	cbz	r0, 329c <z_vrfy_k_msgq_alloc_init+0x28>
    328c:	f003 f8cf 	bl	642e <arch_is_user_context>
    3290:	4b06      	ldr	r3, [pc, #24]	; (32ac <z_vrfy_k_msgq_alloc_init+0x38>)
    3292:	689b      	ldr	r3, [r3, #8]
    3294:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3298:	f002 ff58 	bl	614c <arch_syscall_oops>

	return z_impl_k_msgq_alloc_init(q, msg_size, max_msgs);
    329c:	4632      	mov	r2, r6
    329e:	4629      	mov	r1, r5
    32a0:	4620      	mov	r0, r4
}
    32a2:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	return z_impl_k_msgq_alloc_init(q, msg_size, max_msgs);
    32a6:	f003 b8de 	b.w	6466 <z_impl_k_msgq_alloc_init>
    32aa:	bf00      	nop
    32ac:	20000664 	.word	0x20000664

000032b0 <z_mrsh_k_msgq_alloc_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_msgq_alloc_init(struct k_msgq * msgq, size_t msg_size, uint32_t max_msgs);
uintptr_t z_mrsh_k_msgq_alloc_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    32b0:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    32b2:	4c06      	ldr	r4, [pc, #24]	; (32cc <z_mrsh_k_msgq_alloc_init+0x1c>)
    32b4:	9d06      	ldr	r5, [sp, #24]
    32b6:	68a3      	ldr	r3, [r4, #8]
    32b8:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_msgq_alloc_init(*(struct k_msgq **)&arg0, *(size_t*)&arg1, *(uint32_t*)&arg2)
    32bc:	f7ff ffda 	bl	3274 <z_vrfy_k_msgq_alloc_init>
;
	_current->syscall_frame = NULL;
    32c0:	68a3      	ldr	r3, [r4, #8]
    32c2:	2200      	movs	r2, #0
    32c4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    32c8:	bd38      	pop	{r3, r4, r5, pc}
    32ca:	bf00      	nop
    32cc:	20000664 	.word	0x20000664

000032d0 <z_impl_k_msgq_put>:
	return 0;
}


int z_impl_k_msgq_put(struct k_msgq *msgq, void *data, k_timeout_t timeout)
{
    32d0:	e92d 47f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, r9, sl, lr}
    32d4:	4604      	mov	r4, r0
    32d6:	468a      	mov	sl, r1
    32d8:	4616      	mov	r6, r2
    32da:	461f      	mov	r7, r3

	struct k_thread *pending_thread;
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&msgq->lock);
    32dc:	f100 0908 	add.w	r9, r0, #8
    32e0:	f04f 0320 	mov.w	r3, #32
    32e4:	f3ef 8811 	mrs	r8, BASEPRI
    32e8:	f383 8811 	msr	BASEPRI, r3
    32ec:	f3bf 8f6f 	isb	sy

	if (msgq->used_msgs < msgq->max_msgs) {
    32f0:	6a02      	ldr	r2, [r0, #32]
    32f2:	68c3      	ldr	r3, [r0, #12]
    32f4:	429a      	cmp	r2, r3
    32f6:	d22b      	bcs.n	3350 <z_impl_k_msgq_put+0x80>
		/* message queue isn't full */
		pending_thread = z_unpend_first_thread(&msgq->wait_q);
    32f8:	f003 fad6 	bl	68a8 <z_unpend_first_thread>
		if (pending_thread != NULL) {
			/* give message to waiting thread */
			(void)memcpy(pending_thread->base.swap_data, data,
    32fc:	68a2      	ldr	r2, [r4, #8]
		if (pending_thread != NULL) {
    32fe:	4605      	mov	r5, r0
			(void)memcpy(pending_thread->base.swap_data, data,
    3300:	4651      	mov	r1, sl
		if (pending_thread != NULL) {
    3302:	b180      	cbz	r0, 3326 <z_impl_k_msgq_put+0x56>
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
    3304:	2400      	movs	r4, #0
			(void)memcpy(pending_thread->base.swap_data, data,
    3306:	6940      	ldr	r0, [r0, #20]
    3308:	f002 ff70 	bl	61ec <memcpy>
			       msgq->msg_size);
			/* wake up waiting thread */
			arch_thread_return_value_set(pending_thread, 0);
			z_ready_thread(pending_thread);
    330c:	4628      	mov	r0, r5
    330e:	f8c5 4090 	str.w	r4, [r5, #144]	; 0x90
    3312:	f003 fa53 	bl	67bc <z_ready_thread>
			z_reschedule(&msgq->lock, key);
    3316:	4648      	mov	r0, r9
    3318:	4641      	mov	r1, r8
    331a:	f003 fa07 	bl	672c <z_reschedule>
			return 0;
    331e:	4620      	mov	r0, r4
	}

	k_spin_unlock(&msgq->lock, key);

	return result;
}
    3320:	b002      	add	sp, #8
    3322:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
			(void)memcpy(msgq->write_ptr, data, msgq->msg_size);
    3326:	69e0      	ldr	r0, [r4, #28]
    3328:	f002 ff60 	bl	61ec <memcpy>
			msgq->write_ptr += msgq->msg_size;
    332c:	69e3      	ldr	r3, [r4, #28]
    332e:	68a2      	ldr	r2, [r4, #8]
    3330:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
    3332:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
    3334:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
    3336:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
    3338:	bf04      	itt	eq
    333a:	6923      	ldreq	r3, [r4, #16]
    333c:	61e3      	streq	r3, [r4, #28]
			msgq->used_msgs++;
    333e:	6a23      	ldr	r3, [r4, #32]
    3340:	3301      	adds	r3, #1
    3342:	6223      	str	r3, [r4, #32]
		result = 0;
    3344:	2000      	movs	r0, #0
	__asm__ volatile(
    3346:	f388 8811 	msr	BASEPRI, r8
    334a:	f3bf 8f6f 	isb	sy
	return result;
    334e:	e7e7      	b.n	3320 <z_impl_k_msgq_put+0x50>
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    3350:	ea56 0307 	orrs.w	r3, r6, r7
    3354:	d00a      	beq.n	336c <z_impl_k_msgq_put+0x9c>
		_current->base.swap_data = data;
    3356:	4b07      	ldr	r3, [pc, #28]	; (3374 <z_impl_k_msgq_put+0xa4>)
    3358:	689b      	ldr	r3, [r3, #8]
		return z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
    335a:	4602      	mov	r2, r0
		_current->base.swap_data = data;
    335c:	6159      	str	r1, [r3, #20]
		return z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
    335e:	4648      	mov	r0, r9
    3360:	e9cd 6700 	strd	r6, r7, [sp]
    3364:	4641      	mov	r1, r8
    3366:	f000 fec5 	bl	40f4 <z_pend_curr>
    336a:	e7d9      	b.n	3320 <z_impl_k_msgq_put+0x50>
		result = -ENOMSG;
    336c:	f06f 004f 	mvn.w	r0, #79	; 0x4f
    3370:	e7e9      	b.n	3346 <z_impl_k_msgq_put+0x76>
    3372:	bf00      	nop
    3374:	20000664 	.word	0x20000664

00003378 <z_mrsh_k_msgq_put>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_msgq_put(struct k_msgq * msgq, void * data, k_timeout_t timeout);
uintptr_t z_mrsh_k_msgq_put(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3378:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	_current->syscall_frame = ssf;
    337c:	4c14      	ldr	r4, [pc, #80]	; (33d0 <z_mrsh_k_msgq_put+0x58>)
{
    337e:	4699      	mov	r9, r3
	_current->syscall_frame = ssf;
    3380:	68a3      	ldr	r3, [r4, #8]
{
    3382:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    3384:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    3386:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    338a:	460e      	mov	r6, r1
    338c:	4607      	mov	r7, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_msgq_put(struct k_msgq *q, void *data,
				    k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(q, K_OBJ_MSGQ));
    338e:	f7fc fea5 	bl	dc <z_object_find>
    3392:	2200      	movs	r2, #0
    3394:	2102      	movs	r1, #2
    3396:	f002 f8cf 	bl	5538 <z_object_validate>
    339a:	4602      	mov	r2, r0
    339c:	b130      	cbz	r0, 33ac <z_mrsh_k_msgq_put+0x34>
    339e:	f003 f846 	bl	642e <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_READ(data, q->msg_size));
    33a2:	68a3      	ldr	r3, [r4, #8]
    33a4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    33a8:	f002 fed0 	bl	614c <arch_syscall_oops>
    33ac:	68b9      	ldr	r1, [r7, #8]
    33ae:	4630      	mov	r0, r6
    33b0:	f002 fefa 	bl	61a8 <arch_buffer_validate>
    33b4:	4605      	mov	r5, r0
    33b6:	2800      	cmp	r0, #0
    33b8:	d1f1      	bne.n	339e <z_mrsh_k_msgq_put+0x26>

	return z_impl_k_msgq_put(q, data, timeout);
    33ba:	464b      	mov	r3, r9
    33bc:	4642      	mov	r2, r8
    33be:	4631      	mov	r1, r6
    33c0:	4638      	mov	r0, r7
    33c2:	f7ff ff85 	bl	32d0 <z_impl_k_msgq_put>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_msgq_put(*(struct k_msgq **)&arg0, *(void **)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    33c6:	68a3      	ldr	r3, [r4, #8]
    33c8:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    33cc:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
    33d0:	20000664 	.word	0x20000664

000033d4 <z_mrsh_k_msgq_get_attrs>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_msgq_get_attrs(struct k_msgq * msgq, struct k_msgq_attrs * attrs);
uintptr_t z_mrsh_k_msgq_get_attrs(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    33d4:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    33d6:	4e13      	ldr	r6, [pc, #76]	; (3424 <z_mrsh_k_msgq_get_attrs+0x50>)
    33d8:	9a06      	ldr	r2, [sp, #24]
    33da:	68b3      	ldr	r3, [r6, #8]
    33dc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    33e0:	460c      	mov	r4, r1
    33e2:	4605      	mov	r5, r0

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_msgq_get_attrs(struct k_msgq *q,
					   struct k_msgq_attrs *attrs)
{
	Z_OOPS(Z_SYSCALL_OBJ(q, K_OBJ_MSGQ));
    33e4:	f7fc fe7a 	bl	dc <z_object_find>
    33e8:	2200      	movs	r2, #0
    33ea:	2102      	movs	r1, #2
    33ec:	f002 f8a4 	bl	5538 <z_object_validate>
    33f0:	b130      	cbz	r0, 3400 <z_mrsh_k_msgq_get_attrs+0x2c>
    33f2:	f003 f81c 	bl	642e <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(attrs, sizeof(struct k_msgq_attrs)));
    33f6:	68b3      	ldr	r3, [r6, #8]
    33f8:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    33fc:	f002 fea6 	bl	614c <arch_syscall_oops>
    3400:	2201      	movs	r2, #1
    3402:	210c      	movs	r1, #12
    3404:	4620      	mov	r0, r4
    3406:	f002 fecf 	bl	61a8 <arch_buffer_validate>
    340a:	4603      	mov	r3, r0
    340c:	2800      	cmp	r0, #0
    340e:	d1f0      	bne.n	33f2 <z_mrsh_k_msgq_get_attrs+0x1e>
	attrs->msg_size = msgq->msg_size;
    3410:	68aa      	ldr	r2, [r5, #8]
    3412:	6022      	str	r2, [r4, #0]
	attrs->max_msgs = msgq->max_msgs;
    3414:	68ea      	ldr	r2, [r5, #12]
    3416:	6062      	str	r2, [r4, #4]
	attrs->used_msgs = msgq->used_msgs;
    3418:	6a2a      	ldr	r2, [r5, #32]
    341a:	60a2      	str	r2, [r4, #8]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_msgq_get_attrs(*(struct k_msgq **)&arg0, *(struct k_msgq_attrs **)&arg1)
;
	_current->syscall_frame = NULL;
    341c:	68b2      	ldr	r2, [r6, #8]
    341e:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return 0;
}
    3422:	bd70      	pop	{r4, r5, r6, pc}
    3424:	20000664 	.word	0x20000664

00003428 <z_impl_k_msgq_get>:
}
#include <syscalls/k_msgq_get_attrs_mrsh.c>
#endif

int z_impl_k_msgq_get(struct k_msgq *msgq, void *data, k_timeout_t timeout)
{
    3428:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
    342c:	4604      	mov	r4, r0
    342e:	4616      	mov	r6, r2
    3430:	4608      	mov	r0, r1
    3432:	461f      	mov	r7, r3

	k_spinlock_key_t key;
	struct k_thread *pending_thread;
	int result;

	key = k_spin_lock(&msgq->lock);
    3434:	f104 0908 	add.w	r9, r4, #8
	__asm__ volatile(
    3438:	f04f 0320 	mov.w	r3, #32
    343c:	f3ef 8811 	mrs	r8, BASEPRI
    3440:	f383 8811 	msr	BASEPRI, r3
    3444:	f3bf 8f6f 	isb	sy

	if (msgq->used_msgs > 0) {
    3448:	6a23      	ldr	r3, [r4, #32]
    344a:	2b00      	cmp	r3, #0
    344c:	d034      	beq.n	34b8 <z_impl_k_msgq_get+0x90>
		/* take first available message from queue */
		(void)memcpy(data, msgq->read_ptr, msgq->msg_size);
    344e:	68a2      	ldr	r2, [r4, #8]
    3450:	69a1      	ldr	r1, [r4, #24]
    3452:	f002 fecb 	bl	61ec <memcpy>
		msgq->read_ptr += msgq->msg_size;
    3456:	69a3      	ldr	r3, [r4, #24]
    3458:	68a2      	ldr	r2, [r4, #8]
    345a:	4413      	add	r3, r2
		if (msgq->read_ptr == msgq->buffer_end) {
    345c:	6962      	ldr	r2, [r4, #20]
		msgq->read_ptr += msgq->msg_size;
    345e:	61a3      	str	r3, [r4, #24]
		if (msgq->read_ptr == msgq->buffer_end) {
    3460:	4293      	cmp	r3, r2
			msgq->read_ptr = msgq->buffer_start;
    3462:	bf04      	itt	eq
    3464:	6923      	ldreq	r3, [r4, #16]
    3466:	61a3      	streq	r3, [r4, #24]
		}
		msgq->used_msgs--;
    3468:	6a23      	ldr	r3, [r4, #32]
    346a:	3b01      	subs	r3, #1
    346c:	6223      	str	r3, [r4, #32]

		/* handle first thread waiting to write (if any) */
		pending_thread = z_unpend_first_thread(&msgq->wait_q);
    346e:	4620      	mov	r0, r4
    3470:	f003 fa1a 	bl	68a8 <z_unpend_first_thread>
		if (pending_thread != NULL) {
    3474:	4605      	mov	r5, r0
    3476:	2800      	cmp	r0, #0
    3478:	d02e      	beq.n	34d8 <z_impl_k_msgq_get+0xb0>
			/* add thread's message to queue */
			(void)memcpy(msgq->write_ptr, pending_thread->base.swap_data,
    347a:	6941      	ldr	r1, [r0, #20]
    347c:	68a2      	ldr	r2, [r4, #8]
    347e:	69e0      	ldr	r0, [r4, #28]
    3480:	f002 feb4 	bl	61ec <memcpy>
			       msgq->msg_size);
			msgq->write_ptr += msgq->msg_size;
    3484:	69e3      	ldr	r3, [r4, #28]
    3486:	68a2      	ldr	r2, [r4, #8]
    3488:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
    348a:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
    348c:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
    348e:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
    3490:	bf04      	itt	eq
    3492:	6923      	ldreq	r3, [r4, #16]
    3494:	61e3      	streq	r3, [r4, #28]
			}
			msgq->used_msgs++;
    3496:	6a23      	ldr	r3, [r4, #32]
    3498:	3301      	adds	r3, #1
    349a:	6223      	str	r3, [r4, #32]
    349c:	2400      	movs	r4, #0

			/* wake up waiting thread */
			arch_thread_return_value_set(pending_thread, 0);
			z_ready_thread(pending_thread);
    349e:	4628      	mov	r0, r5
    34a0:	f8c5 4090 	str.w	r4, [r5, #144]	; 0x90
    34a4:	f003 f98a 	bl	67bc <z_ready_thread>
			z_reschedule(&msgq->lock, key);
    34a8:	4648      	mov	r0, r9
    34aa:	4641      	mov	r1, r8
    34ac:	f003 f93e 	bl	672c <z_reschedule>
			return 0;
    34b0:	4620      	mov	r0, r4
	}

	k_spin_unlock(&msgq->lock, key);

	return result;
}
    34b2:	b003      	add	sp, #12
    34b4:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    34b8:	ea56 0307 	orrs.w	r3, r6, r7
    34bc:	d00a      	beq.n	34d4 <z_impl_k_msgq_get+0xac>
		_current->base.swap_data = data;
    34be:	4b09      	ldr	r3, [pc, #36]	; (34e4 <z_impl_k_msgq_get+0xbc>)
    34c0:	689b      	ldr	r3, [r3, #8]
		return z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
    34c2:	4622      	mov	r2, r4
		_current->base.swap_data = data;
    34c4:	6159      	str	r1, [r3, #20]
		return z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
    34c6:	4648      	mov	r0, r9
    34c8:	e9cd 6700 	strd	r6, r7, [sp]
    34cc:	4641      	mov	r1, r8
    34ce:	f000 fe11 	bl	40f4 <z_pend_curr>
    34d2:	e7ee      	b.n	34b2 <z_impl_k_msgq_get+0x8a>
		result = -ENOMSG;
    34d4:	f06f 004f 	mvn.w	r0, #79	; 0x4f
	__asm__ volatile(
    34d8:	f388 8811 	msr	BASEPRI, r8
    34dc:	f3bf 8f6f 	isb	sy
	return result;
    34e0:	e7e7      	b.n	34b2 <z_impl_k_msgq_get+0x8a>
    34e2:	bf00      	nop
    34e4:	20000664 	.word	0x20000664

000034e8 <z_mrsh_k_msgq_get>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_msgq_get(struct k_msgq * msgq, void * data, k_timeout_t timeout);
uintptr_t z_mrsh_k_msgq_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    34e8:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	_current->syscall_frame = ssf;
    34ec:	4c14      	ldr	r4, [pc, #80]	; (3540 <z_mrsh_k_msgq_get+0x58>)
{
    34ee:	4699      	mov	r9, r3
	_current->syscall_frame = ssf;
    34f0:	68a3      	ldr	r3, [r4, #8]
{
    34f2:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    34f4:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    34f6:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    34fa:	460e      	mov	r6, r1
    34fc:	4607      	mov	r7, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_msgq_get(struct k_msgq *q, void *data,
				    k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(q, K_OBJ_MSGQ));
    34fe:	f7fc fded 	bl	dc <z_object_find>
    3502:	2200      	movs	r2, #0
    3504:	2102      	movs	r1, #2
    3506:	f002 f817 	bl	5538 <z_object_validate>
    350a:	b130      	cbz	r0, 351a <z_mrsh_k_msgq_get+0x32>
    350c:	f002 ff8f 	bl	642e <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(data, q->msg_size));
    3510:	68a3      	ldr	r3, [r4, #8]
    3512:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3516:	f002 fe19 	bl	614c <arch_syscall_oops>
    351a:	68b9      	ldr	r1, [r7, #8]
    351c:	2201      	movs	r2, #1
    351e:	4630      	mov	r0, r6
    3520:	f002 fe42 	bl	61a8 <arch_buffer_validate>
    3524:	4605      	mov	r5, r0
    3526:	2800      	cmp	r0, #0
    3528:	d1f0      	bne.n	350c <z_mrsh_k_msgq_get+0x24>

	return z_impl_k_msgq_get(q, data, timeout);
    352a:	464b      	mov	r3, r9
    352c:	4642      	mov	r2, r8
    352e:	4631      	mov	r1, r6
    3530:	4638      	mov	r0, r7
    3532:	f7ff ff79 	bl	3428 <z_impl_k_msgq_get>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_msgq_get(*(struct k_msgq **)&arg0, *(void **)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    3536:	68a3      	ldr	r3, [r4, #8]
    3538:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    353c:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
    3540:	20000664 	.word	0x20000664

00003544 <z_mrsh_k_msgq_peek>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_msgq_peek(struct k_msgq * msgq, void * data);
uintptr_t z_mrsh_k_msgq_peek(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3544:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    3546:	4c12      	ldr	r4, [pc, #72]	; (3590 <z_mrsh_k_msgq_peek+0x4c>)
    3548:	9a08      	ldr	r2, [sp, #32]
    354a:	68a3      	ldr	r3, [r4, #8]
    354c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3550:	460e      	mov	r6, r1
    3552:	4607      	mov	r7, r0
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_msgq_peek(struct k_msgq *q, void *data)
{
	Z_OOPS(Z_SYSCALL_OBJ(q, K_OBJ_MSGQ));
    3554:	f7fc fdc2 	bl	dc <z_object_find>
    3558:	2200      	movs	r2, #0
    355a:	2102      	movs	r1, #2
    355c:	f001 ffec 	bl	5538 <z_object_validate>
    3560:	b130      	cbz	r0, 3570 <z_mrsh_k_msgq_peek+0x2c>
    3562:	f002 ff64 	bl	642e <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(data, q->msg_size));
    3566:	68a3      	ldr	r3, [r4, #8]
    3568:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    356c:	f002 fdee 	bl	614c <arch_syscall_oops>
    3570:	68b9      	ldr	r1, [r7, #8]
    3572:	2201      	movs	r2, #1
    3574:	4630      	mov	r0, r6
    3576:	f002 fe17 	bl	61a8 <arch_buffer_validate>
    357a:	4605      	mov	r5, r0
    357c:	2800      	cmp	r0, #0
    357e:	d1f0      	bne.n	3562 <z_mrsh_k_msgq_peek+0x1e>

	return z_impl_k_msgq_peek(q, data);
    3580:	4631      	mov	r1, r6
    3582:	4638      	mov	r0, r7
    3584:	f002 ff8d 	bl	64a2 <z_impl_k_msgq_peek>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_msgq_peek(*(struct k_msgq **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    3588:	68a3      	ldr	r3, [r4, #8]
    358a:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    358e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3590:	20000664 	.word	0x20000664

00003594 <z_mrsh_k_msgq_purge>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_msgq_purge(struct k_msgq * msgq);
uintptr_t z_mrsh_k_msgq_purge(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3594:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3596:	4d0e      	ldr	r5, [pc, #56]	; (35d0 <z_mrsh_k_msgq_purge+0x3c>)
    3598:	9a06      	ldr	r2, [sp, #24]
    359a:	68ab      	ldr	r3, [r5, #8]
    359c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    35a0:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_msgq_purge(struct k_msgq *q)
{
	Z_OOPS(Z_SYSCALL_OBJ(q, K_OBJ_MSGQ));
    35a2:	f7fc fd9b 	bl	dc <z_object_find>
    35a6:	2200      	movs	r2, #0
    35a8:	2102      	movs	r1, #2
    35aa:	f001 ffc5 	bl	5538 <z_object_validate>
    35ae:	4604      	mov	r4, r0
    35b0:	b130      	cbz	r0, 35c0 <z_mrsh_k_msgq_purge+0x2c>
    35b2:	f002 ff3c 	bl	642e <arch_is_user_context>
    35b6:	68ab      	ldr	r3, [r5, #8]
    35b8:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    35bc:	f002 fdc6 	bl	614c <arch_syscall_oops>
	z_impl_k_msgq_purge(q);
    35c0:	4630      	mov	r0, r6
    35c2:	f002 ff88 	bl	64d6 <z_impl_k_msgq_purge>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_msgq_purge(*(struct k_msgq **)&arg0)
;
	_current->syscall_frame = NULL;
    35c6:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    35c8:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    35ca:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    35ce:	bd70      	pop	{r4, r5, r6, pc}
    35d0:	20000664 	.word	0x20000664

000035d4 <z_mrsh_k_msgq_num_free_get>:
#include <syscalls/kernel.h>

extern uint32_t z_vrfy_k_msgq_num_free_get(struct k_msgq * msgq);
uintptr_t z_mrsh_k_msgq_num_free_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    35d4:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    35d6:	4d0d      	ldr	r5, [pc, #52]	; (360c <z_mrsh_k_msgq_num_free_get+0x38>)
    35d8:	9a06      	ldr	r2, [sp, #24]
    35da:	68ab      	ldr	r3, [r5, #8]
    35dc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    35e0:	4604      	mov	r4, r0
}
#include <syscalls/k_msgq_purge_mrsh.c>

static inline uint32_t z_vrfy_k_msgq_num_free_get(struct k_msgq *q)
{
	Z_OOPS(Z_SYSCALL_OBJ(q, K_OBJ_MSGQ));
    35e2:	f7fc fd7b 	bl	dc <z_object_find>
    35e6:	2200      	movs	r2, #0
    35e8:	2102      	movs	r1, #2
    35ea:	f001 ffa5 	bl	5538 <z_object_validate>
    35ee:	b130      	cbz	r0, 35fe <z_mrsh_k_msgq_num_free_get+0x2a>
    35f0:	f002 ff1d 	bl	642e <arch_is_user_context>
    35f4:	68ab      	ldr	r3, [r5, #8]
    35f6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    35fa:	f002 fda7 	bl	614c <arch_syscall_oops>
	return msgq->max_msgs - msgq->used_msgs;
    35fe:	68e2      	ldr	r2, [r4, #12]
    3600:	6a23      	ldr	r3, [r4, #32]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	uint32_t ret = z_vrfy_k_msgq_num_free_get(*(struct k_msgq **)&arg0)
;
	_current->syscall_frame = NULL;
    3602:	68a9      	ldr	r1, [r5, #8]
    3604:	f8c1 0084 	str.w	r0, [r1, #132]	; 0x84
	return (uintptr_t) ret;
}
    3608:	1ad0      	subs	r0, r2, r3
    360a:	bd38      	pop	{r3, r4, r5, pc}
    360c:	20000664 	.word	0x20000664

00003610 <z_mrsh_k_msgq_num_used_get>:
#include <syscalls/kernel.h>

extern uint32_t z_vrfy_k_msgq_num_used_get(struct k_msgq * msgq);
uintptr_t z_mrsh_k_msgq_num_used_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3610:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    3612:	4c0d      	ldr	r4, [pc, #52]	; (3648 <z_mrsh_k_msgq_num_used_get+0x38>)
    3614:	9a06      	ldr	r2, [sp, #24]
    3616:	68a3      	ldr	r3, [r4, #8]
    3618:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    361c:	4605      	mov	r5, r0
}
#include <syscalls/k_msgq_num_free_get_mrsh.c>

static inline uint32_t z_vrfy_k_msgq_num_used_get(struct k_msgq *q)
{
	Z_OOPS(Z_SYSCALL_OBJ(q, K_OBJ_MSGQ));
    361e:	f7fc fd5d 	bl	dc <z_object_find>
    3622:	2200      	movs	r2, #0
    3624:	2102      	movs	r1, #2
    3626:	f001 ff87 	bl	5538 <z_object_validate>
    362a:	4603      	mov	r3, r0
    362c:	b130      	cbz	r0, 363c <z_mrsh_k_msgq_num_used_get+0x2c>
    362e:	f002 fefe 	bl	642e <arch_is_user_context>
    3632:	68a3      	ldr	r3, [r4, #8]
    3634:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3638:	f002 fd88 	bl	614c <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	uint32_t ret = z_vrfy_k_msgq_num_used_get(*(struct k_msgq **)&arg0)
;
	_current->syscall_frame = NULL;
    363c:	68a2      	ldr	r2, [r4, #8]
	return z_impl_k_msgq_num_used_get(q);
    363e:	6a28      	ldr	r0, [r5, #32]
    3640:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    3644:	bd38      	pop	{r3, r4, r5, pc}
    3646:	bf00      	nop
    3648:	20000664 	.word	0x20000664

0000364c <z_mrsh_k_mutex_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_init(struct k_mutex * mutex);
uintptr_t z_mrsh_k_mutex_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    364c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    364e:	4d0e      	ldr	r5, [pc, #56]	; (3688 <z_mrsh_k_mutex_init+0x3c>)
    3650:	9a06      	ldr	r2, [sp, #24]
    3652:	68ab      	ldr	r3, [r5, #8]
    3654:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3658:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_init(struct k_mutex *mutex)
{
	Z_OOPS(Z_SYSCALL_OBJ_INIT(mutex, K_OBJ_MUTEX));
    365a:	f7fc fd3f 	bl	dc <z_object_find>
    365e:	2201      	movs	r2, #1
    3660:	2103      	movs	r1, #3
    3662:	f001 ff69 	bl	5538 <z_object_validate>
    3666:	4604      	mov	r4, r0
    3668:	b130      	cbz	r0, 3678 <z_mrsh_k_mutex_init+0x2c>
    366a:	f002 ff55 	bl	6518 <arch_is_user_context>
    366e:	68ab      	ldr	r3, [r5, #8]
    3670:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3674:	f002 fd6a 	bl	614c <arch_syscall_oops>
	return z_impl_k_mutex_init(mutex);
    3678:	4630      	mov	r0, r6
    367a:	f002 ff67 	bl	654c <z_impl_k_mutex_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_mutex_init(*(struct k_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
    367e:	68ab      	ldr	r3, [r5, #8]
    3680:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3684:	bd70      	pop	{r4, r5, r6, pc}
    3686:	bf00      	nop
    3688:	20000664 	.word	0x20000664

0000368c <z_impl_k_mutex_lock>:
	}
	return false;
}

int z_impl_k_mutex_lock(struct k_mutex *mutex, k_timeout_t timeout)
{
    368c:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
    3690:	4604      	mov	r4, r0
    3692:	4616      	mov	r6, r2
    3694:	461f      	mov	r7, r3
	__asm__ volatile(
    3696:	f04f 0320 	mov.w	r3, #32
    369a:	f3ef 8811 	mrs	r8, BASEPRI
    369e:	f383 8811 	msr	BASEPRI, r3
    36a2:	f3bf 8f6f 	isb	sy
	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");

	sys_trace_void(SYS_TRACE_ID_MUTEX_LOCK);
	key = k_spin_lock(&lock);

	if (likely((mutex->lock_count == 0U) || (mutex->owner == _current))) {
    36a6:	68c3      	ldr	r3, [r0, #12]
    36a8:	4a39      	ldr	r2, [pc, #228]	; (3790 <z_impl_k_mutex_lock+0x104>)
    36aa:	b16b      	cbz	r3, 36c8 <z_impl_k_mutex_lock+0x3c>
    36ac:	6880      	ldr	r0, [r0, #8]
    36ae:	6891      	ldr	r1, [r2, #8]
    36b0:	4288      	cmp	r0, r1
    36b2:	d01c      	beq.n	36ee <z_impl_k_mutex_lock+0x62>
		sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);

		return 0;
	}

	if (unlikely(K_TIMEOUT_EQ(timeout, K_NO_WAIT))) {
    36b4:	ea56 0307 	orrs.w	r3, r6, r7
    36b8:	d11b      	bne.n	36f2 <z_impl_k_mutex_lock+0x66>
	__asm__ volatile(
    36ba:	f388 8811 	msr	BASEPRI, r8
    36be:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);
		return -EBUSY;
    36c2:	f06f 020f 	mvn.w	r2, #15
    36c6:	e00e      	b.n	36e6 <z_impl_k_mutex_lock+0x5a>
					_current->base.prio :
    36c8:	6891      	ldr	r1, [r2, #8]
    36ca:	f991 100e 	ldrsb.w	r1, [r1, #14]
		mutex->owner_orig_prio = (mutex->lock_count == 0U) ?
    36ce:	6121      	str	r1, [r4, #16]
		mutex->lock_count++;
    36d0:	3301      	adds	r3, #1
    36d2:	60e3      	str	r3, [r4, #12]
		mutex->owner = _current;
    36d4:	6893      	ldr	r3, [r2, #8]
    36d6:	60a3      	str	r3, [r4, #8]
    36d8:	f002 ff1e 	bl	6518 <arch_is_user_context>
    36dc:	f388 8811 	msr	BASEPRI, r8
    36e0:	f3bf 8f6f 	isb	sy
		return 0;
    36e4:	2200      	movs	r2, #0
		k_spin_unlock(&lock, key);
	}

	sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);
	return -EAGAIN;
}
    36e6:	4610      	mov	r0, r2
    36e8:	b002      	add	sp, #8
    36ea:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
					_current->base.prio :
    36ee:	6921      	ldr	r1, [r4, #16]
    36f0:	e7ed      	b.n	36ce <z_impl_k_mutex_lock+0x42>
	new_prio = new_prio_for_inheritance(_current->base.prio,
    36f2:	f991 100e 	ldrsb.w	r1, [r1, #14]
    36f6:	f990 300e 	ldrsb.w	r3, [r0, #14]
    36fa:	4299      	cmp	r1, r3
    36fc:	bfa8      	it	ge
    36fe:	4619      	movge	r1, r3
    3700:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    3704:	f002 ff08 	bl	6518 <arch_is_user_context>
	if (z_is_prio_higher(new_prio, mutex->owner->base.prio)) {
    3708:	68a3      	ldr	r3, [r4, #8]
    370a:	f993 300e 	ldrsb.w	r3, [r3, #14]
    370e:	4299      	cmp	r1, r3
    3710:	da37      	bge.n	3782 <z_impl_k_mutex_lock+0xf6>
		resched = adjust_owner_prio(mutex, new_prio);
    3712:	f104 0008 	add.w	r0, r4, #8
    3716:	f002 ff09 	bl	652c <adjust_owner_prio.isra.0>
    371a:	4605      	mov	r5, r0
	int got_mutex = z_pend_curr(&lock, key, &mutex->wait_q, timeout);
    371c:	4622      	mov	r2, r4
    371e:	4641      	mov	r1, r8
    3720:	e9cd 6700 	strd	r6, r7, [sp]
    3724:	481b      	ldr	r0, [pc, #108]	; (3794 <z_impl_k_mutex_lock+0x108>)
    3726:	f000 fce5 	bl	40f4 <z_pend_curr>
    372a:	4602      	mov	r2, r0
    372c:	f002 fef4 	bl	6518 <arch_is_user_context>
    3730:	f002 fef2 	bl	6518 <arch_is_user_context>
	if (got_mutex == 0) {
    3734:	2a00      	cmp	r2, #0
    3736:	d0d6      	beq.n	36e6 <z_impl_k_mutex_lock+0x5a>
    3738:	f002 feee 	bl	6518 <arch_is_user_context>
	__asm__ volatile(
    373c:	f04f 0320 	mov.w	r3, #32
    3740:	f3ef 8611 	mrs	r6, BASEPRI
    3744:	f383 8811 	msr	BASEPRI, r3
    3748:	f3bf 8f6f 	isb	sy
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
    374c:	6823      	ldr	r3, [r4, #0]
    374e:	6921      	ldr	r1, [r4, #16]
 * @return a pointer to the head element, NULL if list is empty
 */

static inline sys_dnode_t *sys_dlist_peek_head(sys_dlist_t *list)
{
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3750:	42a3      	cmp	r3, r4
    3752:	d007      	beq.n	3764 <z_impl_k_mutex_lock+0xd8>
		new_prio_for_inheritance(waiter->base.prio, mutex->owner_orig_prio) :
    3754:	b133      	cbz	r3, 3764 <z_impl_k_mutex_lock+0xd8>
    3756:	f993 300e 	ldrsb.w	r3, [r3, #14]
    375a:	4299      	cmp	r1, r3
    375c:	bfa8      	it	ge
    375e:	4619      	movge	r1, r3
    3760:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    3764:	f002 fed8 	bl	6518 <arch_is_user_context>
	resched = adjust_owner_prio(mutex, new_prio) || resched;
    3768:	f104 0008 	add.w	r0, r4, #8
    376c:	f002 fede 	bl	652c <adjust_owner_prio.isra.0>
    3770:	b900      	cbnz	r0, 3774 <z_impl_k_mutex_lock+0xe8>
	if (resched) {
    3772:	b145      	cbz	r5, 3786 <z_impl_k_mutex_lock+0xfa>
		z_reschedule(&lock, key);
    3774:	4807      	ldr	r0, [pc, #28]	; (3794 <z_impl_k_mutex_lock+0x108>)
    3776:	4631      	mov	r1, r6
    3778:	f002 ffd8 	bl	672c <z_reschedule>
	return -EAGAIN;
    377c:	f06f 020a 	mvn.w	r2, #10
    3780:	e7b1      	b.n	36e6 <z_impl_k_mutex_lock+0x5a>
	bool resched = false;
    3782:	2500      	movs	r5, #0
    3784:	e7ca      	b.n	371c <z_impl_k_mutex_lock+0x90>
	__asm__ volatile(
    3786:	f386 8811 	msr	BASEPRI, r6
    378a:	f3bf 8f6f 	isb	sy
    378e:	e7f5      	b.n	377c <z_impl_k_mutex_lock+0xf0>
    3790:	20000664 	.word	0x20000664
    3794:	200013f4 	.word	0x200013f4

00003798 <z_mrsh_k_mutex_lock>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout);
uintptr_t z_mrsh_k_mutex_lock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3798:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    379c:	4d10      	ldr	r5, [pc, #64]	; (37e0 <z_mrsh_k_mutex_lock+0x48>)
    379e:	68ab      	ldr	r3, [r5, #8]
{
    37a0:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    37a2:	9a08      	ldr	r2, [sp, #32]
    37a4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    37a8:	4688      	mov	r8, r1
    37aa:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_lock(struct k_mutex *mutex,
				      k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(mutex, K_OBJ_MUTEX));
    37ac:	f7fc fc96 	bl	dc <z_object_find>
    37b0:	2200      	movs	r2, #0
    37b2:	2103      	movs	r1, #3
    37b4:	f001 fec0 	bl	5538 <z_object_validate>
    37b8:	4604      	mov	r4, r0
    37ba:	b130      	cbz	r0, 37ca <z_mrsh_k_mutex_lock+0x32>
    37bc:	f002 feac 	bl	6518 <arch_is_user_context>
    37c0:	68ab      	ldr	r3, [r5, #8]
    37c2:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    37c6:	f002 fcc1 	bl	614c <arch_syscall_oops>
	return z_impl_k_mutex_lock(mutex, timeout);
    37ca:	463b      	mov	r3, r7
    37cc:	4642      	mov	r2, r8
    37ce:	4630      	mov	r0, r6
    37d0:	f7ff ff5c 	bl	368c <z_impl_k_mutex_lock>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_mutex_lock(*(struct k_mutex **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    37d4:	68ab      	ldr	r3, [r5, #8]
    37d6:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    37da:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    37de:	bf00      	nop
    37e0:	20000664 	.word	0x20000664

000037e4 <z_impl_k_mutex_unlock>:
}
#include <syscalls/k_mutex_lock_mrsh.c>
#endif

int z_impl_k_mutex_unlock(struct k_mutex *mutex)
{
    37e4:	b538      	push	{r3, r4, r5, lr}
	struct k_thread *new_owner;

	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");

	CHECKIF(mutex->owner == NULL) {
    37e6:	6883      	ldr	r3, [r0, #8]
{
    37e8:	4604      	mov	r4, r0
	CHECKIF(mutex->owner == NULL) {
    37ea:	2b00      	cmp	r3, #0
    37ec:	d03a      	beq.n	3864 <z_impl_k_mutex_unlock+0x80>
		return -EINVAL;
	}
	/*
	 * The current thread does not own the mutex.
	 */
	CHECKIF(mutex->owner != _current) {
    37ee:	4a20      	ldr	r2, [pc, #128]	; (3870 <z_impl_k_mutex_unlock+0x8c>)
    37f0:	6892      	ldr	r2, [r2, #8]
    37f2:	4293      	cmp	r3, r2
    37f4:	d139      	bne.n	386a <z_impl_k_mutex_unlock+0x86>
{
#ifdef CONFIG_PREEMPT_ENABLED
	__ASSERT(!arch_is_in_isr(), "");
	__ASSERT(_current->base.sched_locked != 1, "");

	--_current->base.sched_locked;
    37f6:	7bda      	ldrb	r2, [r3, #15]
    37f8:	3a01      	subs	r2, #1
    37fa:	73da      	strb	r2, [r3, #15]
    37fc:	f002 fe8c 	bl	6518 <arch_is_user_context>

	/*
	 * If we are the owner and count is greater than 1, then decrement
	 * the count and return and keep current thread as the owner.
	 */
	if (mutex->lock_count - 1U != 0U) {
    3800:	68e3      	ldr	r3, [r4, #12]
    3802:	2b01      	cmp	r3, #1
    3804:	d005      	beq.n	3812 <z_impl_k_mutex_unlock+0x2e>
		mutex->lock_count--;
    3806:	3b01      	subs	r3, #1
    3808:	60e3      	str	r3, [r4, #12]
		k_spin_unlock(&lock, key);
	}


k_mutex_unlock_return:
	k_sched_unlock();
    380a:	f000 fa25 	bl	3c58 <k_sched_unlock>
	sys_trace_end_call(SYS_TRACE_ID_MUTEX_UNLOCK);

	return 0;
    380e:	2000      	movs	r0, #0
}
    3810:	bd38      	pop	{r3, r4, r5, pc}
	__asm__ volatile(
    3812:	f04f 0320 	mov.w	r3, #32
    3816:	f3ef 8511 	mrs	r5, BASEPRI
    381a:	f383 8811 	msr	BASEPRI, r3
    381e:	f3bf 8f6f 	isb	sy
	adjust_owner_prio(mutex, mutex->owner_orig_prio);
    3822:	6921      	ldr	r1, [r4, #16]
    3824:	f104 0008 	add.w	r0, r4, #8
    3828:	f002 fe80 	bl	652c <adjust_owner_prio.isra.0>
	new_owner = z_unpend_first_thread(&mutex->wait_q);
    382c:	4620      	mov	r0, r4
    382e:	f003 f83b 	bl	68a8 <z_unpend_first_thread>
	mutex->owner = new_owner;
    3832:	60a0      	str	r0, [r4, #8]
	new_owner = z_unpend_first_thread(&mutex->wait_q);
    3834:	4602      	mov	r2, r0
    3836:	f002 fe6f 	bl	6518 <arch_is_user_context>
	if (new_owner != NULL) {
    383a:	b16a      	cbz	r2, 3858 <z_impl_k_mutex_unlock+0x74>
		mutex->owner_orig_prio = new_owner->base.prio;
    383c:	f992 300e 	ldrsb.w	r3, [r2, #14]
    3840:	6123      	str	r3, [r4, #16]
    3842:	2300      	movs	r3, #0
		z_ready_thread(new_owner);
    3844:	4610      	mov	r0, r2
    3846:	f8c2 3090 	str.w	r3, [r2, #144]	; 0x90
    384a:	f002 ffb7 	bl	67bc <z_ready_thread>
		z_reschedule(&lock, key);
    384e:	4809      	ldr	r0, [pc, #36]	; (3874 <z_impl_k_mutex_unlock+0x90>)
    3850:	4629      	mov	r1, r5
    3852:	f002 ff6b 	bl	672c <z_reschedule>
    3856:	e7d8      	b.n	380a <z_impl_k_mutex_unlock+0x26>
		mutex->lock_count = 0U;
    3858:	60e2      	str	r2, [r4, #12]
	__asm__ volatile(
    385a:	f385 8811 	msr	BASEPRI, r5
    385e:	f3bf 8f6f 	isb	sy
    3862:	e7d2      	b.n	380a <z_impl_k_mutex_unlock+0x26>
		return -EINVAL;
    3864:	f06f 0015 	mvn.w	r0, #21
    3868:	e7d2      	b.n	3810 <z_impl_k_mutex_unlock+0x2c>
		return -EPERM;
    386a:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    386e:	e7cf      	b.n	3810 <z_impl_k_mutex_unlock+0x2c>
    3870:	20000664 	.word	0x20000664
    3874:	200013f4 	.word	0x200013f4

00003878 <z_mrsh_k_mutex_unlock>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_unlock(struct k_mutex * mutex);
uintptr_t z_mrsh_k_mutex_unlock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3878:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    387a:	4d0e      	ldr	r5, [pc, #56]	; (38b4 <z_mrsh_k_mutex_unlock+0x3c>)
    387c:	9a06      	ldr	r2, [sp, #24]
    387e:	68ab      	ldr	r3, [r5, #8]
    3880:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3884:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_unlock(struct k_mutex *mutex)
{
	Z_OOPS(Z_SYSCALL_OBJ(mutex, K_OBJ_MUTEX));
    3886:	f7fc fc29 	bl	dc <z_object_find>
    388a:	2200      	movs	r2, #0
    388c:	2103      	movs	r1, #3
    388e:	f001 fe53 	bl	5538 <z_object_validate>
    3892:	4604      	mov	r4, r0
    3894:	b130      	cbz	r0, 38a4 <z_mrsh_k_mutex_unlock+0x2c>
    3896:	f002 fe3f 	bl	6518 <arch_is_user_context>
    389a:	68ab      	ldr	r3, [r5, #8]
    389c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    38a0:	f002 fc54 	bl	614c <arch_syscall_oops>
	return z_impl_k_mutex_unlock(mutex);
    38a4:	4630      	mov	r0, r6
    38a6:	f7ff ff9d 	bl	37e4 <z_impl_k_mutex_unlock>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_mutex_unlock(*(struct k_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
    38aa:	68ab      	ldr	r3, [r5, #8]
    38ac:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    38b0:	bd70      	pop	{r4, r5, r6, pc}
    38b2:	bf00      	nop
    38b4:	20000664 	.word	0x20000664

000038b8 <z_mrsh_k_queue_init>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_queue_init(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    38b8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    38ba:	4d0f      	ldr	r5, [pc, #60]	; (38f8 <z_mrsh_k_queue_init+0x40>)
    38bc:	9a06      	ldr	r2, [sp, #24]
    38be:	68ab      	ldr	r3, [r5, #8]
    38c0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    38c4:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_queue_init(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(queue, K_OBJ_QUEUE));
    38c6:	f7fc fc09 	bl	dc <z_object_find>
    38ca:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    38ce:	2105      	movs	r1, #5
    38d0:	f001 fe32 	bl	5538 <z_object_validate>
    38d4:	4604      	mov	r4, r0
    38d6:	b130      	cbz	r0, 38e6 <z_mrsh_k_queue_init+0x2e>
    38d8:	f002 fe42 	bl	6560 <arch_is_user_context>
    38dc:	68ab      	ldr	r3, [r5, #8]
    38de:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    38e2:	f002 fc33 	bl	614c <arch_syscall_oops>
	z_impl_k_queue_init(queue);
    38e6:	4630      	mov	r0, r6
    38e8:	f002 fead 	bl	6646 <z_impl_k_queue_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_queue_init(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    38ec:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    38ee:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    38f0:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    38f4:	bd70      	pop	{r4, r5, r6, pc}
    38f6:	bf00      	nop
    38f8:	20000664 	.word	0x20000664

000038fc <z_mrsh_k_queue_cancel_wait>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_queue_cancel_wait(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_cancel_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    38fc:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    38fe:	4d0e      	ldr	r5, [pc, #56]	; (3938 <z_mrsh_k_queue_cancel_wait+0x3c>)
    3900:	9a06      	ldr	r2, [sp, #24]
    3902:	68ab      	ldr	r3, [r5, #8]
    3904:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3908:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_queue_cancel_wait(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    390a:	f7fc fbe7 	bl	dc <z_object_find>
    390e:	2200      	movs	r2, #0
    3910:	2105      	movs	r1, #5
    3912:	f001 fe11 	bl	5538 <z_object_validate>
    3916:	4604      	mov	r4, r0
    3918:	b130      	cbz	r0, 3928 <z_mrsh_k_queue_cancel_wait+0x2c>
    391a:	f002 fe21 	bl	6560 <arch_is_user_context>
    391e:	68ab      	ldr	r3, [r5, #8]
    3920:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3924:	f002 fc12 	bl	614c <arch_syscall_oops>
	z_impl_k_queue_cancel_wait(queue);
    3928:	4630      	mov	r0, r6
    392a:	f002 fe95 	bl	6658 <z_impl_k_queue_cancel_wait>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_queue_cancel_wait(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    392e:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3930:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3932:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3936:	bd70      	pop	{r4, r5, r6, pc}
    3938:	20000664 	.word	0x20000664

0000393c <z_mrsh_k_queue_alloc_append>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_queue_alloc_append(struct k_queue * queue, void * data);
uintptr_t z_mrsh_k_queue_alloc_append(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    393c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    393e:	4d0f      	ldr	r5, [pc, #60]	; (397c <z_mrsh_k_queue_alloc_append+0x40>)
    3940:	9a08      	ldr	r2, [sp, #32]
    3942:	68ab      	ldr	r3, [r5, #8]
    3944:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3948:	460f      	mov	r7, r1
    394a:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_queue_alloc_append(struct k_queue *queue,
						void *data)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    394c:	f7fc fbc6 	bl	dc <z_object_find>
    3950:	2200      	movs	r2, #0
    3952:	2105      	movs	r1, #5
    3954:	f001 fdf0 	bl	5538 <z_object_validate>
    3958:	4604      	mov	r4, r0
    395a:	b130      	cbz	r0, 396a <z_mrsh_k_queue_alloc_append+0x2e>
    395c:	f002 fe00 	bl	6560 <arch_is_user_context>
    3960:	68ab      	ldr	r3, [r5, #8]
    3962:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3966:	f002 fbf1 	bl	614c <arch_syscall_oops>
	return z_impl_k_queue_alloc_append(queue, data);
    396a:	4639      	mov	r1, r7
    396c:	4630      	mov	r0, r6
    396e:	f002 fe93 	bl	6698 <z_impl_k_queue_alloc_append>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_queue_alloc_append(*(struct k_queue **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    3972:	68ab      	ldr	r3, [r5, #8]
    3974:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3978:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    397a:	bf00      	nop
    397c:	20000664 	.word	0x20000664

00003980 <z_mrsh_k_queue_alloc_prepend>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_queue_alloc_prepend(struct k_queue * queue, void * data);
uintptr_t z_mrsh_k_queue_alloc_prepend(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3980:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    3982:	4d0f      	ldr	r5, [pc, #60]	; (39c0 <z_mrsh_k_queue_alloc_prepend+0x40>)
    3984:	9a08      	ldr	r2, [sp, #32]
    3986:	68ab      	ldr	r3, [r5, #8]
    3988:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    398c:	460f      	mov	r7, r1
    398e:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_queue_alloc_prepend(struct k_queue *queue,
						 void *data)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3990:	f7fc fba4 	bl	dc <z_object_find>
    3994:	2200      	movs	r2, #0
    3996:	2105      	movs	r1, #5
    3998:	f001 fdce 	bl	5538 <z_object_validate>
    399c:	4604      	mov	r4, r0
    399e:	b130      	cbz	r0, 39ae <z_mrsh_k_queue_alloc_prepend+0x2e>
    39a0:	f002 fdde 	bl	6560 <arch_is_user_context>
    39a4:	68ab      	ldr	r3, [r5, #8]
    39a6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    39aa:	f002 fbcf 	bl	614c <arch_syscall_oops>
	return z_impl_k_queue_alloc_prepend(queue, data);
    39ae:	4639      	mov	r1, r7
    39b0:	4630      	mov	r0, r6
    39b2:	f002 fe76 	bl	66a2 <z_impl_k_queue_alloc_prepend>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_queue_alloc_prepend(*(struct k_queue **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    39b6:	68ab      	ldr	r3, [r5, #8]
    39b8:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    39bc:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    39be:	bf00      	nop
    39c0:	20000664 	.word	0x20000664

000039c4 <z_impl_k_queue_get>:

	return 0;
}

void *z_impl_k_queue_get(struct k_queue *queue, k_timeout_t timeout)
{
    39c4:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    39c6:	4616      	mov	r6, r2
    39c8:	461f      	mov	r7, r3
	__asm__ volatile(
    39ca:	f04f 0320 	mov.w	r3, #32
    39ce:	f3ef 8511 	mrs	r5, BASEPRI
    39d2:	f383 8811 	msr	BASEPRI, r3
    39d6:	f3bf 8f6f 	isb	sy
 *
 * @return a boolean, true if it's empty, false otherwise
 */
static inline bool sys_sflist_is_empty(sys_sflist_t *list);

Z_GENLIST_IS_EMPTY(sflist)
    39da:	6804      	ldr	r4, [r0, #0]
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
	void *data;

	if (likely(!sys_sflist_is_empty(&queue->data_q))) {
    39dc:	b19c      	cbz	r4, 3a06 <z_impl_k_queue_get+0x42>
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    39de:	6823      	ldr	r3, [r4, #0]
 *
 * @return A pointer to the first node of the list
 */
static inline sys_sfnode_t *sys_sflist_get_not_empty(sys_sflist_t *list);

Z_GENLIST_GET_NOT_EMPTY(sflist, sfnode)
    39e0:	6842      	ldr	r2, [r0, #4]
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    39e2:	f023 0303 	bic.w	r3, r3, #3
Z_GENLIST_GET_NOT_EMPTY(sflist, sfnode)
    39e6:	4294      	cmp	r4, r2
	list->head = node;
    39e8:	6003      	str	r3, [r0, #0]
	list->tail = node;
    39ea:	bf08      	it	eq
    39ec:	6043      	streq	r3, [r0, #4]
		sys_sfnode_t *node;

		node = sys_sflist_get_not_empty(&queue->data_q);
		data = z_queue_node_peek(node, true);
    39ee:	2101      	movs	r1, #1
    39f0:	4620      	mov	r0, r4
    39f2:	f002 fe1c 	bl	662e <z_queue_node_peek>
    39f6:	4604      	mov	r4, r0
	__asm__ volatile(
    39f8:	f385 8811 	msr	BASEPRI, r5
    39fc:	f3bf 8f6f 	isb	sy
	}

	int ret = z_pend_curr(&queue->lock, key, &queue->wait_q, timeout);

	return (ret != 0) ? NULL : _current->base.swap_data;
}
    3a00:	4620      	mov	r0, r4
    3a02:	b003      	add	sp, #12
    3a04:	bdf0      	pop	{r4, r5, r6, r7, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    3a06:	ea56 0307 	orrs.w	r3, r6, r7
    3a0a:	d0f5      	beq.n	39f8 <z_impl_k_queue_get+0x34>
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    3a0c:	f100 0208 	add.w	r2, r0, #8
	int ret = z_pend_curr(&queue->lock, key, &queue->wait_q, timeout);
    3a10:	e9cd 6700 	strd	r6, r7, [sp]
    3a14:	4629      	mov	r1, r5
    3a16:	4610      	mov	r0, r2
    3a18:	f000 fb6c 	bl	40f4 <z_pend_curr>
	return (ret != 0) ? NULL : _current->base.swap_data;
    3a1c:	2800      	cmp	r0, #0
    3a1e:	d1ef      	bne.n	3a00 <z_impl_k_queue_get+0x3c>
    3a20:	4b01      	ldr	r3, [pc, #4]	; (3a28 <z_impl_k_queue_get+0x64>)
    3a22:	689b      	ldr	r3, [r3, #8]
    3a24:	695c      	ldr	r4, [r3, #20]
    3a26:	e7eb      	b.n	3a00 <z_impl_k_queue_get+0x3c>
    3a28:	20000664 	.word	0x20000664

00003a2c <z_mrsh_k_queue_get>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_get(struct k_queue * queue, k_timeout_t timeout);
uintptr_t z_mrsh_k_queue_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3a2c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    3a30:	4d10      	ldr	r5, [pc, #64]	; (3a74 <z_mrsh_k_queue_get+0x48>)
    3a32:	68ab      	ldr	r3, [r5, #8]
{
    3a34:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    3a36:	9a08      	ldr	r2, [sp, #32]
    3a38:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3a3c:	4688      	mov	r8, r1
    3a3e:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline void *z_vrfy_k_queue_get(struct k_queue *queue,
				       k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3a40:	f7fc fb4c 	bl	dc <z_object_find>
    3a44:	2200      	movs	r2, #0
    3a46:	2105      	movs	r1, #5
    3a48:	f001 fd76 	bl	5538 <z_object_validate>
    3a4c:	4604      	mov	r4, r0
    3a4e:	b130      	cbz	r0, 3a5e <z_mrsh_k_queue_get+0x32>
    3a50:	f002 fd86 	bl	6560 <arch_is_user_context>
    3a54:	68ab      	ldr	r3, [r5, #8]
    3a56:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3a5a:	f002 fb77 	bl	614c <arch_syscall_oops>
	return z_impl_k_queue_get(queue, timeout);
    3a5e:	463b      	mov	r3, r7
    3a60:	4642      	mov	r2, r8
    3a62:	4630      	mov	r0, r6
    3a64:	f7ff ffae 	bl	39c4 <z_impl_k_queue_get>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	void * ret = z_vrfy_k_queue_get(*(struct k_queue **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    3a68:	68ab      	ldr	r3, [r5, #8]
    3a6a:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3a6e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    3a72:	bf00      	nop
    3a74:	20000664 	.word	0x20000664

00003a78 <z_mrsh_k_queue_is_empty>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_queue_is_empty(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_is_empty(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3a78:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    3a7a:	4c0e      	ldr	r4, [pc, #56]	; (3ab4 <z_mrsh_k_queue_is_empty+0x3c>)
    3a7c:	9a06      	ldr	r2, [sp, #24]
    3a7e:	68a3      	ldr	r3, [r4, #8]
    3a80:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3a84:	4605      	mov	r5, r0
}
#include <syscalls/k_queue_get_mrsh.c>

static inline int z_vrfy_k_queue_is_empty(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3a86:	f7fc fb29 	bl	dc <z_object_find>
    3a8a:	2200      	movs	r2, #0
    3a8c:	2105      	movs	r1, #5
    3a8e:	f001 fd53 	bl	5538 <z_object_validate>
    3a92:	b130      	cbz	r0, 3aa2 <z_mrsh_k_queue_is_empty+0x2a>
    3a94:	f002 fd64 	bl	6560 <arch_is_user_context>
    3a98:	68a3      	ldr	r3, [r4, #8]
    3a9a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3a9e:	f002 fb55 	bl	614c <arch_syscall_oops>
Z_GENLIST_IS_EMPTY(sflist)
    3aa2:	682b      	ldr	r3, [r5, #0]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_queue_is_empty(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3aa4:	68a2      	ldr	r2, [r4, #8]
    3aa6:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    3aaa:	fab3 f083 	clz	r0, r3
    3aae:	0940      	lsrs	r0, r0, #5
    3ab0:	bd38      	pop	{r3, r4, r5, pc}
    3ab2:	bf00      	nop
    3ab4:	20000664 	.word	0x20000664

00003ab8 <z_mrsh_k_queue_peek_head>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_peek_head(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_peek_head(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3ab8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3aba:	4d0e      	ldr	r5, [pc, #56]	; (3af4 <z_mrsh_k_queue_peek_head+0x3c>)
    3abc:	9a06      	ldr	r2, [sp, #24]
    3abe:	68ab      	ldr	r3, [r5, #8]
    3ac0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3ac4:	4606      	mov	r6, r0
}
#include <syscalls/k_queue_is_empty_mrsh.c>

static inline void *z_vrfy_k_queue_peek_head(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3ac6:	f7fc fb09 	bl	dc <z_object_find>
    3aca:	2200      	movs	r2, #0
    3acc:	2105      	movs	r1, #5
    3ace:	f001 fd33 	bl	5538 <z_object_validate>
    3ad2:	4604      	mov	r4, r0
    3ad4:	b130      	cbz	r0, 3ae4 <z_mrsh_k_queue_peek_head+0x2c>
    3ad6:	f002 fd43 	bl	6560 <arch_is_user_context>
    3ada:	68ab      	ldr	r3, [r5, #8]
    3adc:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3ae0:	f002 fb34 	bl	614c <arch_syscall_oops>
	return z_queue_node_peek(sys_sflist_peek_head(&queue->data_q), false);
    3ae4:	4601      	mov	r1, r0
    3ae6:	6830      	ldr	r0, [r6, #0]
    3ae8:	f002 fda1 	bl	662e <z_queue_node_peek>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_queue_peek_head(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3aec:	68ab      	ldr	r3, [r5, #8]
    3aee:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3af2:	bd70      	pop	{r4, r5, r6, pc}
    3af4:	20000664 	.word	0x20000664

00003af8 <z_mrsh_k_queue_peek_tail>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_peek_tail(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_peek_tail(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3af8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3afa:	4d0e      	ldr	r5, [pc, #56]	; (3b34 <z_mrsh_k_queue_peek_tail+0x3c>)
    3afc:	9a06      	ldr	r2, [sp, #24]
    3afe:	68ab      	ldr	r3, [r5, #8]
    3b00:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3b04:	4606      	mov	r6, r0
}
#include <syscalls/k_queue_peek_head_mrsh.c>

static inline void *z_vrfy_k_queue_peek_tail(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3b06:	f7fc fae9 	bl	dc <z_object_find>
    3b0a:	2200      	movs	r2, #0
    3b0c:	2105      	movs	r1, #5
    3b0e:	f001 fd13 	bl	5538 <z_object_validate>
    3b12:	4604      	mov	r4, r0
    3b14:	b130      	cbz	r0, 3b24 <z_mrsh_k_queue_peek_tail+0x2c>
    3b16:	f002 fd23 	bl	6560 <arch_is_user_context>
    3b1a:	68ab      	ldr	r3, [r5, #8]
    3b1c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3b20:	f002 fb14 	bl	614c <arch_syscall_oops>
	return z_queue_node_peek(sys_sflist_peek_tail(&queue->data_q), false);
    3b24:	4601      	mov	r1, r0
    3b26:	6870      	ldr	r0, [r6, #4]
    3b28:	f002 fd81 	bl	662e <z_queue_node_peek>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_queue_peek_tail(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3b2c:	68ab      	ldr	r3, [r5, #8]
    3b2e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3b32:	bd70      	pop	{r4, r5, r6, pc}
    3b34:	20000664 	.word	0x20000664

00003b38 <z_reset_time_slice>:
 */
static struct k_thread *pending_current;
#endif

void z_reset_time_slice(void)
{
    3b38:	b510      	push	{r4, lr}
	/* Add the elapsed time since the last announced tick to the
	 * slice count, as we'll see those "expired" ticks arrive in a
	 * FUTURE z_time_slice() call.
	 */
	if (slice_time != 0) {
    3b3a:	4c08      	ldr	r4, [pc, #32]	; (3b5c <z_reset_time_slice+0x24>)
    3b3c:	6823      	ldr	r3, [r4, #0]
    3b3e:	b15b      	cbz	r3, 3b58 <z_reset_time_slice+0x20>
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    3b40:	f7fd fce0 	bl	1504 <z_clock_elapsed>
    3b44:	4603      	mov	r3, r0
    3b46:	6820      	ldr	r0, [r4, #0]
    3b48:	4a05      	ldr	r2, [pc, #20]	; (3b60 <z_reset_time_slice+0x28>)
    3b4a:	4403      	add	r3, r0
		z_set_timeout_expiry(slice_time, false);
	}
}
    3b4c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    3b50:	6113      	str	r3, [r2, #16]
		z_set_timeout_expiry(slice_time, false);
    3b52:	2100      	movs	r1, #0
    3b54:	f002 bfe1 	b.w	6b1a <z_set_timeout_expiry>
}
    3b58:	bd10      	pop	{r4, pc}
    3b5a:	bf00      	nop
    3b5c:	2000069c 	.word	0x2000069c
    3b60:	20000664 	.word	0x20000664

00003b64 <k_sched_time_slice_set>:

void k_sched_time_slice_set(int32_t slice, int prio)
{
    3b64:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    3b66:	4605      	mov	r5, r0
    3b68:	460c      	mov	r4, r1
	__asm__ volatile(
    3b6a:	f04f 0320 	mov.w	r3, #32
    3b6e:	f3ef 8611 	mrs	r6, BASEPRI
    3b72:	f383 8811 	msr	BASEPRI, r3
    3b76:	f3bf 8f6f 	isb	sy
	LOCKED(&sched_spinlock) {
		_current_cpu->slice_ticks = 0;
    3b7a:	4b0d      	ldr	r3, [pc, #52]	; (3bb0 <k_sched_time_slice_set+0x4c>)
    3b7c:	2200      	movs	r2, #0
			return (uint32_t)((t * to_hz + off) / from_hz);
    3b7e:	f44f 4700 	mov.w	r7, #32768	; 0x8000
    3b82:	f240 30e7 	movw	r0, #999	; 0x3e7
    3b86:	2100      	movs	r1, #0
    3b88:	611a      	str	r2, [r3, #16]
    3b8a:	fbe7 0105 	umlal	r0, r1, r7, r5
    3b8e:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    3b92:	2300      	movs	r3, #0
    3b94:	f7fc fb22 	bl	1dc <__aeabi_uldivmod>
		slice_time = k_ms_to_ticks_ceil32(slice);
    3b98:	4b06      	ldr	r3, [pc, #24]	; (3bb4 <k_sched_time_slice_set+0x50>)
    3b9a:	6018      	str	r0, [r3, #0]
		slice_max_prio = prio;
    3b9c:	4b06      	ldr	r3, [pc, #24]	; (3bb8 <k_sched_time_slice_set+0x54>)
    3b9e:	601c      	str	r4, [r3, #0]
		z_reset_time_slice();
    3ba0:	f7ff ffca 	bl	3b38 <z_reset_time_slice>
	__asm__ volatile(
    3ba4:	f386 8811 	msr	BASEPRI, r6
    3ba8:	f3bf 8f6f 	isb	sy
	}
}
    3bac:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3bae:	bf00      	nop
    3bb0:	20000664 	.word	0x20000664
    3bb4:	2000069c 	.word	0x2000069c
    3bb8:	20000698 	.word	0x20000698

00003bbc <k_sched_lock>:
	__asm__ volatile(
    3bbc:	f04f 0320 	mov.w	r3, #32
    3bc0:	f3ef 8111 	mrs	r1, BASEPRI
    3bc4:	f383 8811 	msr	BASEPRI, r3
    3bc8:	f3bf 8f6f 	isb	sy
    3bcc:	4b04      	ldr	r3, [pc, #16]	; (3be0 <k_sched_lock+0x24>)
    3bce:	689a      	ldr	r2, [r3, #8]
    3bd0:	7bd3      	ldrb	r3, [r2, #15]
    3bd2:	3b01      	subs	r3, #1
    3bd4:	73d3      	strb	r3, [r2, #15]
	__asm__ volatile(
    3bd6:	f381 8811 	msr	BASEPRI, r1
    3bda:	f3bf 8f6f 	isb	sy
void k_sched_lock(void)
{
	LOCKED(&sched_spinlock) {
		z_sched_lock();
	}
}
    3bde:	4770      	bx	lr
    3be0:	20000664 	.word	0x20000664

00003be4 <z_priq_dumb_remove>:
}

void z_priq_dumb_remove(sys_dlist_t *pq, struct k_thread *thread)
{
#if defined(CONFIG_SWAP_NONATOMIC) && defined(CONFIG_SCHED_DUMB)
	if (pq == &_kernel.ready_q.runq && thread == _current &&
    3be4:	4b09      	ldr	r3, [pc, #36]	; (3c0c <z_priq_dumb_remove+0x28>)
    3be6:	f103 0228 	add.w	r2, r3, #40	; 0x28
    3bea:	4282      	cmp	r2, r0
    3bec:	d105      	bne.n	3bfa <z_priq_dumb_remove+0x16>
    3bee:	689b      	ldr	r3, [r3, #8]
    3bf0:	428b      	cmp	r3, r1
    3bf2:	d102      	bne.n	3bfa <z_priq_dumb_remove+0x16>
    3bf4:	7b4b      	ldrb	r3, [r1, #13]
    3bf6:	06db      	lsls	r3, r3, #27
    3bf8:	d106      	bne.n	3c08 <z_priq_dumb_remove+0x24>
 * @return N/A
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	node->prev->next = node->next;
    3bfa:	e9d1 3200 	ldrd	r3, r2, [r1]
    3bfe:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    3c00:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    3c02:	2300      	movs	r3, #0
	node->prev = NULL;
    3c04:	e9c1 3300 	strd	r3, r3, [r1]
#endif

	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));

	sys_dlist_remove(&thread->base.qnode_dlist);
}
    3c08:	4770      	bx	lr
    3c0a:	bf00      	nop
    3c0c:	20000664 	.word	0x20000664

00003c10 <update_cache>:
{
    3c10:	b570      	push	{r4, r5, r6, lr}
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    3c12:	4c10      	ldr	r4, [pc, #64]	; (3c54 <update_cache+0x44>)
{
    3c14:	4606      	mov	r6, r0
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    3c16:	f104 0028 	add.w	r0, r4, #40	; 0x28
    3c1a:	f002 fdc5 	bl	67a8 <z_priq_dumb_best>
	if (_current->base.thread_state & _THREAD_ABORTING) {
    3c1e:	68a3      	ldr	r3, [r4, #8]
    3c20:	7b59      	ldrb	r1, [r3, #13]
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    3c22:	4605      	mov	r5, r0
	if (_current->base.thread_state & _THREAD_ABORTING) {
    3c24:	0688      	lsls	r0, r1, #26
		_current->base.thread_state |= _THREAD_DEAD;
    3c26:	bf44      	itt	mi
    3c28:	f041 0108 	orrmi.w	r1, r1, #8
    3c2c:	7359      	strbmi	r1, [r3, #13]
	return thread ? thread : _current_cpu->idle_thread;
    3c2e:	b905      	cbnz	r5, 3c32 <update_cache+0x22>
    3c30:	68e5      	ldr	r5, [r4, #12]
	if (preempt_ok != 0) {
    3c32:	b94e      	cbnz	r6, 3c48 <update_cache+0x38>
	if (z_is_thread_prevented_from_running(_current)) {
    3c34:	7b5a      	ldrb	r2, [r3, #13]
    3c36:	06d2      	lsls	r2, r2, #27
    3c38:	d106      	bne.n	3c48 <update_cache+0x38>
	if (IS_ENABLED(CONFIG_SWAP_NONATOMIC)
    3c3a:	69aa      	ldr	r2, [r5, #24]
    3c3c:	b922      	cbnz	r2, 3c48 <update_cache+0x38>
	if (is_preempt(_current) || is_metairq(thread)) {
    3c3e:	89da      	ldrh	r2, [r3, #14]
    3c40:	2a7f      	cmp	r2, #127	; 0x7f
    3c42:	d901      	bls.n	3c48 <update_cache+0x38>
		_kernel.ready_q.cache = _current;
    3c44:	6263      	str	r3, [r4, #36]	; 0x24
}
    3c46:	bd70      	pop	{r4, r5, r6, pc}
		if (thread != _current) {
    3c48:	42ab      	cmp	r3, r5
    3c4a:	d001      	beq.n	3c50 <update_cache+0x40>
			z_reset_time_slice();
    3c4c:	f7ff ff74 	bl	3b38 <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
    3c50:	6265      	str	r5, [r4, #36]	; 0x24
}
    3c52:	e7f8      	b.n	3c46 <update_cache+0x36>
    3c54:	20000664 	.word	0x20000664

00003c58 <k_sched_unlock>:
{
    3c58:	b510      	push	{r4, lr}
	__asm__ volatile(
    3c5a:	f04f 0320 	mov.w	r3, #32
    3c5e:	f3ef 8411 	mrs	r4, BASEPRI
    3c62:	f383 8811 	msr	BASEPRI, r3
    3c66:	f3bf 8f6f 	isb	sy
		++_current->base.sched_locked;
    3c6a:	4b09      	ldr	r3, [pc, #36]	; (3c90 <k_sched_unlock+0x38>)
    3c6c:	689a      	ldr	r2, [r3, #8]
    3c6e:	7bd3      	ldrb	r3, [r2, #15]
    3c70:	3301      	adds	r3, #1
    3c72:	73d3      	strb	r3, [r2, #15]
		update_cache(0);
    3c74:	2000      	movs	r0, #0
    3c76:	f7ff ffcb 	bl	3c10 <update_cache>
	__asm__ volatile(
    3c7a:	f384 8811 	msr	BASEPRI, r4
    3c7e:	f3bf 8f6f 	isb	sy
    3c82:	f002 fd13 	bl	66ac <arch_is_user_context>
}
    3c86:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule_unlocked();
    3c8a:	f002 bd66 	b.w	675a <z_reschedule_unlocked>
    3c8e:	bf00      	nop
    3c90:	20000664 	.word	0x20000664

00003c94 <ready_thread>:
{
    3c94:	b470      	push	{r4, r5, r6}
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    3c96:	7b43      	ldrb	r3, [r0, #13]
    3c98:	06db      	lsls	r3, r3, #27
    3c9a:	d12a      	bne.n	3cf2 <ready_thread+0x5e>

int z_abort_timeout(struct _timeout *to);

static inline bool z_is_inactive_timeout(struct _timeout *t)
{
	return !sys_dnode_is_linked(&t->node);
    3c9c:	6983      	ldr	r3, [r0, #24]
	if (z_is_thread_ready(thread)) {
    3c9e:	bb43      	cbnz	r3, 3cf2 <ready_thread+0x5e>
	return list->head == list;
    3ca0:	4a15      	ldr	r2, [pc, #84]	; (3cf8 <ready_thread+0x64>)
    3ca2:	4611      	mov	r1, r2
    3ca4:	f851 4f28 	ldr.w	r4, [r1, #40]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3ca8:	428c      	cmp	r4, r1
    3caa:	bf18      	it	ne
    3cac:	4623      	movne	r3, r4
    3cae:	2b00      	cmp	r3, #0
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    3cb0:	6ad4      	ldr	r4, [r2, #44]	; 0x2c
    3cb2:	bf38      	it	cc
    3cb4:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    3cb6:	b1b3      	cbz	r3, 3ce6 <ready_thread+0x52>
	if (thread_1->base.prio < thread_2->base.prio) {
    3cb8:	f990 600e 	ldrsb.w	r6, [r0, #14]
    3cbc:	f993 500e 	ldrsb.w	r5, [r3, #14]
    3cc0:	42ae      	cmp	r6, r5
    3cc2:	db03      	blt.n	3ccc <ready_thread+0x38>
	return (node == list->tail) ? NULL : node->next;
    3cc4:	42a3      	cmp	r3, r4
    3cc6:	d00e      	beq.n	3ce6 <ready_thread+0x52>
    3cc8:	681b      	ldr	r3, [r3, #0]
    3cca:	e7f4      	b.n	3cb6 <ready_thread+0x22>
	node->prev = successor->prev;
    3ccc:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    3cce:	e9c0 3200 	strd	r3, r2, [r0]
	successor->prev->next = node;
    3cd2:	6010      	str	r0, [r2, #0]
	successor->prev = node;
    3cd4:	6058      	str	r0, [r3, #4]
	thread->base.thread_state |= states;
    3cd6:	7b43      	ldrb	r3, [r0, #13]
    3cd8:	f063 037f 	orn	r3, r3, #127	; 0x7f
    3cdc:	7343      	strb	r3, [r0, #13]
}
    3cde:	bc70      	pop	{r4, r5, r6}
		update_cache(0);
    3ce0:	2000      	movs	r0, #0
    3ce2:	f7ff bf95 	b.w	3c10 <update_cache>
	node->prev = list->tail;
    3ce6:	e9c0 1400 	strd	r1, r4, [r0]
	list->tail->next = node;
    3cea:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    3cec:	6018      	str	r0, [r3, #0]
	list->tail = node;
    3cee:	62d0      	str	r0, [r2, #44]	; 0x2c
}
    3cf0:	e7f1      	b.n	3cd6 <ready_thread+0x42>
}
    3cf2:	bc70      	pop	{r4, r5, r6}
    3cf4:	4770      	bx	lr
    3cf6:	bf00      	nop
    3cf8:	20000664 	.word	0x20000664

00003cfc <z_sched_start>:
{
    3cfc:	b510      	push	{r4, lr}
	__asm__ volatile(
    3cfe:	f04f 0220 	mov.w	r2, #32
    3d02:	f3ef 8411 	mrs	r4, BASEPRI
    3d06:	f382 8811 	msr	BASEPRI, r2
    3d0a:	f3bf 8f6f 	isb	sy
	if (z_has_thread_started(thread)) {
    3d0e:	7b42      	ldrb	r2, [r0, #13]
    3d10:	0751      	lsls	r1, r2, #29
    3d12:	d404      	bmi.n	3d1e <z_sched_start+0x22>
	__asm__ volatile(
    3d14:	f384 8811 	msr	BASEPRI, r4
    3d18:	f3bf 8f6f 	isb	sy
}
    3d1c:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_PRESTART;
    3d1e:	f022 0204 	bic.w	r2, r2, #4
    3d22:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
    3d24:	f7ff ffb6 	bl	3c94 <ready_thread>
	z_reschedule(&sched_spinlock, key);
    3d28:	4621      	mov	r1, r4
    3d2a:	4802      	ldr	r0, [pc, #8]	; (3d34 <z_sched_start+0x38>)
}
    3d2c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    3d30:	f002 bcfc 	b.w	672c <z_reschedule>
    3d34:	200013f4 	.word	0x200013f4

00003d38 <z_impl_k_thread_resume>:
{
    3d38:	b510      	push	{r4, lr}
	__asm__ volatile(
    3d3a:	f04f 0220 	mov.w	r2, #32
    3d3e:	f3ef 8411 	mrs	r4, BASEPRI
    3d42:	f382 8811 	msr	BASEPRI, r2
    3d46:	f3bf 8f6f 	isb	sy
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    3d4a:	7b42      	ldrb	r2, [r0, #13]
    3d4c:	f022 0210 	bic.w	r2, r2, #16
    3d50:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
    3d52:	f7ff ff9f 	bl	3c94 <ready_thread>
	z_reschedule(&sched_spinlock, key);
    3d56:	4621      	mov	r1, r4
    3d58:	4802      	ldr	r0, [pc, #8]	; (3d64 <z_impl_k_thread_resume+0x2c>)
}
    3d5a:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    3d5e:	f002 bce5 	b.w	672c <z_reschedule>
    3d62:	bf00      	nop
    3d64:	200013f4 	.word	0x200013f4

00003d68 <z_mrsh_k_thread_resume>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_resume(k_tid_t thread);
uintptr_t z_mrsh_k_thread_resume(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3d68:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3d6a:	4d0e      	ldr	r5, [pc, #56]	; (3da4 <z_mrsh_k_thread_resume+0x3c>)
    3d6c:	9a06      	ldr	r2, [sp, #24]
    3d6e:	68ab      	ldr	r3, [r5, #8]
    3d70:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3d74:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    3d76:	f7fc f9b1 	bl	dc <z_object_find>
    3d7a:	2200      	movs	r2, #0
    3d7c:	2109      	movs	r1, #9
    3d7e:	f001 fbdb 	bl	5538 <z_object_validate>
    3d82:	4604      	mov	r4, r0
    3d84:	b130      	cbz	r0, 3d94 <z_mrsh_k_thread_resume+0x2c>
    3d86:	f002 fc91 	bl	66ac <arch_is_user_context>
    3d8a:	68ab      	ldr	r3, [r5, #8]
    3d8c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3d90:	f002 f9dc 	bl	614c <arch_syscall_oops>
	z_impl_k_thread_resume(thread);
    3d94:	4630      	mov	r0, r6
    3d96:	f7ff ffcf 	bl	3d38 <z_impl_k_thread_resume>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_resume(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    3d9a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3d9c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3d9e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3da2:	bd70      	pop	{r4, r5, r6, pc}
    3da4:	20000664 	.word	0x20000664

00003da8 <z_move_thread_to_end_of_prio_q>:
{
    3da8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    3daa:	4601      	mov	r1, r0
    3dac:	f04f 0320 	mov.w	r3, #32
    3db0:	f3ef 8411 	mrs	r4, BASEPRI
    3db4:	f383 8811 	msr	BASEPRI, r3
    3db8:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    3dbc:	f990 300d 	ldrsb.w	r3, [r0, #13]
    3dc0:	2b00      	cmp	r3, #0
    3dc2:	da02      	bge.n	3dca <z_move_thread_to_end_of_prio_q+0x22>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    3dc4:	4819      	ldr	r0, [pc, #100]	; (3e2c <z_move_thread_to_end_of_prio_q+0x84>)
    3dc6:	f7ff ff0d 	bl	3be4 <z_priq_dumb_remove>
	return list->head == list;
    3dca:	4a19      	ldr	r2, [pc, #100]	; (3e30 <z_move_thread_to_end_of_prio_q+0x88>)
    3dcc:	4610      	mov	r0, r2
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    3dce:	6ad5      	ldr	r5, [r2, #44]	; 0x2c
	return list->head == list;
    3dd0:	f850 3f28 	ldr.w	r3, [r0, #40]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3dd4:	4283      	cmp	r3, r0
    3dd6:	bf08      	it	eq
    3dd8:	2300      	moveq	r3, #0
    3dda:	2b00      	cmp	r3, #0
    3ddc:	bf38      	it	cc
    3dde:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    3de0:	b1eb      	cbz	r3, 3e1e <z_move_thread_to_end_of_prio_q+0x76>
	if (thread_1->base.prio < thread_2->base.prio) {
    3de2:	f991 700e 	ldrsb.w	r7, [r1, #14]
    3de6:	f993 600e 	ldrsb.w	r6, [r3, #14]
    3dea:	42b7      	cmp	r7, r6
    3dec:	db03      	blt.n	3df6 <z_move_thread_to_end_of_prio_q+0x4e>
	return (node == list->tail) ? NULL : node->next;
    3dee:	429d      	cmp	r5, r3
    3df0:	d015      	beq.n	3e1e <z_move_thread_to_end_of_prio_q+0x76>
    3df2:	681b      	ldr	r3, [r3, #0]
    3df4:	e7f4      	b.n	3de0 <z_move_thread_to_end_of_prio_q+0x38>
	node->prev = successor->prev;
    3df6:	6858      	ldr	r0, [r3, #4]
	node->next = successor;
    3df8:	e9c1 3000 	strd	r3, r0, [r1]
	successor->prev->next = node;
    3dfc:	6001      	str	r1, [r0, #0]
	successor->prev = node;
    3dfe:	6059      	str	r1, [r3, #4]
	thread->base.thread_state |= states;
    3e00:	7b4b      	ldrb	r3, [r1, #13]
		update_cache(thread == _current);
    3e02:	6890      	ldr	r0, [r2, #8]
    3e04:	f063 037f 	orn	r3, r3, #127	; 0x7f
    3e08:	734b      	strb	r3, [r1, #13]
    3e0a:	1a43      	subs	r3, r0, r1
    3e0c:	4258      	negs	r0, r3
    3e0e:	4158      	adcs	r0, r3
    3e10:	f7ff fefe 	bl	3c10 <update_cache>
	__asm__ volatile(
    3e14:	f384 8811 	msr	BASEPRI, r4
    3e18:	f3bf 8f6f 	isb	sy
}
    3e1c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	node->prev = list->tail;
    3e1e:	e9c1 0500 	strd	r0, r5, [r1]
	list->tail->next = node;
    3e22:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    3e24:	6019      	str	r1, [r3, #0]
	list->tail = node;
    3e26:	62d1      	str	r1, [r2, #44]	; 0x2c
}
    3e28:	e7ea      	b.n	3e00 <z_move_thread_to_end_of_prio_q+0x58>
    3e2a:	bf00      	nop
    3e2c:	2000068c 	.word	0x2000068c
    3e30:	20000664 	.word	0x20000664

00003e34 <z_time_slice>:
{
    3e34:	b538      	push	{r3, r4, r5, lr}
	if (pending_current == _current) {
    3e36:	4a15      	ldr	r2, [pc, #84]	; (3e8c <z_time_slice+0x58>)
    3e38:	4b15      	ldr	r3, [pc, #84]	; (3e90 <z_time_slice+0x5c>)
    3e3a:	6814      	ldr	r4, [r2, #0]
{
    3e3c:	4601      	mov	r1, r0
	if (pending_current == _current) {
    3e3e:	6898      	ldr	r0, [r3, #8]
    3e40:	42a0      	cmp	r0, r4
    3e42:	461c      	mov	r4, r3
    3e44:	d103      	bne.n	3e4e <z_time_slice+0x1a>
}
    3e46:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
			z_reset_time_slice();
    3e4a:	f7ff be75 	b.w	3b38 <z_reset_time_slice>
	pending_current = NULL;
    3e4e:	2500      	movs	r5, #0
    3e50:	6015      	str	r5, [r2, #0]
	if (slice_time && sliceable(_current)) {
    3e52:	4a10      	ldr	r2, [pc, #64]	; (3e94 <z_time_slice+0x60>)
    3e54:	6812      	ldr	r2, [r2, #0]
    3e56:	b1b2      	cbz	r2, 3e86 <z_time_slice+0x52>
		&& !z_is_thread_timeout_active(thread);
    3e58:	89c2      	ldrh	r2, [r0, #14]
    3e5a:	2a7f      	cmp	r2, #127	; 0x7f
    3e5c:	d813      	bhi.n	3e86 <z_time_slice+0x52>
		&& !z_is_prio_higher(thread->base.prio, slice_max_prio)
    3e5e:	4a0e      	ldr	r2, [pc, #56]	; (3e98 <z_time_slice+0x64>)
    3e60:	f990 500e 	ldrsb.w	r5, [r0, #14]
    3e64:	6812      	ldr	r2, [r2, #0]
    3e66:	4295      	cmp	r5, r2
    3e68:	db0d      	blt.n	3e86 <z_time_slice+0x52>
		&& !z_is_idle_thread_object(thread)
    3e6a:	4a0c      	ldr	r2, [pc, #48]	; (3e9c <z_time_slice+0x68>)
    3e6c:	4290      	cmp	r0, r2
    3e6e:	d00a      	beq.n	3e86 <z_time_slice+0x52>
		&& !z_is_thread_timeout_active(thread);
    3e70:	6982      	ldr	r2, [r0, #24]
    3e72:	b942      	cbnz	r2, 3e86 <z_time_slice+0x52>
		if (ticks >= _current_cpu->slice_ticks) {
    3e74:	691a      	ldr	r2, [r3, #16]
    3e76:	428a      	cmp	r2, r1
    3e78:	dc02      	bgt.n	3e80 <z_time_slice+0x4c>
			z_move_thread_to_end_of_prio_q(_current);
    3e7a:	f7ff ff95 	bl	3da8 <z_move_thread_to_end_of_prio_q>
    3e7e:	e7e2      	b.n	3e46 <z_time_slice+0x12>
			_current_cpu->slice_ticks -= ticks;
    3e80:	1a52      	subs	r2, r2, r1
    3e82:	611a      	str	r2, [r3, #16]
}
    3e84:	bd38      	pop	{r3, r4, r5, pc}
		_current_cpu->slice_ticks = 0;
    3e86:	2300      	movs	r3, #0
    3e88:	6123      	str	r3, [r4, #16]
    3e8a:	e7fb      	b.n	3e84 <z_time_slice+0x50>
    3e8c:	20000694 	.word	0x20000694
    3e90:	20000664 	.word	0x20000664
    3e94:	2000069c 	.word	0x2000069c
    3e98:	20000698 	.word	0x20000698
    3e9c:	20000368 	.word	0x20000368

00003ea0 <z_impl_k_thread_suspend>:
{
    3ea0:	b570      	push	{r4, r5, r6, lr}
    3ea2:	4604      	mov	r4, r0
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
    3ea4:	3018      	adds	r0, #24
    3ea6:	f002 fe02 	bl	6aae <z_abort_timeout>
	__asm__ volatile(
    3eaa:	f04f 0320 	mov.w	r3, #32
    3eae:	f3ef 8611 	mrs	r6, BASEPRI
    3eb2:	f383 8811 	msr	BASEPRI, r3
    3eb6:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    3eba:	f994 300d 	ldrsb.w	r3, [r4, #13]
    3ebe:	2b00      	cmp	r3, #0
    3ec0:	da07      	bge.n	3ed2 <z_impl_k_thread_suspend+0x32>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    3ec2:	480f      	ldr	r0, [pc, #60]	; (3f00 <z_impl_k_thread_suspend+0x60>)
    3ec4:	4621      	mov	r1, r4
    3ec6:	f7ff fe8d 	bl	3be4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    3eca:	7b63      	ldrb	r3, [r4, #13]
    3ecc:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    3ed0:	7363      	strb	r3, [r4, #13]
		update_cache(thread == _current);
    3ed2:	4d0c      	ldr	r5, [pc, #48]	; (3f04 <z_impl_k_thread_suspend+0x64>)
	thread->base.thread_state |= _THREAD_SUSPENDED;
    3ed4:	7b63      	ldrb	r3, [r4, #13]
    3ed6:	68a8      	ldr	r0, [r5, #8]
    3ed8:	f043 0310 	orr.w	r3, r3, #16
    3edc:	7363      	strb	r3, [r4, #13]
    3ede:	1b03      	subs	r3, r0, r4
    3ee0:	4258      	negs	r0, r3
    3ee2:	4158      	adcs	r0, r3
    3ee4:	f7ff fe94 	bl	3c10 <update_cache>
	__asm__ volatile(
    3ee8:	f386 8811 	msr	BASEPRI, r6
    3eec:	f3bf 8f6f 	isb	sy
	if (thread == _current) {
    3ef0:	68ab      	ldr	r3, [r5, #8]
    3ef2:	42a3      	cmp	r3, r4
    3ef4:	d103      	bne.n	3efe <z_impl_k_thread_suspend+0x5e>
}
    3ef6:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule_unlocked();
    3efa:	f002 bc2e 	b.w	675a <z_reschedule_unlocked>
}
    3efe:	bd70      	pop	{r4, r5, r6, pc}
    3f00:	2000068c 	.word	0x2000068c
    3f04:	20000664 	.word	0x20000664

00003f08 <z_mrsh_k_thread_suspend>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_suspend(k_tid_t thread);
uintptr_t z_mrsh_k_thread_suspend(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3f08:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3f0a:	4d0e      	ldr	r5, [pc, #56]	; (3f44 <z_mrsh_k_thread_suspend+0x3c>)
    3f0c:	9a06      	ldr	r2, [sp, #24]
    3f0e:	68ab      	ldr	r3, [r5, #8]
    3f10:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3f14:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    3f16:	f7fc f8e1 	bl	dc <z_object_find>
    3f1a:	2200      	movs	r2, #0
    3f1c:	2109      	movs	r1, #9
    3f1e:	f001 fb0b 	bl	5538 <z_object_validate>
    3f22:	4604      	mov	r4, r0
    3f24:	b130      	cbz	r0, 3f34 <z_mrsh_k_thread_suspend+0x2c>
    3f26:	f002 fbc1 	bl	66ac <arch_is_user_context>
    3f2a:	68ab      	ldr	r3, [r5, #8]
    3f2c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3f30:	f002 f90c 	bl	614c <arch_syscall_oops>
	z_impl_k_thread_suspend(thread);
    3f34:	4630      	mov	r0, r6
    3f36:	f7ff ffb3 	bl	3ea0 <z_impl_k_thread_suspend>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_suspend(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    3f3a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3f3c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3f3e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3f42:	bd70      	pop	{r4, r5, r6, pc}
    3f44:	20000664 	.word	0x20000664

00003f48 <z_thread_single_abort>:
	if (thread->fn_abort != NULL) {
    3f48:	6e03      	ldr	r3, [r0, #96]	; 0x60
{
    3f4a:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    3f4e:	4604      	mov	r4, r0
	if (thread->fn_abort != NULL) {
    3f50:	b103      	cbz	r3, 3f54 <z_thread_single_abort+0xc>
		thread->fn_abort();
    3f52:	4798      	blx	r3
    3f54:	f104 0018 	add.w	r0, r4, #24
    3f58:	f002 fda9 	bl	6aae <z_abort_timeout>
	__asm__ volatile(
    3f5c:	f04f 0320 	mov.w	r3, #32
    3f60:	f3ef 8611 	mrs	r6, BASEPRI
    3f64:	f383 8811 	msr	BASEPRI, r3
    3f68:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    3f6c:	7b63      	ldrb	r3, [r4, #13]
    3f6e:	06d8      	lsls	r0, r3, #27
    3f70:	d12d      	bne.n	3fce <z_thread_single_abort+0x86>
		if (z_is_thread_ready(thread)) {
    3f72:	69a2      	ldr	r2, [r4, #24]
    3f74:	bb5a      	cbnz	r2, 3fce <z_thread_single_abort+0x86>
			if (z_is_thread_queued(thread)) {
    3f76:	0619      	lsls	r1, r3, #24
    3f78:	d507      	bpl.n	3f8a <z_thread_single_abort+0x42>
				_priq_run_remove(&_kernel.ready_q.runq,
    3f7a:	4825      	ldr	r0, [pc, #148]	; (4010 <z_thread_single_abort+0xc8>)
    3f7c:	4621      	mov	r1, r4
    3f7e:	f7ff fe31 	bl	3be4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    3f82:	7b63      	ldrb	r3, [r4, #13]
    3f84:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    3f88:	7363      	strb	r3, [r4, #13]
			update_cache(thread == _current);
    3f8a:	4b22      	ldr	r3, [pc, #136]	; (4014 <z_thread_single_abort+0xcc>)
    3f8c:	6898      	ldr	r0, [r3, #8]
    3f8e:	1b02      	subs	r2, r0, r4
    3f90:	4250      	negs	r0, r2
    3f92:	4150      	adcs	r0, r2
    3f94:	f7ff fe3c 	bl	3c10 <update_cache>
		thread->base.thread_state |= mask;
    3f98:	7b63      	ldrb	r3, [r4, #13]
		z_object_uninit(thread->stack_obj);
    3f9a:	f8d4 0080 	ldr.w	r0, [r4, #128]	; 0x80
		thread->base.thread_state |= mask;
    3f9e:	f043 0308 	orr.w	r3, r3, #8
    3fa2:	7363      	strb	r3, [r4, #13]
		z_object_uninit(thread->stack_obj);
    3fa4:	f002 ff74 	bl	6e90 <z_object_uninit>
		z_object_uninit(thread);
    3fa8:	4620      	mov	r0, r4
    3faa:	f002 ff71 	bl	6e90 <z_object_uninit>
		z_thread_perms_all_clear(thread);
    3fae:	4620      	mov	r0, r4
    3fb0:	f001 fab4 	bl	551c <z_thread_perms_all_clear>
	sys_dlist_init(&w->waitq);
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
    3fb4:	f104 0830 	add.w	r8, r4, #48	; 0x30
			waiter->base.pended_on = NULL;
    3fb8:	2700      	movs	r7, #0
	return list->head == list;
    3fba:	6b25      	ldr	r5, [r4, #48]	; 0x30
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3fbc:	4545      	cmp	r5, r8
    3fbe:	d000      	beq.n	3fc2 <z_thread_single_abort+0x7a>
		while ((waiter = z_waitq_head(&thread->base.join_waiters)) !=
    3fc0:	b995      	cbnz	r5, 3fe8 <z_thread_single_abort+0xa0>
	__asm__ volatile(
    3fc2:	f386 8811 	msr	BASEPRI, r6
    3fc6:	f3bf 8f6f 	isb	sy
}
    3fca:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			if (z_is_thread_pending(thread)) {
    3fce:	079b      	lsls	r3, r3, #30
    3fd0:	d5e2      	bpl.n	3f98 <z_thread_single_abort+0x50>
				_priq_wait_remove(&pended_on(thread)->waitq,
    3fd2:	68a0      	ldr	r0, [r4, #8]
    3fd4:	4621      	mov	r1, r4
    3fd6:	f7ff fe05 	bl	3be4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    3fda:	7b63      	ldrb	r3, [r4, #13]
    3fdc:	f023 0302 	bic.w	r3, r3, #2
    3fe0:	7363      	strb	r3, [r4, #13]
				thread->base.pended_on = NULL;
    3fe2:	2300      	movs	r3, #0
    3fe4:	60a3      	str	r3, [r4, #8]
    3fe6:	e7d7      	b.n	3f98 <z_thread_single_abort+0x50>
    3fe8:	f105 0018 	add.w	r0, r5, #24
    3fec:	f002 fd5f 	bl	6aae <z_abort_timeout>
			_priq_wait_remove(&pended_on(waiter)->waitq, waiter);
    3ff0:	68a8      	ldr	r0, [r5, #8]
    3ff2:	4629      	mov	r1, r5
    3ff4:	f7ff fdf6 	bl	3be4 <z_priq_dumb_remove>
    3ff8:	7b6b      	ldrb	r3, [r5, #13]
			waiter->base.pended_on = NULL;
    3ffa:	60af      	str	r7, [r5, #8]
    3ffc:	f023 0302 	bic.w	r3, r3, #2
    4000:	736b      	strb	r3, [r5, #13]
    4002:	f8c5 7090 	str.w	r7, [r5, #144]	; 0x90
			ready_thread(waiter);
    4006:	4628      	mov	r0, r5
    4008:	f7ff fe44 	bl	3c94 <ready_thread>
    400c:	e7d5      	b.n	3fba <z_thread_single_abort+0x72>
    400e:	bf00      	nop
    4010:	2000068c 	.word	0x2000068c
    4014:	20000664 	.word	0x20000664

00004018 <unready_thread>:
{
    4018:	b508      	push	{r3, lr}
	if (z_is_thread_queued(thread)) {
    401a:	f990 300d 	ldrsb.w	r3, [r0, #13]
    401e:	2b00      	cmp	r3, #0
{
    4020:	4601      	mov	r1, r0
	if (z_is_thread_queued(thread)) {
    4022:	da06      	bge.n	4032 <unready_thread+0x1a>
		_priq_run_remove(&_kernel.ready_q.runq, thread);
    4024:	4807      	ldr	r0, [pc, #28]	; (4044 <unready_thread+0x2c>)
    4026:	f7ff fddd 	bl	3be4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    402a:	7b4b      	ldrb	r3, [r1, #13]
    402c:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    4030:	734b      	strb	r3, [r1, #13]
	update_cache(thread == _current);
    4032:	4b05      	ldr	r3, [pc, #20]	; (4048 <unready_thread+0x30>)
    4034:	6898      	ldr	r0, [r3, #8]
    4036:	1a43      	subs	r3, r0, r1
    4038:	4258      	negs	r0, r3
    403a:	4158      	adcs	r0, r3
}
    403c:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	update_cache(thread == _current);
    4040:	f7ff bde6 	b.w	3c10 <update_cache>
    4044:	2000068c 	.word	0x2000068c
    4048:	20000664 	.word	0x20000664

0000404c <z_tick_sleep.part.0>:
	z_impl_k_yield();
}
#include <syscalls/k_yield_mrsh.c>
#endif

static int32_t z_tick_sleep(int32_t ticks)
    404c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    404e:	4605      	mov	r5, r0
#else
	ticks += _TICK_ALIGN;
	timeout = (k_ticks_t) ticks;
#endif

	expected_wakeup_time = ticks + z_tick_get_32();
    4050:	f002 fd7d 	bl	6b4e <z_tick_get_32>
    4054:	182c      	adds	r4, r5, r0
	__asm__ volatile(
    4056:	f04f 0320 	mov.w	r3, #32
    405a:	f3ef 8711 	mrs	r7, BASEPRI
    405e:	f383 8811 	msr	BASEPRI, r3
    4062:	f3bf 8f6f 	isb	sy
	 */
	struct k_spinlock local_lock = {};
	k_spinlock_key_t key = k_spin_lock(&local_lock);

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    4066:	4e0d      	ldr	r6, [pc, #52]	; (409c <z_tick_sleep.part.0+0x50>)
    4068:	4b0d      	ldr	r3, [pc, #52]	; (40a0 <z_tick_sleep.part.0+0x54>)
    406a:	68b0      	ldr	r0, [r6, #8]
    406c:	6018      	str	r0, [r3, #0]
#endif
	z_remove_thread_from_ready_q(_current);
    406e:	f002 fbe0 	bl	6832 <z_remove_thread_from_ready_q>
	z_add_thread_timeout(_current, timeout);
    4072:	68b0      	ldr	r0, [r6, #8]
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    4074:	490b      	ldr	r1, [pc, #44]	; (40a4 <z_tick_sleep.part.0+0x58>)
    4076:	462a      	mov	r2, r5
    4078:	17eb      	asrs	r3, r5, #31
    407a:	3018      	adds	r0, #24
    407c:	f000 fed2 	bl	4e24 <z_add_timeout>
	z_mark_thread_as_suspended(_current);
    4080:	68b2      	ldr	r2, [r6, #8]
	thread->base.thread_state |= _THREAD_SUSPENDED;
    4082:	7b53      	ldrb	r3, [r2, #13]
    4084:	f043 0310 	orr.w	r3, r3, #16
    4088:	7353      	strb	r3, [r2, #13]
	ret = arch_swap(key);
    408a:	4638      	mov	r0, r7
    408c:	f7fd fa84 	bl	1598 <arch_swap>

	(void)z_swap(&local_lock, key);

	__ASSERT(!z_is_thread_state_set(_current, _THREAD_SUSPENDED), "");

	ticks = expected_wakeup_time - z_tick_get_32();
    4090:	f002 fd5d 	bl	6b4e <z_tick_get_32>
    4094:	1a20      	subs	r0, r4, r0
		return ticks;
	}
#endif

	return 0;
}
    4096:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    409a:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    409c:	20000664 	.word	0x20000664
    40a0:	20000694 	.word	0x20000694
    40a4:	000067dd 	.word	0x000067dd

000040a8 <pend>:
{
    40a8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    40ac:	4606      	mov	r6, r0
    40ae:	4614      	mov	r4, r2
    40b0:	461d      	mov	r5, r3
    40b2:	f04f 0320 	mov.w	r3, #32
    40b6:	f3ef 8711 	mrs	r7, BASEPRI
    40ba:	f383 8811 	msr	BASEPRI, r3
    40be:	f3bf 8f6f 	isb	sy
		add_to_waitq_locked(thread, wait_q);
    40c2:	f002 fbc6 	bl	6852 <add_to_waitq_locked>
	__asm__ volatile(
    40c6:	f387 8811 	msr	BASEPRI, r7
    40ca:	f3bf 8f6f 	isb	sy
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    40ce:	1c6b      	adds	r3, r5, #1
    40d0:	bf08      	it	eq
    40d2:	f1b4 3fff 	cmpeq.w	r4, #4294967295	; 0xffffffff
    40d6:	d008      	beq.n	40ea <pend+0x42>
    40d8:	4622      	mov	r2, r4
    40da:	462b      	mov	r3, r5
    40dc:	f106 0018 	add.w	r0, r6, #24
    40e0:	4903      	ldr	r1, [pc, #12]	; (40f0 <pend+0x48>)
}
    40e2:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    40e6:	f000 be9d 	b.w	4e24 <z_add_timeout>
    40ea:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    40ee:	bf00      	nop
    40f0:	000067dd 	.word	0x000067dd

000040f4 <z_pend_curr>:
{
    40f4:	b510      	push	{r4, lr}
	pending_current = _current;
    40f6:	4b07      	ldr	r3, [pc, #28]	; (4114 <z_pend_curr+0x20>)
    40f8:	6898      	ldr	r0, [r3, #8]
    40fa:	4b07      	ldr	r3, [pc, #28]	; (4118 <z_pend_curr+0x24>)
{
    40fc:	460c      	mov	r4, r1
	pending_current = _current;
    40fe:	6018      	str	r0, [r3, #0]
{
    4100:	4611      	mov	r1, r2
	pend(_current, wait_q, timeout);
    4102:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    4106:	f7ff ffcf 	bl	40a8 <pend>
    410a:	4620      	mov	r0, r4
}
    410c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    4110:	f7fd ba42 	b.w	1598 <arch_swap>
    4114:	20000664 	.word	0x20000664
    4118:	20000694 	.word	0x20000694

0000411c <z_set_prio>:
{
    411c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    4120:	4604      	mov	r4, r0
	__asm__ volatile(
    4122:	f04f 0320 	mov.w	r3, #32
    4126:	f3ef 8811 	mrs	r8, BASEPRI
    412a:	f383 8811 	msr	BASEPRI, r3
    412e:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    4132:	7b43      	ldrb	r3, [r0, #13]
    4134:	06db      	lsls	r3, r3, #27
    4136:	b24e      	sxtb	r6, r1
    4138:	d12e      	bne.n	4198 <z_set_prio+0x7c>
	return !sys_dnode_is_linked(&t->node);
    413a:	6985      	ldr	r5, [r0, #24]
		if (need_sched) {
    413c:	bb65      	cbnz	r5, 4198 <z_set_prio+0x7c>
				_priq_run_remove(&_kernel.ready_q.runq, thread);
    413e:	4f18      	ldr	r7, [pc, #96]	; (41a0 <z_set_prio+0x84>)
    4140:	4621      	mov	r1, r4
    4142:	f107 0028 	add.w	r0, r7, #40	; 0x28
    4146:	f7ff fd4d 	bl	3be4 <z_priq_dumb_remove>
	return list->head == list;
    414a:	6abb      	ldr	r3, [r7, #40]	; 0x28
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    414c:	6afa      	ldr	r2, [r7, #44]	; 0x2c
				thread->base.prio = prio;
    414e:	73a6      	strb	r6, [r4, #14]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4150:	4283      	cmp	r3, r0
    4152:	bf18      	it	ne
    4154:	461d      	movne	r5, r3
    4156:	2d00      	cmp	r5, #0
    4158:	bf38      	it	cc
    415a:	2500      	movcc	r5, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    415c:	b1b5      	cbz	r5, 418c <z_set_prio+0x70>
	if (thread_1->base.prio < thread_2->base.prio) {
    415e:	f995 100e 	ldrsb.w	r1, [r5, #14]
    4162:	42b1      	cmp	r1, r6
    4164:	dc03      	bgt.n	416e <z_set_prio+0x52>
	return (node == list->tail) ? NULL : node->next;
    4166:	42aa      	cmp	r2, r5
    4168:	d010      	beq.n	418c <z_set_prio+0x70>
    416a:	682d      	ldr	r5, [r5, #0]
    416c:	e7f6      	b.n	415c <z_set_prio+0x40>
	node->prev = successor->prev;
    416e:	686a      	ldr	r2, [r5, #4]
	node->next = successor;
    4170:	e9c4 5200 	strd	r5, r2, [r4]
	successor->prev->next = node;
    4174:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    4176:	606c      	str	r4, [r5, #4]
			update_cache(1);
    4178:	2001      	movs	r0, #1
    417a:	f7ff fd49 	bl	3c10 <update_cache>
    417e:	2001      	movs	r0, #1
	__asm__ volatile(
    4180:	f388 8811 	msr	BASEPRI, r8
    4184:	f3bf 8f6f 	isb	sy
}
    4188:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	node->prev = list->tail;
    418c:	e9c4 0200 	strd	r0, r2, [r4]
	list->tail->next = node;
    4190:	6afb      	ldr	r3, [r7, #44]	; 0x2c
    4192:	601c      	str	r4, [r3, #0]
	list->tail = node;
    4194:	62fc      	str	r4, [r7, #44]	; 0x2c
}
    4196:	e7ef      	b.n	4178 <z_set_prio+0x5c>
			thread->base.prio = prio;
    4198:	73a6      	strb	r6, [r4, #14]
    419a:	2000      	movs	r0, #0
    419c:	e7f0      	b.n	4180 <z_set_prio+0x64>
    419e:	bf00      	nop
    41a0:	20000664 	.word	0x20000664

000041a4 <z_thread_priority_set>:
{
    41a4:	b508      	push	{r3, lr}
	bool need_sched = z_set_prio(thread, prio);
    41a6:	f7ff ffb9 	bl	411c <z_set_prio>
	if (need_sched && _current->base.sched_locked == 0) {
    41aa:	b138      	cbz	r0, 41bc <z_thread_priority_set+0x18>
    41ac:	4b04      	ldr	r3, [pc, #16]	; (41c0 <z_thread_priority_set+0x1c>)
    41ae:	689b      	ldr	r3, [r3, #8]
    41b0:	7bdb      	ldrb	r3, [r3, #15]
    41b2:	b91b      	cbnz	r3, 41bc <z_thread_priority_set+0x18>
}
    41b4:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		z_reschedule_unlocked();
    41b8:	f002 bacf 	b.w	675a <z_reschedule_unlocked>
}
    41bc:	bd08      	pop	{r3, pc}
    41be:	bf00      	nop
    41c0:	20000664 	.word	0x20000664

000041c4 <z_sched_init>:
	list->head = (sys_dnode_t *)list;
    41c4:	4b04      	ldr	r3, [pc, #16]	; (41d8 <z_sched_init+0x14>)
	k_sched_time_slice_set(CONFIG_TIMESLICE_SIZE,
    41c6:	2100      	movs	r1, #0
    41c8:	f103 0228 	add.w	r2, r3, #40	; 0x28
	list->tail = (sys_dnode_t *)list;
    41cc:	e9c3 220a 	strd	r2, r2, [r3, #40]	; 0x28
    41d0:	4608      	mov	r0, r1
    41d2:	f7ff bcc7 	b.w	3b64 <k_sched_time_slice_set>
    41d6:	bf00      	nop
    41d8:	20000664 	.word	0x20000664

000041dc <z_mrsh_k_thread_priority_get>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_thread_priority_get(k_tid_t thread);
uintptr_t z_mrsh_k_thread_priority_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    41dc:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    41de:	4c0d      	ldr	r4, [pc, #52]	; (4214 <z_mrsh_k_thread_priority_get+0x38>)
    41e0:	9a06      	ldr	r2, [sp, #24]
    41e2:	68a3      	ldr	r3, [r4, #8]
    41e4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    41e8:	4605      	mov	r5, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    41ea:	f7fb ff77 	bl	dc <z_object_find>
    41ee:	2200      	movs	r2, #0
    41f0:	2109      	movs	r1, #9
    41f2:	f001 f9a1 	bl	5538 <z_object_validate>
    41f6:	4603      	mov	r3, r0
    41f8:	b130      	cbz	r0, 4208 <z_mrsh_k_thread_priority_get+0x2c>
    41fa:	f002 fa57 	bl	66ac <arch_is_user_context>
    41fe:	68a3      	ldr	r3, [r4, #8]
    4200:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4204:	f001 ffa2 	bl	614c <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_thread_priority_get(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    4208:	68a2      	ldr	r2, [r4, #8]
	return thread->base.prio;
    420a:	f995 000e 	ldrsb.w	r0, [r5, #14]
    420e:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    4212:	bd38      	pop	{r3, r4, r5, pc}
    4214:	20000664 	.word	0x20000664

00004218 <z_mrsh_k_thread_priority_set>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_priority_set(k_tid_t thread, int prio);
uintptr_t z_mrsh_k_thread_priority_set(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4218:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    421a:	4e17      	ldr	r6, [pc, #92]	; (4278 <z_mrsh_k_thread_priority_set+0x60>)
    421c:	9a08      	ldr	r2, [sp, #32]
    421e:	68b3      	ldr	r3, [r6, #8]
    4220:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4224:	460c      	mov	r4, r1
    4226:	4607      	mov	r7, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    4228:	f7fb ff58 	bl	dc <z_object_find>
    422c:	2200      	movs	r2, #0
    422e:	2109      	movs	r1, #9
    4230:	f001 f982 	bl	5538 <z_object_validate>
    4234:	4632      	mov	r2, r6
    4236:	4605      	mov	r5, r0
    4238:	b188      	cbz	r0, 425e <z_mrsh_k_thread_priority_set+0x46>
    423a:	f002 fa37 	bl	66ac <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG((int8_t)prio >= thread->base.prio,
    423e:	68b3      	ldr	r3, [r6, #8]
    4240:	e015      	b.n	426e <z_mrsh_k_thread_priority_set+0x56>
    4242:	f997 200e 	ldrsb.w	r2, [r7, #14]
    4246:	b263      	sxtb	r3, r4
    4248:	429a      	cmp	r2, r3
    424a:	dcf6      	bgt.n	423a <z_mrsh_k_thread_priority_set+0x22>
	z_thread_priority_set(thread, prio);
    424c:	4638      	mov	r0, r7
    424e:	4621      	mov	r1, r4
    4250:	f7ff ffa8 	bl	41a4 <z_thread_priority_set>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_priority_set(*(k_tid_t*)&arg0, *(int*)&arg1)
;
	_current->syscall_frame = NULL;
    4254:	68b3      	ldr	r3, [r6, #8]
	return 0;
}
    4256:	4628      	mov	r0, r5
	_current->syscall_frame = NULL;
    4258:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
}
    425c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (!z_is_prio_higher_or_equal(prio,
    425e:	2c0e      	cmp	r4, #14
    4260:	dc02      	bgt.n	4268 <z_mrsh_k_thread_priority_set+0x50>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(_is_valid_prio(prio, NULL),
    4262:	f114 0f10 	cmn.w	r4, #16
    4266:	daec      	bge.n	4242 <z_mrsh_k_thread_priority_set+0x2a>
    4268:	f002 fa20 	bl	66ac <arch_is_user_context>
    426c:	6893      	ldr	r3, [r2, #8]
    426e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4272:	f001 ff6b 	bl	614c <arch_syscall_oops>
    4276:	bf00      	nop
    4278:	20000664 	.word	0x20000664

0000427c <z_impl_k_yield>:
{
    427c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (!z_is_idle_thread_object(_current)) {
    427e:	4c24      	ldr	r4, [pc, #144]	; (4310 <z_impl_k_yield+0x94>)
    4280:	4b24      	ldr	r3, [pc, #144]	; (4314 <z_impl_k_yield+0x98>)
    4282:	68a2      	ldr	r2, [r4, #8]
    4284:	429a      	cmp	r2, r3
    4286:	d030      	beq.n	42ea <z_impl_k_yield+0x6e>
	__asm__ volatile(
    4288:	f04f 0320 	mov.w	r3, #32
    428c:	f3ef 8511 	mrs	r5, BASEPRI
    4290:	f383 8811 	msr	BASEPRI, r3
    4294:	f3bf 8f6f 	isb	sy
				_priq_run_remove(&_kernel.ready_q.runq,
    4298:	68a1      	ldr	r1, [r4, #8]
    429a:	f104 0028 	add.w	r0, r4, #40	; 0x28
    429e:	f7ff fca1 	bl	3be4 <z_priq_dumb_remove>
	return list->head == list;
    42a2:	6aa3      	ldr	r3, [r4, #40]	; 0x28
			_priq_run_add(&_kernel.ready_q.runq, _current);
    42a4:	68a2      	ldr	r2, [r4, #8]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    42a6:	6ae1      	ldr	r1, [r4, #44]	; 0x2c
	return sys_dlist_is_empty(list) ? NULL : list->head;
    42a8:	4283      	cmp	r3, r0
    42aa:	bf08      	it	eq
    42ac:	2300      	moveq	r3, #0
    42ae:	2b00      	cmp	r3, #0
    42b0:	bf38      	it	cc
    42b2:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    42b4:	b32b      	cbz	r3, 4302 <z_impl_k_yield+0x86>
	if (thread_1->base.prio < thread_2->base.prio) {
    42b6:	f992 700e 	ldrsb.w	r7, [r2, #14]
    42ba:	f993 600e 	ldrsb.w	r6, [r3, #14]
    42be:	42b7      	cmp	r7, r6
    42c0:	db03      	blt.n	42ca <z_impl_k_yield+0x4e>
	return (node == list->tail) ? NULL : node->next;
    42c2:	428b      	cmp	r3, r1
    42c4:	d01d      	beq.n	4302 <z_impl_k_yield+0x86>
    42c6:	681b      	ldr	r3, [r3, #0]
    42c8:	e7f4      	b.n	42b4 <z_impl_k_yield+0x38>
	node->prev = successor->prev;
    42ca:	6859      	ldr	r1, [r3, #4]
	node->next = successor;
    42cc:	e9c2 3100 	strd	r3, r1, [r2]
	successor->prev->next = node;
    42d0:	600a      	str	r2, [r1, #0]
	successor->prev = node;
    42d2:	605a      	str	r2, [r3, #4]
	thread->base.thread_state |= states;
    42d4:	7b53      	ldrb	r3, [r2, #13]
    42d6:	f063 037f 	orn	r3, r3, #127	; 0x7f
    42da:	7353      	strb	r3, [r2, #13]
			update_cache(1);
    42dc:	2001      	movs	r0, #1
    42de:	f7ff fc97 	bl	3c10 <update_cache>
	__asm__ volatile(
    42e2:	f385 8811 	msr	BASEPRI, r5
    42e6:	f3bf 8f6f 	isb	sy
	__asm__ volatile(
    42ea:	f04f 0320 	mov.w	r3, #32
    42ee:	f3ef 8011 	mrs	r0, BASEPRI
    42f2:	f383 8811 	msr	BASEPRI, r3
    42f6:	f3bf 8f6f 	isb	sy
}
    42fa:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    42fe:	f7fd b94b 	b.w	1598 <arch_swap>
	node->prev = list->tail;
    4302:	e9c2 0100 	strd	r0, r1, [r2]
	list->tail->next = node;
    4306:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
    4308:	601a      	str	r2, [r3, #0]
	list->tail = node;
    430a:	62e2      	str	r2, [r4, #44]	; 0x2c
}
    430c:	e7e2      	b.n	42d4 <z_impl_k_yield+0x58>
    430e:	bf00      	nop
    4310:	20000664 	.word	0x20000664
    4314:	20000368 	.word	0x20000368

00004318 <z_mrsh_k_yield>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_yield();
uintptr_t z_mrsh_k_yield(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4318:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    431a:	4c06      	ldr	r4, [pc, #24]	; (4334 <z_mrsh_k_yield+0x1c>)
    431c:	9a04      	ldr	r2, [sp, #16]
    431e:	68a3      	ldr	r3, [r4, #8]
    4320:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	z_impl_k_yield();
    4324:	f7ff ffaa 	bl	427c <z_impl_k_yield>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_yield()
;
	_current->syscall_frame = NULL;
    4328:	68a3      	ldr	r3, [r4, #8]
    432a:	2000      	movs	r0, #0
    432c:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4330:	bd10      	pop	{r4, pc}
    4332:	bf00      	nop
    4334:	20000664 	.word	0x20000664

00004338 <z_impl_k_sleep>:

int32_t z_impl_k_sleep(k_timeout_t timeout)
{
    4338:	b5d0      	push	{r4, r6, r7, lr}
    433a:	460f      	mov	r7, r1
	k_ticks_t ticks;

	__ASSERT(!arch_is_in_isr(), "");

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    433c:	3701      	adds	r7, #1
    433e:	bf08      	it	eq
    4340:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    4344:	4606      	mov	r6, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    4346:	d106      	bne.n	4356 <z_impl_k_sleep+0x1e>
		k_thread_suspend(_current);
    4348:	4b0c      	ldr	r3, [pc, #48]	; (437c <z_impl_k_sleep+0x44>)
    434a:	6898      	ldr	r0, [r3, #8]
	z_impl_k_thread_suspend(thread);
    434c:	f7ff fda8 	bl	3ea0 <z_impl_k_thread_suspend>
    4350:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
	ticks = timeout.ticks;
#endif

	ticks = z_tick_sleep(ticks);
	return k_ticks_to_ms_floor64(ticks);
}
    4354:	bdd0      	pop	{r4, r6, r7, pc}
	ticks = z_tick_sleep(ticks);
    4356:	4604      	mov	r4, r0
    4358:	f002 f9a8 	bl	66ac <arch_is_user_context>
	if (ticks == 0) {
    435c:	b94e      	cbnz	r6, 4372 <z_impl_k_sleep+0x3a>
	z_impl_k_yield();
    435e:	f7ff ff8d 	bl	427c <z_impl_k_yield>
			return (t * to_hz + off) / from_hz;
    4362:	f44f 707a 	mov.w	r0, #1000	; 0x3e8
    4366:	fb84 3400 	smull	r3, r4, r4, r0
    436a:	0bd8      	lsrs	r0, r3, #15
    436c:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
	return k_ticks_to_ms_floor64(ticks);
    4370:	e7f0      	b.n	4354 <z_impl_k_sleep+0x1c>
    4372:	4630      	mov	r0, r6
    4374:	f7ff fe6a 	bl	404c <z_tick_sleep.part.0>
    4378:	4604      	mov	r4, r0
    437a:	e7f2      	b.n	4362 <z_impl_k_sleep+0x2a>
    437c:	20000664 	.word	0x20000664

00004380 <z_mrsh_k_sleep>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_sleep(k_timeout_t timeout);
uintptr_t z_mrsh_k_sleep(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4380:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    4382:	4c06      	ldr	r4, [pc, #24]	; (439c <z_mrsh_k_sleep+0x1c>)
    4384:	9a04      	ldr	r2, [sp, #16]
    4386:	68a3      	ldr	r3, [r4, #8]
    4388:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_sleep(k_timeout_t timeout)
{
	return z_impl_k_sleep(timeout);
    438c:	f7ff ffd4 	bl	4338 <z_impl_k_sleep>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg0;
	parm0.split.hi = arg1;
	int32_t ret = z_vrfy_k_sleep(parm0.val)
;
	_current->syscall_frame = NULL;
    4390:	68a3      	ldr	r3, [r4, #8]
    4392:	2200      	movs	r2, #0
    4394:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4398:	bd10      	pop	{r4, pc}
    439a:	bf00      	nop
    439c:	20000664 	.word	0x20000664

000043a0 <z_impl_k_usleep>:
}
#include <syscalls/k_sleep_mrsh.c>
#endif

int32_t z_impl_k_usleep(int us)
{
    43a0:	b538      	push	{r3, r4, r5, lr}
    43a2:	4c0f      	ldr	r4, [pc, #60]	; (43e0 <z_impl_k_usleep+0x40>)
    43a4:	4a0f      	ldr	r2, [pc, #60]	; (43e4 <z_impl_k_usleep+0x44>)
    43a6:	f44f 4100 	mov.w	r1, #32768	; 0x8000
    43aa:	2500      	movs	r5, #0
    43ac:	fbc1 4500 	smlal	r4, r5, r1, r0
    43b0:	4620      	mov	r0, r4
    43b2:	2300      	movs	r3, #0
    43b4:	4629      	mov	r1, r5
    43b6:	f7fb ff11 	bl	1dc <__aeabi_uldivmod>
    43ba:	4604      	mov	r4, r0
    43bc:	f002 f976 	bl	66ac <arch_is_user_context>
	if (ticks == 0) {
    43c0:	b944      	cbnz	r4, 43d4 <z_impl_k_usleep+0x34>
    43c2:	f7ff ff5b 	bl	427c <z_impl_k_yield>
    43c6:	4807      	ldr	r0, [pc, #28]	; (43e4 <z_impl_k_usleep+0x44>)
    43c8:	fb84 3400 	smull	r3, r4, r4, r0
    43cc:	0bd8      	lsrs	r0, r3, #15
	int32_t ticks;

	ticks = k_us_to_ticks_ceil64(us);
	ticks = z_tick_sleep(ticks);
	return k_ticks_to_us_floor64(ticks);
}
    43ce:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
    43d2:	bd38      	pop	{r3, r4, r5, pc}
    43d4:	4620      	mov	r0, r4
    43d6:	f7ff fe39 	bl	404c <z_tick_sleep.part.0>
    43da:	4604      	mov	r4, r0
    43dc:	e7f3      	b.n	43c6 <z_impl_k_usleep+0x26>
    43de:	bf00      	nop
    43e0:	000f423f 	.word	0x000f423f
    43e4:	000f4240 	.word	0x000f4240

000043e8 <z_mrsh_k_usleep>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_usleep(int32_t us);
uintptr_t z_mrsh_k_usleep(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    43e8:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    43ea:	4c06      	ldr	r4, [pc, #24]	; (4404 <z_mrsh_k_usleep+0x1c>)
    43ec:	9a04      	ldr	r2, [sp, #16]
    43ee:	68a3      	ldr	r3, [r4, #8]
    43f0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_usleep(int us)
{
	return z_impl_k_usleep(us);
    43f4:	f7ff ffd4 	bl	43a0 <z_impl_k_usleep>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_usleep(*(int32_t*)&arg0)
;
	_current->syscall_frame = NULL;
    43f8:	68a3      	ldr	r3, [r4, #8]
    43fa:	2200      	movs	r2, #0
    43fc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4400:	bd10      	pop	{r4, pc}
    4402:	bf00      	nop
    4404:	20000664 	.word	0x20000664

00004408 <z_mrsh_k_wakeup>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_wakeup(k_tid_t thread);
uintptr_t z_mrsh_k_wakeup(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4408:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    440a:	4d0e      	ldr	r5, [pc, #56]	; (4444 <z_mrsh_k_wakeup+0x3c>)
    440c:	9a06      	ldr	r2, [sp, #24]
    440e:	68ab      	ldr	r3, [r5, #8]
    4410:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4414:	4606      	mov	r6, r0
#endif

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_wakeup(k_tid_t thread)
{
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    4416:	f7fb fe61 	bl	dc <z_object_find>
    441a:	2200      	movs	r2, #0
    441c:	2109      	movs	r1, #9
    441e:	f001 f88b 	bl	5538 <z_object_validate>
    4422:	4604      	mov	r4, r0
    4424:	b130      	cbz	r0, 4434 <z_mrsh_k_wakeup+0x2c>
    4426:	f002 f941 	bl	66ac <arch_is_user_context>
    442a:	68ab      	ldr	r3, [r5, #8]
    442c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4430:	f001 fe8c 	bl	614c <arch_syscall_oops>
	z_impl_k_wakeup(thread);
    4434:	4630      	mov	r0, r6
    4436:	f002 fa74 	bl	6922 <z_impl_k_wakeup>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_wakeup(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    443a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    443c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    443e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4442:	bd70      	pop	{r4, r5, r6, pc}
    4444:	20000664 	.word	0x20000664

00004448 <z_impl_k_current_get>:

#ifdef CONFIG_SMP
	arch_irq_unlock(k);
#endif
	return ret;
}
    4448:	4b01      	ldr	r3, [pc, #4]	; (4450 <z_impl_k_current_get+0x8>)
    444a:	6898      	ldr	r0, [r3, #8]
    444c:	4770      	bx	lr
    444e:	bf00      	nop
    4450:	20000664 	.word	0x20000664

00004454 <z_mrsh_k_current_get>:

extern k_tid_t z_vrfy_k_current_get();
uintptr_t z_mrsh_k_current_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    4454:	4b02      	ldr	r3, [pc, #8]	; (4460 <z_mrsh_k_current_get+0xc>)
    4456:	6898      	ldr	r0, [r3, #8]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_tid_t ret = z_vrfy_k_current_get()
;
	_current->syscall_frame = NULL;
    4458:	2300      	movs	r3, #0
    445a:	f8c0 3084 	str.w	r3, [r0, #132]	; 0x84
	return (uintptr_t) ret;
}
    445e:	4770      	bx	lr
    4460:	20000664 	.word	0x20000664

00004464 <z_impl_k_is_preempt_thread>:
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    4464:	f3ef 8305 	mrs	r3, IPSR
#include <syscalls/k_current_get_mrsh.c>
#endif

int z_impl_k_is_preempt_thread(void)
{
	return !arch_is_in_isr() && is_preempt(_current);
    4468:	b93b      	cbnz	r3, 447a <z_impl_k_is_preempt_thread+0x16>
    446a:	4b05      	ldr	r3, [pc, #20]	; (4480 <z_impl_k_is_preempt_thread+0x1c>)
    446c:	689b      	ldr	r3, [r3, #8]
    446e:	89d8      	ldrh	r0, [r3, #14]
    4470:	287f      	cmp	r0, #127	; 0x7f
    4472:	bf8c      	ite	hi
    4474:	2000      	movhi	r0, #0
    4476:	2001      	movls	r0, #1
    4478:	4770      	bx	lr
    447a:	2000      	movs	r0, #0
}
    447c:	4770      	bx	lr
    447e:	bf00      	nop
    4480:	20000664 	.word	0x20000664

00004484 <z_mrsh_k_is_preempt_thread>:

extern int z_vrfy_k_is_preempt_thread();
uintptr_t z_mrsh_k_is_preempt_thread(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    4484:	4a06      	ldr	r2, [pc, #24]	; (44a0 <z_mrsh_k_is_preempt_thread+0x1c>)
{
    4486:	b508      	push	{r3, lr}
	_current->syscall_frame = ssf;
    4488:	6893      	ldr	r3, [r2, #8]
    448a:	9904      	ldr	r1, [sp, #16]
    448c:	f8c3 1084 	str.w	r1, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_is_preempt_thread(void)
{
	return z_impl_k_is_preempt_thread();
    4490:	f7ff ffe8 	bl	4464 <z_impl_k_is_preempt_thread>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_is_preempt_thread()
;
	_current->syscall_frame = NULL;
    4494:	6893      	ldr	r3, [r2, #8]
    4496:	2200      	movs	r2, #0
    4498:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    449c:	bd08      	pop	{r3, pc}
    449e:	bf00      	nop
    44a0:	20000664 	.word	0x20000664

000044a4 <z_impl_k_thread_join>:
}

#endif /* CONFIG_SCHED_CPU_MASK */

int z_impl_k_thread_join(struct k_thread *thread, k_timeout_t timeout)
{
    44a4:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    44a6:	4601      	mov	r1, r0
    44a8:	4614      	mov	r4, r2
    44aa:	461d      	mov	r5, r3
    44ac:	f04f 0320 	mov.w	r3, #32
    44b0:	f3ef 8611 	mrs	r6, BASEPRI
    44b4:	f383 8811 	msr	BASEPRI, r3
    44b8:	f3bf 8f6f 	isb	sy
	__ASSERT(((arch_is_in_isr() == false) ||
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	key = k_spin_lock(&sched_spinlock);

	if ((thread->base.pended_on == &_current->base.join_waiters) ||
    44bc:	4f18      	ldr	r7, [pc, #96]	; (4520 <z_impl_k_thread_join+0x7c>)
    44be:	688a      	ldr	r2, [r1, #8]
    44c0:	68b8      	ldr	r0, [r7, #8]
    44c2:	f100 0330 	add.w	r3, r0, #48	; 0x30
    44c6:	429a      	cmp	r2, r3
    44c8:	d01d      	beq.n	4506 <z_impl_k_thread_join+0x62>
    44ca:	4288      	cmp	r0, r1
    44cc:	d01b      	beq.n	4506 <z_impl_k_thread_join+0x62>
	    (thread == _current)) {
		ret = -EDEADLK;
		goto out;
	}

	if ((thread->base.thread_state & _THREAD_DEAD) != 0) {
    44ce:	7b4b      	ldrb	r3, [r1, #13]
    44d0:	071a      	lsls	r2, r3, #28
    44d2:	d41f      	bmi.n	4514 <z_impl_k_thread_join+0x70>
		ret = 0;
		goto out;
	}

	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    44d4:	ea54 0305 	orrs.w	r3, r4, r5
    44d8:	d01e      	beq.n	4518 <z_impl_k_thread_join+0x74>
		ret = -EBUSY;
		goto out;
	}

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    44da:	4b12      	ldr	r3, [pc, #72]	; (4524 <z_impl_k_thread_join+0x80>)
#endif
	add_to_waitq_locked(_current, &thread->base.join_waiters);
    44dc:	3130      	adds	r1, #48	; 0x30
	pending_current = _current;
    44de:	6018      	str	r0, [r3, #0]
	add_to_waitq_locked(_current, &thread->base.join_waiters);
    44e0:	f002 f9b7 	bl	6852 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    44e4:	1c6b      	adds	r3, r5, #1
    44e6:	bf08      	it	eq
    44e8:	f1b4 3fff 	cmpeq.w	r4, #4294967295	; 0xffffffff
    44ec:	d006      	beq.n	44fc <z_impl_k_thread_join+0x58>
	add_thread_timeout(_current, timeout);
    44ee:	68b8      	ldr	r0, [r7, #8]
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    44f0:	490d      	ldr	r1, [pc, #52]	; (4528 <z_impl_k_thread_join+0x84>)
    44f2:	4622      	mov	r2, r4
    44f4:	462b      	mov	r3, r5
    44f6:	3018      	adds	r0, #24
    44f8:	f000 fc94 	bl	4e24 <z_add_timeout>
    44fc:	4630      	mov	r0, r6

	return z_swap(&sched_spinlock, key);
out:
	k_spin_unlock(&sched_spinlock, key);
	return ret;
}
    44fe:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    4502:	f7fd b849 	b.w	1598 <arch_swap>
		ret = -EDEADLK;
    4506:	f06f 0020 	mvn.w	r0, #32
	__asm__ volatile(
    450a:	f386 8811 	msr	BASEPRI, r6
    450e:	f3bf 8f6f 	isb	sy
}
    4512:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		ret = 0;
    4514:	2000      	movs	r0, #0
    4516:	e7f8      	b.n	450a <z_impl_k_thread_join+0x66>
		ret = -EBUSY;
    4518:	f06f 000f 	mvn.w	r0, #15
    451c:	e7f5      	b.n	450a <z_impl_k_thread_join+0x66>
    451e:	bf00      	nop
    4520:	20000664 	.word	0x20000664
    4524:	20000694 	.word	0x20000694
    4528:	000067dd 	.word	0x000067dd

0000452c <z_mrsh_k_thread_join>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_thread_join(struct k_thread * thread, k_timeout_t timeout);
uintptr_t z_mrsh_k_thread_join(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    452c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    452e:	4c0b      	ldr	r4, [pc, #44]	; (455c <z_mrsh_k_thread_join+0x30>)
    4530:	68a3      	ldr	r3, [r4, #8]
{
    4532:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
    4534:	9a08      	ldr	r2, [sp, #32]
    4536:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    453a:	4605      	mov	r5, r0
    453c:	460f      	mov	r7, r1
}

static inline int z_vrfy_k_thread_join(struct k_thread *thread,
				       k_timeout_t timeout)
{
	if (thread_obj_validate(thread)) {
    453e:	f002 f8bf 	bl	66c0 <thread_obj_validate>
    4542:	b948      	cbnz	r0, 4558 <z_mrsh_k_thread_join+0x2c>
		return 0;
	}

	return z_impl_k_thread_join(thread, timeout);
    4544:	463a      	mov	r2, r7
    4546:	4633      	mov	r3, r6
    4548:	4628      	mov	r0, r5
    454a:	f7ff ffab 	bl	44a4 <z_impl_k_thread_join>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_thread_join(*(struct k_thread **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    454e:	68a3      	ldr	r3, [r4, #8]
    4550:	2200      	movs	r2, #0
    4552:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4556:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		return 0;
    4558:	2000      	movs	r0, #0
    455a:	e7f8      	b.n	454e <z_mrsh_k_thread_join+0x22>
    455c:	20000664 	.word	0x20000664

00004560 <z_mrsh_k_thread_abort>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_abort(k_tid_t thread);
uintptr_t z_mrsh_k_thread_abort(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4560:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4562:	4d0e      	ldr	r5, [pc, #56]	; (459c <z_mrsh_k_thread_abort+0x3c>)
    4564:	9a06      	ldr	r2, [sp, #24]
    4566:	68ab      	ldr	r3, [r5, #8]
    4568:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    456c:	4604      	mov	r4, r0
}
#include <syscalls/k_thread_join_mrsh.c>

static inline void z_vrfy_k_thread_abort(k_tid_t thread)
{
	if (thread_obj_validate(thread)) {
    456e:	f002 f8a7 	bl	66c0 <thread_obj_validate>
    4572:	462e      	mov	r6, r5
    4574:	b960      	cbnz	r0, 4590 <z_mrsh_k_thread_abort+0x30>
		return;
	}

	Z_OOPS(Z_SYSCALL_VERIFY_MSG(!(thread->base.user_options & K_ESSENTIAL),
    4576:	7b23      	ldrb	r3, [r4, #12]
    4578:	07db      	lsls	r3, r3, #31
    457a:	d506      	bpl.n	458a <z_mrsh_k_thread_abort+0x2a>
    457c:	f002 f896 	bl	66ac <arch_is_user_context>
    4580:	68ab      	ldr	r3, [r5, #8]
    4582:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4586:	f001 fde1 	bl	614c <arch_syscall_oops>
				    "aborting essential thread %p", thread));

	z_impl_k_thread_abort((struct k_thread *)thread);
    458a:	4620      	mov	r0, r4
    458c:	f7fd fbd2 	bl	1d34 <z_impl_k_thread_abort>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_abort(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    4590:	68b3      	ldr	r3, [r6, #8]
    4592:	2000      	movs	r0, #0
    4594:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4598:	bd70      	pop	{r4, r5, r6, pc}
    459a:	bf00      	nop
    459c:	20000664 	.word	0x20000664

000045a0 <z_vrfy_k_sem_init>:
}

#ifdef CONFIG_USERSPACE
int z_vrfy_k_sem_init(struct k_sem *sem, unsigned int initial_count,
		      unsigned int limit)
{
    45a0:	b570      	push	{r4, r5, r6, lr}
    45a2:	460d      	mov	r5, r1
    45a4:	4616      	mov	r6, r2
    45a6:	4604      	mov	r4, r0
	Z_OOPS(Z_SYSCALL_OBJ_INIT(sem, K_OBJ_SEM));
    45a8:	f7fb fd98 	bl	dc <z_object_find>
    45ac:	2201      	movs	r2, #1
    45ae:	2107      	movs	r1, #7
    45b0:	f000 ffc2 	bl	5538 <z_object_validate>
    45b4:	b138      	cbz	r0, 45c6 <z_vrfy_k_sem_init+0x26>
    45b6:	f002 f9d0 	bl	695a <arch_is_user_context>
    45ba:	4b06      	ldr	r3, [pc, #24]	; (45d4 <z_vrfy_k_sem_init+0x34>)
    45bc:	689b      	ldr	r3, [r3, #8]
    45be:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    45c2:	f001 fdc3 	bl	614c <arch_syscall_oops>
	return z_impl_k_sem_init(sem, initial_count, limit);
    45c6:	4632      	mov	r2, r6
    45c8:	4629      	mov	r1, r5
    45ca:	4620      	mov	r0, r4
}
    45cc:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	return z_impl_k_sem_init(sem, initial_count, limit);
    45d0:	f002 b9cd 	b.w	696e <z_impl_k_sem_init>
    45d4:	20000664 	.word	0x20000664

000045d8 <z_mrsh_k_sem_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_sem_init(struct k_sem * sem, unsigned int initial_count, unsigned int limit);
uintptr_t z_mrsh_k_sem_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    45d8:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    45da:	4c06      	ldr	r4, [pc, #24]	; (45f4 <z_mrsh_k_sem_init+0x1c>)
    45dc:	9d06      	ldr	r5, [sp, #24]
    45de:	68a3      	ldr	r3, [r4, #8]
    45e0:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_sem_init(*(struct k_sem **)&arg0, *(unsigned int*)&arg1, *(unsigned int*)&arg2)
    45e4:	f7ff ffdc 	bl	45a0 <z_vrfy_k_sem_init>
;
	_current->syscall_frame = NULL;
    45e8:	68a3      	ldr	r3, [r4, #8]
    45ea:	2200      	movs	r2, #0
    45ec:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    45f0:	bd38      	pop	{r3, r4, r5, pc}
    45f2:	bf00      	nop
    45f4:	20000664 	.word	0x20000664

000045f8 <z_impl_k_sem_give>:
	ARG_UNUSED(sem);
#endif
}

void z_impl_k_sem_give(struct k_sem *sem)
{
    45f8:	b538      	push	{r3, r4, r5, lr}
    45fa:	4604      	mov	r4, r0
	__asm__ volatile(
    45fc:	f04f 0320 	mov.w	r3, #32
    4600:	f3ef 8511 	mrs	r5, BASEPRI
    4604:	f383 8811 	msr	BASEPRI, r3
    4608:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&lock);
	struct k_thread *thread = z_unpend_first_thread(&sem->wait_q);
    460c:	f002 f94c 	bl	68a8 <z_unpend_first_thread>

	sys_trace_void(SYS_TRACE_ID_SEMA_GIVE);

	if (thread != NULL) {
    4610:	b150      	cbz	r0, 4628 <z_impl_k_sem_give+0x30>
    4612:	2200      	movs	r2, #0
    4614:	f8c0 2090 	str.w	r2, [r0, #144]	; 0x90
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
    4618:	f002 f8d0 	bl	67bc <z_ready_thread>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
		handle_poll_events(sem);
	}

	sys_trace_end_call(SYS_TRACE_ID_SEMA_GIVE);
	z_reschedule(&lock, key);
    461c:	4629      	mov	r1, r5
    461e:	4806      	ldr	r0, [pc, #24]	; (4638 <z_impl_k_sem_give+0x40>)
}
    4620:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&lock, key);
    4624:	f002 b882 	b.w	672c <z_reschedule>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
    4628:	e9d4 3202 	ldrd	r3, r2, [r4, #8]
    462c:	429a      	cmp	r2, r3
    462e:	bf18      	it	ne
    4630:	3301      	addne	r3, #1
    4632:	60a3      	str	r3, [r4, #8]
		handle_poll_events(sem);
    4634:	e7f2      	b.n	461c <z_impl_k_sem_give+0x24>
    4636:	bf00      	nop
    4638:	200013f4 	.word	0x200013f4

0000463c <z_mrsh_k_sem_give>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_sem_give(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_give(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    463c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    463e:	4d0e      	ldr	r5, [pc, #56]	; (4678 <z_mrsh_k_sem_give+0x3c>)
    4640:	9a06      	ldr	r2, [sp, #24]
    4642:	68ab      	ldr	r3, [r5, #8]
    4644:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4648:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_sem_give(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    464a:	f7fb fd47 	bl	dc <z_object_find>
    464e:	2200      	movs	r2, #0
    4650:	2107      	movs	r1, #7
    4652:	f000 ff71 	bl	5538 <z_object_validate>
    4656:	4604      	mov	r4, r0
    4658:	b130      	cbz	r0, 4668 <z_mrsh_k_sem_give+0x2c>
    465a:	f002 f97e 	bl	695a <arch_is_user_context>
    465e:	68ab      	ldr	r3, [r5, #8]
    4660:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4664:	f001 fd72 	bl	614c <arch_syscall_oops>
	z_impl_k_sem_give(sem);
    4668:	4630      	mov	r0, r6
    466a:	f7ff ffc5 	bl	45f8 <z_impl_k_sem_give>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_sem_give(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    466e:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    4670:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    4672:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4676:	bd70      	pop	{r4, r5, r6, pc}
    4678:	20000664 	.word	0x20000664

0000467c <z_impl_k_sem_take>:
}
#include <syscalls/k_sem_give_mrsh.c>
#endif

int z_impl_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
    467c:	b537      	push	{r0, r1, r2, r4, r5, lr}
    467e:	4614      	mov	r4, r2
    4680:	461d      	mov	r5, r3
    4682:	f04f 0320 	mov.w	r3, #32
    4686:	f3ef 8111 	mrs	r1, BASEPRI
    468a:	f383 8811 	msr	BASEPRI, r3
    468e:	f3bf 8f6f 	isb	sy
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	sys_trace_void(SYS_TRACE_ID_SEMA_TAKE);
	k_spinlock_key_t key = k_spin_lock(&lock);

	if (likely(sem->count > 0U)) {
    4692:	6883      	ldr	r3, [r0, #8]
    4694:	b143      	cbz	r3, 46a8 <z_impl_k_sem_take+0x2c>
		sem->count--;
    4696:	3b01      	subs	r3, #1
    4698:	6083      	str	r3, [r0, #8]
	__asm__ volatile(
    469a:	f381 8811 	msr	BASEPRI, r1
    469e:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		ret = 0;
    46a2:	2000      	movs	r0, #0
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);

out:
	sys_trace_end_call(SYS_TRACE_ID_SEMA_TAKE);
	return ret;
}
    46a4:	b003      	add	sp, #12
    46a6:	bd30      	pop	{r4, r5, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    46a8:	ea54 0305 	orrs.w	r3, r4, r5
    46ac:	d106      	bne.n	46bc <z_impl_k_sem_take+0x40>
    46ae:	f381 8811 	msr	BASEPRI, r1
    46b2:	f3bf 8f6f 	isb	sy
		ret = -EBUSY;
    46b6:	f06f 000f 	mvn.w	r0, #15
    46ba:	e7f3      	b.n	46a4 <z_impl_k_sem_take+0x28>
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);
    46bc:	4602      	mov	r2, r0
    46be:	e9cd 4500 	strd	r4, r5, [sp]
    46c2:	4802      	ldr	r0, [pc, #8]	; (46cc <z_impl_k_sem_take+0x50>)
    46c4:	f7ff fd16 	bl	40f4 <z_pend_curr>
	return ret;
    46c8:	e7ec      	b.n	46a4 <z_impl_k_sem_take+0x28>
    46ca:	bf00      	nop
    46cc:	200013f4 	.word	0x200013f4

000046d0 <z_mrsh_k_sem_take>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_sem_take(struct k_sem * sem, k_timeout_t timeout);
uintptr_t z_mrsh_k_sem_take(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    46d0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    46d4:	4d10      	ldr	r5, [pc, #64]	; (4718 <z_mrsh_k_sem_take+0x48>)
    46d6:	68ab      	ldr	r3, [r5, #8]
{
    46d8:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    46da:	9a08      	ldr	r2, [sp, #32]
    46dc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    46e0:	4688      	mov	r8, r1
    46e2:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    46e4:	f7fb fcfa 	bl	dc <z_object_find>
    46e8:	2200      	movs	r2, #0
    46ea:	2107      	movs	r1, #7
    46ec:	f000 ff24 	bl	5538 <z_object_validate>
    46f0:	4604      	mov	r4, r0
    46f2:	b130      	cbz	r0, 4702 <z_mrsh_k_sem_take+0x32>
    46f4:	f002 f931 	bl	695a <arch_is_user_context>
    46f8:	68ab      	ldr	r3, [r5, #8]
    46fa:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    46fe:	f001 fd25 	bl	614c <arch_syscall_oops>
	return z_impl_k_sem_take((struct k_sem *)sem, timeout);
    4702:	463b      	mov	r3, r7
    4704:	4642      	mov	r2, r8
    4706:	4630      	mov	r0, r6
    4708:	f7ff ffb8 	bl	467c <z_impl_k_sem_take>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_sem_take(*(struct k_sem **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    470c:	68ab      	ldr	r3, [r5, #8]
    470e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4712:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    4716:	bf00      	nop
    4718:	20000664 	.word	0x20000664

0000471c <z_mrsh_k_sem_reset>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_sem_reset(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_reset(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    471c:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    471e:	4c0c      	ldr	r4, [pc, #48]	; (4750 <z_mrsh_k_sem_reset+0x34>)
    4720:	9a06      	ldr	r2, [sp, #24]
    4722:	68a3      	ldr	r3, [r4, #8]
    4724:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4728:	4605      	mov	r5, r0
}
#include <syscalls/k_sem_take_mrsh.c>

static inline void z_vrfy_k_sem_reset(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    472a:	f7fb fcd7 	bl	dc <z_object_find>
    472e:	2200      	movs	r2, #0
    4730:	2107      	movs	r1, #7
    4732:	f000 ff01 	bl	5538 <z_object_validate>
    4736:	b130      	cbz	r0, 4746 <z_mrsh_k_sem_reset+0x2a>
    4738:	f002 f90f 	bl	695a <arch_is_user_context>
    473c:	68a3      	ldr	r3, [r4, #8]
    473e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4742:	f001 fd03 	bl	614c <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_sem_reset(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    4746:	68a2      	ldr	r2, [r4, #8]
	sem->count = 0U;
    4748:	60a8      	str	r0, [r5, #8]
    474a:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    474e:	bd38      	pop	{r3, r4, r5, pc}
    4750:	20000664 	.word	0x20000664

00004754 <z_mrsh_k_sem_count_get>:
#include <syscalls/kernel.h>

extern unsigned int z_vrfy_k_sem_count_get(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_count_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4754:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    4756:	4c0d      	ldr	r4, [pc, #52]	; (478c <z_mrsh_k_sem_count_get+0x38>)
    4758:	9a06      	ldr	r2, [sp, #24]
    475a:	68a3      	ldr	r3, [r4, #8]
    475c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4760:	4605      	mov	r5, r0
}
#include <syscalls/k_sem_reset_mrsh.c>

static inline unsigned int z_vrfy_k_sem_count_get(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    4762:	f7fb fcbb 	bl	dc <z_object_find>
    4766:	2200      	movs	r2, #0
    4768:	2107      	movs	r1, #7
    476a:	f000 fee5 	bl	5538 <z_object_validate>
    476e:	4603      	mov	r3, r0
    4770:	b130      	cbz	r0, 4780 <z_mrsh_k_sem_count_get+0x2c>
    4772:	f002 f8f2 	bl	695a <arch_is_user_context>
    4776:	68a3      	ldr	r3, [r4, #8]
    4778:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    477c:	f001 fce6 	bl	614c <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	unsigned int ret = z_vrfy_k_sem_count_get(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    4780:	68a2      	ldr	r2, [r4, #8]
	return z_impl_k_sem_count_get(sem);
    4782:	68a8      	ldr	r0, [r5, #8]
    4784:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    4788:	bd38      	pop	{r3, r4, r5, pc}
    478a:	bf00      	nop
    478c:	20000664 	.word	0x20000664

00004790 <z_mrsh_k_stack_alloc_init>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_stack_alloc_init(struct k_stack * stack, uint32_t num_entries);
uintptr_t z_mrsh_k_stack_alloc_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4790:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    4792:	4c10      	ldr	r4, [pc, #64]	; (47d4 <z_mrsh_k_stack_alloc_init+0x44>)
    4794:	9a08      	ldr	r2, [sp, #32]
    4796:	68a3      	ldr	r3, [r4, #8]
    4798:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    479c:	460d      	mov	r5, r1
    479e:	4607      	mov	r7, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_stack_alloc_init(struct k_stack *stack,
					      uint32_t num_entries)
{
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(stack, K_OBJ_STACK));
    47a0:	f7fb fc9c 	bl	dc <z_object_find>
    47a4:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    47a8:	2108      	movs	r1, #8
    47aa:	f000 fec5 	bl	5538 <z_object_validate>
    47ae:	4606      	mov	r6, r0
    47b0:	b130      	cbz	r0, 47c0 <z_mrsh_k_stack_alloc_init+0x30>
    47b2:	f002 f8eb 	bl	698c <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY(num_entries > 0));
    47b6:	68a3      	ldr	r3, [r4, #8]
    47b8:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    47bc:	f001 fcc6 	bl	614c <arch_syscall_oops>
    47c0:	2d00      	cmp	r5, #0
    47c2:	d0f6      	beq.n	47b2 <z_mrsh_k_stack_alloc_init+0x22>
	return z_impl_k_stack_alloc_init(stack, num_entries);
    47c4:	4629      	mov	r1, r5
    47c6:	4638      	mov	r0, r7
    47c8:	f002 f8f3 	bl	69b2 <z_impl_k_stack_alloc_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_stack_alloc_init(*(struct k_stack **)&arg0, *(uint32_t*)&arg1)
;
	_current->syscall_frame = NULL;
    47cc:	68a3      	ldr	r3, [r4, #8]
    47ce:	f8c3 6084 	str.w	r6, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    47d2:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    47d4:	20000664 	.word	0x20000664

000047d8 <z_mrsh_k_stack_push>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_stack_push(struct k_stack * stack, stack_data_t data);
uintptr_t z_mrsh_k_stack_push(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    47d8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    47da:	4d0f      	ldr	r5, [pc, #60]	; (4818 <z_mrsh_k_stack_push+0x40>)
    47dc:	9a08      	ldr	r2, [sp, #32]
    47de:	68ab      	ldr	r3, [r5, #8]
    47e0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    47e4:	460f      	mov	r7, r1
    47e6:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_stack_push(struct k_stack *stack, stack_data_t data)
{
	Z_OOPS(Z_SYSCALL_OBJ(stack, K_OBJ_STACK));
    47e8:	f7fb fc78 	bl	dc <z_object_find>
    47ec:	2200      	movs	r2, #0
    47ee:	2108      	movs	r1, #8
    47f0:	f000 fea2 	bl	5538 <z_object_validate>
    47f4:	4604      	mov	r4, r0
    47f6:	b130      	cbz	r0, 4806 <z_mrsh_k_stack_push+0x2e>
    47f8:	f002 f8c8 	bl	698c <arch_is_user_context>
    47fc:	68ab      	ldr	r3, [r5, #8]
    47fe:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4802:	f001 fca3 	bl	614c <arch_syscall_oops>

	return z_impl_k_stack_push(stack, data);
    4806:	4639      	mov	r1, r7
    4808:	4630      	mov	r0, r6
    480a:	f002 f8e5 	bl	69d8 <z_impl_k_stack_push>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_stack_push(*(struct k_stack **)&arg0, *(stack_data_t*)&arg1)
;
	_current->syscall_frame = NULL;
    480e:	68ab      	ldr	r3, [r5, #8]
    4810:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4814:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    4816:	bf00      	nop
    4818:	20000664 	.word	0x20000664

0000481c <z_impl_k_stack_pop>:
#include <syscalls/k_stack_push_mrsh.c>
#endif

int z_impl_k_stack_pop(struct k_stack *stack, stack_data_t *data,
		       k_timeout_t timeout)
{
    481c:	b5d3      	push	{r0, r1, r4, r6, r7, lr}
    481e:	460c      	mov	r4, r1
    4820:	4616      	mov	r6, r2
    4822:	461f      	mov	r7, r3
	__asm__ volatile(
    4824:	f04f 0320 	mov.w	r3, #32
    4828:	f3ef 8111 	mrs	r1, BASEPRI
    482c:	f383 8811 	msr	BASEPRI, r3
    4830:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&stack->lock);

	if (likely(stack->next > stack->base)) {
    4834:	e9d0 2302 	ldrd	r2, r3, [r0, #8]
    4838:	4293      	cmp	r3, r2
    483a:	d90a      	bls.n	4852 <z_impl_k_stack_pop+0x36>
		stack->next--;
    483c:	1f1a      	subs	r2, r3, #4
		*data = *(stack->next);
    483e:	f853 3c04 	ldr.w	r3, [r3, #-4]
		stack->next--;
    4842:	60c2      	str	r2, [r0, #12]
		*data = *(stack->next);
    4844:	6023      	str	r3, [r4, #0]
	__asm__ volatile(
    4846:	f381 8811 	msr	BASEPRI, r1
    484a:	f3bf 8f6f 	isb	sy
	if (result == -EAGAIN) {
		return -EAGAIN;
	}

	*data = (stack_data_t)_current->base.swap_data;
	return 0;
    484e:	2000      	movs	r0, #0
    4850:	e008      	b.n	4864 <z_impl_k_stack_pop+0x48>
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    4852:	ea56 0307 	orrs.w	r3, r6, r7
    4856:	d107      	bne.n	4868 <z_impl_k_stack_pop+0x4c>
    4858:	f381 8811 	msr	BASEPRI, r1
    485c:	f3bf 8f6f 	isb	sy
		return -EBUSY;
    4860:	f06f 000f 	mvn.w	r0, #15
}
    4864:	b002      	add	sp, #8
    4866:	bdd0      	pop	{r4, r6, r7, pc}
	result = z_pend_curr(&stack->lock, key, &stack->wait_q, timeout);
    4868:	4602      	mov	r2, r0
    486a:	e9cd 6700 	strd	r6, r7, [sp]
    486e:	3008      	adds	r0, #8
    4870:	f7ff fc40 	bl	40f4 <z_pend_curr>
	if (result == -EAGAIN) {
    4874:	f110 0f0b 	cmn.w	r0, #11
    4878:	d0f4      	beq.n	4864 <z_impl_k_stack_pop+0x48>
	*data = (stack_data_t)_current->base.swap_data;
    487a:	4b02      	ldr	r3, [pc, #8]	; (4884 <z_impl_k_stack_pop+0x68>)
    487c:	689b      	ldr	r3, [r3, #8]
    487e:	695b      	ldr	r3, [r3, #20]
    4880:	6023      	str	r3, [r4, #0]
    4882:	e7e4      	b.n	484e <z_impl_k_stack_pop+0x32>
    4884:	20000664 	.word	0x20000664

00004888 <z_mrsh_k_stack_pop>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_stack_pop(struct k_stack * stack, stack_data_t * data, k_timeout_t timeout);
uintptr_t z_mrsh_k_stack_pop(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4888:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	_current->syscall_frame = ssf;
    488c:	4c14      	ldr	r4, [pc, #80]	; (48e0 <z_mrsh_k_stack_pop+0x58>)
{
    488e:	4699      	mov	r9, r3
	_current->syscall_frame = ssf;
    4890:	68a3      	ldr	r3, [r4, #8]
{
    4892:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    4894:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    4896:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    489a:	460e      	mov	r6, r1
    489c:	4607      	mov	r7, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_stack_pop(struct k_stack *stack,
				     stack_data_t *data, k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(stack, K_OBJ_STACK));
    489e:	f7fb fc1d 	bl	dc <z_object_find>
    48a2:	2200      	movs	r2, #0
    48a4:	2108      	movs	r1, #8
    48a6:	f000 fe47 	bl	5538 <z_object_validate>
    48aa:	b130      	cbz	r0, 48ba <z_mrsh_k_stack_pop+0x32>
    48ac:	f002 f86e 	bl	698c <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(data, sizeof(stack_data_t)));
    48b0:	68a3      	ldr	r3, [r4, #8]
    48b2:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    48b6:	f001 fc49 	bl	614c <arch_syscall_oops>
    48ba:	2201      	movs	r2, #1
    48bc:	2104      	movs	r1, #4
    48be:	4630      	mov	r0, r6
    48c0:	f001 fc72 	bl	61a8 <arch_buffer_validate>
    48c4:	4605      	mov	r5, r0
    48c6:	2800      	cmp	r0, #0
    48c8:	d1f0      	bne.n	48ac <z_mrsh_k_stack_pop+0x24>
	return z_impl_k_stack_pop(stack, data, timeout);
    48ca:	464b      	mov	r3, r9
    48cc:	4642      	mov	r2, r8
    48ce:	4631      	mov	r1, r6
    48d0:	4638      	mov	r0, r7
    48d2:	f7ff ffa3 	bl	481c <z_impl_k_stack_pop>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_stack_pop(*(struct k_stack **)&arg0, *(stack_data_t **)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    48d6:	68a3      	ldr	r3, [r4, #8]
    48d8:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    48dc:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
    48e0:	20000664 	.word	0x20000664

000048e4 <schedule_new_thread>:
#endif
#endif

#ifdef CONFIG_MULTITHREADING
static void schedule_new_thread(struct k_thread *thread, k_timeout_t delay)
{
    48e4:	b4d0      	push	{r4, r6, r7}
    48e6:	4616      	mov	r6, r2
    48e8:	461f      	mov	r7, r3
#ifdef CONFIG_SYS_CLOCK_EXISTS
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
    48ea:	ea56 0107 	orrs.w	r1, r6, r7
    48ee:	d102      	bne.n	48f6 <schedule_new_thread+0x12>
	}
#else
	ARG_UNUSED(delay);
	k_thread_start(thread);
#endif
}
    48f0:	bcd0      	pop	{r4, r6, r7}
	z_sched_start(thread);
    48f2:	f7ff ba03 	b.w	3cfc <z_sched_start>
}
    48f6:	bcd0      	pop	{r4, r6, r7}
    48f8:	4901      	ldr	r1, [pc, #4]	; (4900 <schedule_new_thread+0x1c>)
    48fa:	3018      	adds	r0, #24
    48fc:	f000 ba92 	b.w	4e24 <z_add_timeout>
    4900:	000067dd 	.word	0x000067dd

00004904 <z_mrsh_k_busy_wait>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_busy_wait(uint32_t usec_to_wait);
uintptr_t z_mrsh_k_busy_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4904:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    4906:	4c06      	ldr	r4, [pc, #24]	; (4920 <z_mrsh_k_busy_wait+0x1c>)
    4908:	9a04      	ldr	r2, [sp, #16]
    490a:	68a3      	ldr	r3, [r4, #8]
    490c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	arch_busy_wait(usec_to_wait);
    4910:	f7fd fc54 	bl	21bc <arch_busy_wait>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_busy_wait(*(uint32_t*)&arg0)
;
	_current->syscall_frame = NULL;
    4914:	68a3      	ldr	r3, [r4, #8]
    4916:	2000      	movs	r0, #0
    4918:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    491c:	bd10      	pop	{r4, pc}
    491e:	bf00      	nop
    4920:	20000664 	.word	0x20000664

00004924 <z_mrsh_k_thread_name_set>:

extern int z_vrfy_k_thread_name_set(k_tid_t thread_id, const char * value);
uintptr_t z_mrsh_k_thread_name_set(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    4924:	4b03      	ldr	r3, [pc, #12]	; (4934 <z_mrsh_k_thread_name_set+0x10>)
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_thread_name_set(*(k_tid_t*)&arg0, *(const char **)&arg1)
;
	_current->syscall_frame = NULL;
    4926:	689b      	ldr	r3, [r3, #8]
    4928:	2200      	movs	r2, #0
    492a:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    492e:	f06f 0046 	mvn.w	r0, #70	; 0x46
    4932:	4770      	bx	lr
    4934:	20000664 	.word	0x20000664

00004938 <z_mrsh_k_thread_name_copy>:
    4938:	4b03      	ldr	r3, [pc, #12]	; (4948 <z_mrsh_k_thread_name_copy+0x10>)
    493a:	689b      	ldr	r3, [r3, #8]
    493c:	2200      	movs	r2, #0
    493e:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
    4942:	f06f 0046 	mvn.w	r0, #70	; 0x46
    4946:	4770      	bx	lr
    4948:	20000664 	.word	0x20000664

0000494c <z_mrsh_k_thread_start>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_start(k_tid_t thread);
uintptr_t z_mrsh_k_thread_start(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    494c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    494e:	4d0e      	ldr	r5, [pc, #56]	; (4988 <z_mrsh_k_thread_start+0x3c>)
    4950:	9a06      	ldr	r2, [sp, #24]
    4952:	68ab      	ldr	r3, [r5, #8]
    4954:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4958:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    495a:	f7fb fbbf 	bl	dc <z_object_find>
    495e:	2200      	movs	r2, #0
    4960:	2109      	movs	r1, #9
    4962:	f000 fde9 	bl	5538 <z_object_validate>
    4966:	4604      	mov	r4, r0
    4968:	b130      	cbz	r0, 4978 <z_mrsh_k_thread_start+0x2c>
    496a:	f002 f864 	bl	6a36 <arch_is_user_context>
    496e:	68ab      	ldr	r3, [r5, #8]
    4970:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4974:	f001 fbea 	bl	614c <arch_syscall_oops>
	z_sched_start(thread);
    4978:	4630      	mov	r0, r6
    497a:	f7ff f9bf 	bl	3cfc <z_sched_start>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_start(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    497e:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    4980:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    4982:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4986:	bd70      	pop	{r4, r5, r6, pc}
    4988:	20000664 	.word	0x20000664

0000498c <z_setup_new_thread>:
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
    498c:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    4990:	b085      	sub	sp, #20
    4992:	4604      	mov	r4, r0
    4994:	460e      	mov	r6, r1
    4996:	4617      	mov	r7, r2
    4998:	4699      	mov	r9, r3
		 "user thread %p with kernel-only stack %p",
		 new_thread, stack);
	z_object_init(new_thread);
	z_object_init(stack);
	new_thread->stack_obj = stack;
	new_thread->mem_domain_info.mem_domain = NULL;
    499a:	2500      	movs	r5, #0
{
    499c:	f8dd 8040 	ldr.w	r8, [sp, #64]	; 0x40
	z_object_init(new_thread);
    49a0:	f002 fa6d 	bl	6e7e <z_object_init>
	z_object_init(stack);
    49a4:	4630      	mov	r0, r6
    49a6:	f002 fa6a 	bl	6e7e <z_object_init>
	new_thread->stack_obj = stack;
    49aa:	f8c4 6080 	str.w	r6, [r4, #128]	; 0x80
	new_thread->mem_domain_info.mem_domain = NULL;
    49ae:	67e5      	str	r5, [r4, #124]	; 0x7c
	new_thread->syscall_frame = NULL;
    49b0:	f8c4 5084 	str.w	r5, [r4, #132]	; 0x84
	z_impl_k_object_access_grant(object, thread);
    49b4:	4620      	mov	r0, r4
    49b6:	4621      	mov	r1, r4
    49b8:	f002 fa56 	bl	6e68 <z_impl_k_object_access_grant>
	sys_dlist_init(&w->waitq);
    49bc:	f104 0330 	add.w	r3, r4, #48	; 0x30
	list->tail = (sys_dnode_t *)list;
    49c0:	e9c4 330c 	strd	r3, r3, [r4, #48]	; 0x30
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */

	thread_base->user_options = (uint8_t)options;
	thread_base->thread_state = (uint8_t)initial_state;
    49c4:	2304      	movs	r3, #4
    49c6:	7363      	strb	r3, [r4, #13]

	thread_base->prio = priority;
    49c8:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
	thread_base->user_options = (uint8_t)options;
    49ca:	f884 800c 	strb.w	r8, [r4, #12]
	node->prev = NULL;
    49ce:	e9c4 5506 	strd	r5, r5, [r4, #24]
	thread_base->prio = priority;
    49d2:	73a3      	strb	r3, [r4, #14]

	thread_base->sched_locked = 0U;
    49d4:	73e5      	strb	r5, [r4, #15]
	if (z_stack_is_user_capable(stack)) {
    49d6:	4630      	mov	r0, r6
    49d8:	f002 f842 	bl	6a60 <z_stack_is_user_capable>
    49dc:	b360      	cbz	r0, 4a38 <z_setup_new_thread+0xac>
		stack_obj_size = Z_THREAD_STACK_SIZE_ADJUST(stack_size);
    49de:	fab7 f387 	clz	r3, r7
    49e2:	f04f 4500 	mov.w	r5, #2147483648	; 0x80000000
    49e6:	40dd      	lsrs	r5, r3
    49e8:	42af      	cmp	r7, r5
    49ea:	d903      	bls.n	49f4 <z_setup_new_thread+0x68>
    49ec:	f1c3 0320 	rsb	r3, r3, #32
    49f0:	2501      	movs	r5, #1
    49f2:	409d      	lsls	r5, r3
	stack_ptr = (char *)stack + stack_obj_size;
    49f4:	1977      	adds	r7, r6, r5
    49f6:	f002 f81e 	bl	6a36 <arch_is_user_context>
		(struct _thread_userspace_local_data *)(stack_ptr - delta);
    49fa:	1f3b      	subs	r3, r7, #4
	new_thread->stack_info.start = (uintptr_t)stack_buf_start;
    49fc:	e9c4 3619 	strd	r3, r6, [r4, #100]	; 0x64
	new_thread->stack_info.delta = delta;
    4a00:	2308      	movs	r3, #8
    4a02:	6723      	str	r3, [r4, #112]	; 0x70
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4a04:	9b0e      	ldr	r3, [sp, #56]	; 0x38
    4a06:	9302      	str	r3, [sp, #8]
    4a08:	9b0d      	ldr	r3, [sp, #52]	; 0x34
    4a0a:	9301      	str	r3, [sp, #4]
	stack_ptr -= delta;
    4a0c:	3f08      	subs	r7, #8
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4a0e:	9b0c      	ldr	r3, [sp, #48]	; 0x30
	new_thread->stack_info.size = stack_buf_size;
    4a10:	66e5      	str	r5, [r4, #108]	; 0x6c
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4a12:	9300      	str	r3, [sp, #0]
	if (!_current) {
    4a14:	4d12      	ldr	r5, [pc, #72]	; (4a60 <z_setup_new_thread+0xd4>)
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4a16:	464b      	mov	r3, r9
    4a18:	463a      	mov	r2, r7
    4a1a:	4631      	mov	r1, r6
    4a1c:	4620      	mov	r0, r4
    4a1e:	f7fc fe8b 	bl	1738 <arch_new_thread>
	new_thread->init_data = NULL;
    4a22:	2300      	movs	r3, #0
	new_thread->fn_abort = NULL;
    4a24:	e9c4 3317 	strd	r3, r3, [r4, #92]	; 0x5c
	if (!_current) {
    4a28:	68ab      	ldr	r3, [r5, #8]
    4a2a:	b94b      	cbnz	r3, 4a40 <z_setup_new_thread+0xb4>
}
    4a2c:	4638      	mov	r0, r7
	new_thread->resource_pool = _current->resource_pool;
    4a2e:	f8c4 3088 	str.w	r3, [r4, #136]	; 0x88
}
    4a32:	b005      	add	sp, #20
    4a34:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
    4a38:	1dfd      	adds	r5, r7, #7
    4a3a:	f025 0507 	bic.w	r5, r5, #7
		stack_buf_size = stack_obj_size - K_KERNEL_STACK_RESERVED;
    4a3e:	e7d9      	b.n	49f4 <z_setup_new_thread+0x68>
	if (_current->mem_domain_info.mem_domain != NULL) {
    4a40:	6fd8      	ldr	r0, [r3, #124]	; 0x7c
    4a42:	b110      	cbz	r0, 4a4a <z_setup_new_thread+0xbe>
		k_mem_domain_add_thread(_current->mem_domain_info.mem_domain,
    4a44:	4621      	mov	r1, r4
    4a46:	f002 f963 	bl	6d10 <k_mem_domain_add_thread>
	if ((options & K_INHERIT_PERMS) != 0U) {
    4a4a:	f018 0f08 	tst.w	r8, #8
    4a4e:	d003      	beq.n	4a58 <z_setup_new_thread+0xcc>
		z_thread_perms_inherit(_current, new_thread);
    4a50:	68a8      	ldr	r0, [r5, #8]
    4a52:	4621      	mov	r1, r4
    4a54:	f000 fd48 	bl	54e8 <z_thread_perms_inherit>
	new_thread->resource_pool = _current->resource_pool;
    4a58:	68ab      	ldr	r3, [r5, #8]
    4a5a:	f8d3 3088 	ldr.w	r3, [r3, #136]	; 0x88
    4a5e:	e7e5      	b.n	4a2c <z_setup_new_thread+0xa0>
    4a60:	20000664 	.word	0x20000664

00004a64 <z_vrfy_k_thread_create>:
{
    4a64:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    4a68:	b087      	sub	sp, #28
    4a6a:	460e      	mov	r6, r1
    4a6c:	4617      	mov	r7, r2
    4a6e:	4699      	mov	r9, r3
    4a70:	e9dd a813 	ldrd	sl, r8, [sp, #76]	; 0x4c
    4a74:	4605      	mov	r5, r0
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(new_thread, K_OBJ_THREAD));
    4a76:	f7fb fb31 	bl	dc <z_object_find>
    4a7a:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    4a7e:	2109      	movs	r1, #9
    4a80:	f000 fd5a 	bl	5538 <z_object_validate>
    4a84:	4c23      	ldr	r4, [pc, #140]	; (4b14 <z_vrfy_k_thread_create+0xb0>)
    4a86:	b130      	cbz	r0, 4a96 <z_vrfy_k_thread_create+0x32>
    4a88:	f001 ffd5 	bl	6a36 <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY(z_is_prio_lower_or_equal(prio,
    4a8c:	68a3      	ldr	r3, [r4, #8]
    4a8e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4a92:	f001 fb5b 	bl	614c <arch_syscall_oops>
	stack_object = z_object_find(stack);
    4a96:	4630      	mov	r0, r6
    4a98:	f7fb fb20 	bl	dc <z_object_find>
    4a9c:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    4aa0:	210b      	movs	r1, #11
    4aa2:	4683      	mov	fp, r0
    4aa4:	f000 fd48 	bl	5538 <z_object_validate>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(z_obj_validation_check(stack_object, stack,
    4aa8:	2800      	cmp	r0, #0
    4aaa:	d1ed      	bne.n	4a88 <z_vrfy_k_thread_create+0x24>
	stack_obj_size = stack_object->data.stack_data->size;
    4aac:	f8db 3008 	ldr.w	r3, [fp, #8]
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(total_size <= stack_obj_size,
    4ab0:	681b      	ldr	r3, [r3, #0]
    4ab2:	42bb      	cmp	r3, r7
    4ab4:	d3e8      	bcc.n	4a88 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(options & K_USER));
    4ab6:	f018 0f04 	tst.w	r8, #4
    4aba:	d0e5      	beq.n	4a88 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(!(options & K_ESSENTIAL)));
    4abc:	f018 0301 	ands.w	r3, r8, #1
    4ac0:	d1e2      	bne.n	4a88 <z_vrfy_k_thread_create+0x24>
	if (!z_is_prio_higher_or_equal(prio,
    4ac2:	f10a 0210 	add.w	r2, sl, #16
    4ac6:	2a1e      	cmp	r2, #30
    4ac8:	d8de      	bhi.n	4a88 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(z_is_prio_lower_or_equal(prio,
    4aca:	68a2      	ldr	r2, [r4, #8]
    4acc:	f992 200e 	ldrsb.w	r2, [r2, #14]
    4ad0:	4592      	cmp	sl, r2
    4ad2:	dbd9      	blt.n	4a88 <z_vrfy_k_thread_create+0x24>
	z_setup_new_thread(new_thread, stack, stack_size,
    4ad4:	e9cd 8304 	strd	r8, r3, [sp, #16]
    4ad8:	9b12      	ldr	r3, [sp, #72]	; 0x48
    4ada:	9302      	str	r3, [sp, #8]
    4adc:	9b11      	ldr	r3, [sp, #68]	; 0x44
    4ade:	9301      	str	r3, [sp, #4]
    4ae0:	9b10      	ldr	r3, [sp, #64]	; 0x40
    4ae2:	9300      	str	r3, [sp, #0]
    4ae4:	f8cd a00c 	str.w	sl, [sp, #12]
    4ae8:	464b      	mov	r3, r9
    4aea:	463a      	mov	r2, r7
    4aec:	4631      	mov	r1, r6
    4aee:	4628      	mov	r0, r5
    4af0:	f7ff ff4c 	bl	498c <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
    4af4:	e9dd 3416 	ldrd	r3, r4, [sp, #88]	; 0x58
    4af8:	3401      	adds	r4, #1
    4afa:	bf08      	it	eq
    4afc:	f1b3 3fff 	cmpeq.w	r3, #4294967295	; 0xffffffff
    4b00:	d004      	beq.n	4b0c <z_vrfy_k_thread_create+0xa8>
		schedule_new_thread(new_thread, delay);
    4b02:	e9dd 2316 	ldrd	r2, r3, [sp, #88]	; 0x58
    4b06:	4628      	mov	r0, r5
    4b08:	f7ff feec 	bl	48e4 <schedule_new_thread>
}
    4b0c:	4628      	mov	r0, r5
    4b0e:	b007      	add	sp, #28
    4b10:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    4b14:	20000664 	.word	0x20000664

00004b18 <z_mrsh_k_thread_create>:
#include <syscalls/kernel.h>

extern k_tid_t z_vrfy_k_thread_create(struct k_thread * new_thread, k_thread_stack_t * stack, size_t stack_size, k_thread_entry_t entry, void * p1, void * p2, void * p3, int prio, uint32_t options, k_timeout_t delay);
uintptr_t z_mrsh_k_thread_create(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, void *more, void *ssf)
{
    4b18:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    4b1c:	4e19      	ldr	r6, [pc, #100]	; (4b84 <z_mrsh_k_thread_create+0x6c>)
{
    4b1e:	b088      	sub	sp, #32
    4b20:	469a      	mov	sl, r3
    4b22:	9c11      	ldr	r4, [sp, #68]	; 0x44
	_current->syscall_frame = ssf;
    4b24:	68b3      	ldr	r3, [r6, #8]
{
    4b26:	4691      	mov	r9, r2
	_current->syscall_frame = ssf;
    4b28:	9a12      	ldr	r2, [sp, #72]	; 0x48
    4b2a:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4b2e:	4607      	mov	r7, r0
    4b30:	4688      	mov	r8, r1
	Z_OOPS(Z_SYSCALL_MEMORY_READ(more, 5 * sizeof(uintptr_t)));
    4b32:	2200      	movs	r2, #0
    4b34:	2114      	movs	r1, #20
    4b36:	4620      	mov	r0, r4
    4b38:	f001 fb36 	bl	61a8 <arch_buffer_validate>
    4b3c:	4605      	mov	r5, r0
    4b3e:	b130      	cbz	r0, 4b4e <z_mrsh_k_thread_create+0x36>
    4b40:	f001 ff79 	bl	6a36 <arch_is_user_context>
    4b44:	68b3      	ldr	r3, [r6, #8]
    4b46:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4b4a:	f001 faff 	bl	614c <arch_syscall_oops>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = (((uintptr_t *)more)[4]);
	parm0.split.hi = (((uintptr_t *)more)[5]);
    4b4e:	e9d4 2304 	ldrd	r2, r3, [r4, #16]
	k_tid_t ret = z_vrfy_k_thread_create(*(struct k_thread **)&arg0, *(k_thread_stack_t **)&arg1, *(size_t*)&arg2, *(k_thread_entry_t*)&arg3, *(void **)&arg4, *(void **)&(((uintptr_t *)more)[0]), *(void **)&(((uintptr_t *)more)[1]), *(int*)&(((uintptr_t *)more)[2]), *(uint32_t*)&(((uintptr_t *)more)[3]), parm0.val)
    4b52:	e9cd 2306 	strd	r2, r3, [sp, #24]
    4b56:	68e3      	ldr	r3, [r4, #12]
    4b58:	9304      	str	r3, [sp, #16]
    4b5a:	68a3      	ldr	r3, [r4, #8]
    4b5c:	9303      	str	r3, [sp, #12]
    4b5e:	6863      	ldr	r3, [r4, #4]
    4b60:	9302      	str	r3, [sp, #8]
    4b62:	6823      	ldr	r3, [r4, #0]
    4b64:	9301      	str	r3, [sp, #4]
    4b66:	9b10      	ldr	r3, [sp, #64]	; 0x40
    4b68:	9300      	str	r3, [sp, #0]
    4b6a:	464a      	mov	r2, r9
    4b6c:	4653      	mov	r3, sl
    4b6e:	4641      	mov	r1, r8
    4b70:	4638      	mov	r0, r7
    4b72:	f7ff ff77 	bl	4a64 <z_vrfy_k_thread_create>
;
	_current->syscall_frame = NULL;
    4b76:	68b3      	ldr	r3, [r6, #8]
    4b78:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4b7c:	b008      	add	sp, #32
    4b7e:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    4b82:	bf00      	nop
    4b84:	20000664 	.word	0x20000664

00004b88 <z_init_static_threads>:
{
    4b88:	e92d 4bf0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, fp, lr}
	_FOREACH_STATIC_THREAD(thread_data) {
    4b8c:	4f2e      	ldr	r7, [pc, #184]	; (4c48 <z_init_static_threads+0xc0>)
    4b8e:	4e2f      	ldr	r6, [pc, #188]	; (4c4c <z_init_static_threads+0xc4>)
{
    4b90:	b086      	sub	sp, #24
    4b92:	463d      	mov	r5, r7
	_FOREACH_STATIC_THREAD(thread_data) {
    4b94:	42be      	cmp	r6, r7
    4b96:	f106 0430 	add.w	r4, r6, #48	; 0x30
    4b9a:	d312      	bcc.n	4bc2 <z_init_static_threads+0x3a>
	Z_STRUCT_SECTION_FOREACH(z_object_assignment, pos) {
    4b9c:	4c2c      	ldr	r4, [pc, #176]	; (4c50 <z_init_static_threads+0xc8>)
    4b9e:	4f2d      	ldr	r7, [pc, #180]	; (4c54 <z_init_static_threads+0xcc>)
    4ba0:	42bc      	cmp	r4, r7
    4ba2:	d335      	bcc.n	4c10 <z_init_static_threads+0x88>
	k_sched_lock();
    4ba4:	f7ff f80a 	bl	3bbc <k_sched_lock>
	_FOREACH_STATIC_THREAD(thread_data) {
    4ba8:	4c28      	ldr	r4, [pc, #160]	; (4c4c <z_init_static_threads+0xc4>)
    4baa:	f44f 4800 	mov.w	r8, #32768	; 0x8000
    4bae:	f240 36e7 	movw	r6, #999	; 0x3e7
    4bb2:	2700      	movs	r7, #0
    4bb4:	42ac      	cmp	r4, r5
    4bb6:	d32d      	bcc.n	4c14 <z_init_static_threads+0x8c>
}
    4bb8:	b006      	add	sp, #24
    4bba:	e8bd 4bf0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, fp, lr}
	k_sched_unlock();
    4bbe:	f7ff b84b 	b.w	3c58 <k_sched_unlock>
		z_setup_new_thread(
    4bc2:	f854 3c04 	ldr.w	r3, [r4, #-4]
    4bc6:	9305      	str	r3, [sp, #20]
    4bc8:	f854 3c10 	ldr.w	r3, [r4, #-16]
    4bcc:	9304      	str	r3, [sp, #16]
    4bce:	f854 3c14 	ldr.w	r3, [r4, #-20]
    4bd2:	9303      	str	r3, [sp, #12]
    4bd4:	f854 3c18 	ldr.w	r3, [r4, #-24]
    4bd8:	9302      	str	r3, [sp, #8]
    4bda:	f854 3c1c 	ldr.w	r3, [r4, #-28]
    4bde:	9301      	str	r3, [sp, #4]
    4be0:	f854 3c20 	ldr.w	r3, [r4, #-32]
    4be4:	9300      	str	r3, [sp, #0]
    4be6:	e954 230a 	ldrd	r2, r3, [r4, #-40]	; 0x28
    4bea:	e954 010c 	ldrd	r0, r1, [r4, #-48]	; 0x30
    4bee:	f7ff fecd 	bl	498c <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
    4bf2:	f854 3c30 	ldr.w	r3, [r4, #-48]
    4bf6:	65de      	str	r6, [r3, #92]	; 0x5c
    4bf8:	4626      	mov	r6, r4
    4bfa:	e7cb      	b.n	4b94 <z_init_static_threads+0xc>
			k_object_access_grant(pos->objects[i],
    4bfc:	6821      	ldr	r1, [r4, #0]
    4bfe:	f002 f933 	bl	6e68 <z_impl_k_object_access_grant>
		for (int i = 0; pos->objects[i] != NULL; i++) {
    4c02:	6863      	ldr	r3, [r4, #4]
    4c04:	5998      	ldr	r0, [r3, r6]
    4c06:	3604      	adds	r6, #4
    4c08:	2800      	cmp	r0, #0
    4c0a:	d1f7      	bne.n	4bfc <z_init_static_threads+0x74>
	Z_STRUCT_SECTION_FOREACH(z_object_assignment, pos) {
    4c0c:	3408      	adds	r4, #8
    4c0e:	e7c7      	b.n	4ba0 <z_init_static_threads+0x18>
    4c10:	2600      	movs	r6, #0
    4c12:	e7f6      	b.n	4c02 <z_init_static_threads+0x7a>
		if (thread_data->init_delay != K_TICKS_FOREVER) {
    4c14:	6a61      	ldr	r1, [r4, #36]	; 0x24
    4c16:	1c4b      	adds	r3, r1, #1
    4c18:	d013      	beq.n	4c42 <z_init_static_threads+0xba>
					    K_MSEC(thread_data->init_delay));
    4c1a:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    4c1e:	46b3      	mov	fp, r6
    4c20:	46bc      	mov	ip, r7
    4c22:	fbc8 bc01 	smlal	fp, ip, r8, r1
    4c26:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    4c2a:	2300      	movs	r3, #0
    4c2c:	4658      	mov	r0, fp
    4c2e:	4661      	mov	r1, ip
    4c30:	f7fb fad4 	bl	1dc <__aeabi_uldivmod>
			schedule_new_thread(thread_data->init_thread,
    4c34:	f8d4 9000 	ldr.w	r9, [r4]
    4c38:	4602      	mov	r2, r0
    4c3a:	460b      	mov	r3, r1
    4c3c:	4648      	mov	r0, r9
    4c3e:	f7ff fe51 	bl	48e4 <schedule_new_thread>
	_FOREACH_STATIC_THREAD(thread_data) {
    4c42:	3430      	adds	r4, #48	; 0x30
    4c44:	e7b6      	b.n	4bb4 <z_init_static_threads+0x2c>
    4c46:	bf00      	nop
    4c48:	20002e60 	.word	0x20002e60
    4c4c:	20002e60 	.word	0x20002e60
    4c50:	0000721c 	.word	0x0000721c
    4c54:	0000721c 	.word	0x0000721c

00004c58 <z_mrsh_k_float_disable>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_float_disable(struct k_thread * thread);
uintptr_t z_mrsh_k_float_disable(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4c58:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    4c5a:	4c0c      	ldr	r4, [pc, #48]	; (4c8c <z_mrsh_k_float_disable+0x34>)
    4c5c:	9a04      	ldr	r2, [sp, #16]
    4c5e:	68a3      	ldr	r3, [r4, #8]
    4c60:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_float_disable(struct k_thread *thread)
{
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    4c64:	f7fb fa3a 	bl	dc <z_object_find>
    4c68:	2200      	movs	r2, #0
    4c6a:	2109      	movs	r1, #9
    4c6c:	f000 fc64 	bl	5538 <z_object_validate>
    4c70:	b130      	cbz	r0, 4c80 <z_mrsh_k_float_disable+0x28>
    4c72:	f001 fee0 	bl	6a36 <arch_is_user_context>
    4c76:	68a3      	ldr	r3, [r4, #8]
    4c78:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4c7c:	f001 fa66 	bl	614c <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_float_disable(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    4c80:	68a3      	ldr	r3, [r4, #8]
    4c82:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4c86:	f06f 0046 	mvn.w	r0, #70	; 0x46
    4c8a:	bd10      	pop	{r4, pc}
    4c8c:	20000664 	.word	0x20000664

00004c90 <z_mrsh_k_thread_timeout_remaining_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_thread_timeout_remaining_ticks(struct k_thread * t);
uintptr_t z_mrsh_k_thread_timeout_remaining_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4c90:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4c92:	4d0e      	ldr	r5, [pc, #56]	; (4ccc <z_mrsh_k_thread_timeout_remaining_ticks+0x3c>)
    4c94:	9a06      	ldr	r2, [sp, #24]
    4c96:	68ab      	ldr	r3, [r5, #8]
    4c98:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4c9c:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline k_ticks_t z_vrfy_k_thread_timeout_remaining_ticks(
						    struct k_thread *t)
{
	Z_OOPS(Z_SYSCALL_OBJ(t, K_OBJ_THREAD));
    4c9e:	f7fb fa1d 	bl	dc <z_object_find>
    4ca2:	2200      	movs	r2, #0
    4ca4:	2109      	movs	r1, #9
    4ca6:	f000 fc47 	bl	5538 <z_object_validate>
    4caa:	4604      	mov	r4, r0
    4cac:	b130      	cbz	r0, 4cbc <z_mrsh_k_thread_timeout_remaining_ticks+0x2c>
    4cae:	f001 fec2 	bl	6a36 <arch_is_user_context>
    4cb2:	68ab      	ldr	r3, [r5, #8]
    4cb4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4cb8:	f001 fa48 	bl	614c <arch_syscall_oops>
	return z_timeout_remaining(&t->base.timeout);
    4cbc:	f106 0018 	add.w	r0, r6, #24
    4cc0:	f001 ff0b 	bl	6ada <z_timeout_remaining>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_thread_timeout_remaining_ticks(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    4cc4:	68ab      	ldr	r3, [r5, #8]
    4cc6:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4cca:	bd70      	pop	{r4, r5, r6, pc}
    4ccc:	20000664 	.word	0x20000664

00004cd0 <z_mrsh_k_thread_timeout_expires_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_thread_timeout_expires_ticks(struct k_thread * t);
uintptr_t z_mrsh_k_thread_timeout_expires_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4cd0:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4cd2:	4d0e      	ldr	r5, [pc, #56]	; (4d0c <z_mrsh_k_thread_timeout_expires_ticks+0x3c>)
    4cd4:	9a06      	ldr	r2, [sp, #24]
    4cd6:	68ab      	ldr	r3, [r5, #8]
    4cd8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4cdc:	4606      	mov	r6, r0
#include <syscalls/k_thread_timeout_remaining_ticks_mrsh.c>

static inline k_ticks_t z_vrfy_k_thread_timeout_expires_ticks(
						  struct k_thread *t)
{
	Z_OOPS(Z_SYSCALL_OBJ(t, K_OBJ_THREAD));
    4cde:	f7fb f9fd 	bl	dc <z_object_find>
    4ce2:	2200      	movs	r2, #0
    4ce4:	2109      	movs	r1, #9
    4ce6:	f000 fc27 	bl	5538 <z_object_validate>
    4cea:	4604      	mov	r4, r0
    4cec:	b130      	cbz	r0, 4cfc <z_mrsh_k_thread_timeout_expires_ticks+0x2c>
    4cee:	f001 fea2 	bl	6a36 <arch_is_user_context>
    4cf2:	68ab      	ldr	r3, [r5, #8]
    4cf4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4cf8:	f001 fa28 	bl	614c <arch_syscall_oops>
	return z_timeout_expires(&t->base.timeout);
    4cfc:	f106 0018 	add.w	r0, r6, #24
    4d00:	f000 f918 	bl	4f34 <z_timeout_expires>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_thread_timeout_expires_ticks(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    4d04:	68ab      	ldr	r3, [r5, #8]
    4d06:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4d0a:	bd70      	pop	{r4, r5, r6, pc}
    4d0c:	20000664 	.word	0x20000664

00004d10 <k_work_q_start>:

extern void z_work_q_main(void *work_q_ptr, void *p2, void *p3);

void k_work_q_start(struct k_work_q *work_q, k_thread_stack_t *stack,
		    size_t stack_size, int prio)
{
    4d10:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    4d14:	4604      	mov	r4, r0
    4d16:	b088      	sub	sp, #32
    4d18:	460d      	mov	r5, r1
    4d1a:	4616      	mov	r6, r2
    4d1c:	461f      	mov	r7, r3
	z_impl_k_queue_init(queue);
    4d1e:	f001 fc92 	bl	6646 <z_impl_k_queue_init>
	k_queue_init(&work_q->queue);
	(void)k_thread_create(&work_q->thread, stack, stack_size, z_work_q_main,
    4d22:	f104 0810 	add.w	r8, r4, #16
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
    4d26:	2200      	movs	r2, #0
    4d28:	2300      	movs	r3, #0
    4d2a:	e9cd 2306 	strd	r2, r3, [sp, #24]
    4d2e:	e9cd 7203 	strd	r7, r2, [sp, #12]
    4d32:	e9cd 2201 	strd	r2, r2, [sp, #4]
    4d36:	4b07      	ldr	r3, [pc, #28]	; (4d54 <k_work_q_start+0x44>)
    4d38:	9400      	str	r4, [sp, #0]
    4d3a:	4632      	mov	r2, r6
    4d3c:	4629      	mov	r1, r5
    4d3e:	4640      	mov	r0, r8
    4d40:	f001 fe95 	bl	6a6e <z_impl_k_thread_create>
	return z_impl_k_thread_name_set(thread_id, value);
    4d44:	4904      	ldr	r1, [pc, #16]	; (4d58 <k_work_q_start+0x48>)
    4d46:	4640      	mov	r0, r8
			work_q, NULL, NULL, prio, 0, K_NO_WAIT);

	k_thread_name_set(&work_q->thread, WORKQUEUE_THREAD_NAME);
}
    4d48:	b008      	add	sp, #32
    4d4a:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    4d4e:	f001 be84 	b.w	6a5a <z_impl_k_thread_name_set>
    4d52:	bf00      	nop
    4d54:	00005a2f 	.word	0x00005a2f
    4d58:	00007868 	.word	0x00007868

00004d5c <elapsed>:
	sys_dlist_remove(&t->node);
}

static int32_t elapsed(void)
{
	return announce_remaining == 0 ? z_clock_elapsed() : 0;
    4d5c:	4b03      	ldr	r3, [pc, #12]	; (4d6c <elapsed+0x10>)
    4d5e:	681b      	ldr	r3, [r3, #0]
    4d60:	b90b      	cbnz	r3, 4d66 <elapsed+0xa>
    4d62:	f7fc bbcf 	b.w	1504 <z_clock_elapsed>
}
    4d66:	2000      	movs	r0, #0
    4d68:	4770      	bx	lr
    4d6a:	bf00      	nop
    4d6c:	200006a0 	.word	0x200006a0

00004d70 <remove_timeout>:
{
    4d70:	b530      	push	{r4, r5, lr}
    4d72:	6803      	ldr	r3, [r0, #0]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    4d74:	b168      	cbz	r0, 4d92 <remove_timeout+0x22>
    4d76:	4a0a      	ldr	r2, [pc, #40]	; (4da0 <remove_timeout+0x30>)
	return (node == list->tail) ? NULL : node->next;
    4d78:	6852      	ldr	r2, [r2, #4]
    4d7a:	4290      	cmp	r0, r2
    4d7c:	d009      	beq.n	4d92 <remove_timeout+0x22>
	if (next(t) != NULL) {
    4d7e:	b143      	cbz	r3, 4d92 <remove_timeout+0x22>
		next(t)->dticks += t->dticks;
    4d80:	e9d3 2104 	ldrd	r2, r1, [r3, #16]
    4d84:	e9d0 4504 	ldrd	r4, r5, [r0, #16]
    4d88:	1912      	adds	r2, r2, r4
    4d8a:	eb45 0101 	adc.w	r1, r5, r1
    4d8e:	e9c3 2104 	strd	r2, r1, [r3, #16]
	node->prev->next = node->next;
    4d92:	6842      	ldr	r2, [r0, #4]
    4d94:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    4d96:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    4d98:	2300      	movs	r3, #0
	node->prev = NULL;
    4d9a:	e9c0 3300 	strd	r3, r3, [r0]
}
    4d9e:	bd30      	pop	{r4, r5, pc}
    4da0:	20002e14 	.word	0x20002e14

00004da4 <next_timeout>:
	return list->head == list;
    4da4:	4b0a      	ldr	r3, [pc, #40]	; (4dd0 <next_timeout+0x2c>)

static int32_t next_timeout(void)
{
    4da6:	b510      	push	{r4, lr}
    4da8:	681c      	ldr	r4, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4daa:	429c      	cmp	r4, r3
    4dac:	bf08      	it	eq
    4dae:	2400      	moveq	r4, #0
	struct _timeout *to = first();
	int32_t ticks_elapsed = elapsed();
    4db0:	f7ff ffd4 	bl	4d5c <elapsed>
	int32_t ret = to == NULL ? MAX_WAIT : MAX(0, to->dticks - ticks_elapsed);
    4db4:	b144      	cbz	r4, 4dc8 <next_timeout+0x24>
    4db6:	6923      	ldr	r3, [r4, #16]
    4db8:	1a18      	subs	r0, r3, r0

#ifdef CONFIG_TIMESLICING
	if (_current_cpu->slice_ticks && _current_cpu->slice_ticks < ret) {
    4dba:	4b06      	ldr	r3, [pc, #24]	; (4dd4 <next_timeout+0x30>)
    4dbc:	691b      	ldr	r3, [r3, #16]
    4dbe:	b113      	cbz	r3, 4dc6 <next_timeout+0x22>
    4dc0:	4298      	cmp	r0, r3
    4dc2:	bfa8      	it	ge
    4dc4:	4618      	movge	r0, r3
		ret = _current_cpu->slice_ticks;
	}
#endif
	return ret;
}
    4dc6:	bd10      	pop	{r4, pc}
	int32_t ret = to == NULL ? MAX_WAIT : MAX(0, to->dticks - ticks_elapsed);
    4dc8:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
    4dcc:	e7f5      	b.n	4dba <next_timeout+0x16>
    4dce:	bf00      	nop
    4dd0:	20002e14 	.word	0x20002e14
    4dd4:	20000664 	.word	0x20000664

00004dd8 <timeout_rem>:
/* must be locked */
static k_ticks_t timeout_rem(struct _timeout *timeout)
{
	k_ticks_t ticks = 0;

	if (z_is_inactive_timeout(timeout)) {
    4dd8:	6803      	ldr	r3, [r0, #0]
{
    4dda:	b570      	push	{r4, r5, r6, lr}
	if (z_is_inactive_timeout(timeout)) {
    4ddc:	b1eb      	cbz	r3, 4e1a <timeout_rem+0x42>
	return list->head == list;
    4dde:	4a10      	ldr	r2, [pc, #64]	; (4e20 <timeout_rem+0x48>)
    4de0:	6813      	ldr	r3, [r2, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4de2:	4293      	cmp	r3, r2
    4de4:	d016      	beq.n	4e14 <timeout_rem+0x3c>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    4de6:	6851      	ldr	r1, [r2, #4]
    4de8:	2400      	movs	r4, #0
    4dea:	2500      	movs	r5, #0
		return 0;
	}

	for (struct _timeout *t = first(); t != NULL; t = next(t)) {
    4dec:	b93b      	cbnz	r3, 4dfe <timeout_rem+0x26>
		if (timeout == t) {
			break;
		}
	}

	return ticks - elapsed();
    4dee:	f7ff ffb5 	bl	4d5c <elapsed>
    4df2:	1a24      	subs	r4, r4, r0
    4df4:	eb65 75e0 	sbc.w	r5, r5, r0, asr #31
}
    4df8:	4620      	mov	r0, r4
    4dfa:	4629      	mov	r1, r5
    4dfc:	bd70      	pop	{r4, r5, r6, pc}
		ticks += t->dticks;
    4dfe:	e9d3 2604 	ldrd	r2, r6, [r3, #16]
    4e02:	18a4      	adds	r4, r4, r2
    4e04:	eb46 0505 	adc.w	r5, r6, r5
		if (timeout == t) {
    4e08:	4283      	cmp	r3, r0
    4e0a:	d0f0      	beq.n	4dee <timeout_rem+0x16>
	return (node == list->tail) ? NULL : node->next;
    4e0c:	428b      	cmp	r3, r1
    4e0e:	d0ee      	beq.n	4dee <timeout_rem+0x16>
    4e10:	681b      	ldr	r3, [r3, #0]
    4e12:	e7eb      	b.n	4dec <timeout_rem+0x14>
    4e14:	2400      	movs	r4, #0
    4e16:	2500      	movs	r5, #0
    4e18:	e7e9      	b.n	4dee <timeout_rem+0x16>
		return 0;
    4e1a:	2400      	movs	r4, #0
    4e1c:	2500      	movs	r5, #0
    4e1e:	e7eb      	b.n	4df8 <timeout_rem+0x20>
    4e20:	20002e14 	.word	0x20002e14

00004e24 <z_add_timeout>:
{
    4e24:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    4e28:	9101      	str	r1, [sp, #4]
    4e2a:	4619      	mov	r1, r3
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    4e2c:	1c4b      	adds	r3, r1, #1
    4e2e:	bf08      	it	eq
    4e30:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
{
    4e34:	4682      	mov	sl, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    4e36:	d06c      	beq.n	4f12 <z_add_timeout+0xee>
	k_ticks_t ticks = timeout.ticks + 1;
    4e38:	1c54      	adds	r4, r2, #1
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    4e3a:	f06f 0301 	mvn.w	r3, #1
	k_ticks_t ticks = timeout.ticks + 1;
    4e3e:	f141 0500 	adc.w	r5, r1, #0
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    4e42:	f04f 3bff 	mov.w	fp, #4294967295	; 0xffffffff
    4e46:	ebb3 0804 	subs.w	r8, r3, r4
    4e4a:	eb6b 0905 	sbc.w	r9, fp, r5
    4e4e:	f1b8 0f00 	cmp.w	r8, #0
    4e52:	f179 0300 	sbcs.w	r3, r9, #0
    4e56:	db0f      	blt.n	4e78 <z_add_timeout+0x54>
		ticks = Z_TICK_ABS(ticks) - (curr_tick + elapsed());
    4e58:	f7ff ff80 	bl	4d5c <elapsed>
    4e5c:	4a33      	ldr	r2, [pc, #204]	; (4f2c <z_add_timeout+0x108>)
    4e5e:	e9d2 1c00 	ldrd	r1, ip, [r2]
    4e62:	f06f 0301 	mvn.w	r3, #1
    4e66:	1a5b      	subs	r3, r3, r1
    4e68:	eb6b 020c 	sbc.w	r2, fp, ip
    4e6c:	1b1e      	subs	r6, r3, r4
    4e6e:	eb62 0705 	sbc.w	r7, r2, r5
    4e72:	1a34      	subs	r4, r6, r0
    4e74:	eb67 75e0 	sbc.w	r5, r7, r0, asr #31
	to->fn = fn;
    4e78:	9b01      	ldr	r3, [sp, #4]
    4e7a:	f8ca 3008 	str.w	r3, [sl, #8]
	__asm__ volatile(
    4e7e:	f04f 0320 	mov.w	r3, #32
    4e82:	f3ef 8611 	mrs	r6, BASEPRI
    4e86:	f383 8811 	msr	BASEPRI, r3
    4e8a:	f3bf 8f6f 	isb	sy
		to->dticks = ticks + elapsed();
    4e8e:	f7ff ff65 	bl	4d5c <elapsed>
	ticks = MAX(1, ticks);
    4e92:	2c01      	cmp	r4, #1
    4e94:	f175 0300 	sbcs.w	r3, r5, #0
	return list->head == list;
    4e98:	4b25      	ldr	r3, [pc, #148]	; (4f30 <z_add_timeout+0x10c>)
    4e9a:	bfb8      	it	lt
    4e9c:	2401      	movlt	r4, #1
    4e9e:	681a      	ldr	r2, [r3, #0]
    4ea0:	bfb8      	it	lt
    4ea2:	2500      	movlt	r5, #0
		to->dticks = ticks + elapsed();
    4ea4:	1824      	adds	r4, r4, r0
    4ea6:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4eaa:	429a      	cmp	r2, r3
    4eac:	e9ca 4504 	strd	r4, r5, [sl, #16]
    4eb0:	d001      	beq.n	4eb6 <z_add_timeout+0x92>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    4eb2:	685f      	ldr	r7, [r3, #4]
		for (t = first(); t != NULL; t = next(t)) {
    4eb4:	b952      	cbnz	r2, 4ecc <z_add_timeout+0xa8>
	node->prev = list->tail;
    4eb6:	685a      	ldr	r2, [r3, #4]
    4eb8:	f8ca 2004 	str.w	r2, [sl, #4]
	list->tail->next = node;
    4ebc:	685a      	ldr	r2, [r3, #4]
	node->next = list;
    4ebe:	f8ca 3000 	str.w	r3, [sl]
	list->tail->next = node;
    4ec2:	f8c2 a000 	str.w	sl, [r2]
	list->tail = node;
    4ec6:	f8c3 a004 	str.w	sl, [r3, #4]
}
    4eca:	e014      	b.n	4ef6 <z_add_timeout+0xd2>
			if (t->dticks > to->dticks) {
    4ecc:	e9d2 8904 	ldrd	r8, r9, [r2, #16]
    4ed0:	e9da 4504 	ldrd	r4, r5, [sl, #16]
    4ed4:	454d      	cmp	r5, r9
    4ed6:	bf08      	it	eq
    4ed8:	4544      	cmpeq	r4, r8
    4eda:	d21d      	bcs.n	4f18 <z_add_timeout+0xf4>
				t->dticks -= to->dticks;
    4edc:	ebb8 0004 	subs.w	r0, r8, r4
    4ee0:	eb69 0105 	sbc.w	r1, r9, r5
    4ee4:	e9c2 0104 	strd	r0, r1, [r2, #16]
	node->prev = successor->prev;
    4ee8:	6851      	ldr	r1, [r2, #4]
	node->next = successor;
    4eea:	e9ca 2100 	strd	r2, r1, [sl]
	successor->prev->next = node;
    4eee:	f8c1 a000 	str.w	sl, [r1]
	successor->prev = node;
    4ef2:	f8c2 a004 	str.w	sl, [r2, #4]
	return list->head == list;
    4ef6:	681a      	ldr	r2, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4ef8:	429a      	cmp	r2, r3
    4efa:	d006      	beq.n	4f0a <z_add_timeout+0xe6>
		if (to == first()) {
    4efc:	4592      	cmp	sl, r2
    4efe:	d104      	bne.n	4f0a <z_add_timeout+0xe6>
			z_clock_set_timeout(next_timeout(), false);
    4f00:	f7ff ff50 	bl	4da4 <next_timeout>
    4f04:	2100      	movs	r1, #0
    4f06:	f7fc fa91 	bl	142c <z_clock_set_timeout>
	__asm__ volatile(
    4f0a:	f386 8811 	msr	BASEPRI, r6
    4f0e:	f3bf 8f6f 	isb	sy
}
    4f12:	b003      	add	sp, #12
    4f14:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			to->dticks -= t->dticks;
    4f18:	ebb4 0008 	subs.w	r0, r4, r8
    4f1c:	eb65 0109 	sbc.w	r1, r5, r9
	return (node == list->tail) ? NULL : node->next;
    4f20:	42ba      	cmp	r2, r7
    4f22:	e9ca 0104 	strd	r0, r1, [sl, #16]
    4f26:	d0c6      	beq.n	4eb6 <z_add_timeout+0x92>
    4f28:	6812      	ldr	r2, [r2, #0]
    4f2a:	e7c3      	b.n	4eb4 <z_add_timeout+0x90>
    4f2c:	200004a8 	.word	0x200004a8
    4f30:	20002e14 	.word	0x20002e14

00004f34 <z_timeout_expires>:

	return ticks;
}

k_ticks_t z_timeout_expires(struct _timeout *timeout)
{
    4f34:	b510      	push	{r4, lr}
	__asm__ volatile(
    4f36:	f04f 0320 	mov.w	r3, #32
    4f3a:	f3ef 8411 	mrs	r4, BASEPRI
    4f3e:	f383 8811 	msr	BASEPRI, r3
    4f42:	f3bf 8f6f 	isb	sy
	k_ticks_t ticks = 0;

	LOCKED(&timeout_lock) {
		ticks = curr_tick + timeout_rem(timeout);
    4f46:	f7ff ff47 	bl	4dd8 <timeout_rem>
    4f4a:	4a05      	ldr	r2, [pc, #20]	; (4f60 <z_timeout_expires+0x2c>)
    4f4c:	e9d2 3200 	ldrd	r3, r2, [r2]
    4f50:	18c0      	adds	r0, r0, r3
    4f52:	eb42 0101 	adc.w	r1, r2, r1
	__asm__ volatile(
    4f56:	f384 8811 	msr	BASEPRI, r4
    4f5a:	f3bf 8f6f 	isb	sy
	}

	return ticks;
}
    4f5e:	bd10      	pop	{r4, pc}
    4f60:	200004a8 	.word	0x200004a8

00004f64 <z_clock_announce>:
		}
	}
}

void z_clock_announce(int32_t ticks)
{
    4f64:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    4f68:	4606      	mov	r6, r0
#ifdef CONFIG_TIMESLICING
	z_time_slice(ticks);
    4f6a:	f7fe ff63 	bl	3e34 <z_time_slice>
	__asm__ volatile(
    4f6e:	f04f 0320 	mov.w	r3, #32
    4f72:	f3ef 8411 	mrs	r4, BASEPRI
    4f76:	f383 8811 	msr	BASEPRI, r3
    4f7a:	f3bf 8f6f 	isb	sy
#endif

	k_spinlock_key_t key = k_spin_lock(&timeout_lock);

	announce_remaining = ticks;
    4f7e:	4d2d      	ldr	r5, [pc, #180]	; (5034 <z_clock_announce+0xd0>)
    4f80:	f8df a0b4 	ldr.w	sl, [pc, #180]	; 5038 <z_clock_announce+0xd4>
	return list->head == list;
    4f84:	f8df b0b4 	ldr.w	fp, [pc, #180]	; 503c <z_clock_announce+0xd8>
    4f88:	602e      	str	r6, [r5, #0]

	while (first() != NULL && first()->dticks <= announce_remaining) {
    4f8a:	4651      	mov	r1, sl
    4f8c:	f8d5 c000 	ldr.w	ip, [r5]
    4f90:	f8db 0000 	ldr.w	r0, [fp]
    4f94:	4662      	mov	r2, ip
    4f96:	17d3      	asrs	r3, r2, #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4f98:	4558      	cmp	r0, fp
    4f9a:	e9cd 2300 	strd	r2, r3, [sp]
    4f9e:	e9da 8900 	ldrd	r8, r9, [sl]
    4fa2:	d00e      	beq.n	4fc2 <z_clock_announce+0x5e>
    4fa4:	b168      	cbz	r0, 4fc2 <z_clock_announce+0x5e>
    4fa6:	e9d0 6704 	ldrd	r6, r7, [r0, #16]
    4faa:	42bb      	cmp	r3, r7
    4fac:	bf08      	it	eq
    4fae:	45b4      	cmpeq	ip, r6
    4fb0:	d21e      	bcs.n	4ff0 <z_clock_announce+0x8c>
		t->fn(t);
		key = k_spin_lock(&timeout_lock);
	}

	if (first() != NULL) {
		first()->dticks -= announce_remaining;
    4fb2:	9b00      	ldr	r3, [sp, #0]
    4fb4:	ebb6 0c03 	subs.w	ip, r6, r3
    4fb8:	9b01      	ldr	r3, [sp, #4]
    4fba:	eb67 0603 	sbc.w	r6, r7, r3
    4fbe:	e9c0 c604 	strd	ip, r6, [r0, #16]
	}

	curr_tick += announce_remaining;
    4fc2:	9b00      	ldr	r3, [sp, #0]
    4fc4:	eb13 0208 	adds.w	r2, r3, r8
    4fc8:	9b01      	ldr	r3, [sp, #4]
	announce_remaining = 0;
    4fca:	f04f 0600 	mov.w	r6, #0
	curr_tick += announce_remaining;
    4fce:	eb43 0309 	adc.w	r3, r3, r9
    4fd2:	e9c1 2300 	strd	r2, r3, [r1]
	announce_remaining = 0;
    4fd6:	602e      	str	r6, [r5, #0]

	z_clock_set_timeout(next_timeout(), false);
    4fd8:	f7ff fee4 	bl	4da4 <next_timeout>
    4fdc:	4631      	mov	r1, r6
    4fde:	f7fc fa25 	bl	142c <z_clock_set_timeout>
	__asm__ volatile(
    4fe2:	f384 8811 	msr	BASEPRI, r4
    4fe6:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&timeout_lock, key);
}
    4fea:	b003      	add	sp, #12
    4fec:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		curr_tick += dt;
    4ff0:	eb18 0806 	adds.w	r8, r8, r6
		t->dticks = 0;
    4ff4:	f04f 0200 	mov.w	r2, #0
    4ff8:	f04f 0300 	mov.w	r3, #0
		curr_tick += dt;
    4ffc:	eb49 79e6 	adc.w	r9, r9, r6, asr #31
		t->dticks = 0;
    5000:	e9c0 2304 	strd	r2, r3, [r0, #16]
		announce_remaining -= dt;
    5004:	ebac 0606 	sub.w	r6, ip, r6
		curr_tick += dt;
    5008:	e9ca 8900 	strd	r8, r9, [sl]
		announce_remaining -= dt;
    500c:	602e      	str	r6, [r5, #0]
		remove_timeout(t);
    500e:	f7ff feaf 	bl	4d70 <remove_timeout>
    5012:	f384 8811 	msr	BASEPRI, r4
    5016:	f3bf 8f6f 	isb	sy
		t->fn(t);
    501a:	6883      	ldr	r3, [r0, #8]
    501c:	4798      	blx	r3
	__asm__ volatile(
    501e:	f04f 0320 	mov.w	r3, #32
    5022:	f3ef 8411 	mrs	r4, BASEPRI
    5026:	f383 8811 	msr	BASEPRI, r3
    502a:	f3bf 8f6f 	isb	sy

	/* Note that we need to use the underlying arch-specific lock
	 * implementation.  The "irq_lock()" API in SMP context is
	 * actually a wrapper for a global spinlock!
	 */
	k.key = arch_irq_lock();
    502e:	4902      	ldr	r1, [pc, #8]	; (5038 <z_clock_announce+0xd4>)
#endif

#ifdef CONFIG_SPIN_VALIDATE
	z_spin_lock_set_owner(l);
#endif
	return k;
    5030:	e7ac      	b.n	4f8c <z_clock_announce+0x28>
    5032:	bf00      	nop
    5034:	200006a0 	.word	0x200006a0
    5038:	200004a8 	.word	0x200004a8
    503c:	20002e14 	.word	0x20002e14

00005040 <z_tick_get>:

int64_t z_tick_get(void)
{
    5040:	b510      	push	{r4, lr}
    5042:	f04f 0320 	mov.w	r3, #32
    5046:	f3ef 8411 	mrs	r4, BASEPRI
    504a:	f383 8811 	msr	BASEPRI, r3
    504e:	f3bf 8f6f 	isb	sy
	uint64_t t = 0U;

	LOCKED(&timeout_lock) {
		t = curr_tick + z_clock_elapsed();
    5052:	f7fc fa57 	bl	1504 <z_clock_elapsed>
    5056:	4b06      	ldr	r3, [pc, #24]	; (5070 <z_tick_get+0x30>)
    5058:	e9d3 2300 	ldrd	r2, r3, [r3]
    505c:	1812      	adds	r2, r2, r0
    505e:	f143 0300 	adc.w	r3, r3, #0
	__asm__ volatile(
    5062:	f384 8811 	msr	BASEPRI, r4
    5066:	f3bf 8f6f 	isb	sy
	}
	return t;
}
    506a:	4610      	mov	r0, r2
    506c:	4619      	mov	r1, r3
    506e:	bd10      	pop	{r4, pc}
    5070:	200004a8 	.word	0x200004a8

00005074 <z_mrsh_k_uptime_ticks>:
#include <syscalls/kernel.h>

extern int64_t z_vrfy_k_uptime_ticks();
uintptr_t z_mrsh_k_uptime_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5074:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    5076:	4d10      	ldr	r5, [pc, #64]	; (50b8 <z_mrsh_k_uptime_ticks+0x44>)
    5078:	9a08      	ldr	r2, [sp, #32]
    507a:	68ab      	ldr	r3, [r5, #8]
    507c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    5080:	4604      	mov	r4, r0
#endif
}

int64_t z_impl_k_uptime_ticks(void)
{
	return z_tick_get();
    5082:	f7ff ffdd 	bl	5040 <z_tick_get>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int64_t ret = z_vrfy_k_uptime_ticks()
;
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(((uint64_t *)arg0), 8));
    5086:	2201      	movs	r2, #1
    5088:	4607      	mov	r7, r0
    508a:	460e      	mov	r6, r1
    508c:	4620      	mov	r0, r4
    508e:	2108      	movs	r1, #8
    5090:	f001 f88a 	bl	61a8 <arch_buffer_validate>
    5094:	462a      	mov	r2, r5
    5096:	b148      	cbz	r0, 50ac <z_mrsh_k_uptime_ticks+0x38>
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5098:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    509c:	b90b      	cbnz	r3, 50a2 <z_mrsh_k_uptime_ticks+0x2e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    509e:	f3ef 8314 	mrs	r3, CONTROL
    50a2:	6893      	ldr	r3, [r2, #8]
    50a4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    50a8:	f001 f850 	bl	614c <arch_syscall_oops>
	*((uint64_t *)arg0) = ret;
	_current->syscall_frame = NULL;
    50ac:	68aa      	ldr	r2, [r5, #8]
	*((uint64_t *)arg0) = ret;
    50ae:	e9c4 7600 	strd	r7, r6, [r4]
	_current->syscall_frame = NULL;
    50b2:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    50b6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    50b8:	20000664 	.word	0x20000664

000050bc <z_timer_expiration_handler>:
 * @param t  Timeout used by the timer.
 *
 * @return N/A
 */
void z_timer_expiration_handler(struct _timeout *t)
{
    50bc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}

	/*
	 * if the timer is periodic, start it again; don't add _TICK_ALIGN
	 * since we're already aligned to a tick boundary
	 */
	if (!K_TIMEOUT_EQ(timer->period, K_NO_WAIT) &&
    50be:	e9d0 230a 	ldrd	r2, r3, [r0, #40]	; 0x28
    50c2:	1c56      	adds	r6, r2, #1
    50c4:	f143 0700 	adc.w	r7, r3, #0
    50c8:	2f00      	cmp	r7, #0
    50ca:	bf08      	it	eq
    50cc:	2e02      	cmpeq	r6, #2
{
    50ce:	4604      	mov	r4, r0
	if (!K_TIMEOUT_EQ(timer->period, K_NO_WAIT) &&
    50d0:	d302      	bcc.n	50d8 <z_timer_expiration_handler+0x1c>
	    !K_TIMEOUT_EQ(timer->period, K_FOREVER)) {
		z_add_timeout(&timer->timeout, z_timer_expiration_handler,
    50d2:	490c      	ldr	r1, [pc, #48]	; (5104 <z_timer_expiration_handler+0x48>)
    50d4:	f7ff fea6 	bl	4e24 <z_add_timeout>
			     timer->period);
	}

	/* update timer's status */
	timer->status += 1U;
    50d8:	6b23      	ldr	r3, [r4, #48]	; 0x30
    50da:	3301      	adds	r3, #1
    50dc:	6323      	str	r3, [r4, #48]	; 0x30

	/* invoke timer expiry function */
	if (timer->expiry_fn != NULL) {
    50de:	6a23      	ldr	r3, [r4, #32]
    50e0:	b10b      	cbz	r3, 50e6 <z_timer_expiration_handler+0x2a>
		timer->expiry_fn(timer);
    50e2:	4620      	mov	r0, r4
    50e4:	4798      	blx	r3
	return list->head == list;
    50e6:	f854 5f18 	ldr.w	r5, [r4, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    50ea:	42a5      	cmp	r5, r4
    50ec:	d009      	beq.n	5102 <z_timer_expiration_handler+0x46>
	}

	thread = z_waitq_head(&timer->wait_q);

	if (thread == NULL) {
    50ee:	b145      	cbz	r5, 5102 <z_timer_expiration_handler+0x46>
	 * place a thread can be taken off this pend queue, and b) the
	 * only place a thread can be put on the pend queue is at
	 * thread level, which of course cannot interrupt the current
	 * context.
	 */
	z_unpend_thread_no_timeout(thread);
    50f0:	4628      	mov	r0, r5
    50f2:	f001 fb02 	bl	66fa <z_unpend_thread_no_timeout>

	z_ready_thread(thread);
    50f6:	4628      	mov	r0, r5
    50f8:	f001 fb60 	bl	67bc <z_ready_thread>
    50fc:	2300      	movs	r3, #0
    50fe:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90

	arch_thread_return_value_set(thread, 0);
}
    5102:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    5104:	000050bd 	.word	0x000050bd

00005108 <z_impl_k_timer_start>:
}


void z_impl_k_timer_start(struct k_timer *timer, k_timeout_t duration,
			  k_timeout_t period)
{
    5108:	e92d 4f73 	stmdb	sp!, {r0, r1, r4, r5, r6, r8, r9, sl, fp, lr}
    510c:	4619      	mov	r1, r3
    510e:	4606      	mov	r6, r0
	if (K_TIMEOUT_EQ(duration, K_FOREVER)) {
    5110:	1c4c      	adds	r4, r1, #1
{
    5112:	4610      	mov	r0, r2
	if (K_TIMEOUT_EQ(duration, K_FOREVER)) {
    5114:	bf08      	it	eq
    5116:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    511a:	e9dd 230a 	ldrd	r2, r3, [sp, #40]	; 0x28
    511e:	4680      	mov	r8, r0
    5120:	4689      	mov	r9, r1
	if (K_TIMEOUT_EQ(duration, K_FOREVER)) {
    5122:	d047      	beq.n	51b4 <z_impl_k_timer_start+0xac>
    5124:	4614      	mov	r4, r2
    5126:	461d      	mov	r5, r3
	 * for backwards compatibility.  This is unfortunate
	 * (i.e. k_timer_start() doesn't treat its initial sleep
	 * argument the same way k_sleep() does), but historical.  The
	 * timer_api test relies on this behavior.
	 */
	if (period.ticks != 0 && Z_TICK_ABS(period.ticks) < 0) {
    5128:	ea54 0305 	orrs.w	r3, r4, r5
    512c:	d016      	beq.n	515c <z_impl_k_timer_start+0x54>
    512e:	f06f 0301 	mvn.w	r3, #1
    5132:	ebb3 0a02 	subs.w	sl, r3, r2
    5136:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    513a:	eb63 0b05 	sbc.w	fp, r3, r5
    513e:	f1ba 0f00 	cmp.w	sl, #0
    5142:	f17b 0300 	sbcs.w	r3, fp, #0
    5146:	da09      	bge.n	515c <z_impl_k_timer_start+0x54>
		period.ticks = MAX(period.ticks - 1, 1);
    5148:	f112 34ff 	adds.w	r4, r2, #4294967295	; 0xffffffff
    514c:	f145 35ff 	adc.w	r5, r5, #4294967295	; 0xffffffff
    5150:	2c01      	cmp	r4, #1
    5152:	f175 0300 	sbcs.w	r3, r5, #0
    5156:	bfbc      	itt	lt
    5158:	2401      	movlt	r4, #1
    515a:	2500      	movlt	r5, #0
	}
	if (Z_TICK_ABS(duration.ticks) < 0) {
    515c:	f06f 0301 	mvn.w	r3, #1
    5160:	1a1b      	subs	r3, r3, r0
    5162:	9300      	str	r3, [sp, #0]
    5164:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    5168:	eb63 0301 	sbc.w	r3, r3, r1
    516c:	9301      	str	r3, [sp, #4]
    516e:	e9dd 2300 	ldrd	r2, r3, [sp]
    5172:	2a00      	cmp	r2, #0
    5174:	f173 0300 	sbcs.w	r3, r3, #0
    5178:	da0c      	bge.n	5194 <z_impl_k_timer_start+0x8c>
		duration.ticks = MAX(duration.ticks - 1, 0);
    517a:	f110 38ff 	adds.w	r8, r0, #4294967295	; 0xffffffff
    517e:	f141 39ff 	adc.w	r9, r1, #4294967295	; 0xffffffff
    5182:	f1b8 0f00 	cmp.w	r8, #0
    5186:	f179 0300 	sbcs.w	r3, r9, #0
    518a:	bfbc      	itt	lt
    518c:	f04f 0800 	movlt.w	r8, #0
    5190:	f04f 0900 	movlt.w	r9, #0
	}
#endif

	(void)z_abort_timeout(&timer->timeout);
    5194:	4630      	mov	r0, r6
    5196:	f001 fc8a 	bl	6aae <z_abort_timeout>
	timer->period = period;
	timer->status = 0U;
    519a:	2300      	movs	r3, #0

	z_add_timeout(&timer->timeout, z_timer_expiration_handler,
    519c:	4907      	ldr	r1, [pc, #28]	; (51bc <z_impl_k_timer_start+0xb4>)
	timer->status = 0U;
    519e:	6333      	str	r3, [r6, #48]	; 0x30
	z_add_timeout(&timer->timeout, z_timer_expiration_handler,
    51a0:	4642      	mov	r2, r8
    51a2:	464b      	mov	r3, r9
    51a4:	4630      	mov	r0, r6
	timer->period = period;
    51a6:	e9c6 450a 	strd	r4, r5, [r6, #40]	; 0x28
		     duration);
}
    51aa:	b002      	add	sp, #8
    51ac:	e8bd 4f70 	ldmia.w	sp!, {r4, r5, r6, r8, r9, sl, fp, lr}
	z_add_timeout(&timer->timeout, z_timer_expiration_handler,
    51b0:	f7ff be38 	b.w	4e24 <z_add_timeout>
}
    51b4:	b002      	add	sp, #8
    51b6:	e8bd 8f70 	ldmia.w	sp!, {r4, r5, r6, r8, r9, sl, fp, pc}
    51ba:	bf00      	nop
    51bc:	000050bd 	.word	0x000050bd

000051c0 <z_mrsh_k_timer_start>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_timer_start(struct k_timer * timer, k_timeout_t duration, k_timeout_t period);
uintptr_t z_mrsh_k_timer_start(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    51c0:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
	_current->syscall_frame = ssf;
    51c4:	4d13      	ldr	r5, [pc, #76]	; (5214 <z_mrsh_k_timer_start+0x54>)
{
    51c6:	4699      	mov	r9, r3
	_current->syscall_frame = ssf;
    51c8:	68ab      	ldr	r3, [r5, #8]
{
    51ca:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    51cc:	9a0c      	ldr	r2, [sp, #48]	; 0x30
    51ce:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    51d2:	4688      	mov	r8, r1
    51d4:	4606      	mov	r6, r0
#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_timer_start(struct k_timer *timer,
					k_timeout_t duration,
					k_timeout_t period)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    51d6:	f7fa ff81 	bl	dc <z_object_find>
    51da:	2200      	movs	r2, #0
    51dc:	210a      	movs	r1, #10
    51de:	f000 f9ab 	bl	5538 <z_object_validate>
    51e2:	4604      	mov	r4, r0
    51e4:	b130      	cbz	r0, 51f4 <z_mrsh_k_timer_start+0x34>
    51e6:	f001 fcdf 	bl	6ba8 <arch_is_user_context>
    51ea:	68ab      	ldr	r3, [r5, #8]
    51ec:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    51f0:	f000 ffac 	bl	614c <arch_syscall_oops>
	z_impl_k_timer_start(timer, duration, period);
    51f4:	9b0a      	ldr	r3, [sp, #40]	; 0x28
    51f6:	9301      	str	r3, [sp, #4]
    51f8:	4630      	mov	r0, r6
    51fa:	463b      	mov	r3, r7
    51fc:	f8cd 9000 	str.w	r9, [sp]
    5200:	4642      	mov	r2, r8
    5202:	f7ff ff81 	bl	5108 <z_impl_k_timer_start>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm1;
	parm1.split.lo = arg3;
	parm1.split.hi = arg4;
	z_vrfy_k_timer_start(*(struct k_timer **)&arg0, parm0.val, parm1.val)
;
	_current->syscall_frame = NULL;
    5206:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    5208:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    520a:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    520e:	b003      	add	sp, #12
    5210:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
    5214:	20000664 	.word	0x20000664

00005218 <z_mrsh_k_timer_stop>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_timer_stop(struct k_timer * timer);
uintptr_t z_mrsh_k_timer_stop(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5218:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    521a:	4d0e      	ldr	r5, [pc, #56]	; (5254 <z_mrsh_k_timer_stop+0x3c>)
    521c:	9a06      	ldr	r2, [sp, #24]
    521e:	68ab      	ldr	r3, [r5, #8]
    5220:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    5224:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_timer_stop(struct k_timer *timer)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    5226:	f7fa ff59 	bl	dc <z_object_find>
    522a:	2200      	movs	r2, #0
    522c:	210a      	movs	r1, #10
    522e:	f000 f983 	bl	5538 <z_object_validate>
    5232:	4604      	mov	r4, r0
    5234:	b130      	cbz	r0, 5244 <z_mrsh_k_timer_stop+0x2c>
    5236:	f001 fcb7 	bl	6ba8 <arch_is_user_context>
    523a:	68ab      	ldr	r3, [r5, #8]
    523c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5240:	f000 ff84 	bl	614c <arch_syscall_oops>
	z_impl_k_timer_stop(timer);
    5244:	4630      	mov	r0, r6
    5246:	f001 fcc6 	bl	6bd6 <z_impl_k_timer_stop>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_timer_stop(*(struct k_timer **)&arg0)
;
	_current->syscall_frame = NULL;
    524a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    524c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    524e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    5252:	bd70      	pop	{r4, r5, r6, pc}
    5254:	20000664 	.word	0x20000664

00005258 <z_mrsh_k_timer_status_get>:
#include <syscalls/kernel.h>

extern uint32_t z_vrfy_k_timer_status_get(struct k_timer * timer);
uintptr_t z_mrsh_k_timer_status_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5258:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    525a:	4d0e      	ldr	r5, [pc, #56]	; (5294 <z_mrsh_k_timer_status_get+0x3c>)
    525c:	9a06      	ldr	r2, [sp, #24]
    525e:	68ab      	ldr	r3, [r5, #8]
    5260:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    5264:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline uint32_t z_vrfy_k_timer_status_get(struct k_timer *timer)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    5266:	f7fa ff39 	bl	dc <z_object_find>
    526a:	2200      	movs	r2, #0
    526c:	210a      	movs	r1, #10
    526e:	f000 f963 	bl	5538 <z_object_validate>
    5272:	4604      	mov	r4, r0
    5274:	b130      	cbz	r0, 5284 <z_mrsh_k_timer_status_get+0x2c>
    5276:	f001 fc97 	bl	6ba8 <arch_is_user_context>
    527a:	68ab      	ldr	r3, [r5, #8]
    527c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5280:	f000 ff64 	bl	614c <arch_syscall_oops>
	return z_impl_k_timer_status_get(timer);
    5284:	4630      	mov	r0, r6
    5286:	f001 fcc8 	bl	6c1a <z_impl_k_timer_status_get>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	uint32_t ret = z_vrfy_k_timer_status_get(*(struct k_timer **)&arg0)
;
	_current->syscall_frame = NULL;
    528a:	68ab      	ldr	r3, [r5, #8]
    528c:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    5290:	bd70      	pop	{r4, r5, r6, pc}
    5292:	bf00      	nop
    5294:	20000664 	.word	0x20000664

00005298 <z_impl_k_timer_status_sync>:
}
#include <syscalls/k_timer_status_get_mrsh.c>
#endif

uint32_t z_impl_k_timer_status_sync(struct k_timer *timer)
{
    5298:	b513      	push	{r0, r1, r4, lr}
    529a:	4604      	mov	r4, r0
	__asm__ volatile(
    529c:	f04f 0320 	mov.w	r3, #32
    52a0:	f3ef 8111 	mrs	r1, BASEPRI
    52a4:	f383 8811 	msr	BASEPRI, r3
    52a8:	f3bf 8f6f 	isb	sy
	__ASSERT(!arch_is_in_isr(), "");

	k_spinlock_key_t key = k_spin_lock(&lock);
	uint32_t result = timer->status;
    52ac:	6b00      	ldr	r0, [r0, #48]	; 0x30

	if (result == 0U) {
    52ae:	b9a8      	cbnz	r0, 52dc <z_impl_k_timer_status_sync+0x44>
		if (!z_is_inactive_timeout(&timer->timeout)) {
    52b0:	6823      	ldr	r3, [r4, #0]
    52b2:	b19b      	cbz	r3, 52dc <z_impl_k_timer_status_sync+0x44>
			/* wait for timer to expire or stop */
			(void)z_pend_curr(&lock, key, &timer->wait_q, K_FOREVER);
    52b4:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    52b8:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    52bc:	e9cd 2300 	strd	r2, r3, [sp]
    52c0:	480a      	ldr	r0, [pc, #40]	; (52ec <z_impl_k_timer_status_sync+0x54>)
    52c2:	f104 0218 	add.w	r2, r4, #24
    52c6:	f7fe ff15 	bl	40f4 <z_pend_curr>
    52ca:	f04f 0320 	mov.w	r3, #32
    52ce:	f3ef 8111 	mrs	r1, BASEPRI
    52d2:	f383 8811 	msr	BASEPRI, r3
    52d6:	f3bf 8f6f 	isb	sy

			/* get updated timer status */
			key = k_spin_lock(&lock);
			result = timer->status;
    52da:	6b20      	ldr	r0, [r4, #48]	; 0x30
		}
	} else {
		/* timer has already expired at least once */
	}

	timer->status = 0U;
    52dc:	2300      	movs	r3, #0
    52de:	6323      	str	r3, [r4, #48]	; 0x30
	__asm__ volatile(
    52e0:	f381 8811 	msr	BASEPRI, r1
    52e4:	f3bf 8f6f 	isb	sy
	k_spin_unlock(&lock, key);

	return result;
}
    52e8:	b002      	add	sp, #8
    52ea:	bd10      	pop	{r4, pc}
    52ec:	200013f4 	.word	0x200013f4

000052f0 <z_mrsh_k_timer_status_sync>:
#include <syscalls/kernel.h>

extern uint32_t z_vrfy_k_timer_status_sync(struct k_timer * timer);
uintptr_t z_mrsh_k_timer_status_sync(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    52f0:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    52f2:	4d0e      	ldr	r5, [pc, #56]	; (532c <z_mrsh_k_timer_status_sync+0x3c>)
    52f4:	9a06      	ldr	r2, [sp, #24]
    52f6:	68ab      	ldr	r3, [r5, #8]
    52f8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    52fc:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline uint32_t z_vrfy_k_timer_status_sync(struct k_timer *timer)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    52fe:	f7fa feed 	bl	dc <z_object_find>
    5302:	2200      	movs	r2, #0
    5304:	210a      	movs	r1, #10
    5306:	f000 f917 	bl	5538 <z_object_validate>
    530a:	4604      	mov	r4, r0
    530c:	b130      	cbz	r0, 531c <z_mrsh_k_timer_status_sync+0x2c>
    530e:	f001 fc4b 	bl	6ba8 <arch_is_user_context>
    5312:	68ab      	ldr	r3, [r5, #8]
    5314:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5318:	f000 ff18 	bl	614c <arch_syscall_oops>
	return z_impl_k_timer_status_sync(timer);
    531c:	4630      	mov	r0, r6
    531e:	f7ff ffbb 	bl	5298 <z_impl_k_timer_status_sync>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	uint32_t ret = z_vrfy_k_timer_status_sync(*(struct k_timer **)&arg0)
;
	_current->syscall_frame = NULL;
    5322:	68ab      	ldr	r3, [r5, #8]
    5324:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    5328:	bd70      	pop	{r4, r5, r6, pc}
    532a:	bf00      	nop
    532c:	20000664 	.word	0x20000664

00005330 <z_mrsh_k_timer_remaining_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_timer_remaining_ticks(struct k_timer * timer);
uintptr_t z_mrsh_k_timer_remaining_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5330:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    5332:	4d0e      	ldr	r5, [pc, #56]	; (536c <z_mrsh_k_timer_remaining_ticks+0x3c>)
    5334:	9a06      	ldr	r2, [sp, #24]
    5336:	68ab      	ldr	r3, [r5, #8]
    5338:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    533c:	4606      	mov	r6, r0
}
#include <syscalls/k_timer_status_sync_mrsh.c>

static inline k_ticks_t z_vrfy_k_timer_remaining_ticks(struct k_timer *timer)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    533e:	f7fa fecd 	bl	dc <z_object_find>
    5342:	2200      	movs	r2, #0
    5344:	210a      	movs	r1, #10
    5346:	f000 f8f7 	bl	5538 <z_object_validate>
    534a:	4604      	mov	r4, r0
    534c:	b130      	cbz	r0, 535c <z_mrsh_k_timer_remaining_ticks+0x2c>
    534e:	f001 fc2b 	bl	6ba8 <arch_is_user_context>
    5352:	68ab      	ldr	r3, [r5, #8]
    5354:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5358:	f000 fef8 	bl	614c <arch_syscall_oops>
	return z_timeout_remaining(&timer->timeout);
    535c:	4630      	mov	r0, r6
    535e:	f001 fbbc 	bl	6ada <z_timeout_remaining>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_timer_remaining_ticks(*(struct k_timer **)&arg0)
;
	_current->syscall_frame = NULL;
    5362:	68ab      	ldr	r3, [r5, #8]
    5364:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    5368:	bd70      	pop	{r4, r5, r6, pc}
    536a:	bf00      	nop
    536c:	20000664 	.word	0x20000664

00005370 <z_mrsh_k_timer_expires_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_timer_expires_ticks(struct k_timer * timer);
uintptr_t z_mrsh_k_timer_expires_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5370:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    5372:	4d0e      	ldr	r5, [pc, #56]	; (53ac <z_mrsh_k_timer_expires_ticks+0x3c>)
    5374:	9a06      	ldr	r2, [sp, #24]
    5376:	68ab      	ldr	r3, [r5, #8]
    5378:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    537c:	4606      	mov	r6, r0
}
#include <syscalls/k_timer_remaining_ticks_mrsh.c>

static inline k_ticks_t z_vrfy_k_timer_expires_ticks(struct k_timer *timer)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    537e:	f7fa fead 	bl	dc <z_object_find>
    5382:	2200      	movs	r2, #0
    5384:	210a      	movs	r1, #10
    5386:	f000 f8d7 	bl	5538 <z_object_validate>
    538a:	4604      	mov	r4, r0
    538c:	b130      	cbz	r0, 539c <z_mrsh_k_timer_expires_ticks+0x2c>
    538e:	f001 fc0b 	bl	6ba8 <arch_is_user_context>
    5392:	68ab      	ldr	r3, [r5, #8]
    5394:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5398:	f000 fed8 	bl	614c <arch_syscall_oops>
	return z_timeout_expires(&timer->timeout);
    539c:	4630      	mov	r0, r6
    539e:	f7ff fdc9 	bl	4f34 <z_timeout_expires>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_timer_expires_ticks(*(struct k_timer **)&arg0)
;
	_current->syscall_frame = NULL;
    53a2:	68ab      	ldr	r3, [r5, #8]
    53a4:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    53a8:	bd70      	pop	{r4, r5, r6, pc}
    53aa:	bf00      	nop
    53ac:	20000664 	.word	0x20000664

000053b0 <z_mrsh_k_timer_user_data_get>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_timer_user_data_get(struct k_timer * timer);
uintptr_t z_mrsh_k_timer_user_data_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    53b0:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    53b2:	4c0d      	ldr	r4, [pc, #52]	; (53e8 <z_mrsh_k_timer_user_data_get+0x38>)
    53b4:	9a06      	ldr	r2, [sp, #24]
    53b6:	68a3      	ldr	r3, [r4, #8]
    53b8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    53bc:	4605      	mov	r5, r0
}
#include <syscalls/k_timer_expires_ticks_mrsh.c>

static inline void *z_vrfy_k_timer_user_data_get(struct k_timer *timer)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    53be:	f7fa fe8d 	bl	dc <z_object_find>
    53c2:	2200      	movs	r2, #0
    53c4:	210a      	movs	r1, #10
    53c6:	f000 f8b7 	bl	5538 <z_object_validate>
    53ca:	4603      	mov	r3, r0
    53cc:	b130      	cbz	r0, 53dc <z_mrsh_k_timer_user_data_get+0x2c>
    53ce:	f001 fbeb 	bl	6ba8 <arch_is_user_context>
    53d2:	68a3      	ldr	r3, [r4, #8]
    53d4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    53d8:	f000 feb8 	bl	614c <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_timer_user_data_get(*(struct k_timer **)&arg0)
;
	_current->syscall_frame = NULL;
    53dc:	68a2      	ldr	r2, [r4, #8]
	return z_impl_k_timer_user_data_get(timer);
    53de:	6b68      	ldr	r0, [r5, #52]	; 0x34
    53e0:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    53e4:	bd38      	pop	{r3, r4, r5, pc}
    53e6:	bf00      	nop
    53e8:	20000664 	.word	0x20000664

000053ec <z_mrsh_k_timer_user_data_set>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_timer_user_data_set(struct k_timer * timer, void * user_data);
uintptr_t z_mrsh_k_timer_user_data_set(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    53ec:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    53ee:	4c0d      	ldr	r4, [pc, #52]	; (5424 <z_mrsh_k_timer_user_data_set+0x38>)
    53f0:	9a06      	ldr	r2, [sp, #24]
    53f2:	68a3      	ldr	r3, [r4, #8]
    53f4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    53f8:	460e      	mov	r6, r1
    53fa:	4605      	mov	r5, r0
#include <syscalls/k_timer_user_data_get_mrsh.c>

static inline void z_vrfy_k_timer_user_data_set(struct k_timer *timer,
						void *user_data)
{
	Z_OOPS(Z_SYSCALL_OBJ(timer, K_OBJ_TIMER));
    53fc:	f7fa fe6e 	bl	dc <z_object_find>
    5400:	2200      	movs	r2, #0
    5402:	210a      	movs	r1, #10
    5404:	f000 f898 	bl	5538 <z_object_validate>
    5408:	b130      	cbz	r0, 5418 <z_mrsh_k_timer_user_data_set+0x2c>
    540a:	f001 fbcd 	bl	6ba8 <arch_is_user_context>
    540e:	68a3      	ldr	r3, [r4, #8]
    5410:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5414:	f000 fe9a 	bl	614c <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_timer_user_data_set(*(struct k_timer **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    5418:	68a2      	ldr	r2, [r4, #8]
	timer->user_data = user_data;
    541a:	636e      	str	r6, [r5, #52]	; 0x34
    541c:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    5420:	bd70      	pop	{r4, r5, r6, pc}
    5422:	bf00      	nop
    5424:	20000664 	.word	0x20000664

00005428 <z_mrsh_k_futex_wake>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_futex_wake(struct k_futex * futex, bool wake_all);
uintptr_t z_mrsh_k_futex_wake(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5428:	b573      	push	{r0, r1, r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    542a:	4c0e      	ldr	r4, [pc, #56]	; (5464 <z_mrsh_k_futex_wake+0x3c>)
    542c:	9a08      	ldr	r2, [sp, #32]
    542e:	68a3      	ldr	r3, [r4, #8]
{
    5430:	9101      	str	r1, [sp, #4]
	_current->syscall_frame = ssf;
    5432:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_futex_wake(*(struct k_futex **)&arg0, *(bool*)&arg1)
    5436:	b2ce      	uxtb	r6, r1
	return woken;
}

static inline int z_vrfy_k_futex_wake(struct k_futex *futex, bool wake_all)
{
	if (Z_SYSCALL_MEMORY_WRITE(futex, sizeof(struct k_futex)) != 0) {
    5438:	2201      	movs	r2, #1
    543a:	2104      	movs	r1, #4
{
    543c:	4605      	mov	r5, r0
    543e:	f000 feb3 	bl	61a8 <arch_buffer_validate>
    5442:	b148      	cbz	r0, 5458 <z_mrsh_k_futex_wake+0x30>
    5444:	f001 fbfa 	bl	6c3c <arch_is_user_context>
		return -EACCES;
    5448:	f06f 000c 	mvn.w	r0, #12
;
	_current->syscall_frame = NULL;
    544c:	68a3      	ldr	r3, [r4, #8]
    544e:	2200      	movs	r2, #0
    5450:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    5454:	b002      	add	sp, #8
    5456:	bd70      	pop	{r4, r5, r6, pc}
	}

	return z_impl_k_futex_wake(futex, wake_all);
    5458:	4631      	mov	r1, r6
    545a:	4628      	mov	r0, r5
    545c:	f001 fbf8 	bl	6c50 <z_impl_k_futex_wake>
    5460:	e7f4      	b.n	544c <z_mrsh_k_futex_wake+0x24>
    5462:	bf00      	nop
    5464:	20000664 	.word	0x20000664

00005468 <z_mrsh_k_futex_wait>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_futex_wait(struct k_futex * futex, int expected, k_timeout_t timeout);
uintptr_t z_mrsh_k_futex_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5468:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    546c:	4c0f      	ldr	r4, [pc, #60]	; (54ac <z_mrsh_k_futex_wait+0x44>)
{
    546e:	461f      	mov	r7, r3
	_current->syscall_frame = ssf;
    5470:	68a3      	ldr	r3, [r4, #8]
{
    5472:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    5474:	9a08      	ldr	r2, [sp, #32]
    5476:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    547a:	460e      	mov	r6, r1
}

static inline int z_vrfy_k_futex_wait(struct k_futex *futex, int expected,
				      k_timeout_t timeout)
{
	if (Z_SYSCALL_MEMORY_WRITE(futex, sizeof(struct k_futex)) != 0) {
    547c:	2201      	movs	r2, #1
    547e:	2104      	movs	r1, #4
    5480:	4605      	mov	r5, r0
    5482:	f000 fe91 	bl	61a8 <arch_buffer_validate>
    5486:	b148      	cbz	r0, 549c <z_mrsh_k_futex_wait+0x34>
    5488:	f001 fbd8 	bl	6c3c <arch_is_user_context>
		return -EACCES;
    548c:	f06f 000c 	mvn.w	r0, #12
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_futex_wait(*(struct k_futex **)&arg0, *(int*)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    5490:	68a3      	ldr	r3, [r4, #8]
    5492:	2200      	movs	r2, #0
    5494:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    5498:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	}

	return z_impl_k_futex_wait(futex, expected, timeout);
    549c:	4642      	mov	r2, r8
    549e:	463b      	mov	r3, r7
    54a0:	4631      	mov	r1, r6
    54a2:	4628      	mov	r0, r5
    54a4:	f001 fc01 	bl	6caa <z_impl_k_futex_wait>
    54a8:	e7f2      	b.n	5490 <z_mrsh_k_futex_wait+0x28>
    54aa:	bf00      	nop
    54ac:	20000664 	.word	0x20000664

000054b0 <init_mem_domain_module>:
	thread->mem_domain_info.mem_domain = NULL;
	k_spin_unlock(&lock, key);
}

static int init_mem_domain_module(struct device *arg)
{
    54b0:	b508      	push	{r3, lr}
	ARG_UNUSED(arg);

	max_partitions = arch_mem_domain_max_partitions_get();
    54b2:	f000 fe74 	bl	619e <arch_mem_domain_max_partitions_get>
    54b6:	4b02      	ldr	r3, [pc, #8]	; (54c0 <init_mem_domain_module+0x10>)
    54b8:	7018      	strb	r0, [r3, #0]
	 * out of bounds error.
	 */
	__ASSERT(max_partitions <= CONFIG_MAX_DOMAIN_PARTITIONS, "");

	return 0;
}
    54ba:	2000      	movs	r0, #0
    54bc:	bd08      	pop	{r3, pc}
    54be:	bf00      	nop
    54c0:	200013f4 	.word	0x200013f4

000054c4 <app_shmem_bss_zero>:

extern char __app_shmem_regions_start[];
extern char __app_shmem_regions_end[];

static int app_shmem_bss_zero(struct device *unused)
{
    54c4:	b538      	push	{r3, r4, r5, lr}
	struct z_app_region *region, *end;

	ARG_UNUSED(unused);

	end = (struct z_app_region *)&__app_shmem_regions_end;
	region = (struct z_app_region *)&__app_shmem_regions_start;
    54c6:	4c06      	ldr	r4, [pc, #24]	; (54e0 <app_shmem_bss_zero+0x1c>)

	for ( ; region < end; region++) {
    54c8:	4d06      	ldr	r5, [pc, #24]	; (54e4 <app_shmem_bss_zero+0x20>)
    54ca:	42ac      	cmp	r4, r5
    54cc:	d301      	bcc.n	54d2 <app_shmem_bss_zero+0xe>
		(void)memset(region->bss_start, 0, region->bss_size);
	}

	return 0;
}
    54ce:	2000      	movs	r0, #0
    54d0:	bd38      	pop	{r3, r4, r5, pc}
		(void)memset(region->bss_start, 0, region->bss_size);
    54d2:	6862      	ldr	r2, [r4, #4]
    54d4:	f854 0b08 	ldr.w	r0, [r4], #8
    54d8:	2100      	movs	r1, #0
    54da:	f000 feb2 	bl	6242 <memset>
	for ( ; region < end; region++) {
    54de:	e7f4      	b.n	54ca <app_shmem_bss_zero+0x6>
    54e0:	0000721c 	.word	0x0000721c
    54e4:	0000721c 	.word	0x0000721c

000054e8 <z_thread_perms_inherit>:
{
    54e8:	b530      	push	{r4, r5, lr}
    54ea:	b085      	sub	sp, #20
    54ec:	460d      	mov	r5, r1
    54ee:	4604      	mov	r4, r0
		thread_index_get(parent),
    54f0:	f001 fc71 	bl	6dd6 <thread_index_get>
	struct perm_ctx ctx = {
    54f4:	9001      	str	r0, [sp, #4]
		thread_index_get(child),
    54f6:	4628      	mov	r0, r5
    54f8:	f001 fc6d 	bl	6dd6 <thread_index_get>
	if ((ctx.parent_id != -1) && (ctx.child_id != -1)) {
    54fc:	9b01      	ldr	r3, [sp, #4]
    54fe:	3301      	adds	r3, #1
	struct perm_ctx ctx = {
    5500:	e9cd 0402 	strd	r0, r4, [sp, #8]
	if ((ctx.parent_id != -1) && (ctx.child_id != -1)) {
    5504:	d005      	beq.n	5512 <z_thread_perms_inherit+0x2a>
    5506:	3001      	adds	r0, #1
    5508:	d003      	beq.n	5512 <z_thread_perms_inherit+0x2a>
		z_object_wordlist_foreach(wordlist_cb, &ctx);
    550a:	4803      	ldr	r0, [pc, #12]	; (5518 <z_thread_perms_inherit+0x30>)
    550c:	a901      	add	r1, sp, #4
    550e:	f7fa fdff 	bl	110 <z_object_gperf_wordlist_foreach>
}
    5512:	b005      	add	sp, #20
    5514:	bd30      	pop	{r4, r5, pc}
    5516:	bf00      	nop
    5518:	00006d9b 	.word	0x00006d9b

0000551c <z_thread_perms_all_clear>:
{
    551c:	b508      	push	{r3, lr}
	uintptr_t index = thread_index_get(thread);
    551e:	f001 fc5a 	bl	6dd6 <thread_index_get>
	if (index != -1) {
    5522:	1c43      	adds	r3, r0, #1
	uintptr_t index = thread_index_get(thread);
    5524:	4601      	mov	r1, r0
	if (index != -1) {
    5526:	d004      	beq.n	5532 <z_thread_perms_all_clear+0x16>
}
    5528:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		z_object_wordlist_foreach(clear_perms_cb, (void *)index);
    552c:	4801      	ldr	r0, [pc, #4]	; (5534 <z_thread_perms_all_clear+0x18>)
    552e:	f7fa bdef 	b.w	110 <z_object_gperf_wordlist_foreach>
}
    5532:	bd08      	pop	{r3, pc}
    5534:	00006dd3 	.word	0x00006dd3

00005538 <z_object_validate>:
{
    5538:	b538      	push	{r3, r4, r5, lr}
    553a:	4615      	mov	r5, r2
	if (unlikely((ko == NULL) ||
    553c:	4604      	mov	r4, r0
    553e:	b368      	cbz	r0, 559c <z_object_validate+0x64>
    5540:	b111      	cbz	r1, 5548 <z_object_validate+0x10>
    5542:	7983      	ldrb	r3, [r0, #6]
    5544:	428b      	cmp	r3, r1
    5546:	d129      	bne.n	559c <z_object_validate+0x64>
	if ((ko->flags & K_OBJ_FLAG_PUBLIC) != 0U) {
    5548:	79e3      	ldrb	r3, [r4, #7]
    554a:	079a      	lsls	r2, r3, #30
    554c:	d50a      	bpl.n	5564 <z_object_validate+0x2c>
	if (likely(init == _OBJ_INIT_TRUE)) {
    554e:	2d00      	cmp	r5, #0
    5550:	d01c      	beq.n	558c <z_object_validate+0x54>
	} else if (init < _OBJ_INIT_TRUE) { /* _OBJ_INIT_FALSE case */
    5552:	da26      	bge.n	55a2 <z_object_validate+0x6a>
		if (unlikely((ko->flags & K_OBJ_FLAG_INITIALIZED) != 0U)) {
    5554:	79e3      	ldrb	r3, [r4, #7]
			return -EADDRINUSE;
    5556:	f013 0f01 	tst.w	r3, #1
    555a:	bf0c      	ite	eq
    555c:	2000      	moveq	r0, #0
    555e:	f06f 002f 	mvnne.w	r0, #47	; 0x2f
    5562:	e01a      	b.n	559a <z_object_validate+0x62>
	index = thread_index_get(_current);
    5564:	4b10      	ldr	r3, [pc, #64]	; (55a8 <z_object_validate+0x70>)
    5566:	6898      	ldr	r0, [r3, #8]
    5568:	f001 fc35 	bl	6dd6 <thread_index_get>
	if (index != -1) {
    556c:	1c43      	adds	r3, r0, #1
    556e:	d014      	beq.n	559a <z_object_validate+0x62>
}

static ALWAYS_INLINE
	int sys_bitfield_test_bit(mem_addr_t addr, unsigned int bit)
{
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    5570:	0942      	lsrs	r2, r0, #5
		return sys_bitfield_test_bit((mem_addr_t)&ko->perms, index);
    5572:	1d23      	adds	r3, r4, #4
    5574:	f000 001f 	and.w	r0, r0, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    5578:	f853 2022 	ldr.w	r2, [r3, r2, lsl #2]
	return temp & (1 << bit);
    557c:	2301      	movs	r3, #1
    557e:	fa03 f000 	lsl.w	r0, r3, r0
	if (unlikely(thread_perms_test(ko) == 0)) {
    5582:	4210      	tst	r0, r2
    5584:	d1e3      	bne.n	554e <z_object_validate+0x16>
		return -EPERM;
    5586:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    558a:	e006      	b.n	559a <z_object_validate+0x62>
		if (unlikely((ko->flags & K_OBJ_FLAG_INITIALIZED) == 0U)) {
    558c:	79e3      	ldrb	r3, [r4, #7]
			return -EINVAL;
    558e:	f013 0f01 	tst.w	r3, #1
    5592:	bf14      	ite	ne
    5594:	2000      	movne	r0, #0
    5596:	f06f 0015 	mvneq.w	r0, #21
}
    559a:	bd38      	pop	{r3, r4, r5, pc}
		return -EBADF;
    559c:	f06f 0008 	mvn.w	r0, #8
    55a0:	e7fb      	b.n	559a <z_object_validate+0x62>
	return 0;
    55a2:	2000      	movs	r0, #0
    55a4:	e7f9      	b.n	559a <z_object_validate+0x62>
    55a6:	bf00      	nop
    55a8:	20000664 	.word	0x20000664

000055ac <z_thread_malloc>:
#else
#define _HEAP_MEM_POOL	NULL
#endif

void *z_thread_malloc(size_t size)
{
    55ac:	b510      	push	{r4, lr}
    55ae:	4604      	mov	r4, r0
	void *ret;
	struct k_mem_pool *pool;

	if (k_is_in_isr()) {
    55b0:	f001 fa4b 	bl	6a4a <k_is_in_isr>
    55b4:	b950      	cbnz	r0, 55cc <z_thread_malloc+0x20>
		pool = _HEAP_MEM_POOL;
	} else {
		pool = _current->resource_pool;
    55b6:	4b07      	ldr	r3, [pc, #28]	; (55d4 <z_thread_malloc+0x28>)
    55b8:	689b      	ldr	r3, [r3, #8]
    55ba:	f8d3 3088 	ldr.w	r3, [r3, #136]	; 0x88
	}

	if (pool) {
    55be:	b13b      	cbz	r3, 55d0 <z_thread_malloc+0x24>
		ret = k_mem_pool_malloc(pool, size);
    55c0:	4621      	mov	r1, r4
    55c2:	4618      	mov	r0, r3
	} else {
		ret = NULL;
	}

	return ret;
}
    55c4:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		ret = k_mem_pool_malloc(pool, size);
    55c8:	f001 bca1 	b.w	6f0e <k_mem_pool_malloc>
		pool = _HEAP_MEM_POOL;
    55cc:	4b02      	ldr	r3, [pc, #8]	; (55d8 <z_thread_malloc+0x2c>)
    55ce:	e7f7      	b.n	55c0 <z_thread_malloc+0x14>
}
    55d0:	bd10      	pop	{r4, pc}
    55d2:	bf00      	nop
    55d4:	20000664 	.word	0x20000664
    55d8:	20002e1c 	.word	0x20002e1c

000055dc <z_mrsh_k_object_access_grant>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_object_access_grant(void * object, struct k_thread * thread);
uintptr_t z_mrsh_k_object_access_grant(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    55dc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    55de:	4d12      	ldr	r5, [pc, #72]	; (5628 <z_mrsh_k_object_access_grant+0x4c>)
    55e0:	9a08      	ldr	r2, [sp, #32]
    55e2:	68ab      	ldr	r3, [r5, #8]
{
    55e4:	4607      	mov	r7, r0
	_current->syscall_frame = ssf;
    55e6:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
static inline void z_vrfy_k_object_access_grant(void *object,
						struct k_thread *thread)
{
	struct z_object *ko;

	Z_OOPS(Z_SYSCALL_OBJ_INIT(thread, K_OBJ_THREAD));
    55ea:	4608      	mov	r0, r1
{
    55ec:	460e      	mov	r6, r1
    55ee:	f7fa fd75 	bl	dc <z_object_find>
    55f2:	2201      	movs	r2, #1
    55f4:	2109      	movs	r1, #9
    55f6:	f7ff ff9f 	bl	5538 <z_object_validate>
    55fa:	4604      	mov	r4, r0
    55fc:	b130      	cbz	r0, 560c <z_mrsh_k_object_access_grant+0x30>
    55fe:	f001 fca3 	bl	6f48 <arch_is_user_context>
	ko = validate_any_object(object);
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    5602:	68ab      	ldr	r3, [r5, #8]
    5604:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5608:	f000 fda0 	bl	614c <arch_syscall_oops>
	ko = validate_any_object(object);
    560c:	4638      	mov	r0, r7
    560e:	f001 fca5 	bl	6f5c <validate_any_object>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    5612:	2800      	cmp	r0, #0
    5614:	d0f3      	beq.n	55fe <z_mrsh_k_object_access_grant+0x22>
				    object));
	z_thread_perms_set(ko, thread);
    5616:	4631      	mov	r1, r6
    5618:	f001 fbf8 	bl	6e0c <z_thread_perms_set>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_object_access_grant(*(void **)&arg0, *(struct k_thread **)&arg1)
;
	_current->syscall_frame = NULL;
    561c:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    561e:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    5620:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    5624:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    5626:	bf00      	nop
    5628:	20000664 	.word	0x20000664

0000562c <z_mrsh_k_object_release>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_object_release(void * object);
uintptr_t z_mrsh_k_object_release(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    562c:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    562e:	4c0b      	ldr	r4, [pc, #44]	; (565c <z_mrsh_k_object_release+0x30>)
    5630:	9a04      	ldr	r2, [sp, #16]
    5632:	68a3      	ldr	r3, [r4, #8]
    5634:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

static inline void z_vrfy_k_object_release(void *object)
{
	struct z_object *ko;

	ko = validate_any_object((void *)object);
    5638:	f001 fc90 	bl	6f5c <validate_any_object>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    563c:	b930      	cbnz	r0, 564c <z_mrsh_k_object_release+0x20>
    563e:	f001 fc83 	bl	6f48 <arch_is_user_context>
    5642:	68a3      	ldr	r3, [r4, #8]
    5644:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5648:	f000 fd80 	bl	614c <arch_syscall_oops>
				    (void *)object));
	z_thread_perms_clear(ko, _current);
    564c:	68a1      	ldr	r1, [r4, #8]
    564e:	f001 fbf1 	bl	6e34 <z_thread_perms_clear>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_object_release(*(void **)&arg0)
;
	_current->syscall_frame = NULL;
    5652:	68a3      	ldr	r3, [r4, #8]
    5654:	2000      	movs	r0, #0
    5656:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    565a:	bd10      	pop	{r4, pc}
    565c:	20000664 	.word	0x20000664

00005660 <z_mrsh_k_object_alloc>:

extern void * z_vrfy_k_object_alloc(enum k_objects otype);
uintptr_t z_mrsh_k_object_alloc(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    5660:	4b02      	ldr	r3, [pc, #8]	; (566c <z_mrsh_k_object_alloc+0xc>)
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_object_alloc(*(enum k_objects*)&arg0)
;
	_current->syscall_frame = NULL;
    5662:	689b      	ldr	r3, [r3, #8]
    5664:	2000      	movs	r0, #0
    5666:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    566a:	4770      	bx	lr
    566c:	20000664 	.word	0x20000664

00005670 <statics_init>:
	z_waitq_init(&h->wait_q);
	sys_heap_init(&h->heap, mem, bytes);
}

static int statics_init(struct device *unused)
{
    5670:	b538      	push	{r3, r4, r5, lr}
	ARG_UNUSED(unused);
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    5672:	4c06      	ldr	r4, [pc, #24]	; (568c <statics_init+0x1c>)
    5674:	4d06      	ldr	r5, [pc, #24]	; (5690 <statics_init+0x20>)
    5676:	42ac      	cmp	r4, r5
    5678:	d301      	bcc.n	567e <statics_init+0xe>
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
	}
	return 0;
}
    567a:	2000      	movs	r0, #0
    567c:	bd38      	pop	{r3, r4, r5, pc}
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
    567e:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
    5682:	4620      	mov	r0, r4
    5684:	f001 fc77 	bl	6f76 <k_heap_init>
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    5688:	3414      	adds	r4, #20
    568a:	e7f4      	b.n	5676 <statics_init+0x6>
    568c:	20002e60 	.word	0x20002e60
    5690:	20002e74 	.word	0x20002e74

00005694 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5694:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5698:	b923      	cbnz	r3, 56a4 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    569a:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    569e:	f000 0001 	and.w	r0, r0, #1
    56a2:	4770      	bx	lr
		return false;
    56a4:	2000      	movs	r0, #0
}
    56a6:	4770      	bx	lr

000056a8 <k_sleep>:
{
    56a8:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    56ac:	4602      	mov	r2, r0
	ret = arch_is_user_context();
    56ae:	f7ff fff1 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
    56b2:	b120      	cbz	r0, 56be <k_sleep+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    56b4:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    56b6:	2688      	movs	r6, #136	; 0x88
	__asm__ volatile("svc %[svid]\n"
    56b8:	df03      	svc	3
}
    56ba:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    56be:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_k_sleep(timeout);
    56c2:	4610      	mov	r0, r2
    56c4:	f7fe be38 	b.w	4338 <z_impl_k_sleep>

000056c8 <gpio_pin_configure.constprop.0>:
static inline int gpio_pin_configure(struct device *port, gpio_pin_t pin,
    56c8:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
	struct gpio_driver_data *data =
    56cc:	68c7      	ldr	r7, [r0, #12]
	ret = gpio_config(port, pin, flags);
    56ce:	f88d 1007 	strb.w	r1, [sp, #7]
static inline int gpio_pin_configure(struct device *port, gpio_pin_t pin,
    56d2:	4604      	mov	r4, r0
    56d4:	460d      	mov	r5, r1
    56d6:	f7ff ffdd 	bl	5694 <arch_is_user_context>

extern int z_impl_gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
static inline int gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    56da:	b180      	cbz	r0, 56fe <gpio_pin_configure.constprop.0+0x36>
	register uint32_t ret __asm__("r0") = arg1;
    56dc:	4620      	mov	r0, r4
	register uint32_t r1 __asm__("r1") = arg2;
    56de:	f8dd 1007 	ldr.w	r1, [sp, #7]
	register uint32_t r2 __asm__("r2") = arg3;
    56e2:	f240 6201 	movw	r2, #1537	; 0x601
	register uint32_t r6 __asm__("r6") = call_id;
    56e6:	2644      	movs	r6, #68	; 0x44
	__asm__ volatile("svc %[svid]\n"
    56e8:	df03      	svc	3
	if (ret != 0) {
    56ea:	b928      	cbnz	r0, 56f8 <gpio_pin_configure.constprop.0+0x30>
		data->invert |= (gpio_port_pins_t)BIT(pin);
    56ec:	2301      	movs	r3, #1
    56ee:	fa03 f505 	lsl.w	r5, r3, r5
    56f2:	683b      	ldr	r3, [r7, #0]
    56f4:	432b      	orrs	r3, r5
    56f6:	603b      	str	r3, [r7, #0]
}
    56f8:	b002      	add	sp, #8
    56fa:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return api->pin_configure(port, pin, flags);
    56fe:	68a3      	ldr	r3, [r4, #8]
    5700:	f89d 1007 	ldrb.w	r1, [sp, #7]
    5704:	681b      	ldr	r3, [r3, #0]
    5706:	f240 6201 	movw	r2, #1537	; 0x601
    570a:	4620      	mov	r0, r4
    570c:	4798      	blx	r3
		return (int) arch_syscall_invoke3(*(uintptr_t *)&port, *(uintptr_t *)&pin, *(uintptr_t *)&flags, K_SYSCALL_GPIO_CONFIG);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_config(port, pin, flags);
    570e:	e7ec      	b.n	56ea <gpio_pin_configure.constprop.0+0x22>

00005710 <k_thread_create.constprop.0>:
static inline k_tid_t k_thread_create(struct k_thread * new_thread, k_thread_stack_t * stack, size_t stack_size, k_thread_entry_t entry, void * p1, void * p2, void * p3, int prio, uint32_t options, k_timeout_t delay)
    5710:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    5714:	b08f      	sub	sp, #60	; 0x3c
    5716:	4616      	mov	r6, r2
    5718:	e9dd 9818 	ldrd	r9, r8, [sp, #96]	; 0x60
    571c:	e9dd 2716 	ldrd	r2, r7, [sp, #88]	; 0x58
    5720:	4605      	mov	r5, r0
    5722:	461c      	mov	r4, r3
    5724:	f7ff ffb6 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
    5728:	b188      	cbz	r0, 574e <k_thread_create.constprop.0+0x3e>
		uintptr_t more[] = {
    572a:	2300      	movs	r3, #0
    572c:	e9cd 3709 	strd	r3, r7, [sp, #36]	; 0x24
    5730:	e9cd 390b 	strd	r3, r9, [sp, #44]	; 0x2c
    5734:	9208      	str	r2, [sp, #32]
	register uint32_t ret __asm__("r0") = arg1;
    5736:	4628      	mov	r0, r5
	register uint32_t r3 __asm__("r3") = arg4;
    5738:	4633      	mov	r3, r6
    573a:	f8cd 8034 	str.w	r8, [sp, #52]	; 0x34
	register uint32_t r2 __asm__("r2") = arg3;
    573e:	f44f 7200 	mov.w	r2, #512	; 0x200
	register uint32_t r5 __asm__("r5") = arg6;
    5742:	ad08      	add	r5, sp, #32
	register uint32_t r6 __asm__("r6") = call_id;
    5744:	268e      	movs	r6, #142	; 0x8e
	__asm__ volatile("svc %[svid]\n"
    5746:	df03      	svc	3
}
    5748:	b00f      	add	sp, #60	; 0x3c
    574a:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
    574e:	e9cd 2001 	strd	r2, r0, [sp, #4]
    5752:	e9cd 7003 	strd	r7, r0, [sp, #12]
    5756:	e9cd 9806 	strd	r9, r8, [sp, #24]
    575a:	9400      	str	r4, [sp, #0]
    575c:	4633      	mov	r3, r6
    575e:	f44f 7200 	mov.w	r2, #512	; 0x200
    5762:	4628      	mov	r0, r5
    5764:	f001 f983 	bl	6a6e <z_impl_k_thread_create>
    5768:	e7ee      	b.n	5748 <k_thread_create.constprop.0+0x38>

0000576a <k_thread_name_set>:
{
    576a:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    576e:	4602      	mov	r2, r0
    5770:	f7ff ff90 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
    5774:	b120      	cbz	r0, 5780 <k_thread_name_set+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    5776:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    5778:	2694      	movs	r6, #148	; 0x94
	__asm__ volatile("svc %[svid]\n"
    577a:	df03      	svc	3
}
    577c:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    5780:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_k_thread_name_set(thread_id, value);
    5784:	4610      	mov	r0, r2
    5786:	f001 b968 	b.w	6a5a <z_impl_k_thread_name_set>

0000578a <gpio_port_set_bits_raw>:
}


extern int z_impl_gpio_port_set_bits_raw(struct device * port, gpio_port_pins_t pins);
static inline int gpio_port_set_bits_raw(struct device * port, gpio_port_pins_t pins)
{
    578a:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    578e:	4602      	mov	r2, r0
    5790:	f7ff ff80 	bl	5694 <arch_is_user_context>
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    5794:	b120      	cbz	r0, 57a0 <gpio_port_set_bits_raw+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    5796:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    5798:	2649      	movs	r6, #73	; 0x49
	__asm__ volatile("svc %[svid]\n"
    579a:	df03      	svc	3
		return (int) arch_syscall_invoke2(*(uintptr_t *)&port, *(uintptr_t *)&pins, K_SYSCALL_GPIO_PORT_SET_BITS_RAW);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_port_set_bits_raw(port, pins);
}
    579c:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return api->port_set_bits_raw(port, pins);
    57a0:	6893      	ldr	r3, [r2, #8]
    57a2:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
    57a6:	68db      	ldr	r3, [r3, #12]
    57a8:	4610      	mov	r0, r2
    57aa:	4718      	bx	r3

000057ac <gpio_port_clear_bits_raw>:


extern int z_impl_gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins);
static inline int gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins)
{
    57ac:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    57b0:	4602      	mov	r2, r0
    57b2:	f7ff ff6f 	bl	5694 <arch_is_user_context>
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    57b6:	b120      	cbz	r0, 57c2 <gpio_port_clear_bits_raw+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    57b8:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    57ba:	2647      	movs	r6, #71	; 0x47
	__asm__ volatile("svc %[svid]\n"
    57bc:	df03      	svc	3
		return (int) arch_syscall_invoke2(*(uintptr_t *)&port, *(uintptr_t *)&pins, K_SYSCALL_GPIO_PORT_CLEAR_BITS_RAW);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_port_clear_bits_raw(port, pins);
}
    57be:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return api->port_clear_bits_raw(port, pins);
    57c2:	6893      	ldr	r3, [r2, #8]
    57c4:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
    57c8:	691b      	ldr	r3, [r3, #16]
    57ca:	4610      	mov	r0, r2
    57cc:	4718      	bx	r3

000057ce <k_thread_suspend>:
{
    57ce:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    57d2:	4602      	mov	r2, r0
    57d4:	f7ff ff5e 	bl	5694 <arch_is_user_context>
	if (z_syscall_trap()) {
    57d8:	b120      	cbz	r0, 57e4 <k_thread_suspend+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    57da:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    57dc:	269a      	movs	r6, #154	; 0x9a
	__asm__ volatile("svc %[svid]\n"
    57de:	df03      	svc	3
}
    57e0:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    57e4:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_thread_suspend(thread);
    57e8:	4610      	mov	r0, r2
    57ea:	f7fe bb59 	b.w	3ea0 <z_impl_k_thread_suspend>

000057ee <sys_notify_validate>:

int sys_notify_validate(struct sys_notify *notify)
{
	int rv = 0;

	if (notify == NULL) {
    57ee:	4603      	mov	r3, r0
    57f0:	b158      	cbz	r0, 580a <sys_notify_validate+0x1c>
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    57f2:	6842      	ldr	r2, [r0, #4]
	return method & SYS_NOTIFY_METHOD_MASK;
    57f4:	f002 0203 	and.w	r2, r2, #3
		return -EINVAL;
	}

	/* Validate configuration based on mode */
	switch (sys_notify_get_method(notify)) {
    57f8:	2a01      	cmp	r2, #1
    57fa:	d003      	beq.n	5804 <sys_notify_validate+0x16>
    57fc:	2a03      	cmp	r2, #3
    57fe:	d104      	bne.n	580a <sys_notify_validate+0x1c>
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		if (notify->method.callback == NULL) {
    5800:	6802      	ldr	r2, [r0, #0]
    5802:	b112      	cbz	r2, 580a <sys_notify_validate+0x1c>
		break;
	}

	/* Clear the result here instead of in all callers. */
	if (rv == 0) {
		notify->result = 0;
    5804:	2000      	movs	r0, #0
    5806:	6098      	str	r0, [r3, #8]
    5808:	4770      	bx	lr
		return -EINVAL;
    580a:	f06f 0015 	mvn.w	r0, #21
	}

	return rv;
}
    580e:	4770      	bx	lr

00005810 <sys_notify_finalize>:
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    5810:	6842      	ldr	r2, [r0, #4]
	uint32_t method = sys_notify_get_method(notify);

	/* Store the result and capture secondary notification
	 * information.
	 */
	notify->result = res;
    5812:	6081      	str	r1, [r0, #8]
	return method & SYS_NOTIFY_METHOD_MASK;
    5814:	f002 0203 	and.w	r2, r2, #3
	switch (method) {
    5818:	2a03      	cmp	r2, #3
    581a:	f04f 0200 	mov.w	r2, #0
{
    581e:	4603      	mov	r3, r0
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		rv = notify->method.callback;
    5820:	bf0c      	ite	eq
    5822:	6800      	ldreq	r0, [r0, #0]
	sys_notify_generic_callback rv = 0;
    5824:	4610      	movne	r0, r2
	/* Mark completion by clearing the flags field to the
	 * completed state, releasing any spin-waiters, then complete
	 * secondary notification.
	 */
	compiler_barrier();
	notify->flags = SYS_NOTIFY_METHOD_COMPLETED;
    5826:	605a      	str	r2, [r3, #4]
	if (IS_ENABLED(CONFIG_POLL) && (sig != NULL)) {
		k_poll_signal_raise(sig, res);
	}

	return rv;
}
    5828:	4770      	bx	lr

0000582a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    582a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    582e:	b923      	cbnz	r3, 583a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5830:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5834:	f000 0001 	and.w	r0, r0, #1
    5838:	4770      	bx	lr
		return false;
    583a:	2000      	movs	r0, #0
}
    583c:	4770      	bx	lr

0000583e <arch_printk_char_out>:
}
    583e:	2000      	movs	r0, #0
    5840:	4770      	bx	lr

00005842 <buf_flush>:
{
    5842:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	k_str_out(ctx->buf, ctx->buf_count);
    5846:	6841      	ldr	r1, [r0, #4]
{
    5848:	4604      	mov	r4, r0
	k_str_out(ctx->buf, ctx->buf_count);
    584a:	f100 0208 	add.w	r2, r0, #8
    584e:	f7ff ffec 	bl	582a <arch_is_user_context>

extern void z_impl_k_str_out(char * c, size_t n);
static inline void k_str_out(char * c, size_t n)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    5852:	b130      	cbz	r0, 5862 <buf_flush+0x20>
	register uint32_t ret __asm__("r0") = arg1;
    5854:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    5856:	268c      	movs	r6, #140	; 0x8c
	__asm__ volatile("svc %[svid]\n"
    5858:	df03      	svc	3
	ctx->buf_count = 0U;
    585a:	2300      	movs	r3, #0
    585c:	6063      	str	r3, [r4, #4]
}
    585e:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
		arch_syscall_invoke2(*(uintptr_t *)&c, *(uintptr_t *)&n, K_SYSCALL_K_STR_OUT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_str_out(c, n);
    5862:	4610      	mov	r0, r2
    5864:	f7fb fa08 	bl	c78 <z_impl_k_str_out>
    5868:	e7f7      	b.n	585a <buf_flush+0x18>

0000586a <buf_char_out>:
	ctx->count++;
    586a:	680b      	ldr	r3, [r1, #0]
    586c:	3301      	adds	r3, #1
    586e:	600b      	str	r3, [r1, #0]
	ctx->buf[ctx->buf_count++] = c;
    5870:	684b      	ldr	r3, [r1, #4]
    5872:	1c5a      	adds	r2, r3, #1
    5874:	440b      	add	r3, r1
{
    5876:	b510      	push	{r4, lr}
	if (ctx->buf_count == CONFIG_PRINTK_BUFFER_SIZE) {
    5878:	2a20      	cmp	r2, #32
{
    587a:	4604      	mov	r4, r0
	ctx->buf[ctx->buf_count++] = c;
    587c:	604a      	str	r2, [r1, #4]
{
    587e:	4608      	mov	r0, r1
	ctx->buf[ctx->buf_count++] = c;
    5880:	721c      	strb	r4, [r3, #8]
	if (ctx->buf_count == CONFIG_PRINTK_BUFFER_SIZE) {
    5882:	d101      	bne.n	5888 <buf_char_out+0x1e>
		buf_flush(ctx);
    5884:	f7ff ffdd 	bl	5842 <buf_flush>
}
    5888:	4620      	mov	r0, r4
    588a:	bd10      	pop	{r4, pc}

0000588c <printk>:
 * @param fmt formatted string to output
 *
 * @return N/A
 */
void printk(const char *fmt, ...)
{
    588c:	b40f      	push	{r0, r1, r2, r3}
    588e:	b507      	push	{r0, r1, r2, lr}
    5890:	a904      	add	r1, sp, #16
    5892:	f851 0b04 	ldr.w	r0, [r1], #4
	va_list ap;

	va_start(ap, fmt);
    5896:	9101      	str	r1, [sp, #4]

	if (IS_ENABLED(CONFIG_LOG_PRINTK)) {
		log_printk(fmt, ap);
	} else {
		vprintk(fmt, ap);
    5898:	f7fb f9fc 	bl	c94 <vprintk>
	}
	va_end(ap);
}
    589c:	b003      	add	sp, #12
    589e:	f85d eb04 	ldr.w	lr, [sp], #4
    58a2:	b004      	add	sp, #16
    58a4:	4770      	bx	lr

000058a6 <process_recheck>:
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    58a6:	8b03      	ldrh	r3, [r0, #24]
	if ((state == ONOFF_STATE_OFF)
    58a8:	f013 0307 	ands.w	r3, r3, #7
    58ac:	d105      	bne.n	58ba <process_recheck+0x14>
	    && !sys_slist_is_empty(&mgr->clients)) {
    58ae:	6803      	ldr	r3, [r0, #0]
    58b0:	2b00      	cmp	r3, #0
		evt = EVT_START;
    58b2:	bf0c      	ite	eq
    58b4:	2000      	moveq	r0, #0
    58b6:	2003      	movne	r0, #3
    58b8:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ON)
    58ba:	2b02      	cmp	r3, #2
    58bc:	d105      	bne.n	58ca <process_recheck+0x24>
		   && (mgr->refs == 0)) {
    58be:	8b43      	ldrh	r3, [r0, #26]
    58c0:	2b00      	cmp	r3, #0
		evt = EVT_STOP;
    58c2:	bf14      	ite	ne
    58c4:	2000      	movne	r0, #0
    58c6:	2004      	moveq	r0, #4
    58c8:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ERROR)
    58ca:	2b01      	cmp	r3, #1
    58cc:	d105      	bne.n	58da <process_recheck+0x34>
		   && !sys_slist_is_empty(&mgr->clients)) {
    58ce:	6803      	ldr	r3, [r0, #0]
    58d0:	2b00      	cmp	r3, #0
		evt = EVT_RESET;
    58d2:	bf0c      	ite	eq
    58d4:	2000      	moveq	r0, #0
    58d6:	2005      	movne	r0, #5
    58d8:	4770      	bx	lr
	int evt = EVT_NOP;
    58da:	2000      	movs	r0, #0
}
    58dc:	4770      	bx	lr

000058de <validate_args>:
{
    58de:	b510      	push	{r4, lr}
    58e0:	460c      	mov	r4, r1
	if ((mgr == NULL) || (cli == NULL)) {
    58e2:	b140      	cbz	r0, 58f6 <validate_args+0x18>
    58e4:	b139      	cbz	r1, 58f6 <validate_args+0x18>
	int rv = sys_notify_validate(&cli->notify);
    58e6:	1d08      	adds	r0, r1, #4
    58e8:	f7ff ff81 	bl	57ee <sys_notify_validate>
	if ((rv == 0)
    58ec:	b928      	cbnz	r0, 58fa <validate_args+0x1c>
	    && ((cli->notify.flags
    58ee:	68a3      	ldr	r3, [r4, #8]
    58f0:	f033 0303 	bics.w	r3, r3, #3
    58f4:	d001      	beq.n	58fa <validate_args+0x1c>
		rv = -EINVAL;
    58f6:	f06f 0015 	mvn.w	r0, #21
}
    58fa:	bd10      	pop	{r4, pc}

000058fc <transition_complete>:
{
    58fc:	b410      	push	{r4}
	__asm__ volatile(
    58fe:	f04f 0420 	mov.w	r4, #32
    5902:	f3ef 8211 	mrs	r2, BASEPRI
    5906:	f384 8811 	msr	BASEPRI, r4
    590a:	f3bf 8f6f 	isb	sy
	mgr->last_res = res;
    590e:	6141      	str	r1, [r0, #20]
}
    5910:	bc10      	pop	{r4}
	process_event(mgr, EVT_COMPLETE, key);
    5912:	2101      	movs	r1, #1
    5914:	f7fb ba04 	b.w	d20 <process_event>

00005918 <onoff_manager_init>:
{
    5918:	b538      	push	{r3, r4, r5, lr}
    591a:	460c      	mov	r4, r1
	if ((mgr == NULL)
    591c:	4605      	mov	r5, r0
    591e:	b158      	cbz	r0, 5938 <onoff_manager_init+0x20>
	    || (transitions == NULL)
    5920:	b151      	cbz	r1, 5938 <onoff_manager_init+0x20>
	    || (transitions->start == NULL)
    5922:	680b      	ldr	r3, [r1, #0]
    5924:	b143      	cbz	r3, 5938 <onoff_manager_init+0x20>
	    || (transitions->stop == NULL)) {
    5926:	684b      	ldr	r3, [r1, #4]
    5928:	b133      	cbz	r3, 5938 <onoff_manager_init+0x20>
	*mgr = (struct onoff_manager)ONOFF_MANAGER_INITIALIZER(transitions);
    592a:	221c      	movs	r2, #28
    592c:	2100      	movs	r1, #0
    592e:	f000 fc88 	bl	6242 <memset>
    5932:	612c      	str	r4, [r5, #16]
	return 0;
    5934:	2000      	movs	r0, #0
}
    5936:	bd38      	pop	{r3, r4, r5, pc}
		return -EINVAL;
    5938:	f06f 0015 	mvn.w	r0, #21
    593c:	e7fb      	b.n	5936 <onoff_manager_init+0x1e>

0000593e <onoff_request>:

int onoff_request(struct onoff_manager *mgr,
		  struct onoff_client *cli)
{
    593e:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5942:	4604      	mov	r4, r0
    5944:	460d      	mov	r5, r1
	bool add_client = false;        /* add client to pending list */
	bool start = false;             /* trigger a start transition */
	bool notify = false;            /* do client notification */
	int rv = validate_args(mgr, cli);
    5946:	f7ff ffca 	bl	58de <validate_args>

	if (rv < 0) {
    594a:	1e06      	subs	r6, r0, #0
    594c:	db36      	blt.n	59bc <onoff_request+0x7e>
    594e:	f04f 0320 	mov.w	r3, #32
    5952:	f3ef 8211 	mrs	r2, BASEPRI
    5956:	f383 8811 	msr	BASEPRI, r3
    595a:	f3bf 8f6f 	isb	sy

	k_spinlock_key_t key = k_spin_lock(&mgr->lock);
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;

	/* Reject if this would overflow the reference count. */
	if (mgr->refs == SERVICE_REFS_MAX) {
    595e:	8b63      	ldrh	r3, [r4, #26]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    5960:	8b21      	ldrh	r1, [r4, #24]
	if (mgr->refs == SERVICE_REFS_MAX) {
    5962:	f64f 70ff 	movw	r0, #65535	; 0xffff
    5966:	4283      	cmp	r3, r0
    5968:	f001 0707 	and.w	r7, r1, #7
    596c:	d034      	beq.n	59d8 <onoff_request+0x9a>
		rv = -EAGAIN;
		goto out;
	}

	rv = state;
	if (state == ONOFF_STATE_ON) {
    596e:	2f02      	cmp	r7, #2
    5970:	d114      	bne.n	599c <onoff_request+0x5e>
		/* Increment reference count, notify in exit */
		notify = true;
		mgr->refs += 1U;
    5972:	3301      	adds	r3, #1
    5974:	8363      	strh	r3, [r4, #26]
	rv = state;
    5976:	463e      	mov	r6, r7
		notify = true;
    5978:	2301      	movs	r3, #1
	__asm__ volatile(
    597a:	f382 8811 	msr	BASEPRI, r2
    597e:	f3bf 8f6f 	isb	sy
	if (start) {
		process_event(mgr, EVT_RECHECK, key);
	} else {
		k_spin_unlock(&mgr->lock, key);

		if (notify) {
    5982:	b1db      	cbz	r3, 59bc <onoff_request+0x7e>
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
    5984:	2100      	movs	r1, #0
    5986:	1d28      	adds	r0, r5, #4
    5988:	f7ff ff42 	bl	5810 <sys_notify_finalize>
	if (cb) {
    598c:	4680      	mov	r8, r0
    598e:	b1a8      	cbz	r0, 59bc <onoff_request+0x7e>
		cb(mgr, cli, state, res);
    5990:	2300      	movs	r3, #0
    5992:	463a      	mov	r2, r7
    5994:	4629      	mov	r1, r5
    5996:	4620      	mov	r0, r4
    5998:	47c0      	blx	r8
    599a:	e00f      	b.n	59bc <onoff_request+0x7e>
	} else if ((state == ONOFF_STATE_OFF)
    599c:	078b      	lsls	r3, r1, #30
    599e:	d001      	beq.n	59a4 <onoff_request+0x66>
		   || (state == ONOFF_STATE_TO_ON)) {
    59a0:	2f06      	cmp	r7, #6
    59a2:	d10e      	bne.n	59c2 <onoff_request+0x84>
	parent->next = child;
    59a4:	2300      	movs	r3, #0
    59a6:	602b      	str	r3, [r5, #0]
Z_GENLIST_APPEND(slist, snode)
    59a8:	6863      	ldr	r3, [r4, #4]
    59aa:	b993      	cbnz	r3, 59d2 <onoff_request+0x94>
	list->head = node;
    59ac:	e9c4 5500 	strd	r5, r5, [r4]
	if (start) {
    59b0:	463e      	mov	r6, r7
    59b2:	b967      	cbnz	r7, 59ce <onoff_request+0x90>
		process_event(mgr, EVT_RECHECK, key);
    59b4:	2102      	movs	r1, #2
    59b6:	4620      	mov	r0, r4
    59b8:	f7fb f9b2 	bl	d20 <process_event>
			notify_one(mgr, cli, state, 0);
		}
	}

	return rv;
}
    59bc:	4630      	mov	r0, r6
    59be:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		rv = -EIO;
    59c2:	2f05      	cmp	r7, #5
    59c4:	bf0c      	ite	eq
    59c6:	f06f 0622 	mvneq.w	r6, #34	; 0x22
    59ca:	f06f 0604 	mvnne.w	r6, #4
    59ce:	2300      	movs	r3, #0
    59d0:	e7d3      	b.n	597a <onoff_request+0x3c>
	parent->next = child;
    59d2:	601d      	str	r5, [r3, #0]
	list->tail = node;
    59d4:	6065      	str	r5, [r4, #4]
}
    59d6:	e7eb      	b.n	59b0 <onoff_request+0x72>
		rv = -EAGAIN;
    59d8:	f06f 060a 	mvn.w	r6, #10
    59dc:	e7f7      	b.n	59ce <onoff_request+0x90>

000059de <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
    59de:	4604      	mov	r4, r0
    59e0:	b508      	push	{r3, lr}
    59e2:	4608      	mov	r0, r1
    59e4:	4611      	mov	r1, r2
	entry(p1, p2, p3);
    59e6:	461a      	mov	r2, r3
    59e8:	47a0      	blx	r4
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    59ea:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    59ee:	b973      	cbnz	r3, 5a0e <z_thread_entry+0x30>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    59f0:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    59f4:	07da      	lsls	r2, r3, #31
    59f6:	d50a      	bpl.n	5a0e <z_thread_entry+0x30>
	register uint32_t r6 __asm__("r6") = call_id;
    59f8:	265e      	movs	r6, #94	; 0x5e
	__asm__ volatile("svc %[svid]\n"
    59fa:	df03      	svc	3
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    59fc:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5a00:	b943      	cbnz	r3, 5a14 <z_thread_entry+0x36>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5a02:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    5a06:	07db      	lsls	r3, r3, #31
    5a08:	d504      	bpl.n	5a14 <z_thread_entry+0x36>
	register uint32_t r6 __asm__("r6") = call_id;
    5a0a:	268d      	movs	r6, #141	; 0x8d
	__asm__ volatile("svc %[svid]\n"
    5a0c:	df03      	svc	3
	return z_impl_k_current_get();
    5a0e:	f7fe fd1b 	bl	4448 <z_impl_k_current_get>
    5a12:	e7f3      	b.n	59fc <z_thread_entry+0x1e>
	z_impl_k_thread_abort(thread);
    5a14:	f7fc f98e 	bl	1d34 <z_impl_k_thread_abort>
    5a18:	e7f9      	b.n	5a0e <z_thread_entry+0x30>

00005a1a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5a1a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5a1e:	b923      	cbnz	r3, 5a2a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5a20:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5a24:	f000 0001 	and.w	r0, r0, #1
    5a28:	4770      	bx	lr
		return false;
    5a2a:	2000      	movs	r0, #0
}
    5a2c:	4770      	bx	lr

00005a2e <z_work_q_main>:

#include <kernel.h>
#define WORKQUEUE_THREAD_NAME	"workqueue"

void z_work_q_main(void *work_q_ptr, void *p2, void *p3)
{
    5a2e:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    5a32:	4604      	mov	r4, r0
    5a34:	f7ff fff1 	bl	5a1a <arch_is_user_context>
	if (z_syscall_trap()) {
    5a38:	b300      	cbz	r0, 5a7c <z_work_q_main+0x4e>
	register uint32_t r1 __asm__("r1") = arg2;
    5a3a:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
	register uint32_t ret __asm__("r0") = arg1;
    5a3e:	4620      	mov	r0, r4
	register uint32_t r2 __asm__("r2") = arg3;
    5a40:	460a      	mov	r2, r1
	register uint32_t r6 __asm__("r6") = call_id;
    5a42:	267e      	movs	r6, #126	; 0x7e
	__asm__ volatile("svc %[svid]\n"
    5a44:	df03      	svc	3
	while (true) {
		struct k_work *work;
		k_work_handler_t handler;

		work = k_queue_get(&work_q->queue, K_FOREVER);
		if (work == NULL) {
    5a46:	2800      	cmp	r0, #0
    5a48:	d0f4      	beq.n	5a34 <z_work_q_main+0x6>
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    5a4a:	f100 0308 	add.w	r3, r0, #8
			continue;
		}

		handler = work->handler;
    5a4e:	6842      	ldr	r2, [r0, #4]
    5a50:	f3bf 8f5b 	dmb	ish
    5a54:	e853 1f00 	ldrex	r1, [r3]
    5a58:	f021 0601 	bic.w	r6, r1, #1
    5a5c:	e843 6c00 	strex	ip, r6, [r3]
    5a60:	f1bc 0f00 	cmp.w	ip, #0
    5a64:	d1f6      	bne.n	5a54 <z_work_q_main+0x26>
    5a66:	f3bf 8f5b 	dmb	ish
		__ASSERT(handler != NULL, "handler must be provided");

		/* Reset pending state so it can be resubmitted by handler */
		if (atomic_test_and_clear_bit(work->flags,
    5a6a:	07cb      	lsls	r3, r1, #31
    5a6c:	d500      	bpl.n	5a70 <z_work_q_main+0x42>
					      K_WORK_STATE_PENDING)) {
			handler(work);
    5a6e:	4790      	blx	r2
    5a70:	f7ff ffd3 	bl	5a1a <arch_is_user_context>
	if (z_syscall_trap()) {
    5a74:	b150      	cbz	r0, 5a8c <z_work_q_main+0x5e>
	register uint32_t r6 __asm__("r6") = call_id;
    5a76:	26a8      	movs	r6, #168	; 0xa8
	__asm__ volatile("svc %[svid]\n"
    5a78:	df03      	svc	3
	return ret;
    5a7a:	e7db      	b.n	5a34 <z_work_q_main+0x6>
	return z_impl_k_queue_get(queue, timeout);
    5a7c:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    5a80:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    5a84:	4620      	mov	r0, r4
    5a86:	f7fd ff9d 	bl	39c4 <z_impl_k_queue_get>
    5a8a:	e7dc      	b.n	5a46 <z_work_q_main+0x18>
	z_impl_k_yield();
    5a8c:	f7fe fbf6 	bl	427c <z_impl_k_yield>
    5a90:	e7d0      	b.n	5a34 <z_work_q_main+0x6>

00005a92 <chunk_field>:
				 enum chunk_fields f)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    5a92:	6883      	ldr	r3, [r0, #8]
	void *cmem = &buf[c];
    5a94:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    5a98:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
		return ((uint32_t *)cmem)[f];
    5a9c:	bf2c      	ite	cs
    5a9e:	f851 0022 	ldrcs.w	r0, [r1, r2, lsl #2]
	} else {
		return ((uint16_t *)cmem)[f];
    5aa2:	f831 0012 	ldrhcc.w	r0, [r1, r2, lsl #1]
	}
}
    5aa6:	4770      	bx	lr

00005aa8 <chunk_set>:
			     enum chunk_fields f, chunkid_t val)
{
	CHECK(c <= h->len);

	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];
    5aa8:	eb00 01c1 	add.w	r1, r0, r1, lsl #3

	if (big_heap(h)) {
    5aac:	6880      	ldr	r0, [r0, #8]
    5aae:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
		CHECK(val == (uint32_t)val);
		((uint32_t *)cmem)[f] = val;
    5ab2:	bf2c      	ite	cs
    5ab4:	f841 3022 	strcs.w	r3, [r1, r2, lsl #2]
	} else {
		CHECK(val == (uint16_t)val);
		((uint16_t *)cmem)[f] = val;
    5ab8:	f821 3012 	strhcc.w	r3, [r1, r2, lsl #1]
	}
}
    5abc:	4770      	bx	lr

00005abe <chunk_size>:
{
	return chunk_field(h, c, SIZE_AND_USED) & 1;
}

static inline size_t chunk_size(struct z_heap *h, chunkid_t c)
{
    5abe:	b508      	push	{r3, lr}
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
    5ac0:	2201      	movs	r2, #1
    5ac2:	f7ff ffe6 	bl	5a92 <chunk_field>
}
    5ac6:	0840      	lsrs	r0, r0, #1
    5ac8:	bd08      	pop	{r3, pc}

00005aca <set_chunk_used>:
static inline void set_chunk_used(struct z_heap *h, chunkid_t c, bool used)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    5aca:	6883      	ldr	r3, [r0, #8]
    5acc:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
	void *cmem = &buf[c];
    5ad0:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    5ad4:	d308      	bcc.n	5ae8 <set_chunk_used+0x1e>
		if (used) {
    5ad6:	684b      	ldr	r3, [r1, #4]
    5ad8:	b11a      	cbz	r2, 5ae2 <set_chunk_used+0x18>
			((uint32_t *)cmem)[SIZE_AND_USED] |= 1;
    5ada:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint32_t *)cmem)[SIZE_AND_USED] &= ~1;
    5ade:	604b      	str	r3, [r1, #4]
    5ae0:	4770      	bx	lr
    5ae2:	f023 0301 	bic.w	r3, r3, #1
    5ae6:	e7fa      	b.n	5ade <set_chunk_used+0x14>
		}
	} else {
		if (used) {
    5ae8:	884b      	ldrh	r3, [r1, #2]
    5aea:	b11a      	cbz	r2, 5af4 <set_chunk_used+0x2a>
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1;
    5aec:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    5af0:	804b      	strh	r3, [r1, #2]
		}
	}
}
    5af2:	4770      	bx	lr
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    5af4:	f023 0301 	bic.w	r3, r3, #1
    5af8:	e7fa      	b.n	5af0 <set_chunk_used+0x26>

00005afa <set_chunk_size>:
 * when its size is modified, and potential set_chunk_used() is always
 * invoked after set_chunk_size().
 */
static inline void set_chunk_size(struct z_heap *h, chunkid_t c, size_t size)
{
	chunk_set(h, c, SIZE_AND_USED, size << 1);
    5afa:	0053      	lsls	r3, r2, #1
    5afc:	2201      	movs	r2, #1
    5afe:	f7ff bfd3 	b.w	5aa8 <chunk_set>

00005b02 <bucket_idx>:
	return big_heap(h) && chunk_size(h, c) == 1;
}

static inline size_t chunk_header_bytes(struct z_heap *h)
{
	return big_heap(h) ? 8 : 4;
    5b02:	6880      	ldr	r0, [r0, #8]
	return bytes_to_chunksz(h, 1);
}

static inline int bucket_idx(struct z_heap *h, size_t sz)
{
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    5b04:	3101      	adds	r1, #1
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    5b06:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
    5b0a:	bf2c      	ite	cs
    5b0c:	2002      	movcs	r0, #2
    5b0e:	2001      	movcc	r0, #1
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    5b10:	1a08      	subs	r0, r1, r0
	return 31 - __builtin_clz(usable_sz);
    5b12:	fab0 f080 	clz	r0, r0
}
    5b16:	f1c0 001f 	rsb	r0, r0, #31
    5b1a:	4770      	bx	lr

00005b1c <merge_chunks>:
	set_left_chunk_size(h, right_chunk(h, rc), rsz);
}

/* Does not modify free list */
static void merge_chunks(struct z_heap *h, chunkid_t lc, chunkid_t rc)
{
    5b1c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5b20:	4616      	mov	r6, r2
    5b22:	4604      	mov	r4, r0
    5b24:	460f      	mov	r7, r1
	size_t newsz = chunk_size(h, lc) + chunk_size(h, rc);
    5b26:	f7ff ffca 	bl	5abe <chunk_size>
    5b2a:	4631      	mov	r1, r6
    5b2c:	4605      	mov	r5, r0
    5b2e:	4620      	mov	r0, r4
    5b30:	f7ff ffc5 	bl	5abe <chunk_size>
    5b34:	4405      	add	r5, r0

	set_chunk_size(h, lc, newsz);
    5b36:	462a      	mov	r2, r5
    5b38:	4639      	mov	r1, r7
    5b3a:	4620      	mov	r0, r4
    5b3c:	f7ff ffdd 	bl	5afa <set_chunk_size>
	return c + chunk_size(h, c);
    5b40:	4631      	mov	r1, r6
    5b42:	4620      	mov	r0, r4
    5b44:	f7ff ffbb 	bl	5abe <chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5b48:	462b      	mov	r3, r5
    5b4a:	1831      	adds	r1, r6, r0
    5b4c:	2200      	movs	r2, #0
    5b4e:	4620      	mov	r0, r4
	set_left_chunk_size(h, right_chunk(h, rc), newsz);
}
    5b50:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5b54:	f7ff bfa8 	b.w	5aa8 <chunk_set>

00005b58 <split_chunks>:
{
    5b58:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5b5c:	4614      	mov	r4, r2
    5b5e:	4605      	mov	r5, r0
    5b60:	460e      	mov	r6, r1
	size_t sz0 = chunk_size(h, lc);
    5b62:	f7ff ffac 	bl	5abe <chunk_size>
	size_t lsz = rc - lc;
    5b66:	eba4 0806 	sub.w	r8, r4, r6
	size_t rsz = sz0 - lsz;
    5b6a:	1b37      	subs	r7, r6, r4
    5b6c:	4407      	add	r7, r0
	set_chunk_size(h, lc, lsz);
    5b6e:	4642      	mov	r2, r8
    5b70:	4631      	mov	r1, r6
    5b72:	4628      	mov	r0, r5
    5b74:	f7ff ffc1 	bl	5afa <set_chunk_size>
	set_chunk_size(h, rc, rsz);
    5b78:	463a      	mov	r2, r7
    5b7a:	4621      	mov	r1, r4
    5b7c:	4628      	mov	r0, r5
    5b7e:	f7ff ffbc 	bl	5afa <set_chunk_size>
    5b82:	4643      	mov	r3, r8
    5b84:	2200      	movs	r2, #0
    5b86:	4621      	mov	r1, r4
    5b88:	4628      	mov	r0, r5
    5b8a:	f7ff ff8d 	bl	5aa8 <chunk_set>
	return c + chunk_size(h, c);
    5b8e:	4621      	mov	r1, r4
    5b90:	4628      	mov	r0, r5
    5b92:	f7ff ff94 	bl	5abe <chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5b96:	463b      	mov	r3, r7
    5b98:	1821      	adds	r1, r4, r0
    5b9a:	2200      	movs	r2, #0
    5b9c:	4628      	mov	r0, r5
}
    5b9e:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5ba2:	f7ff bf81 	b.w	5aa8 <chunk_set>

00005ba6 <free_list_remove_bidx>:
{
    5ba6:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5baa:	4617      	mov	r7, r2
	return chunk_field(h, c, FREE_NEXT);
    5bac:	2203      	movs	r2, #3
    5bae:	460e      	mov	r6, r1
    5bb0:	4604      	mov	r4, r0
    5bb2:	f7ff ff6e 	bl	5a92 <chunk_field>
	if (next_free_chunk(h, c) == c) {
    5bb6:	4286      	cmp	r6, r0
    5bb8:	4605      	mov	r5, r0
    5bba:	f107 0804 	add.w	r8, r7, #4
    5bbe:	d10b      	bne.n	5bd8 <free_list_remove_bidx+0x32>
		h->avail_buckets &= ~(1 << bidx);
    5bc0:	2301      	movs	r3, #1
    5bc2:	fa03 f707 	lsl.w	r7, r3, r7
    5bc6:	68e3      	ldr	r3, [r4, #12]
    5bc8:	ea23 0307 	bic.w	r3, r3, r7
    5bcc:	60e3      	str	r3, [r4, #12]
		b->next = 0;
    5bce:	2300      	movs	r3, #0
    5bd0:	f844 3028 	str.w	r3, [r4, r8, lsl #2]
}
    5bd4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return chunk_field(h, c, FREE_PREV);
    5bd8:	4631      	mov	r1, r6
    5bda:	2202      	movs	r2, #2
    5bdc:	4620      	mov	r0, r4
    5bde:	f7ff ff58 	bl	5a92 <chunk_field>
	chunk_set(h, c, FREE_NEXT, next);
    5be2:	462b      	mov	r3, r5
	return chunk_field(h, c, FREE_PREV);
    5be4:	4606      	mov	r6, r0
	chunk_set(h, c, FREE_NEXT, next);
    5be6:	4601      	mov	r1, r0
		b->next = second;
    5be8:	f844 5028 	str.w	r5, [r4, r8, lsl #2]
    5bec:	4620      	mov	r0, r4
    5bee:	2203      	movs	r2, #3
    5bf0:	f7ff ff5a 	bl	5aa8 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    5bf4:	4633      	mov	r3, r6
    5bf6:	4629      	mov	r1, r5
    5bf8:	4620      	mov	r0, r4
    5bfa:	2202      	movs	r2, #2
}
    5bfc:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5c00:	f7ff bf52 	b.w	5aa8 <chunk_set>

00005c04 <free_list_remove>:
{
    5c04:	b538      	push	{r3, r4, r5, lr}
    5c06:	4604      	mov	r4, r0
    5c08:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    5c0a:	f7ff ff58 	bl	5abe <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    5c0e:	68a3      	ldr	r3, [r4, #8]
    5c10:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5c14:	4601      	mov	r1, r0
    5c16:	d301      	bcc.n	5c1c <free_list_remove+0x18>
	if (!solo_free_header(h, c)) {
    5c18:	2801      	cmp	r0, #1
    5c1a:	d009      	beq.n	5c30 <free_list_remove+0x2c>
		int bidx = bucket_idx(h, chunk_size(h, c));
    5c1c:	4620      	mov	r0, r4
    5c1e:	f7ff ff70 	bl	5b02 <bucket_idx>
		free_list_remove_bidx(h, c, bidx);
    5c22:	4629      	mov	r1, r5
		int bidx = bucket_idx(h, chunk_size(h, c));
    5c24:	4602      	mov	r2, r0
		free_list_remove_bidx(h, c, bidx);
    5c26:	4620      	mov	r0, r4
}
    5c28:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		free_list_remove_bidx(h, c, bidx);
    5c2c:	f7ff bfbb 	b.w	5ba6 <free_list_remove_bidx>
}
    5c30:	bd38      	pop	{r3, r4, r5, pc}

00005c32 <alloc_chunk>:
	set_chunk_used(h, c, false);
	free_chunk(h, c);
}

static chunkid_t alloc_chunk(struct z_heap *h, size_t sz)
{
    5c32:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    5c36:	4604      	mov	r4, r0
    5c38:	4688      	mov	r8, r1
	int bi = bucket_idx(h, sz);
    5c3a:	f7ff ff62 	bl	5b02 <bucket_idx>
	struct z_heap_bucket *b = &h->buckets[bi];

	if (bi > bucket_idx(h, h->len)) {
    5c3e:	68a1      	ldr	r1, [r4, #8]
	int bi = bucket_idx(h, sz);
    5c40:	4605      	mov	r5, r0
	if (bi > bucket_idx(h, h->len)) {
    5c42:	4620      	mov	r0, r4
    5c44:	f7ff ff5d 	bl	5b02 <bucket_idx>
    5c48:	42a8      	cmp	r0, r5
    5c4a:	da03      	bge.n	5c54 <alloc_chunk+0x22>
		return 0;
    5c4c:	2600      	movs	r6, #0
		CHECK(chunk_size(h, c) >= sz);
		return c;
	}

	return 0;
}
    5c4e:	4630      	mov	r0, r6
    5c50:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	if (b->next) {
    5c54:	eb04 0a85 	add.w	sl, r4, r5, lsl #2
    5c58:	f8da 9010 	ldr.w	r9, [sl, #16]
    5c5c:	f1b9 0f00 	cmp.w	r9, #0
    5c60:	d019      	beq.n	5c96 <alloc_chunk+0x64>
    5c62:	2703      	movs	r7, #3
			chunkid_t c = b->next;
    5c64:	f8da 6010 	ldr.w	r6, [sl, #16]
			if (chunk_size(h, c) >= sz) {
    5c68:	4620      	mov	r0, r4
    5c6a:	4631      	mov	r1, r6
    5c6c:	f7ff ff27 	bl	5abe <chunk_size>
    5c70:	4540      	cmp	r0, r8
    5c72:	d305      	bcc.n	5c80 <alloc_chunk+0x4e>
				free_list_remove_bidx(h, c, bi);
    5c74:	462a      	mov	r2, r5
		free_list_remove_bidx(h, c, minbucket);
    5c76:	4631      	mov	r1, r6
    5c78:	4620      	mov	r0, r4
    5c7a:	f7ff ff94 	bl	5ba6 <free_list_remove_bidx>
		return c;
    5c7e:	e7e6      	b.n	5c4e <alloc_chunk+0x1c>
	return chunk_field(h, c, FREE_NEXT);
    5c80:	2203      	movs	r2, #3
    5c82:	4631      	mov	r1, r6
    5c84:	4620      	mov	r0, r4
    5c86:	f7ff ff04 	bl	5a92 <chunk_field>
		} while (--i && b->next != first);
    5c8a:	3f01      	subs	r7, #1
			b->next = next_free_chunk(h, c);
    5c8c:	f8ca 0010 	str.w	r0, [sl, #16]
		} while (--i && b->next != first);
    5c90:	d001      	beq.n	5c96 <alloc_chunk+0x64>
    5c92:	4581      	cmp	r9, r0
    5c94:	d1e6      	bne.n	5c64 <alloc_chunk+0x32>
	size_t bmask = h->avail_buckets & ~((1 << (bi + 1)) - 1);
    5c96:	68e3      	ldr	r3, [r4, #12]
    5c98:	3501      	adds	r5, #1
    5c9a:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    5c9e:	40aa      	lsls	r2, r5
	if ((bmask & h->avail_buckets) != 0) {
    5ca0:	401a      	ands	r2, r3
    5ca2:	d0d3      	beq.n	5c4c <alloc_chunk+0x1a>
		int minbucket = __builtin_ctz(bmask & h->avail_buckets);
    5ca4:	fa92 f2a2 	rbit	r2, r2
    5ca8:	fab2 f282 	clz	r2, r2
		chunkid_t c = h->buckets[minbucket].next;
    5cac:	1d13      	adds	r3, r2, #4
    5cae:	f854 6023 	ldr.w	r6, [r4, r3, lsl #2]
    5cb2:	e7e0      	b.n	5c76 <alloc_chunk+0x44>

00005cb4 <free_list_add>:
{
    5cb4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5cb8:	4604      	mov	r4, r0
    5cba:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    5cbc:	f7ff feff 	bl	5abe <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    5cc0:	68a3      	ldr	r3, [r4, #8]
    5cc2:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5cc6:	4601      	mov	r1, r0
    5cc8:	d301      	bcc.n	5cce <free_list_add+0x1a>
	if (!solo_free_header(h, c)) {
    5cca:	2801      	cmp	r0, #1
    5ccc:	d035      	beq.n	5d3a <free_list_add+0x86>
		int bidx = bucket_idx(h, chunk_size(h, c));
    5cce:	4620      	mov	r0, r4
    5cd0:	f7ff ff17 	bl	5b02 <bucket_idx>
	if (b->next == 0) {
    5cd4:	eb04 0280 	add.w	r2, r4, r0, lsl #2
    5cd8:	6916      	ldr	r6, [r2, #16]
    5cda:	b99e      	cbnz	r6, 5d04 <free_list_add+0x50>
		h->avail_buckets |= (1 << bidx);
    5cdc:	2301      	movs	r3, #1
    5cde:	fa03 f000 	lsl.w	r0, r3, r0
    5ce2:	68e3      	ldr	r3, [r4, #12]
    5ce4:	4303      	orrs	r3, r0
    5ce6:	60e3      	str	r3, [r4, #12]
	chunk_set(h, c, FREE_PREV, prev);
    5ce8:	4629      	mov	r1, r5
		b->next = c;
    5cea:	6115      	str	r5, [r2, #16]
    5cec:	462b      	mov	r3, r5
    5cee:	2202      	movs	r2, #2
    5cf0:	4620      	mov	r0, r4
    5cf2:	f7ff fed9 	bl	5aa8 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    5cf6:	2203      	movs	r2, #3
    5cf8:	4629      	mov	r1, r5
	chunk_set(h, c, FREE_PREV, prev);
    5cfa:	4620      	mov	r0, r4
}
    5cfc:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5d00:	f7ff bed2 	b.w	5aa8 <chunk_set>
	return chunk_field(h, c, FREE_PREV);
    5d04:	2202      	movs	r2, #2
    5d06:	4631      	mov	r1, r6
    5d08:	4620      	mov	r0, r4
    5d0a:	f7ff fec2 	bl	5a92 <chunk_field>
	chunk_set(h, c, FREE_PREV, prev);
    5d0e:	2202      	movs	r2, #2
    5d10:	4603      	mov	r3, r0
	return chunk_field(h, c, FREE_PREV);
    5d12:	4607      	mov	r7, r0
	chunk_set(h, c, FREE_PREV, prev);
    5d14:	4629      	mov	r1, r5
    5d16:	4620      	mov	r0, r4
    5d18:	f7ff fec6 	bl	5aa8 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    5d1c:	4633      	mov	r3, r6
    5d1e:	2203      	movs	r2, #3
    5d20:	4629      	mov	r1, r5
    5d22:	4620      	mov	r0, r4
    5d24:	f7ff fec0 	bl	5aa8 <chunk_set>
    5d28:	2203      	movs	r2, #3
    5d2a:	4639      	mov	r1, r7
    5d2c:	462b      	mov	r3, r5
    5d2e:	4620      	mov	r0, r4
    5d30:	f7ff feba 	bl	5aa8 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    5d34:	2202      	movs	r2, #2
    5d36:	4631      	mov	r1, r6
    5d38:	e7df      	b.n	5cfa <free_list_add+0x46>
    5d3a:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

00005d3e <sys_heap_free>:
{
    5d3e:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (mem == NULL) {
    5d40:	2900      	cmp	r1, #0
    5d42:	d050      	beq.n	5de6 <sys_heap_free+0xa8>
	struct z_heap *h = heap->heap;
    5d44:	6805      	ldr	r5, [r0, #0]
	return big_heap(h) ? 8 : 4;
    5d46:	68ab      	ldr	r3, [r5, #8]
    5d48:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5d4c:	bf2c      	ite	cs
    5d4e:	2408      	movcs	r4, #8
    5d50:	2404      	movcc	r4, #4
	return (mem - chunk_header_bytes(h) - base) / CHUNK_UNIT;
    5d52:	1b0c      	subs	r4, r1, r4
    5d54:	1b64      	subs	r4, r4, r5
    5d56:	bf48      	it	mi
    5d58:	3407      	addmi	r4, #7
    5d5a:	10e4      	asrs	r4, r4, #3
	set_chunk_used(h, c, false);
    5d5c:	2200      	movs	r2, #0
    5d5e:	4621      	mov	r1, r4
    5d60:	4628      	mov	r0, r5
    5d62:	f7ff feb2 	bl	5aca <set_chunk_used>
	return c + chunk_size(h, c);
    5d66:	4621      	mov	r1, r4
    5d68:	f7ff fea9 	bl	5abe <chunk_size>
    5d6c:	1826      	adds	r6, r4, r0
	return chunk_field(h, c, SIZE_AND_USED) & 1;
    5d6e:	2201      	movs	r2, #1
    5d70:	4631      	mov	r1, r6
    5d72:	4628      	mov	r0, r5
    5d74:	f7ff fe8d 	bl	5a92 <chunk_field>
	if (!chunk_used(h, right_chunk(h, c))) {
    5d78:	07c3      	lsls	r3, r0, #31
    5d7a:	d40c      	bmi.n	5d96 <sys_heap_free+0x58>
		free_list_remove(h, right_chunk(h, c));
    5d7c:	4631      	mov	r1, r6
    5d7e:	4628      	mov	r0, r5
    5d80:	f7ff ff40 	bl	5c04 <free_list_remove>
	return c + chunk_size(h, c);
    5d84:	4621      	mov	r1, r4
    5d86:	4628      	mov	r0, r5
    5d88:	f7ff fe99 	bl	5abe <chunk_size>
		merge_chunks(h, c, right_chunk(h, c));
    5d8c:	4621      	mov	r1, r4
    5d8e:	1822      	adds	r2, r4, r0
    5d90:	4628      	mov	r0, r5
    5d92:	f7ff fec3 	bl	5b1c <merge_chunks>
	return c - chunk_field(h, c, LEFT_SIZE);
    5d96:	2200      	movs	r2, #0
    5d98:	4621      	mov	r1, r4
    5d9a:	4628      	mov	r0, r5
    5d9c:	f7ff fe79 	bl	5a92 <chunk_field>
    5da0:	1a27      	subs	r7, r4, r0
	return chunk_field(h, c, SIZE_AND_USED) & 1;
    5da2:	2201      	movs	r2, #1
    5da4:	4639      	mov	r1, r7
    5da6:	4628      	mov	r0, r5
    5da8:	f7ff fe73 	bl	5a92 <chunk_field>
	if (!chunk_used(h, left_chunk(h, c))) {
    5dac:	f010 0601 	ands.w	r6, r0, #1
    5db0:	d113      	bne.n	5dda <sys_heap_free+0x9c>
		free_list_remove(h, left_chunk(h, c));
    5db2:	4639      	mov	r1, r7
    5db4:	4628      	mov	r0, r5
    5db6:	f7ff ff25 	bl	5c04 <free_list_remove>
	return c - chunk_field(h, c, LEFT_SIZE);
    5dba:	4621      	mov	r1, r4
    5dbc:	4632      	mov	r2, r6
    5dbe:	4628      	mov	r0, r5
    5dc0:	f7ff fe67 	bl	5a92 <chunk_field>
		merge_chunks(h, left_chunk(h, c), c);
    5dc4:	4622      	mov	r2, r4
    5dc6:	1a21      	subs	r1, r4, r0
    5dc8:	4628      	mov	r0, r5
    5dca:	f7ff fea7 	bl	5b1c <merge_chunks>
    5dce:	4621      	mov	r1, r4
    5dd0:	4632      	mov	r2, r6
    5dd2:	4628      	mov	r0, r5
    5dd4:	f7ff fe5d 	bl	5a92 <chunk_field>
    5dd8:	1a24      	subs	r4, r4, r0
	free_list_add(h, c);
    5dda:	4621      	mov	r1, r4
    5ddc:	4628      	mov	r0, r5
}
    5dde:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, c);
    5de2:	f7ff bf67 	b.w	5cb4 <free_list_add>
}
    5de6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

00005de8 <sys_heap_alloc>:

void *sys_heap_alloc(struct sys_heap *heap, size_t bytes)
{
    5de8:	b570      	push	{r4, r5, r6, lr}
	if (bytes == 0) {
    5dea:	b909      	cbnz	r1, 5df0 <sys_heap_alloc+0x8>
		return NULL;
    5dec:	2000      	movs	r0, #0
		free_list_add(h, c + chunk_sz);
	}

	set_chunk_used(h, c, true);
	return chunk_mem(h, c);
}
    5dee:	bd70      	pop	{r4, r5, r6, pc}
	struct z_heap *h = heap->heap;
    5df0:	6805      	ldr	r5, [r0, #0]
	return big_heap(h) ? 8 : 4;
    5df2:	68ab      	ldr	r3, [r5, #8]
    5df4:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5df8:	bf2c      	ite	cs
    5dfa:	2208      	movcs	r2, #8
    5dfc:	2204      	movcc	r2, #4
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    5dfe:	1dcc      	adds	r4, r1, #7
    5e00:	4414      	add	r4, r2
    5e02:	08e4      	lsrs	r4, r4, #3
	chunkid_t c = alloc_chunk(h, chunk_sz);
    5e04:	4621      	mov	r1, r4
    5e06:	4628      	mov	r0, r5
    5e08:	f7ff ff13 	bl	5c32 <alloc_chunk>
	if (c == 0) {
    5e0c:	4606      	mov	r6, r0
    5e0e:	2800      	cmp	r0, #0
    5e10:	d0ec      	beq.n	5dec <sys_heap_alloc+0x4>
	if (chunk_size(h, c) > chunk_sz) {
    5e12:	4601      	mov	r1, r0
    5e14:	4628      	mov	r0, r5
    5e16:	f7ff fe52 	bl	5abe <chunk_size>
    5e1a:	42a0      	cmp	r0, r4
    5e1c:	d909      	bls.n	5e32 <sys_heap_alloc+0x4a>
		split_chunks(h, c, c + chunk_sz);
    5e1e:	4434      	add	r4, r6
    5e20:	4631      	mov	r1, r6
    5e22:	4628      	mov	r0, r5
    5e24:	4622      	mov	r2, r4
    5e26:	f7ff fe97 	bl	5b58 <split_chunks>
		free_list_add(h, c + chunk_sz);
    5e2a:	4621      	mov	r1, r4
    5e2c:	4628      	mov	r0, r5
    5e2e:	f7ff ff41 	bl	5cb4 <free_list_add>
	set_chunk_used(h, c, true);
    5e32:	4628      	mov	r0, r5
    5e34:	2201      	movs	r2, #1
    5e36:	4631      	mov	r1, r6
    5e38:	f7ff fe47 	bl	5aca <set_chunk_used>
	return big_heap(h) ? 8 : 4;
    5e3c:	68ab      	ldr	r3, [r5, #8]
    5e3e:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5e42:	bf2c      	ite	cs
    5e44:	2008      	movcs	r0, #8
    5e46:	2004      	movcc	r0, #4
	uint8_t *ret = ((uint8_t *)&buf[c]) + chunk_header_bytes(h);
    5e48:	eb00 00c6 	add.w	r0, r0, r6, lsl #3
    5e4c:	4428      	add	r0, r5
	return chunk_mem(h, c);
    5e4e:	e7ce      	b.n	5dee <sys_heap_alloc+0x6>

00005e50 <sys_heap_init>:
	return big_heap_bytes(size) ? 8 : 4;
    5e50:	f5b2 2f80 	cmp.w	r2, #262144	; 0x40000
	set_chunk_used(h, c, true);
	return mem;
}

void sys_heap_init(struct sys_heap *heap, void *mem, size_t bytes)
{
    5e54:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    5e56:	bf2c      	ite	cs
    5e58:	2508      	movcs	r5, #8
    5e5a:	2504      	movcc	r5, #4
	/* Must fit in a 32 bit count of HUNK_UNIT */
	__ASSERT(bytes / CHUNK_UNIT <= 0xffffffffU, "heap size is too big");

	/* Reserve the final marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
    5e5c:	1b55      	subs	r5, r2, r5

	/* Round the start up, the end down */
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    5e5e:	1dcc      	adds	r4, r1, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    5e60:	440d      	add	r5, r1
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    5e62:	f024 0407 	bic.w	r4, r4, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    5e66:	f025 0507 	bic.w	r5, r5, #7
	CHECK(end > addr);
	__ASSERT(buf_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->chunk0_hdr_area = 0;
    5e6a:	2200      	movs	r2, #0
    5e6c:	2300      	movs	r3, #0
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    5e6e:	1b2d      	subs	r5, r5, r4
	heap->heap = h;
    5e70:	6004      	str	r4, [r0, #0]
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    5e72:	08ed      	lsrs	r5, r5, #3
	h->chunk0_hdr_area = 0;
    5e74:	e9c4 2300 	strd	r2, r3, [r4]
	h->len = buf_sz;
	h->avail_buckets = 0;
    5e78:	2300      	movs	r3, #0

	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5e7a:	4629      	mov	r1, r5
	h->len = buf_sz;
    5e7c:	60a5      	str	r5, [r4, #8]
	h->avail_buckets = 0;
    5e7e:	60e3      	str	r3, [r4, #12]
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5e80:	4620      	mov	r0, r4
    5e82:	f7ff fe3e 	bl	5b02 <bucket_idx>
	size_t chunk0_size = chunksz(sizeof(struct z_heap) +
    5e86:	0086      	lsls	r6, r0, #2
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    5e88:	361b      	adds	r6, #27
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5e8a:	1c41      	adds	r1, r0, #1
    5e8c:	08f6      	lsrs	r6, r6, #3
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) < buf_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
    5e8e:	f104 0210 	add.w	r2, r4, #16
		h->buckets[i].next = 0;
    5e92:	4618      	mov	r0, r3
	for (int i = 0; i < nb_buckets; i++) {
    5e94:	428b      	cmp	r3, r1
    5e96:	db29      	blt.n	5eec <sys_heap_init+0x9c>
	}

	/* chunk containing our struct z_heap */
	set_chunk_size(h, 0, chunk0_size);
    5e98:	4632      	mov	r2, r6
    5e9a:	4620      	mov	r0, r4
    5e9c:	2100      	movs	r1, #0
    5e9e:	f7ff fe2c 	bl	5afa <set_chunk_size>
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    5ea2:	1baf      	subs	r7, r5, r6
	set_chunk_used(h, 0, true);
    5ea4:	4620      	mov	r0, r4
    5ea6:	2201      	movs	r2, #1
    5ea8:	2100      	movs	r1, #0
    5eaa:	f7ff fe0e 	bl	5aca <set_chunk_used>
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    5eae:	463a      	mov	r2, r7
    5eb0:	4631      	mov	r1, r6
    5eb2:	f7ff fe22 	bl	5afa <set_chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5eb6:	4633      	mov	r3, r6
    5eb8:	4631      	mov	r1, r6
    5eba:	4620      	mov	r0, r4
    5ebc:	2200      	movs	r2, #0
    5ebe:	f7ff fdf3 	bl	5aa8 <chunk_set>
	set_left_chunk_size(h, chunk0_size, chunk0_size);

	/* the end marker chunk */
	set_chunk_size(h, buf_sz, 0);
    5ec2:	4629      	mov	r1, r5
    5ec4:	4620      	mov	r0, r4
    5ec6:	2200      	movs	r2, #0
    5ec8:	f7ff fe17 	bl	5afa <set_chunk_size>
    5ecc:	463b      	mov	r3, r7
    5ece:	4629      	mov	r1, r5
    5ed0:	4620      	mov	r0, r4
    5ed2:	2200      	movs	r2, #0
    5ed4:	f7ff fde8 	bl	5aa8 <chunk_set>
	set_left_chunk_size(h, buf_sz, buf_sz - chunk0_size);
	set_chunk_used(h, buf_sz, true);
    5ed8:	4629      	mov	r1, r5
    5eda:	4620      	mov	r0, r4
    5edc:	2201      	movs	r2, #1
    5ede:	f7ff fdf4 	bl	5aca <set_chunk_used>

	free_list_add(h, chunk0_size);
    5ee2:	4631      	mov	r1, r6
}
    5ee4:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, chunk0_size);
    5ee8:	f7ff bee4 	b.w	5cb4 <free_list_add>
		h->buckets[i].next = 0;
    5eec:	f842 0b04 	str.w	r0, [r2], #4
	for (int i = 0; i < nb_buckets; i++) {
    5ef0:	3301      	adds	r3, #1
    5ef2:	e7cf      	b.n	5e94 <sys_heap_init+0x44>

00005ef4 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5ef4:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5ef8:	b923      	cbnz	r3, 5f04 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5efa:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5efe:	f000 0001 	and.w	r0, r0, #1
    5f02:	4770      	bx	lr
		return false;
    5f04:	2000      	movs	r0, #0
}
    5f06:	4770      	bx	lr

00005f08 <z_impl_z_sys_mutex_kernel_lock>:
{
    5f08:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5f0c:	4615      	mov	r5, r2
    5f0e:	461c      	mov	r4, r3
	obj = z_object_find(mutex);
    5f10:	f7fa f8e4 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_SYS_MUTEX) {
    5f14:	b1a8      	cbz	r0, 5f42 <z_impl_z_sys_mutex_kernel_lock+0x3a>
    5f16:	7983      	ldrb	r3, [r0, #6]
    5f18:	2b0e      	cmp	r3, #14
    5f1a:	d112      	bne.n	5f42 <z_impl_z_sys_mutex_kernel_lock+0x3a>
	return obj->data.mutex;
    5f1c:	6881      	ldr	r1, [r0, #8]
	if (kernel_mutex == NULL) {
    5f1e:	b181      	cbz	r1, 5f42 <z_impl_z_sys_mutex_kernel_lock+0x3a>
    5f20:	f7ff ffe8 	bl	5ef4 <arch_is_user_context>
	if (z_syscall_trap()) {
    5f24:	b130      	cbz	r0, 5f34 <z_impl_z_sys_mutex_kernel_lock+0x2c>
	register uint32_t ret __asm__("r0") = arg1;
    5f26:	4608      	mov	r0, r1
	register uint32_t r2 __asm__("r2") = arg3;
    5f28:	4622      	mov	r2, r4
	register uint32_t r1 __asm__("r1") = arg2;
    5f2a:	4629      	mov	r1, r5
	register uint32_t r6 __asm__("r6") = call_id;
    5f2c:	266c      	movs	r6, #108	; 0x6c
	__asm__ volatile("svc %[svid]\n"
    5f2e:	df03      	svc	3
}
    5f30:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return z_impl_k_mutex_lock(mutex, timeout);
    5f34:	462a      	mov	r2, r5
    5f36:	4623      	mov	r3, r4
    5f38:	4608      	mov	r0, r1
    5f3a:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5f3e:	f7fd bba5 	b.w	368c <z_impl_k_mutex_lock>
		return -EINVAL;
    5f42:	f06f 0015 	mvn.w	r0, #21
    5f46:	e7f3      	b.n	5f30 <z_impl_z_sys_mutex_kernel_lock+0x28>

00005f48 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_DISASSEMBLY, 1);
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_PRINT_MEMORY_USAGE, 1);
GEN_ABSOLUTE_SYM(CONFIG_BUILD_OUTPUT_BIN, 1);
GEN_ABSOLUTE_SYM(CONFIG_COMPAT_INCLUDES, 1);

GEN_ABS_SYM_END
    5f48:	4770      	bx	lr

00005f4a <uart_poll_out>:
}


extern void z_impl_uart_poll_out(struct device * dev, unsigned char out_char);
static inline void uart_poll_out(struct device * dev, unsigned char out_char)
{
    5f4a:	e92d 4147 	stmdb	sp!, {r0, r1, r2, r6, r8, lr}
    5f4e:	4603      	mov	r3, r0
    5f50:	f88d 1007 	strb.w	r1, [sp, #7]
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5f54:	f3ef 8205 	mrs	r2, IPSR
	if (value) {
    5f58:	b952      	cbnz	r2, 5f70 <uart_poll_out+0x26>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5f5a:	f3ef 8214 	mrs	r2, CONTROL
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    5f5e:	07d2      	lsls	r2, r2, #31
    5f60:	d506      	bpl.n	5f70 <uart_poll_out+0x26>
	register uint32_t r1 __asm__("r1") = arg2;
    5f62:	f8dd 1007 	ldr.w	r1, [sp, #7]
	register uint32_t r6 __asm__("r6") = call_id;
    5f66:	26e5      	movs	r6, #229	; 0xe5
	__asm__ volatile("svc %[svid]\n"
    5f68:	df03      	svc	3
		return;
	}
#endif
	compiler_barrier();
	z_impl_uart_poll_out(dev, out_char);
}
    5f6a:	b003      	add	sp, #12
    5f6c:	e8bd 8140 	ldmia.w	sp!, {r6, r8, pc}
	api->poll_out(dev, out_char);
    5f70:	689a      	ldr	r2, [r3, #8]
    5f72:	f89d 1007 	ldrb.w	r1, [sp, #7]
    5f76:	6852      	ldr	r2, [r2, #4]
    5f78:	4618      	mov	r0, r3
    5f7a:	4790      	blx	r2
}
    5f7c:	e7f5      	b.n	5f6a <uart_poll_out+0x20>

00005f7e <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5f7e:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5f82:	b923      	cbnz	r3, 5f8e <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5f84:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5f88:	f000 0001 	and.w	r0, r0, #1
    5f8c:	4770      	bx	lr
		return false;
    5f8e:	2000      	movs	r0, #0
}
    5f90:	4770      	bx	lr

00005f92 <get_status>:
	return GET_STATUS(get_sub_data(dev, type)->flags);
    5f92:	68c2      	ldr	r2, [r0, #12]
    5f94:	b2cb      	uxtb	r3, r1
    5f96:	210c      	movs	r1, #12
    5f98:	fb03 2101 	mla	r1, r3, r1, r2
    5f9c:	6c08      	ldr	r0, [r1, #64]	; 0x40
}
    5f9e:	f000 0007 	and.w	r0, r0, #7
    5fa2:	4770      	bx	lr

00005fa4 <set_off_state>:
	__asm__ volatile(
    5fa4:	f04f 0320 	mov.w	r3, #32
    5fa8:	f3ef 8211 	mrs	r2, BASEPRI
    5fac:	f383 8811 	msr	BASEPRI, r3
    5fb0:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    5fb4:	6803      	ldr	r3, [r0, #0]
	if ((current_ctx != 0) && (current_ctx != ctx)) {
    5fb6:	f013 03c0 	ands.w	r3, r3, #192	; 0xc0
    5fba:	d001      	beq.n	5fc0 <set_off_state+0x1c>
    5fbc:	428b      	cmp	r3, r1
    5fbe:	d107      	bne.n	5fd0 <set_off_state+0x2c>
		*flags = CLOCK_CONTROL_STATUS_OFF;
    5fc0:	2301      	movs	r3, #1
    5fc2:	6003      	str	r3, [r0, #0]
	int err = 0;
    5fc4:	2000      	movs	r0, #0
	__asm__ volatile(
    5fc6:	f382 8811 	msr	BASEPRI, r2
    5fca:	f3bf 8f6f 	isb	sy
}
    5fce:	4770      	bx	lr
		err = -EPERM;
    5fd0:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    5fd4:	e7f7      	b.n	5fc6 <set_off_state+0x22>

00005fd6 <set_starting_state>:
{
    5fd6:	b510      	push	{r4, lr}
	__asm__ volatile(
    5fd8:	f04f 0320 	mov.w	r3, #32
    5fdc:	f3ef 8211 	mrs	r2, BASEPRI
    5fe0:	f383 8811 	msr	BASEPRI, r3
    5fe4:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    5fe8:	6803      	ldr	r3, [r0, #0]
	if ((*flags & (STATUS_MASK)) == CLOCK_CONTROL_STATUS_OFF) {
    5fea:	f003 0407 	and.w	r4, r3, #7
    5fee:	2c01      	cmp	r4, #1
    5ff0:	d106      	bne.n	6000 <set_starting_state+0x2a>
		*flags = CLOCK_CONTROL_STATUS_STARTING | ctx;
    5ff2:	6001      	str	r1, [r0, #0]
	int err = 0;
    5ff4:	2000      	movs	r0, #0
	__asm__ volatile(
    5ff6:	f382 8811 	msr	BASEPRI, r2
    5ffa:	f3bf 8f6f 	isb	sy
}
    5ffe:	bd10      	pop	{r4, pc}
	uint32_t current_ctx = GET_CTX(*flags);
    6000:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
	} else if (current_ctx != ctx) {
    6004:	428b      	cmp	r3, r1
		err = -EBUSY;
    6006:	bf14      	ite	ne
    6008:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
    600c:	f06f 000f 	mvneq.w	r0, #15
    6010:	e7f1      	b.n	5ff6 <set_starting_state+0x20>

00006012 <set_on_state>:
	__asm__ volatile(
    6012:	f04f 0320 	mov.w	r3, #32
    6016:	f3ef 8211 	mrs	r2, BASEPRI
    601a:	f383 8811 	msr	BASEPRI, r3
    601e:	f3bf 8f6f 	isb	sy
	*flags = CLOCK_CONTROL_STATUS_ON | GET_CTX(*flags);
    6022:	6803      	ldr	r3, [r0, #0]
    6024:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
    6028:	f043 0302 	orr.w	r3, r3, #2
    602c:	6003      	str	r3, [r0, #0]
	__asm__ volatile(
    602e:	f382 8811 	msr	BASEPRI, r2
    6032:	f3bf 8f6f 	isb	sy
}
    6036:	4770      	bx	lr

00006038 <onoff_started_callback>:
	return &data->mgr[type];
    6038:	68c0      	ldr	r0, [r0, #12]
{
    603a:	b410      	push	{r4}
	return &data->mgr[type];
    603c:	b2cb      	uxtb	r3, r1
	notify(mgr, 0);
    603e:	241c      	movs	r4, #28
    6040:	fb03 0004 	mla	r0, r3, r4, r0
    6044:	2100      	movs	r1, #0
}
    6046:	bc10      	pop	{r4}
	notify(mgr, 0);
    6048:	4710      	bx	r2

0000604a <blocking_start_callback>:
{
    604a:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    604e:	f7ff ff96 	bl	5f7e <arch_is_user_context>
	if (z_syscall_trap()) {
    6052:	b120      	cbz	r0, 605e <blocking_start_callback+0x14>
	register uint32_t ret __asm__("r0") = arg1;
    6054:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    6056:	2684      	movs	r6, #132	; 0x84
	__asm__ volatile("svc %[svid]\n"
    6058:	df03      	svc	3
}
    605a:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    605e:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_sem_give(sem);
    6062:	4610      	mov	r0, r2
    6064:	f7fe bac8 	b.w	45f8 <z_impl_k_sem_give>

00006068 <lfclk_spinwait>:
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    6068:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    606c:	f8d2 3418 	ldr.w	r3, [r2, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    6070:	f8d2 1418 	ldr.w	r1, [r2, #1048]	; 0x418
    6074:	03c9      	lsls	r1, r1, #15
    6076:	d5f9      	bpl.n	606c <lfclk_spinwait+0x4>
                                        >> CLOCK_LFCLKSTAT_SRC_Pos);
    6078:	f003 0303 	and.w	r3, r3, #3
	while (!(nrf_clock_is_running(NRF_CLOCK, d, (void *)&type)
    607c:	4298      	cmp	r0, r3
    607e:	d1f5      	bne.n	606c <lfclk_spinwait+0x4>
}
    6080:	4770      	bx	lr

00006082 <api_stop>:
{
    6082:	b538      	push	{r3, r4, r5, lr}
    6084:	b2cc      	uxtb	r4, r1
	err = set_off_state(&subdata->flags, ctx);
    6086:	230c      	movs	r3, #12
{
    6088:	4605      	mov	r5, r0
	err = set_off_state(&subdata->flags, ctx);
    608a:	4363      	muls	r3, r4
    608c:	68c0      	ldr	r0, [r0, #12]
    608e:	3340      	adds	r3, #64	; 0x40
    6090:	2180      	movs	r1, #128	; 0x80
    6092:	4418      	add	r0, r3
    6094:	f7ff ff86 	bl	5fa4 <set_off_state>
	if (err < 0) {
    6098:	2800      	cmp	r0, #0
    609a:	db05      	blt.n	60a8 <api_stop+0x26>
	get_sub_config(dev, type)->stop();
    609c:	6869      	ldr	r1, [r5, #4]
    609e:	eb01 04c4 	add.w	r4, r1, r4, lsl #3
    60a2:	6863      	ldr	r3, [r4, #4]
    60a4:	4798      	blx	r3
	return 0;
    60a6:	2000      	movs	r0, #0
}
    60a8:	bd38      	pop	{r3, r4, r5, pc}

000060aa <api_start>:
{
    60aa:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    60ae:	b2cd      	uxtb	r5, r1
	err = set_starting_state(&subdata->flags, ctx);
    60b0:	f04f 080c 	mov.w	r8, #12
	struct nrf_clock_control_sub_data *subdata = get_sub_data(dev, type);
    60b4:	68c4      	ldr	r4, [r0, #12]
	err = set_starting_state(&subdata->flags, ctx);
    60b6:	fb08 f805 	mul.w	r8, r8, r5
{
    60ba:	4606      	mov	r6, r0
	err = set_starting_state(&subdata->flags, ctx);
    60bc:	f108 0040 	add.w	r0, r8, #64	; 0x40
    60c0:	2180      	movs	r1, #128	; 0x80
    60c2:	4420      	add	r0, r4
{
    60c4:	4617      	mov	r7, r2
	err = set_starting_state(&subdata->flags, ctx);
    60c6:	f7ff ff86 	bl	5fd6 <set_starting_state>
	if (err < 0) {
    60ca:	2800      	cmp	r0, #0
    60cc:	db09      	blt.n	60e2 <api_start+0x38>
	subdata->cb = data->cb;
    60ce:	4444      	add	r4, r8
    60d0:	687b      	ldr	r3, [r7, #4]
    60d2:	63a3      	str	r3, [r4, #56]	; 0x38
	subdata->user_data = data->user_data;
    60d4:	68bb      	ldr	r3, [r7, #8]
    60d6:	63e3      	str	r3, [r4, #60]	; 0x3c
	 get_sub_config(dev, type)->start();
    60d8:	6873      	ldr	r3, [r6, #4]
    60da:	f853 3035 	ldr.w	r3, [r3, r5, lsl #3]
    60de:	4798      	blx	r3
	return 0;
    60e0:	2000      	movs	r0, #0
}
    60e2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

000060e6 <z_clock_isr>:
/* Weak-linked noop defaults for optional driver interfaces: */

void __weak z_clock_isr(void *arg)
{
	__ASSERT_NO_MSG(false);
}
    60e6:	4770      	bx	lr

000060e8 <z_clock_idle_exit>:
{
}

void __weak z_clock_idle_exit(void)
{
}
    60e8:	4770      	bx	lr

000060ea <SEGGER_RTT_Init>:
*    Initializes the RTT Control Block.
*    Should be used in RAM targets, at start of the application.
*
*/
void SEGGER_RTT_Init (void) {
  _DoInit();
    60ea:	f7fb ba25 	b.w	1538 <_DoInit>

000060ee <rtt_init>:
 */

K_MUTEX_DEFINE(rtt_term_mutex);

static int rtt_init(struct device *unused)
{
    60ee:	b508      	push	{r3, lr}
	ARG_UNUSED(unused);

	SEGGER_RTT_Init();
    60f0:	f7ff fffb 	bl	60ea <SEGGER_RTT_Init>

	return 0;
}
    60f4:	2000      	movs	r0, #0
    60f6:	bd08      	pop	{r3, pc}

000060f8 <z_irq_spurious>:
 */
void z_irq_spurious(void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
    60f8:	2100      	movs	r1, #0
    60fa:	2001      	movs	r0, #1
    60fc:	f000 b80a 	b.w	6114 <z_arm_fatal_error>

00006100 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6100:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6104:	b923      	cbnz	r3, 6110 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6106:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    610a:	f000 0001 	and.w	r0, r0, #1
    610e:	4770      	bx	lr
		return false;
    6110:	2000      	movs	r0, #0
}
    6112:	4770      	bx	lr

00006114 <z_arm_fatal_error>:
	LOG_ERR("Faulting instruction address (r15/pc): 0x%08x",
		esf->basic.pc);
}

void z_arm_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    6114:	b508      	push	{r3, lr}
    6116:	4602      	mov	r2, r0

	if (esf != NULL) {
    6118:	b139      	cbz	r1, 612a <z_arm_fatal_error+0x16>
	return arch_is_user_context();
    611a:	f7ff fff1 	bl	6100 <arch_is_user_context>
    611e:	f7ff ffef 	bl	6100 <arch_is_user_context>
    6122:	f7ff ffed 	bl	6100 <arch_is_user_context>
    6126:	f7ff ffeb 	bl	6100 <arch_is_user_context>
		esf_dump(esf);
	}
	z_fatal_error(reason, esf);
}
    612a:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_fatal_error(reason, esf);
    612e:	4610      	mov	r0, r2
    6130:	f000 b955 	b.w	63de <z_fatal_error>

00006134 <z_do_kernel_oops>:
 *   fault handler will executed insted of the SVC.
 *
 * @param esf exception frame
 */
void z_do_kernel_oops(const z_arch_esf_t *esf)
{
    6134:	4601      	mov	r1, r0
	/* Stacked R0 holds the exception reason. */
	unsigned int reason = esf->basic.r0;
    6136:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    6138:	f3ef 8314 	mrs	r3, CONTROL

#if defined(CONFIG_USERSPACE)
	if ((__get_CONTROL() & CONTROL_nPRIV_Msk) == CONTROL_nPRIV_Msk) {
    613c:	07db      	lsls	r3, r3, #31
    613e:	d503      	bpl.n	6148 <z_do_kernel_oops+0x14>
		 * Exception triggered from nPRIV mode.
		 *
		 * User mode is only allowed to induce oopses and stack check
		 * failures via software-triggered system fatal exceptions.
		 */
		if (!((esf->basic.r0 == K_ERR_KERNEL_OOPS) ||
    6140:	1e83      	subs	r3, r0, #2
			(esf->basic.r0 == K_ERR_STACK_CHK_FAIL))) {

			reason = K_ERR_KERNEL_OOPS;
    6142:	2b02      	cmp	r3, #2
    6144:	bf28      	it	cs
    6146:	2003      	movcs	r0, #3
		}
	}

#endif /* CONFIG_USERSPACE */
	z_arm_fatal_error(reason, esf);
    6148:	f7ff bfe4 	b.w	6114 <z_arm_fatal_error>

0000614c <arch_syscall_oops>:
}

FUNC_NORETURN void arch_syscall_oops(void *ssf_ptr)
{
    614c:	b500      	push	{lr}
    614e:	4604      	mov	r4, r0
    6150:	b089      	sub	sp, #36	; 0x24
	uint32_t *ssf_contents = ssf_ptr;
	z_arch_esf_t oops_esf = { 0 };
    6152:	2100      	movs	r1, #0
    6154:	2220      	movs	r2, #32
    6156:	4668      	mov	r0, sp
    6158:	f000 f873 	bl	6242 <memset>

	/* TODO: Copy the rest of the register set out of ssf_ptr */
	oops_esf.basic.pc = ssf_contents[3];
    615c:	68e3      	ldr	r3, [r4, #12]
    615e:	9306      	str	r3, [sp, #24]

	z_arm_fatal_error(K_ERR_KERNEL_OOPS, &oops_esf);
    6160:	4669      	mov	r1, sp
    6162:	2003      	movs	r0, #3
    6164:	f7ff ffd6 	bl	6114 <z_arm_fatal_error>

00006168 <z_arm_nmi>:
 *
 * @return N/A
 */

void z_arm_nmi(void)
{
    6168:	b508      	push	{r3, lr}
	handler();
    616a:	f7fb fb5f 	bl	182c <z_SysNmiOnReset>
	z_arm_int_exit();
}
    616e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
    6172:	f7fb bdc5 	b.w	1d00 <z_arm_exc_exit>

00006176 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6176:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    617a:	b923      	cbnz	r3, 6186 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    617c:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6180:	f000 0001 	and.w	r0, r0, #1
    6184:	4770      	bx	lr
		return false;
    6186:	2000      	movs	r0, #0
}
    6188:	4770      	bx	lr

0000618a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    618a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    618e:	b923      	cbnz	r3, 619a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6190:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6194:	f000 0001 	and.w	r0, r0, #1
    6198:	4770      	bx	lr
		return false;
    619a:	2000      	movs	r0, #0
}
    619c:	4770      	bx	lr

0000619e <arch_mem_domain_max_partitions_get>:
{
    619e:	b508      	push	{r3, lr}
	int available_regions = arm_core_mpu_get_max_available_dyn_regions();
    61a0:	f7fb fede 	bl	1f60 <arm_core_mpu_get_max_available_dyn_regions>
}
    61a4:	3801      	subs	r0, #1
    61a6:	bd08      	pop	{r3, pc}

000061a8 <arch_buffer_validate>:
	arch_mem_domain_destroy(thread->mem_domain_info.mem_domain);
}

int arch_buffer_validate(void *addr, size_t size, int write)
{
	return arm_core_mpu_buffer_validate(addr, size, write);
    61a8:	f7fb bee2 	b.w	1f70 <arm_core_mpu_buffer_validate>

000061ac <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    61ac:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    61b0:	b923      	cbnz	r3, 61bc <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    61b2:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    61b6:	f000 0001 	and.w	r0, r0, #1
    61ba:	4770      	bx	lr
		return false;
    61bc:	2000      	movs	r0, #0
}
    61be:	4770      	bx	lr

000061c0 <strcpy>:

char *strcpy(char *_MLIBC_RESTRICT d, const char *_MLIBC_RESTRICT s)
{
	char *dest = d;

	while (*s != '\0') {
    61c0:	3901      	subs	r1, #1
    61c2:	4603      	mov	r3, r0
    61c4:	f811 2f01 	ldrb.w	r2, [r1, #1]!
    61c8:	b90a      	cbnz	r2, 61ce <strcpy+0xe>
		*d = *s;
		d++;
		s++;
	}

	*d = '\0';
    61ca:	701a      	strb	r2, [r3, #0]

	return dest;
}
    61cc:	4770      	bx	lr
		*d = *s;
    61ce:	f803 2b01 	strb.w	r2, [r3], #1
		s++;
    61d2:	e7f7      	b.n	61c4 <strcpy+0x4>

000061d4 <strcmp>:
 * @return negative # if <s1> < <s2>, 0 if <s1> == <s2>, else positive #
 */

int strcmp(const char *s1, const char *s2)
{
	while ((*s1 == *s2) && (*s1 != '\0')) {
    61d4:	1e43      	subs	r3, r0, #1
    61d6:	3901      	subs	r1, #1
    61d8:	f813 2f01 	ldrb.w	r2, [r3, #1]!
    61dc:	f811 0f01 	ldrb.w	r0, [r1, #1]!
    61e0:	4282      	cmp	r2, r0
    61e2:	d101      	bne.n	61e8 <strcmp+0x14>
    61e4:	2a00      	cmp	r2, #0
    61e6:	d1f7      	bne.n	61d8 <strcmp+0x4>
		s1++;
		s2++;
	}

	return *s1 - *s2;
}
    61e8:	1a10      	subs	r0, r2, r0
    61ea:	4770      	bx	lr

000061ec <memcpy>:
 *
 * @return pointer to start of destination buffer
 */

void *memcpy(void *_MLIBC_RESTRICT d, const void *_MLIBC_RESTRICT s, size_t n)
{
    61ec:	b5f0      	push	{r4, r5, r6, r7, lr}

	unsigned char *d_byte = (unsigned char *)d;
	const unsigned char *s_byte = (const unsigned char *)s;
	const uintptr_t mask = sizeof(mem_word_t) - 1;

	if ((((uintptr_t)d ^ (uintptr_t)s_byte) & mask) == 0) {
    61ee:	ea81 0400 	eor.w	r4, r1, r0
    61f2:	07a5      	lsls	r5, r4, #30
    61f4:	4603      	mov	r3, r0
    61f6:	d00b      	beq.n	6210 <memcpy+0x24>
    61f8:	3b01      	subs	r3, #1
    61fa:	440a      	add	r2, r1
		s_byte = (unsigned char *)s_word;
	}

	/* do byte-sized copying until finished */

	while (n > 0) {
    61fc:	4291      	cmp	r1, r2
    61fe:	d11b      	bne.n	6238 <memcpy+0x4c>
		*(d_byte++) = *(s_byte++);
		n--;
	}

	return d;
}
    6200:	bdf0      	pop	{r4, r5, r6, r7, pc}
			if (n == 0) {
    6202:	2a00      	cmp	r2, #0
    6204:	d0fc      	beq.n	6200 <memcpy+0x14>
			*(d_byte++) = *(s_byte++);
    6206:	f811 4b01 	ldrb.w	r4, [r1], #1
    620a:	f803 4b01 	strb.w	r4, [r3], #1
			n--;
    620e:	3a01      	subs	r2, #1
		while (((uintptr_t)d_byte) & mask) {
    6210:	079c      	lsls	r4, r3, #30
    6212:	d1f6      	bne.n	6202 <memcpy+0x16>
    6214:	f022 0403 	bic.w	r4, r2, #3
    6218:	1f1d      	subs	r5, r3, #4
    621a:	0896      	lsrs	r6, r2, #2
    621c:	190f      	adds	r7, r1, r4
		while (n >= sizeof(mem_word_t)) {
    621e:	42b9      	cmp	r1, r7
    6220:	d105      	bne.n	622e <memcpy+0x42>
    6222:	f06f 0503 	mvn.w	r5, #3
    6226:	fb05 2206 	mla	r2, r5, r6, r2
    622a:	4423      	add	r3, r4
    622c:	e7e4      	b.n	61f8 <memcpy+0xc>
			*(d_word++) = *(s_word++);
    622e:	f851 cb04 	ldr.w	ip, [r1], #4
    6232:	f845 cf04 	str.w	ip, [r5, #4]!
			n -= sizeof(mem_word_t);
    6236:	e7f2      	b.n	621e <memcpy+0x32>
		*(d_byte++) = *(s_byte++);
    6238:	f811 4b01 	ldrb.w	r4, [r1], #1
    623c:	f803 4f01 	strb.w	r4, [r3, #1]!
		n--;
    6240:	e7dc      	b.n	61fc <memcpy+0x10>

00006242 <memset>:
 *
 * @return pointer to start of buffer
 */

void *memset(void *buf, int c, size_t n)
{
    6242:	b570      	push	{r4, r5, r6, lr}
	/* do byte-sized initialization until word-aligned or finished */

	unsigned char *d_byte = (unsigned char *)buf;
	unsigned char c_byte = (unsigned char)c;
    6244:	b2c9      	uxtb	r1, r1
	unsigned char *d_byte = (unsigned char *)buf;
    6246:	4603      	mov	r3, r0

	while (((uintptr_t)d_byte) & (sizeof(mem_word_t) - 1)) {
    6248:	079c      	lsls	r4, r3, #30
    624a:	d111      	bne.n	6270 <memset+0x2e>
	/* do word-sized initialization as long as possible */

	mem_word_t *d_word = (mem_word_t *)d_byte;
	mem_word_t c_word = (mem_word_t)c_byte;

	c_word |= c_word << 8;
    624c:	ea41 2401 	orr.w	r4, r1, r1, lsl #8
	c_word |= c_word << 16;
    6250:	f022 0603 	bic.w	r6, r2, #3
    6254:	ea44 4504 	orr.w	r5, r4, r4, lsl #16
#if Z_MEM_WORD_T_WIDTH > 32
	c_word |= c_word << 32;
#endif

	while (n >= sizeof(mem_word_t)) {
    6258:	441e      	add	r6, r3
    625a:	0894      	lsrs	r4, r2, #2
    625c:	42b3      	cmp	r3, r6
    625e:	d10d      	bne.n	627c <memset+0x3a>
    6260:	f06f 0503 	mvn.w	r5, #3
    6264:	fb05 2204 	mla	r2, r5, r4, r2
    6268:	441a      	add	r2, r3

	/* do byte-sized initialization until finished */

	d_byte = (unsigned char *)d_word;

	while (n > 0) {
    626a:	4293      	cmp	r3, r2
    626c:	d109      	bne.n	6282 <memset+0x40>
		*(d_byte++) = c_byte;
		n--;
	}

	return buf;
}
    626e:	bd70      	pop	{r4, r5, r6, pc}
		if (n == 0) {
    6270:	2a00      	cmp	r2, #0
    6272:	d0fc      	beq.n	626e <memset+0x2c>
		*(d_byte++) = c_byte;
    6274:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    6278:	3a01      	subs	r2, #1
    627a:	e7e5      	b.n	6248 <memset+0x6>
		*(d_word++) = c_word;
    627c:	f843 5b04 	str.w	r5, [r3], #4
		n -= sizeof(mem_word_t);
    6280:	e7ec      	b.n	625c <memset+0x1a>
		*(d_byte++) = c_byte;
    6282:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    6286:	e7f0      	b.n	626a <memset+0x28>

00006288 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6288:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    628c:	b923      	cbnz	r3, 6298 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    628e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6292:	f000 0001 	and.w	r0, r0, #1
    6296:	4770      	bx	lr
		return false;
    6298:	2000      	movs	r0, #0
}
    629a:	4770      	bx	lr

0000629c <_stdout_hook_default>:
}
    629c:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    62a0:	4770      	bx	lr

000062a2 <z_platform_init>:

void z_platform_init(void)
{
	SystemInit();
    62a2:	f7fc bd65 	b.w	2d70 <SystemInit>

000062a6 <gpio_nrfx_port_get_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    62a6:	6843      	ldr	r3, [r0, #4]
    62a8:	685b      	ldr	r3, [r3, #4]
    return p_reg->IN;
    62aa:	f8d3 3510 	ldr.w	r3, [r3, #1296]	; 0x510
	*value = nrf_gpio_port_in_read(reg);
    62ae:	600b      	str	r3, [r1, #0]
}
    62b0:	2000      	movs	r0, #0
    62b2:	4770      	bx	lr

000062b4 <gpio_nrfx_port_set_masked_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    62b4:	6843      	ldr	r3, [r0, #4]
    62b6:	685b      	ldr	r3, [r3, #4]
    return p_reg->OUT;
    62b8:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
	nrf_gpio_port_out_write(reg, value_tmp | (mask & value));
    62bc:	4042      	eors	r2, r0
    62be:	400a      	ands	r2, r1
    62c0:	4042      	eors	r2, r0
    p_reg->OUT = value;
    62c2:	f8c3 2504 	str.w	r2, [r3, #1284]	; 0x504
}
    62c6:	2000      	movs	r0, #0
    62c8:	4770      	bx	lr

000062ca <gpio_nrfx_port_set_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    62ca:	6843      	ldr	r3, [r0, #4]
    62cc:	685b      	ldr	r3, [r3, #4]
}
    62ce:	2000      	movs	r0, #0
    p_reg->OUTSET = set_mask;
    62d0:	f8c3 1508 	str.w	r1, [r3, #1288]	; 0x508
    62d4:	4770      	bx	lr

000062d6 <gpio_nrfx_port_clear_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    62d6:	6843      	ldr	r3, [r0, #4]
    62d8:	685b      	ldr	r3, [r3, #4]
}
    62da:	2000      	movs	r0, #0
    p_reg->OUTCLR = clr_mask;
    62dc:	f8c3 150c 	str.w	r1, [r3, #1292]	; 0x50c
    62e0:	4770      	bx	lr

000062e2 <gpio_nrfx_port_toggle_bits>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    62e2:	6843      	ldr	r3, [r0, #4]
    62e4:	685a      	ldr	r2, [r3, #4]
    return p_reg->OUT;
    62e6:	f8d2 3504 	ldr.w	r3, [r2, #1284]	; 0x504
	nrf_gpio_port_out_write(reg, value ^ mask);
    62ea:	404b      	eors	r3, r1
    p_reg->OUT = value;
    62ec:	f8c2 3504 	str.w	r3, [r2, #1284]	; 0x504
}
    62f0:	2000      	movs	r0, #0
    62f2:	4770      	bx	lr

000062f4 <gpio_nrfx_manage_callback>:
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    62f4:	68c3      	ldr	r3, [r0, #12]
Z_GENLIST_IS_EMPTY(slist)
    62f6:	6858      	ldr	r0, [r3, #4]
{
    62f8:	b530      	push	{r4, r5, lr}
	if (!sys_slist_is_empty(callbacks)) {
    62fa:	b158      	cbz	r0, 6314 <gpio_nrfx_manage_callback+0x20>
 * @return true if node was removed
 */
static inline bool sys_slist_find_and_remove(sys_slist_t *list,
					     sys_snode_t *node);

Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    62fc:	2400      	movs	r4, #0
    62fe:	4281      	cmp	r1, r0
    6300:	d113      	bne.n	632a <gpio_nrfx_manage_callback+0x36>
Z_GENLIST_REMOVE(slist, snode)
    6302:	6808      	ldr	r0, [r1, #0]
    6304:	b95c      	cbnz	r4, 631e <gpio_nrfx_manage_callback+0x2a>
    6306:	689c      	ldr	r4, [r3, #8]
	list->head = node;
    6308:	6058      	str	r0, [r3, #4]
Z_GENLIST_REMOVE(slist, snode)
    630a:	42a1      	cmp	r1, r4
    630c:	d100      	bne.n	6310 <gpio_nrfx_manage_callback+0x1c>
	list->tail = node;
    630e:	6098      	str	r0, [r3, #8]
	parent->next = child;
    6310:	2000      	movs	r0, #0
    6312:	6008      	str	r0, [r1, #0]
	if (set) {
    6314:	b972      	cbnz	r2, 6334 <gpio_nrfx_manage_callback+0x40>
	return 0;
    6316:	2000      	movs	r0, #0
}
    6318:	bd30      	pop	{r4, r5, pc}
    631a:	4628      	mov	r0, r5
    631c:	e7ef      	b.n	62fe <gpio_nrfx_manage_callback+0xa>
    631e:	6020      	str	r0, [r4, #0]
Z_GENLIST_REMOVE(slist, snode)
    6320:	6898      	ldr	r0, [r3, #8]
    6322:	4281      	cmp	r1, r0
	list->tail = node;
    6324:	bf08      	it	eq
    6326:	609c      	streq	r4, [r3, #8]
}
    6328:	e7f2      	b.n	6310 <gpio_nrfx_manage_callback+0x1c>
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    632a:	6805      	ldr	r5, [r0, #0]
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    632c:	4604      	mov	r4, r0
    632e:	2d00      	cmp	r5, #0
    6330:	d1f3      	bne.n	631a <gpio_nrfx_manage_callback+0x26>
			if (!set) {
    6332:	b13a      	cbz	r2, 6344 <gpio_nrfx_manage_callback+0x50>
Z_GENLIST_PREPEND(slist, snode)
    6334:	685a      	ldr	r2, [r3, #4]
	parent->next = child;
    6336:	600a      	str	r2, [r1, #0]
Z_GENLIST_PREPEND(slist, snode)
    6338:	6898      	ldr	r0, [r3, #8]
	list->head = node;
    633a:	6059      	str	r1, [r3, #4]
Z_GENLIST_PREPEND(slist, snode)
    633c:	2800      	cmp	r0, #0
    633e:	d1ea      	bne.n	6316 <gpio_nrfx_manage_callback+0x22>
	list->tail = node;
    6340:	6099      	str	r1, [r3, #8]
}
    6342:	e7e9      	b.n	6318 <gpio_nrfx_manage_callback+0x24>
				return -EINVAL;
    6344:	f06f 0015 	mvn.w	r0, #21
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    6348:	e7e6      	b.n	6318 <gpio_nrfx_manage_callback+0x24>

0000634a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    634a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    634e:	b923      	cbnz	r3, 635a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6350:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6354:	f000 0001 	and.w	r0, r0, #1
    6358:	4770      	bx	lr
		return false;
    635a:	2000      	movs	r0, #0
}
    635c:	4770      	bx	lr

0000635e <uart_nrfx_config_get>:
	*cfg = get_dev_data(dev)->uart_config;
    635e:	68c2      	ldr	r2, [r0, #12]
{
    6360:	460b      	mov	r3, r1
	*cfg = get_dev_data(dev)->uart_config;
    6362:	e892 0003 	ldmia.w	r2, {r0, r1}
    6366:	e883 0003 	stmia.w	r3, {r0, r1}
}
    636a:	2000      	movs	r0, #0
    636c:	4770      	bx	lr

0000636e <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    636e:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6372:	b923      	cbnz	r3, 637e <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6374:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6378:	f000 0001 	and.w	r0, r0, #1
    637c:	4770      	bx	lr
		return false;
    637e:	2000      	movs	r0, #0
}
    6380:	4770      	bx	lr

00006382 <nrfx_busy_wait>:
{
	((nrfx_irq_handler_t)irq_handler)();
}

void nrfx_busy_wait(uint32_t usec_to_wait)
{
    6382:	e92d 0140 	stmdb	sp!, {r6, r8}
    6386:	4603      	mov	r3, r0
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6388:	f3ef 8205 	mrs	r2, IPSR
	if (value) {
    638c:	b942      	cbnz	r2, 63a0 <nrfx_busy_wait+0x1e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    638e:	f3ef 8214 	mrs	r2, CONTROL
	if (z_syscall_trap()) {
    6392:	07d2      	lsls	r2, r2, #31
    6394:	d504      	bpl.n	63a0 <nrfx_busy_wait+0x1e>
	register uint32_t r6 __asm__("r6") = call_id;
    6396:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    6398:	df03      	svc	3
	k_busy_wait(usec_to_wait);
}
    639a:	e8bd 0140 	ldmia.w	sp!, {r6, r8}
    639e:	4770      	bx	lr
    63a0:	e8bd 0140 	ldmia.w	sp!, {r6, r8}
	z_impl_k_busy_wait(usec_to_wait);
    63a4:	4618      	mov	r0, r3
    63a6:	f000 bb56 	b.w	6a56 <z_impl_k_busy_wait>

000063aa <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    63aa:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    63ae:	b923      	cbnz	r3, 63ba <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    63b0:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    63b4:	f000 0001 	and.w	r0, r0, #1
    63b8:	4770      	bx	lr
		return false;
    63ba:	2000      	movs	r0, #0
}
    63bc:	4770      	bx	lr

000063be <arch_system_halt>:
	__asm__ volatile(
    63be:	f04f 0220 	mov.w	r2, #32
    63c2:	f3ef 8311 	mrs	r3, BASEPRI
    63c6:	f382 8811 	msr	BASEPRI, r2
    63ca:	f3bf 8f6f 	isb	sy
	/* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 */

	(void)arch_irq_lock();
	for (;;) {
    63ce:	e7fe      	b.n	63ce <arch_system_halt+0x10>

000063d0 <k_sys_fatal_error_handler>:
/* LCOV_EXCL_STOP */

/* LCOV_EXCL_START */
__weak void k_sys_fatal_error_handler(unsigned int reason,
				      const z_arch_esf_t *esf)
{
    63d0:	b508      	push	{r3, lr}
    63d2:	4602      	mov	r2, r0
    63d4:	f7ff ffe9 	bl	63aa <arch_is_user_context>
	ARG_UNUSED(esf);

	LOG_PANIC();
	LOG_ERR("Halting system");
	arch_system_halt(reason);
    63d8:	4610      	mov	r0, r2
    63da:	f7ff fff0 	bl	63be <arch_system_halt>

000063de <z_fatal_error>:
	return 0;
#endif
}

void z_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    63de:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    63e0:	4606      	mov	r6, r0
    63e2:	460c      	mov	r4, r1
    63e4:	f04f 0320 	mov.w	r3, #32
    63e8:	f3ef 8711 	mrs	r7, BASEPRI
    63ec:	f383 8811 	msr	BASEPRI, r3
    63f0:	f3bf 8f6f 	isb	sy
	return z_impl_k_current_get();
    63f4:	f7fe f828 	bl	4448 <z_impl_k_current_get>
    63f8:	4605      	mov	r5, r0
    63fa:	f7ff ffd6 	bl	63aa <arch_is_user_context>
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
    63fe:	b12c      	cbz	r4, 640c <z_fatal_error+0x2e>
	return (esf->basic.xpsr & IPSR_ISR_Msk) ? (true) : (false);
    6400:	69e3      	ldr	r3, [r4, #28]
    6402:	f3c3 0308 	ubfx	r3, r3, #0, #9
    6406:	b10b      	cbz	r3, 640c <z_fatal_error+0x2e>
    6408:	f7ff ffcf 	bl	63aa <arch_is_user_context>
    640c:	f7ff ffcd 	bl	63aa <arch_is_user_context>
#endif

	LOG_ERR("Current thread: %p (%s)", thread,
		log_strdup(thread_name_get(thread)));

	k_sys_fatal_error_handler(reason, esf);
    6410:	4621      	mov	r1, r4
    6412:	4630      	mov	r0, r6
    6414:	f7ff ffdc 	bl	63d0 <k_sys_fatal_error_handler>
	__asm__ volatile(
    6418:	f387 8811 	msr	BASEPRI, r7
    641c:	f3bf 8f6f 	isb	sy
	z_impl_k_thread_abort(thread);
    6420:	4628      	mov	r0, r5
#endif /*CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION */
	}

	arch_irq_unlock(key);
	k_thread_abort(thread);
}
    6422:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    6426:	f7fb bc85 	b.w	1d34 <z_impl_k_thread_abort>

0000642a <z_sys_power_save_idle_exit>:
	z_clock_idle_exit();
    642a:	f7ff be5d 	b.w	60e8 <z_clock_idle_exit>

0000642e <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    642e:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6432:	b923      	cbnz	r3, 643e <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6434:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6438:	f000 0001 	and.w	r0, r0, #1
    643c:	4770      	bx	lr
		return false;
    643e:	2000      	movs	r0, #0
}
    6440:	4770      	bx	lr

00006442 <k_msgq_init>:
	msgq->max_msgs = max_msgs;
    6442:	e9c0 2302 	strd	r2, r3, [r0, #8]
{
    6446:	b410      	push	{r4}
	msgq->buffer_end = buffer + (max_msgs * msg_size);
    6448:	fb03 1202 	mla	r2, r3, r2, r1
	msgq->used_msgs = 0;
    644c:	2300      	movs	r3, #0
	msgq->read_ptr = buffer;
    644e:	e9c0 2105 	strd	r2, r1, [r0, #20]
	list->tail = (sys_dnode_t *)list;
    6452:	e9c0 0000 	strd	r0, r0, [r0]
}
    6456:	bc10      	pop	{r4}
	msgq->buffer_start = buffer;
    6458:	6101      	str	r1, [r0, #16]
	msgq->write_ptr = buffer;
    645a:	61c1      	str	r1, [r0, #28]
	msgq->used_msgs = 0;
    645c:	6203      	str	r3, [r0, #32]
	msgq->flags = 0;
    645e:	f880 3024 	strb.w	r3, [r0, #36]	; 0x24
	z_object_init(msgq);
    6462:	f000 bd0c 	b.w	6e7e <z_object_init>

00006466 <z_impl_k_msgq_alloc_init>:
{
    6466:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    646a:	fba1 6702 	umull	r6, r7, r1, r2
    646e:	4604      	mov	r4, r0
    6470:	460d      	mov	r5, r1
    6472:	4690      	mov	r8, r2
    6474:	b93f      	cbnz	r7, 6486 <z_impl_k_msgq_alloc_init+0x20>
		buffer = z_thread_malloc(total_size);
    6476:	4630      	mov	r0, r6
    6478:	f7ff f898 	bl	55ac <z_thread_malloc>
		if (buffer != NULL) {
    647c:	4601      	mov	r1, r0
    647e:	b930      	cbnz	r0, 648e <z_impl_k_msgq_alloc_init+0x28>
			ret = -ENOMEM;
    6480:	f06f 000b 	mvn.w	r0, #11
	return ret;
    6484:	e001      	b.n	648a <z_impl_k_msgq_alloc_init+0x24>
		ret = -EINVAL;
    6486:	f06f 0015 	mvn.w	r0, #21
}
    648a:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			k_msgq_init(msgq, buffer, msg_size, max_msgs);
    648e:	4643      	mov	r3, r8
    6490:	4620      	mov	r0, r4
    6492:	462a      	mov	r2, r5
    6494:	f7ff ffd5 	bl	6442 <k_msgq_init>
			msgq->flags = K_MSGQ_FLAG_ALLOC;
    6498:	2301      	movs	r3, #1
    649a:	f884 3024 	strb.w	r3, [r4, #36]	; 0x24
			ret = 0;
    649e:	4638      	mov	r0, r7
    64a0:	e7f3      	b.n	648a <z_impl_k_msgq_alloc_init+0x24>

000064a2 <z_impl_k_msgq_peek>:
{
    64a2:	4603      	mov	r3, r0
    64a4:	b510      	push	{r4, lr}
    64a6:	4608      	mov	r0, r1
	__asm__ volatile(
    64a8:	f04f 0220 	mov.w	r2, #32
    64ac:	f3ef 8411 	mrs	r4, BASEPRI
    64b0:	f382 8811 	msr	BASEPRI, r2
    64b4:	f3bf 8f6f 	isb	sy
	if (msgq->used_msgs > 0) {
    64b8:	6a1a      	ldr	r2, [r3, #32]
    64ba:	b14a      	cbz	r2, 64d0 <z_impl_k_msgq_peek+0x2e>
		(void)memcpy(data, msgq->read_ptr, msgq->msg_size);
    64bc:	689a      	ldr	r2, [r3, #8]
    64be:	6999      	ldr	r1, [r3, #24]
    64c0:	f7ff fe94 	bl	61ec <memcpy>
		result = 0;
    64c4:	2000      	movs	r0, #0
	__asm__ volatile(
    64c6:	f384 8811 	msr	BASEPRI, r4
    64ca:	f3bf 8f6f 	isb	sy
}
    64ce:	bd10      	pop	{r4, pc}
		result = -ENOMSG;
    64d0:	f06f 004f 	mvn.w	r0, #79	; 0x4f
    64d4:	e7f7      	b.n	64c6 <z_impl_k_msgq_peek+0x24>

000064d6 <z_impl_k_msgq_purge>:
{
    64d6:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    64d8:	4604      	mov	r4, r0
	key = k_spin_lock(&msgq->lock);
    64da:	f100 0508 	add.w	r5, r0, #8
	__asm__ volatile(
    64de:	f04f 0320 	mov.w	r3, #32
    64e2:	f3ef 8611 	mrs	r6, BASEPRI
    64e6:	f383 8811 	msr	BASEPRI, r3
    64ea:	f3bf 8f6f 	isb	sy
    64ee:	f06f 074f 	mvn.w	r7, #79	; 0x4f
	while ((pending_thread = z_unpend_first_thread(&msgq->wait_q)) != NULL) {
    64f2:	4620      	mov	r0, r4
    64f4:	f000 f9d8 	bl	68a8 <z_unpend_first_thread>
    64f8:	4603      	mov	r3, r0
    64fa:	b940      	cbnz	r0, 650e <z_impl_k_msgq_purge+0x38>
	msgq->read_ptr = msgq->write_ptr;
    64fc:	69e3      	ldr	r3, [r4, #28]
	msgq->used_msgs = 0;
    64fe:	6220      	str	r0, [r4, #32]
	msgq->read_ptr = msgq->write_ptr;
    6500:	61a3      	str	r3, [r4, #24]
	z_reschedule(&msgq->lock, key);
    6502:	4631      	mov	r1, r6
    6504:	4628      	mov	r0, r5
}
    6506:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	z_reschedule(&msgq->lock, key);
    650a:	f000 b90f 	b.w	672c <z_reschedule>
    650e:	f8c3 7090 	str.w	r7, [r3, #144]	; 0x90
		z_ready_thread(pending_thread);
    6512:	f000 f953 	bl	67bc <z_ready_thread>
    6516:	e7ec      	b.n	64f2 <z_impl_k_msgq_purge+0x1c>

00006518 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6518:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    651c:	b923      	cbnz	r3, 6528 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    651e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6522:	f000 0001 	and.w	r0, r0, #1
    6526:	4770      	bx	lr
		return false;
    6528:	2000      	movs	r0, #0
}
    652a:	4770      	bx	lr

0000652c <adjust_owner_prio.isra.0>:
static bool adjust_owner_prio(struct k_mutex *mutex, int32_t new_prio)
    652c:	b508      	push	{r3, lr}
	if (mutex->owner->base.prio != new_prio) {
    652e:	6803      	ldr	r3, [r0, #0]
    6530:	f993 300e 	ldrsb.w	r3, [r3, #14]
    6534:	428b      	cmp	r3, r1
static bool adjust_owner_prio(struct k_mutex *mutex, int32_t new_prio)
    6536:	4602      	mov	r2, r0
	if (mutex->owner->base.prio != new_prio) {
    6538:	d006      	beq.n	6548 <adjust_owner_prio.isra.0+0x1c>
    653a:	f7ff ffed 	bl	6518 <arch_is_user_context>
}
    653e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		return z_set_prio(mutex->owner, new_prio);
    6542:	6810      	ldr	r0, [r2, #0]
    6544:	f7fd bdea 	b.w	411c <z_set_prio>
}
    6548:	2000      	movs	r0, #0
    654a:	bd08      	pop	{r3, pc}

0000654c <z_impl_k_mutex_init>:
{
    654c:	b510      	push	{r4, lr}
	mutex->owner = NULL;
    654e:	2400      	movs	r4, #0
	mutex->lock_count = 0U;
    6550:	e9c0 4402 	strd	r4, r4, [r0, #8]
    6554:	e9c0 0000 	strd	r0, r0, [r0]
	z_object_init(mutex);
    6558:	f000 fc91 	bl	6e7e <z_object_init>
}
    655c:	4620      	mov	r0, r4
    655e:	bd10      	pop	{r4, pc}

00006560 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6560:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6564:	b923      	cbnz	r3, 6570 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6566:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    656a:	f000 0001 	and.w	r0, r0, #1
    656e:	4770      	bx	lr
		return false;
    6570:	2000      	movs	r0, #0
}
    6572:	4770      	bx	lr

00006574 <queue_insert>:
{
    6574:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    6578:	4604      	mov	r4, r0
    657a:	460d      	mov	r5, r1
    657c:	4690      	mov	r8, r2
    657e:	4699      	mov	r9, r3
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    6580:	f100 0708 	add.w	r7, r0, #8
    6584:	f04f 0320 	mov.w	r3, #32
    6588:	f3ef 8611 	mrs	r6, BASEPRI
    658c:	f383 8811 	msr	BASEPRI, r3
    6590:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&queue->wait_q);
    6594:	4638      	mov	r0, r7
    6596:	f000 f987 	bl	68a8 <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    659a:	b160      	cbz	r0, 65b6 <queue_insert+0x42>
    659c:	2400      	movs	r4, #0
    659e:	f8c0 4090 	str.w	r4, [r0, #144]	; 0x90
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
    65a2:	f8c0 8014 	str.w	r8, [r0, #20]
	z_ready_thread(thread);
    65a6:	f000 f909 	bl	67bc <z_ready_thread>
	z_reschedule(&queue->lock, key);
    65aa:	4638      	mov	r0, r7
    65ac:	4631      	mov	r1, r6
    65ae:	f000 f8bd 	bl	672c <z_reschedule>
	return 0;
    65b2:	2000      	movs	r0, #0
    65b4:	e00c      	b.n	65d0 <queue_insert+0x5c>
	if (alloc) {
    65b6:	f1b9 0f00 	cmp.w	r9, #0
    65ba:	d01c      	beq.n	65f6 <queue_insert+0x82>
		anode = z_thread_malloc(sizeof(*anode));
    65bc:	2008      	movs	r0, #8
    65be:	f7fe fff5 	bl	55ac <z_thread_malloc>
		if (anode == NULL) {
    65c2:	b938      	cbnz	r0, 65d4 <queue_insert+0x60>
	__asm__ volatile(
    65c4:	f386 8811 	msr	BASEPRI, r6
    65c8:	f3bf 8f6f 	isb	sy
			return -ENOMEM;
    65cc:	f06f 000b 	mvn.w	r0, #11
}
    65d0:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
	node->next_and_flags = flags;
    65d4:	2301      	movs	r3, #1
		anode->data = data;
    65d6:	f8c0 8004 	str.w	r8, [r0, #4]
    65da:	6003      	str	r3, [r0, #0]
Z_GENLIST_INSERT(sflist, sfnode)
    65dc:	6803      	ldr	r3, [r0, #0]
    65de:	f003 0203 	and.w	r2, r3, #3
    65e2:	b965      	cbnz	r5, 65fe <queue_insert+0x8a>
	parent->next_and_flags = cur_flags | (unative_t)child;
    65e4:	6823      	ldr	r3, [r4, #0]
    65e6:	4313      	orrs	r3, r2
    65e8:	6003      	str	r3, [r0, #0]
Z_GENLIST_PREPEND(sflist, sfnode)
    65ea:	6863      	ldr	r3, [r4, #4]
	list->head = node;
    65ec:	6020      	str	r0, [r4, #0]
Z_GENLIST_PREPEND(sflist, sfnode)
    65ee:	2b00      	cmp	r3, #0
    65f0:	d1db      	bne.n	65aa <queue_insert+0x36>
	list->tail = node;
    65f2:	6060      	str	r0, [r4, #4]
}
    65f4:	e7d9      	b.n	65aa <queue_insert+0x36>
	node->next_and_flags = flags;
    65f6:	f8c8 9000 	str.w	r9, [r8]
}
    65fa:	4640      	mov	r0, r8
    65fc:	e7ee      	b.n	65dc <queue_insert+0x68>
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    65fe:	682b      	ldr	r3, [r5, #0]
Z_GENLIST_INSERT(sflist, sfnode)
    6600:	f033 0303 	bics.w	r3, r3, #3
    6604:	d10b      	bne.n	661e <queue_insert+0xaa>
	parent->next_and_flags = cur_flags | (unative_t)child;
    6606:	6002      	str	r2, [r0, #0]
Z_GENLIST_APPEND(sflist, sfnode)
    6608:	6862      	ldr	r2, [r4, #4]
    660a:	b912      	cbnz	r2, 6612 <queue_insert+0x9e>
	list->head = node;
    660c:	e9c4 0000 	strd	r0, r0, [r4]
}
    6610:	e7cb      	b.n	65aa <queue_insert+0x36>
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    6612:	6813      	ldr	r3, [r2, #0]
	parent->next_and_flags = cur_flags | (unative_t)child;
    6614:	f003 0303 	and.w	r3, r3, #3
    6618:	4303      	orrs	r3, r0
    661a:	6013      	str	r3, [r2, #0]
    661c:	e7e9      	b.n	65f2 <queue_insert+0x7e>
    661e:	4313      	orrs	r3, r2
    6620:	6003      	str	r3, [r0, #0]
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    6622:	682b      	ldr	r3, [r5, #0]
	parent->next_and_flags = cur_flags | (unative_t)child;
    6624:	f003 0303 	and.w	r3, r3, #3
    6628:	4318      	orrs	r0, r3
    662a:	6028      	str	r0, [r5, #0]
}
    662c:	e7bd      	b.n	65aa <queue_insert+0x36>

0000662e <z_queue_node_peek>:
{
    662e:	b510      	push	{r4, lr}
	if ((node != NULL) && (sys_sfnode_flags_get(node) != (uint8_t)0)) {
    6630:	4604      	mov	r4, r0
    6632:	b130      	cbz	r0, 6642 <z_queue_node_peek+0x14>
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    6634:	6802      	ldr	r2, [r0, #0]
    6636:	0793      	lsls	r3, r2, #30
    6638:	d003      	beq.n	6642 <z_queue_node_peek+0x14>
		ret = anode->data;
    663a:	6844      	ldr	r4, [r0, #4]
		if (needs_free) {
    663c:	b109      	cbz	r1, 6642 <z_queue_node_peek+0x14>
			k_free(anode);
    663e:	f000 fc7e 	bl	6f3e <k_free>
}
    6642:	4620      	mov	r0, r4
    6644:	bd10      	pop	{r4, pc}

00006646 <z_impl_k_queue_init>:
	list->head = NULL;
    6646:	2200      	movs	r2, #0
	list->tail = NULL;
    6648:	e9c0 2200 	strd	r2, r2, [r0]
    664c:	f100 0208 	add.w	r2, r0, #8
    6650:	e9c0 2202 	strd	r2, r2, [r0, #8]
	z_object_init(queue);
    6654:	f000 bc13 	b.w	6e7e <z_object_init>

00006658 <z_impl_k_queue_cancel_wait>:
{
    6658:	b538      	push	{r3, r4, r5, lr}
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    665a:	f100 0408 	add.w	r4, r0, #8
	__asm__ volatile(
    665e:	f04f 0320 	mov.w	r3, #32
    6662:	f3ef 8511 	mrs	r5, BASEPRI
    6666:	f383 8811 	msr	BASEPRI, r3
    666a:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&queue->wait_q);
    666e:	4620      	mov	r0, r4
    6670:	f000 f91a 	bl	68a8 <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    6674:	b128      	cbz	r0, 6682 <z_impl_k_queue_cancel_wait+0x2a>
    6676:	2200      	movs	r2, #0
    6678:	f8c0 2090 	str.w	r2, [r0, #144]	; 0x90
    667c:	6142      	str	r2, [r0, #20]
	z_ready_thread(thread);
    667e:	f000 f89d 	bl	67bc <z_ready_thread>
	z_reschedule(&queue->lock, key);
    6682:	4629      	mov	r1, r5
    6684:	4620      	mov	r0, r4
}
    6686:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&queue->lock, key);
    668a:	f000 b84f 	b.w	672c <z_reschedule>

0000668e <k_queue_append>:
{
    668e:	460a      	mov	r2, r1
	(void)queue_insert(queue, sys_sflist_peek_tail(&queue->data_q),
    6690:	2300      	movs	r3, #0
    6692:	6841      	ldr	r1, [r0, #4]
    6694:	f7ff bf6e 	b.w	6574 <queue_insert>

00006698 <z_impl_k_queue_alloc_append>:
{
    6698:	460a      	mov	r2, r1
	return queue_insert(queue, sys_sflist_peek_tail(&queue->data_q), data,
    669a:	2301      	movs	r3, #1
    669c:	6841      	ldr	r1, [r0, #4]
    669e:	f7ff bf69 	b.w	6574 <queue_insert>

000066a2 <z_impl_k_queue_alloc_prepend>:
{
    66a2:	460a      	mov	r2, r1
	return queue_insert(queue, NULL, data, true);
    66a4:	2301      	movs	r3, #1
    66a6:	2100      	movs	r1, #0
    66a8:	f7ff bf64 	b.w	6574 <queue_insert>

000066ac <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    66ac:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    66b0:	b923      	cbnz	r3, 66bc <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    66b2:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    66b6:	f000 0001 	and.w	r0, r0, #1
    66ba:	4770      	bx	lr
		return false;
    66bc:	2000      	movs	r0, #0
}
    66be:	4770      	bx	lr

000066c0 <thread_obj_validate>:
{
    66c0:	b508      	push	{r3, lr}
	struct z_object *ko = z_object_find(thread);
    66c2:	f7f9 fd0b 	bl	dc <z_object_find>
	int ret = z_object_validate(ko, K_OBJ_THREAD, _OBJ_INIT_TRUE);
    66c6:	2200      	movs	r2, #0
    66c8:	2109      	movs	r1, #9
    66ca:	f7fe ff35 	bl	5538 <z_object_validate>
}
    66ce:	f110 0f16 	cmn.w	r0, #22
    66d2:	bf14      	ite	ne
    66d4:	2000      	movne	r0, #0
    66d6:	2001      	moveq	r0, #1
    66d8:	bd08      	pop	{r3, pc}

000066da <z_find_first_thread_to_unpend>:
{
    66da:	b510      	push	{r4, lr}
    66dc:	f04f 0320 	mov.w	r3, #32
    66e0:	f3ef 8411 	mrs	r4, BASEPRI
    66e4:	f383 8811 	msr	BASEPRI, r3
    66e8:	f3bf 8f6f 	isb	sy
		ret = _priq_wait_best(&wait_q->waitq);
    66ec:	f000 f85c 	bl	67a8 <z_priq_dumb_best>
	__asm__ volatile(
    66f0:	f384 8811 	msr	BASEPRI, r4
    66f4:	f3bf 8f6f 	isb	sy
}
    66f8:	bd10      	pop	{r4, pc}

000066fa <z_unpend_thread_no_timeout>:
{
    66fa:	b538      	push	{r3, r4, r5, lr}
    66fc:	4604      	mov	r4, r0
	__asm__ volatile(
    66fe:	f04f 0320 	mov.w	r3, #32
    6702:	f3ef 8511 	mrs	r5, BASEPRI
    6706:	f383 8811 	msr	BASEPRI, r3
    670a:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    670e:	4601      	mov	r1, r0
    6710:	6880      	ldr	r0, [r0, #8]
    6712:	f7fd fa67 	bl	3be4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    6716:	7b63      	ldrb	r3, [r4, #13]
    6718:	f023 0302 	bic.w	r3, r3, #2
    671c:	7363      	strb	r3, [r4, #13]
		thread->base.pended_on = NULL;
    671e:	2300      	movs	r3, #0
    6720:	60a3      	str	r3, [r4, #8]
	__asm__ volatile(
    6722:	f385 8811 	msr	BASEPRI, r5
    6726:	f3bf 8f6f 	isb	sy
}
    672a:	bd38      	pop	{r3, r4, r5, pc}

0000672c <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    672c:	b921      	cbnz	r1, 6738 <z_reschedule+0xc>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    672e:	f3ef 8005 	mrs	r0, IPSR
    6732:	b908      	cbnz	r0, 6738 <z_reschedule+0xc>
    6734:	f7fa bf30 	b.w	1598 <arch_swap>
    6738:	f381 8811 	msr	BASEPRI, r1
    673c:	f3bf 8f6f 	isb	sy
}
    6740:	4770      	bx	lr

00006742 <z_reschedule_irqlock>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    6742:	4603      	mov	r3, r0
    6744:	b920      	cbnz	r0, 6750 <z_reschedule_irqlock+0xe>
    6746:	f3ef 8205 	mrs	r2, IPSR
    674a:	b90a      	cbnz	r2, 6750 <z_reschedule_irqlock+0xe>
    674c:	f7fa bf24 	b.w	1598 <arch_swap>
    6750:	f383 8811 	msr	BASEPRI, r3
    6754:	f3bf 8f6f 	isb	sy
}
    6758:	4770      	bx	lr

0000675a <z_reschedule_unlocked>:
	__asm__ volatile(
    675a:	f04f 0320 	mov.w	r3, #32
    675e:	f3ef 8011 	mrs	r0, BASEPRI
    6762:	f383 8811 	msr	BASEPRI, r3
    6766:	f3bf 8f6f 	isb	sy
	(void) z_reschedule_irqlock(arch_irq_lock());
    676a:	f7ff bfea 	b.w	6742 <z_reschedule_irqlock>

0000676e <z_unpend_thread>:
{
    676e:	b510      	push	{r4, lr}
    6770:	4601      	mov	r1, r0
    6772:	f04f 0320 	mov.w	r3, #32
    6776:	f3ef 8411 	mrs	r4, BASEPRI
    677a:	f383 8811 	msr	BASEPRI, r3
    677e:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    6782:	6880      	ldr	r0, [r0, #8]
    6784:	f7fd fa2e 	bl	3be4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    6788:	7b4b      	ldrb	r3, [r1, #13]
    678a:	f023 0302 	bic.w	r3, r3, #2
    678e:	734b      	strb	r3, [r1, #13]
		thread->base.pended_on = NULL;
    6790:	2300      	movs	r3, #0
    6792:	608b      	str	r3, [r1, #8]
	__asm__ volatile(
    6794:	f384 8811 	msr	BASEPRI, r4
    6798:	f3bf 8f6f 	isb	sy
}
    679c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_abort_timeout(&thread->base.timeout);
    67a0:	f101 0018 	add.w	r0, r1, #24
    67a4:	f000 b983 	b.w	6aae <z_abort_timeout>

000067a8 <z_priq_dumb_best>:
{
    67a8:	4603      	mov	r3, r0
	return list->head == list;
    67aa:	6800      	ldr	r0, [r0, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    67ac:	4283      	cmp	r3, r0
    67ae:	d003      	beq.n	67b8 <z_priq_dumb_best+0x10>
	if (n != NULL) {
    67b0:	2800      	cmp	r0, #0
    67b2:	bf38      	it	cc
    67b4:	2000      	movcc	r0, #0
    67b6:	4770      	bx	lr
	struct k_thread *thread = NULL;
    67b8:	2000      	movs	r0, #0
}
    67ba:	4770      	bx	lr

000067bc <z_ready_thread>:
{
    67bc:	b510      	push	{r4, lr}
	__asm__ volatile(
    67be:	f04f 0320 	mov.w	r3, #32
    67c2:	f3ef 8411 	mrs	r4, BASEPRI
    67c6:	f383 8811 	msr	BASEPRI, r3
    67ca:	f3bf 8f6f 	isb	sy
		ready_thread(thread);
    67ce:	f7fd fa61 	bl	3c94 <ready_thread>
	__asm__ volatile(
    67d2:	f384 8811 	msr	BASEPRI, r4
    67d6:	f3bf 8f6f 	isb	sy
}
    67da:	bd10      	pop	{r4, pc}

000067dc <z_thread_timeout>:
{
    67dc:	b538      	push	{r3, r4, r5, lr}
	if (thread->base.pended_on != NULL) {
    67de:	f850 3c10 	ldr.w	r3, [r0, #-16]
{
    67e2:	4604      	mov	r4, r0
	struct k_thread *thread = CONTAINER_OF(timeout,
    67e4:	f1a0 0118 	sub.w	r1, r0, #24
	if (thread->base.pended_on != NULL) {
    67e8:	b1c3      	cbz	r3, 681c <z_thread_timeout+0x40>
	__asm__ volatile(
    67ea:	f04f 0320 	mov.w	r3, #32
    67ee:	f3ef 8511 	mrs	r5, BASEPRI
    67f2:	f383 8811 	msr	BASEPRI, r3
    67f6:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    67fa:	f850 0c10 	ldr.w	r0, [r0, #-16]
    67fe:	f7fd f9f1 	bl	3be4 <z_priq_dumb_remove>
    6802:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
    6806:	f023 0302 	bic.w	r3, r3, #2
    680a:	f804 3c0b 	strb.w	r3, [r4, #-11]
		thread->base.pended_on = NULL;
    680e:	2300      	movs	r3, #0
    6810:	f844 3c10 	str.w	r3, [r4, #-16]
	__asm__ volatile(
    6814:	f385 8811 	msr	BASEPRI, r5
    6818:	f3bf 8f6f 	isb	sy
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    681c:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
    6820:	f023 0314 	bic.w	r3, r3, #20
    6824:	f804 3c0b 	strb.w	r3, [r4, #-11]
	z_ready_thread(thread);
    6828:	4608      	mov	r0, r1
}
    682a:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_ready_thread(thread);
    682e:	f7ff bfc5 	b.w	67bc <z_ready_thread>

00006832 <z_remove_thread_from_ready_q>:
{
    6832:	b510      	push	{r4, lr}
	__asm__ volatile(
    6834:	f04f 0320 	mov.w	r3, #32
    6838:	f3ef 8411 	mrs	r4, BASEPRI
    683c:	f383 8811 	msr	BASEPRI, r3
    6840:	f3bf 8f6f 	isb	sy
		unready_thread(thread);
    6844:	f7fd fbe8 	bl	4018 <unready_thread>
	__asm__ volatile(
    6848:	f384 8811 	msr	BASEPRI, r4
    684c:	f3bf 8f6f 	isb	sy
}
    6850:	bd10      	pop	{r4, pc}

00006852 <add_to_waitq_locked>:
{
    6852:	b538      	push	{r3, r4, r5, lr}
    6854:	4604      	mov	r4, r0
    6856:	460d      	mov	r5, r1
	unready_thread(thread);
    6858:	f7fd fbde 	bl	4018 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
    685c:	7b63      	ldrb	r3, [r4, #13]
    685e:	f043 0302 	orr.w	r3, r3, #2
    6862:	7363      	strb	r3, [r4, #13]
	if (wait_q != NULL) {
    6864:	b1c5      	cbz	r5, 6898 <add_to_waitq_locked+0x46>
	return list->head == list;
    6866:	682b      	ldr	r3, [r5, #0]
		thread->base.pended_on = wait_q;
    6868:	60a5      	str	r5, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    686a:	429d      	cmp	r5, r3
    686c:	bf08      	it	eq
    686e:	2300      	moveq	r3, #0
    6870:	2b00      	cmp	r3, #0
    6872:	bf38      	it	cc
    6874:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    6876:	b183      	cbz	r3, 689a <add_to_waitq_locked+0x48>
	if (thread_1->base.prio < thread_2->base.prio) {
    6878:	f994 100e 	ldrsb.w	r1, [r4, #14]
    687c:	f993 200e 	ldrsb.w	r2, [r3, #14]
    6880:	4291      	cmp	r1, r2
    6882:	db04      	blt.n	688e <add_to_waitq_locked+0x3c>
	return (node == list->tail) ? NULL : node->next;
    6884:	686a      	ldr	r2, [r5, #4]
    6886:	429a      	cmp	r2, r3
    6888:	d007      	beq.n	689a <add_to_waitq_locked+0x48>
    688a:	681b      	ldr	r3, [r3, #0]
    688c:	e7f3      	b.n	6876 <add_to_waitq_locked+0x24>
	node->prev = successor->prev;
    688e:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    6890:	e9c4 3200 	strd	r3, r2, [r4]
	successor->prev->next = node;
    6894:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    6896:	605c      	str	r4, [r3, #4]
}
    6898:	bd38      	pop	{r3, r4, r5, pc}
	node->prev = list->tail;
    689a:	686b      	ldr	r3, [r5, #4]
    689c:	6063      	str	r3, [r4, #4]
	list->tail->next = node;
    689e:	686b      	ldr	r3, [r5, #4]
	node->next = list;
    68a0:	6025      	str	r5, [r4, #0]
	list->tail->next = node;
    68a2:	601c      	str	r4, [r3, #0]
	list->tail = node;
    68a4:	606c      	str	r4, [r5, #4]
    68a6:	e7f7      	b.n	6898 <add_to_waitq_locked+0x46>

000068a8 <z_unpend_first_thread>:
{
    68a8:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
    68aa:	f04f 0320 	mov.w	r3, #32
    68ae:	f3ef 8211 	mrs	r2, BASEPRI
    68b2:	f383 8811 	msr	BASEPRI, r3
    68b6:	f3bf 8f6f 	isb	sy
		ret = _priq_wait_best(&wait_q->waitq);
    68ba:	f7ff ff75 	bl	67a8 <z_priq_dumb_best>
    68be:	4604      	mov	r4, r0
	__asm__ volatile(
    68c0:	f382 8811 	msr	BASEPRI, r2
    68c4:	f3bf 8f6f 	isb	sy

static inline struct k_thread *z_unpend1_no_timeout(_wait_q_t *wait_q)
{
	struct k_thread *thread = z_find_first_thread_to_unpend(wait_q, NULL);

	if (thread != NULL) {
    68c8:	b1c8      	cbz	r0, 68fe <z_unpend_first_thread+0x56>
	__asm__ volatile(
    68ca:	f04f 0320 	mov.w	r3, #32
    68ce:	f3ef 8511 	mrs	r5, BASEPRI
    68d2:	f383 8811 	msr	BASEPRI, r3
    68d6:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    68da:	4601      	mov	r1, r0
    68dc:	6880      	ldr	r0, [r0, #8]
    68de:	f7fd f981 	bl	3be4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    68e2:	7b63      	ldrb	r3, [r4, #13]
    68e4:	f023 0302 	bic.w	r3, r3, #2
    68e8:	7363      	strb	r3, [r4, #13]
		thread->base.pended_on = NULL;
    68ea:	2300      	movs	r3, #0
    68ec:	60a3      	str	r3, [r4, #8]
	__asm__ volatile(
    68ee:	f385 8811 	msr	BASEPRI, r5
    68f2:	f3bf 8f6f 	isb	sy
    68f6:	f104 0018 	add.w	r0, r4, #24
    68fa:	f000 f8d8 	bl	6aae <z_abort_timeout>
}
    68fe:	4620      	mov	r0, r4
    6900:	bd38      	pop	{r3, r4, r5, pc}

00006902 <z_unpend_all>:
{
    6902:	b538      	push	{r3, r4, r5, lr}
    6904:	4605      	mov	r5, r0
	int need_sched = 0;
    6906:	2000      	movs	r0, #0
	return list->head == list;
    6908:	682c      	ldr	r4, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    690a:	42a5      	cmp	r5, r4
    690c:	d000      	beq.n	6910 <z_unpend_all+0xe>
	while ((thread = z_waitq_head(wait_q)) != NULL) {
    690e:	b904      	cbnz	r4, 6912 <z_unpend_all+0x10>
}
    6910:	bd38      	pop	{r3, r4, r5, pc}
		z_unpend_thread(thread);
    6912:	4620      	mov	r0, r4
    6914:	f7ff ff2b 	bl	676e <z_unpend_thread>
		z_ready_thread(thread);
    6918:	4620      	mov	r0, r4
    691a:	f7ff ff4f 	bl	67bc <z_ready_thread>
		need_sched = 1;
    691e:	2001      	movs	r0, #1
    6920:	e7f2      	b.n	6908 <z_unpend_all+0x6>

00006922 <z_impl_k_wakeup>:
{
    6922:	b510      	push	{r4, lr}
	if (z_is_thread_pending(thread)) {
    6924:	7b43      	ldrb	r3, [r0, #13]
    6926:	079b      	lsls	r3, r3, #30
{
    6928:	4604      	mov	r4, r0
	if (z_is_thread_pending(thread)) {
    692a:	d415      	bmi.n	6958 <z_impl_k_wakeup+0x36>
    692c:	3018      	adds	r0, #24
    692e:	f000 f8be 	bl	6aae <z_abort_timeout>
	if (z_abort_thread_timeout(thread) < 0) {
    6932:	2800      	cmp	r0, #0
    6934:	da02      	bge.n	693c <z_impl_k_wakeup+0x1a>
		if (thread->base.thread_state != _THREAD_SUSPENDED) {
    6936:	7b63      	ldrb	r3, [r4, #13]
    6938:	2b10      	cmp	r3, #16
    693a:	d10d      	bne.n	6958 <z_impl_k_wakeup+0x36>
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    693c:	7b63      	ldrb	r3, [r4, #13]
    693e:	f023 0310 	bic.w	r3, r3, #16
    6942:	7363      	strb	r3, [r4, #13]
	z_ready_thread(thread);
    6944:	4620      	mov	r0, r4
    6946:	f7ff ff39 	bl	67bc <z_ready_thread>
    694a:	f3ef 8305 	mrs	r3, IPSR
	if (!arch_is_in_isr()) {
    694e:	b91b      	cbnz	r3, 6958 <z_impl_k_wakeup+0x36>
}
    6950:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		z_reschedule_unlocked();
    6954:	f7ff bf01 	b.w	675a <z_reschedule_unlocked>
}
    6958:	bd10      	pop	{r4, pc}

0000695a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    695a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    695e:	b923      	cbnz	r3, 696a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6960:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6964:	f000 0001 	and.w	r0, r0, #1
    6968:	4770      	bx	lr
		return false;
    696a:	2000      	movs	r0, #0
}
    696c:	4770      	bx	lr

0000696e <z_impl_k_sem_init>:
{
    696e:	b508      	push	{r3, lr}
	CHECKIF(limit == 0U || initial_count > limit) {
    6970:	b14a      	cbz	r2, 6986 <z_impl_k_sem_init+0x18>
    6972:	428a      	cmp	r2, r1
    6974:	d307      	bcc.n	6986 <z_impl_k_sem_init+0x18>
	sem->limit = limit;
    6976:	e9c0 1202 	strd	r1, r2, [r0, #8]
	list->tail = (sys_dnode_t *)list;
    697a:	e9c0 0000 	strd	r0, r0, [r0]
	z_object_init(sem);
    697e:	f000 fa7e 	bl	6e7e <z_object_init>
	return 0;
    6982:	2000      	movs	r0, #0
}
    6984:	bd08      	pop	{r3, pc}
		return -EINVAL;
    6986:	f06f 0015 	mvn.w	r0, #21
    698a:	e7fb      	b.n	6984 <z_impl_k_sem_init+0x16>

0000698c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    698c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6990:	b923      	cbnz	r3, 699c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6992:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6996:	f000 0001 	and.w	r0, r0, #1
    699a:	4770      	bx	lr
		return false;
    699c:	2000      	movs	r0, #0
}
    699e:	4770      	bx	lr

000069a0 <k_stack_init>:
	stack->next = stack->base = buffer;
    69a0:	e9c0 1102 	strd	r1, r1, [r0, #8]
	stack->top = stack->base + num_entries;
    69a4:	eb01 0182 	add.w	r1, r1, r2, lsl #2
    69a8:	e9c0 0000 	strd	r0, r0, [r0]
    69ac:	6101      	str	r1, [r0, #16]
	z_object_init(stack);
    69ae:	f000 ba66 	b.w	6e7e <z_object_init>

000069b2 <z_impl_k_stack_alloc_init>:
{
    69b2:	b538      	push	{r3, r4, r5, lr}
    69b4:	4604      	mov	r4, r0
	buffer = z_thread_malloc(num_entries * sizeof(stack_data_t));
    69b6:	0088      	lsls	r0, r1, #2
{
    69b8:	460d      	mov	r5, r1
	buffer = z_thread_malloc(num_entries * sizeof(stack_data_t));
    69ba:	f7fe fdf7 	bl	55ac <z_thread_malloc>
	if (buffer != NULL) {
    69be:	4601      	mov	r1, r0
    69c0:	b138      	cbz	r0, 69d2 <z_impl_k_stack_alloc_init+0x20>
		k_stack_init(stack, buffer, num_entries);
    69c2:	4620      	mov	r0, r4
    69c4:	462a      	mov	r2, r5
    69c6:	f7ff ffeb 	bl	69a0 <k_stack_init>
		stack->flags = K_STACK_FLAG_ALLOC;
    69ca:	2301      	movs	r3, #1
    69cc:	7523      	strb	r3, [r4, #20]
		ret = (int32_t)0;
    69ce:	2000      	movs	r0, #0
}
    69d0:	bd38      	pop	{r3, r4, r5, pc}
		ret = -ENOMEM;
    69d2:	f06f 000b 	mvn.w	r0, #11
	return ret;
    69d6:	e7fb      	b.n	69d0 <z_impl_k_stack_alloc_init+0x1e>

000069d8 <z_impl_k_stack_push>:
	CHECKIF(stack->next == stack->top) {
    69d8:	e9d0 2303 	ldrd	r2, r3, [r0, #12]
    69dc:	429a      	cmp	r2, r3
{
    69de:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    69e2:	4605      	mov	r5, r0
    69e4:	460e      	mov	r6, r1
	CHECKIF(stack->next == stack->top) {
    69e6:	d023      	beq.n	6a30 <z_impl_k_stack_push+0x58>
	__asm__ volatile(
    69e8:	f04f 0320 	mov.w	r3, #32
    69ec:	f3ef 8711 	mrs	r7, BASEPRI
    69f0:	f383 8811 	msr	BASEPRI, r3
    69f4:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&stack->wait_q);
    69f8:	f7ff ff56 	bl	68a8 <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    69fc:	4604      	mov	r4, r0
    69fe:	b170      	cbz	r0, 6a1e <z_impl_k_stack_push+0x46>
    6a00:	f04f 0800 	mov.w	r8, #0
		z_ready_thread(first_pending_thread);
    6a04:	f7ff feda 	bl	67bc <z_ready_thread>
		z_reschedule(&stack->lock, key);
    6a08:	f105 0008 	add.w	r0, r5, #8
    6a0c:	f8c4 8090 	str.w	r8, [r4, #144]	; 0x90
    6a10:	6166      	str	r6, [r4, #20]
    6a12:	4639      	mov	r1, r7
    6a14:	f7ff fe8a 	bl	672c <z_reschedule>
	return 0;
    6a18:	4640      	mov	r0, r8
}
    6a1a:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		*(stack->next) = data;
    6a1e:	68eb      	ldr	r3, [r5, #12]
    6a20:	f843 6b04 	str.w	r6, [r3], #4
		stack->next++;
    6a24:	60eb      	str	r3, [r5, #12]
	__asm__ volatile(
    6a26:	f387 8811 	msr	BASEPRI, r7
    6a2a:	f3bf 8f6f 	isb	sy
    6a2e:	e7f4      	b.n	6a1a <z_impl_k_stack_push+0x42>
		return -ENOMEM;
    6a30:	f06f 000b 	mvn.w	r0, #11
    6a34:	e7f1      	b.n	6a1a <z_impl_k_stack_push+0x42>

00006a36 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6a36:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6a3a:	b923      	cbnz	r3, 6a46 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6a3c:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6a40:	f000 0001 	and.w	r0, r0, #1
    6a44:	4770      	bx	lr
		return false;
    6a46:	2000      	movs	r0, #0
}
    6a48:	4770      	bx	lr

00006a4a <k_is_in_isr>:
    6a4a:	f3ef 8005 	mrs	r0, IPSR
}
    6a4e:	3800      	subs	r0, #0
    6a50:	bf18      	it	ne
    6a52:	2001      	movne	r0, #1
    6a54:	4770      	bx	lr

00006a56 <z_impl_k_busy_wait>:
	arch_busy_wait(usec_to_wait);
    6a56:	f7fb bbb1 	b.w	21bc <arch_busy_wait>

00006a5a <z_impl_k_thread_name_set>:
}
    6a5a:	f06f 0046 	mvn.w	r0, #70	; 0x46
    6a5e:	4770      	bx	lr

00006a60 <z_stack_is_user_capable>:
{
    6a60:	b508      	push	{r3, lr}
	return z_object_find(stack) != NULL;
    6a62:	f7f9 fb3b 	bl	dc <z_object_find>
}
    6a66:	3800      	subs	r0, #0
    6a68:	bf18      	it	ne
    6a6a:	2001      	movne	r0, #1
    6a6c:	bd08      	pop	{r3, pc}

00006a6e <z_impl_k_thread_create>:
{
    6a6e:	b5f0      	push	{r4, r5, r6, r7, lr}
    6a70:	b087      	sub	sp, #28
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    6a72:	2500      	movs	r5, #0
    6a74:	9505      	str	r5, [sp, #20]
    6a76:	9d10      	ldr	r5, [sp, #64]	; 0x40
    6a78:	9504      	str	r5, [sp, #16]
    6a7a:	9d0f      	ldr	r5, [sp, #60]	; 0x3c
    6a7c:	9503      	str	r5, [sp, #12]
    6a7e:	9d0e      	ldr	r5, [sp, #56]	; 0x38
    6a80:	9502      	str	r5, [sp, #8]
{
    6a82:	e9dd 6712 	ldrd	r6, r7, [sp, #72]	; 0x48
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    6a86:	9d0d      	ldr	r5, [sp, #52]	; 0x34
    6a88:	9501      	str	r5, [sp, #4]
    6a8a:	9d0c      	ldr	r5, [sp, #48]	; 0x30
    6a8c:	9500      	str	r5, [sp, #0]
{
    6a8e:	4604      	mov	r4, r0
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    6a90:	f7fd ff7c 	bl	498c <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
    6a94:	1c7b      	adds	r3, r7, #1
    6a96:	bf08      	it	eq
    6a98:	f1b6 3fff 	cmpeq.w	r6, #4294967295	; 0xffffffff
    6a9c:	d004      	beq.n	6aa8 <z_impl_k_thread_create+0x3a>
		schedule_new_thread(new_thread, delay);
    6a9e:	4632      	mov	r2, r6
    6aa0:	463b      	mov	r3, r7
    6aa2:	4620      	mov	r0, r4
    6aa4:	f7fd ff1e 	bl	48e4 <schedule_new_thread>
}
    6aa8:	4620      	mov	r0, r4
    6aaa:	b007      	add	sp, #28
    6aac:	bdf0      	pop	{r4, r5, r6, r7, pc}

00006aae <z_abort_timeout>:
{
    6aae:	b510      	push	{r4, lr}
	__asm__ volatile(
    6ab0:	f04f 0220 	mov.w	r2, #32
    6ab4:	f3ef 8411 	mrs	r4, BASEPRI
    6ab8:	f382 8811 	msr	BASEPRI, r2
    6abc:	f3bf 8f6f 	isb	sy
		if (sys_dnode_is_linked(&to->node)) {
    6ac0:	6803      	ldr	r3, [r0, #0]
    6ac2:	b13b      	cbz	r3, 6ad4 <z_abort_timeout+0x26>
			remove_timeout(to);
    6ac4:	f7fe f954 	bl	4d70 <remove_timeout>
			ret = 0;
    6ac8:	2000      	movs	r0, #0
	__asm__ volatile(
    6aca:	f384 8811 	msr	BASEPRI, r4
    6ace:	f3bf 8f6f 	isb	sy
}
    6ad2:	bd10      	pop	{r4, pc}
	int ret = -EINVAL;
    6ad4:	f06f 0015 	mvn.w	r0, #21
    6ad8:	e7f7      	b.n	6aca <z_abort_timeout+0x1c>

00006ada <z_timeout_remaining>:
{
    6ada:	b510      	push	{r4, lr}
	__asm__ volatile(
    6adc:	f04f 0320 	mov.w	r3, #32
    6ae0:	f3ef 8411 	mrs	r4, BASEPRI
    6ae4:	f383 8811 	msr	BASEPRI, r3
    6ae8:	f3bf 8f6f 	isb	sy
		ticks = timeout_rem(timeout);
    6aec:	f7fe f974 	bl	4dd8 <timeout_rem>
	__asm__ volatile(
    6af0:	f384 8811 	msr	BASEPRI, r4
    6af4:	f3bf 8f6f 	isb	sy
}
    6af8:	bd10      	pop	{r4, pc}

00006afa <z_get_next_timeout_expiry>:
{
    6afa:	b510      	push	{r4, lr}
	__asm__ volatile(
    6afc:	f04f 0320 	mov.w	r3, #32
    6b00:	f3ef 8411 	mrs	r4, BASEPRI
    6b04:	f383 8811 	msr	BASEPRI, r3
    6b08:	f3bf 8f6f 	isb	sy
		ret = next_timeout();
    6b0c:	f7fe f94a 	bl	4da4 <next_timeout>
	__asm__ volatile(
    6b10:	f384 8811 	msr	BASEPRI, r4
    6b14:	f3bf 8f6f 	isb	sy
}
    6b18:	bd10      	pop	{r4, pc}

00006b1a <z_set_timeout_expiry>:
{
    6b1a:	b570      	push	{r4, r5, r6, lr}
    6b1c:	4604      	mov	r4, r0
    6b1e:	460d      	mov	r5, r1
	__asm__ volatile(
    6b20:	f04f 0320 	mov.w	r3, #32
    6b24:	f3ef 8611 	mrs	r6, BASEPRI
    6b28:	f383 8811 	msr	BASEPRI, r3
    6b2c:	f3bf 8f6f 	isb	sy
		int next_to = next_timeout();
    6b30:	f7fe f938 	bl	4da4 <next_timeout>
		if (!imminent && (sooner || IS_ENABLED(CONFIG_SMP))) {
    6b34:	2801      	cmp	r0, #1
    6b36:	dd05      	ble.n	6b44 <z_set_timeout_expiry+0x2a>
    6b38:	42a0      	cmp	r0, r4
    6b3a:	dd03      	ble.n	6b44 <z_set_timeout_expiry+0x2a>
			z_clock_set_timeout(ticks, is_idle);
    6b3c:	4629      	mov	r1, r5
    6b3e:	4620      	mov	r0, r4
    6b40:	f7fa fc74 	bl	142c <z_clock_set_timeout>
	__asm__ volatile(
    6b44:	f386 8811 	msr	BASEPRI, r6
    6b48:	f3bf 8f6f 	isb	sy
}
    6b4c:	bd70      	pop	{r4, r5, r6, pc}

00006b4e <z_tick_get_32>:
{
    6b4e:	b508      	push	{r3, lr}
	return (uint32_t)z_tick_get();
    6b50:	f7fe fa76 	bl	5040 <z_tick_get>
}
    6b54:	bd08      	pop	{r3, pc}

00006b56 <z_timeout_end_calc>:
 * timeout object.  When used correctly, this should be called once,
 * synchronously with the user passing a new timeout value.  It should
 * not be used iteratively to adjust a timeout.
 */
uint64_t z_timeout_end_calc(k_timeout_t timeout)
{
    6b56:	b538      	push	{r3, r4, r5, lr}
	k_ticks_t dt;

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    6b58:	1c4b      	adds	r3, r1, #1
    6b5a:	bf08      	it	eq
    6b5c:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    6b60:	4604      	mov	r4, r0
    6b62:	460d      	mov	r5, r1
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    6b64:	d013      	beq.n	6b8e <z_timeout_end_calc+0x38>
		return UINT64_MAX;
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    6b66:	ea54 0105 	orrs.w	r1, r4, r5
    6b6a:	d103      	bne.n	6b74 <z_timeout_end_calc+0x1e>
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(dt) >= 0) {
		return Z_TICK_ABS(dt);
	}
#endif
	return z_tick_get() + MAX(1, dt);
}
    6b6c:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		return z_tick_get();
    6b70:	f7fe ba66 	b.w	5040 <z_tick_get>
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(dt) >= 0) {
    6b74:	f06f 0101 	mvn.w	r1, #1
    6b78:	1a0a      	subs	r2, r1, r0
    6b7a:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
    6b7e:	eb61 0305 	sbc.w	r3, r1, r5
    6b82:	2a00      	cmp	r2, #0
    6b84:	f173 0100 	sbcs.w	r1, r3, #0
    6b88:	db02      	blt.n	6b90 <z_timeout_end_calc+0x3a>
		return Z_TICK_ABS(dt);
    6b8a:	4610      	mov	r0, r2
    6b8c:	4619      	mov	r1, r3
}
    6b8e:	bd38      	pop	{r3, r4, r5, pc}
	return z_tick_get() + MAX(1, dt);
    6b90:	f7fe fa56 	bl	5040 <z_tick_get>
    6b94:	2c01      	cmp	r4, #1
    6b96:	f175 0300 	sbcs.w	r3, r5, #0
    6b9a:	bfbc      	itt	lt
    6b9c:	2401      	movlt	r4, #1
    6b9e:	2500      	movlt	r5, #0
    6ba0:	1820      	adds	r0, r4, r0
    6ba2:	eb45 0101 	adc.w	r1, r5, r1
    6ba6:	e7f2      	b.n	6b8e <z_timeout_end_calc+0x38>

00006ba8 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6ba8:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6bac:	b923      	cbnz	r3, 6bb8 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6bae:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6bb2:	f000 0001 	and.w	r0, r0, #1
    6bb6:	4770      	bx	lr
		return false;
    6bb8:	2000      	movs	r0, #0
}
    6bba:	4770      	bx	lr

00006bbc <k_timer_init>:
	timer->stop_fn = stop_fn;
    6bbc:	e9c0 1208 	strd	r1, r2, [r0, #32]
	timer->status = 0U;
    6bc0:	2200      	movs	r2, #0
    6bc2:	f100 0118 	add.w	r1, r0, #24
    6bc6:	e9c0 1106 	strd	r1, r1, [r0, #24]
	node->prev = NULL;
    6bca:	e9c0 2200 	strd	r2, r2, [r0]
    6bce:	6302      	str	r2, [r0, #48]	; 0x30
	timer->user_data = NULL;
    6bd0:	6342      	str	r2, [r0, #52]	; 0x34
	z_object_init(timer);
    6bd2:	f000 b954 	b.w	6e7e <z_object_init>

00006bd6 <z_impl_k_timer_stop>:
{
    6bd6:	b510      	push	{r4, lr}
    6bd8:	4604      	mov	r4, r0
	int inactive = z_abort_timeout(&timer->timeout) != 0;
    6bda:	f7ff ff68 	bl	6aae <z_abort_timeout>
	if (inactive) {
    6bde:	b9d8      	cbnz	r0, 6c18 <z_impl_k_timer_stop+0x42>
	if (timer->stop_fn != NULL) {
    6be0:	6a63      	ldr	r3, [r4, #36]	; 0x24
    6be2:	b10b      	cbz	r3, 6be8 <z_impl_k_timer_stop+0x12>
		timer->stop_fn(timer);
    6be4:	4620      	mov	r0, r4
    6be6:	4798      	blx	r3
	struct k_thread *thread = z_find_first_thread_to_unpend(wait_q, NULL);
    6be8:	f104 0018 	add.w	r0, r4, #24
    6bec:	2100      	movs	r1, #0
    6bee:	f7ff fd74 	bl	66da <z_find_first_thread_to_unpend>
	if (thread != NULL) {
    6bf2:	4604      	mov	r4, r0
    6bf4:	b180      	cbz	r0, 6c18 <z_impl_k_timer_stop+0x42>
		z_unpend_thread_no_timeout(thread);
    6bf6:	f7ff fd80 	bl	66fa <z_unpend_thread_no_timeout>
		z_ready_thread(pending_thread);
    6bfa:	4620      	mov	r0, r4
    6bfc:	f7ff fdde 	bl	67bc <z_ready_thread>
	__asm__ volatile(
    6c00:	f04f 0320 	mov.w	r3, #32
    6c04:	f3ef 8011 	mrs	r0, BASEPRI
    6c08:	f383 8811 	msr	BASEPRI, r3
    6c0c:	f3bf 8f6f 	isb	sy
}
    6c10:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	(void) z_reschedule_irqlock(arch_irq_lock());
    6c14:	f7ff bd95 	b.w	6742 <z_reschedule_irqlock>
    6c18:	bd10      	pop	{r4, pc}

00006c1a <z_impl_k_timer_status_get>:
{
    6c1a:	4603      	mov	r3, r0
    6c1c:	f04f 0120 	mov.w	r1, #32
    6c20:	f3ef 8211 	mrs	r2, BASEPRI
    6c24:	f381 8811 	msr	BASEPRI, r1
    6c28:	f3bf 8f6f 	isb	sy
	timer->status = 0U;
    6c2c:	2100      	movs	r1, #0
	uint32_t result = timer->status;
    6c2e:	6b00      	ldr	r0, [r0, #48]	; 0x30
	timer->status = 0U;
    6c30:	6319      	str	r1, [r3, #48]	; 0x30
	__asm__ volatile(
    6c32:	f382 8811 	msr	BASEPRI, r2
    6c36:	f3bf 8f6f 	isb	sy
}
    6c3a:	4770      	bx	lr

00006c3c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6c3c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6c40:	b923      	cbnz	r3, 6c4c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6c42:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6c46:	f000 0001 	and.w	r0, r0, #1
    6c4a:	4770      	bx	lr
		return false;
    6c4c:	2000      	movs	r0, #0
}
    6c4e:	4770      	bx	lr

00006c50 <z_impl_k_futex_wake>:
{
    6c50:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    6c54:	460e      	mov	r6, r1
	obj = z_object_find(futex);
    6c56:	f7f9 fa41 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_FUTEX) {
    6c5a:	b318      	cbz	r0, 6ca4 <z_impl_k_futex_wake+0x54>
    6c5c:	7983      	ldrb	r3, [r0, #6]
    6c5e:	2b0f      	cmp	r3, #15
    6c60:	d120      	bne.n	6ca4 <z_impl_k_futex_wake+0x54>
	return obj->data.futex_data;
    6c62:	6887      	ldr	r7, [r0, #8]
	if (futex_data == NULL) {
    6c64:	b1f7      	cbz	r7, 6ca4 <z_impl_k_futex_wake+0x54>
	key = k_spin_lock(&futex_data->lock);
    6c66:	f107 0808 	add.w	r8, r7, #8
	__asm__ volatile(
    6c6a:	f04f 0320 	mov.w	r3, #32
    6c6e:	f3ef 8911 	mrs	r9, BASEPRI
    6c72:	f383 8811 	msr	BASEPRI, r3
    6c76:	f3bf 8f6f 	isb	sy
	unsigned int woken = 0;
    6c7a:	2400      	movs	r4, #0
    6c7c:	46a2      	mov	sl, r4
		thread = z_unpend_first_thread(&futex_data->wait_q);
    6c7e:	4638      	mov	r0, r7
    6c80:	f7ff fe12 	bl	68a8 <z_unpend_first_thread>
		if (thread) {
    6c84:	4605      	mov	r5, r0
    6c86:	b130      	cbz	r0, 6c96 <z_impl_k_futex_wake+0x46>
			z_ready_thread(thread);
    6c88:	f7ff fd98 	bl	67bc <z_ready_thread>
			woken++;
    6c8c:	3401      	adds	r4, #1
    6c8e:	f8c5 a090 	str.w	sl, [r5, #144]	; 0x90
	} while (thread && wake_all);
    6c92:	2e00      	cmp	r6, #0
    6c94:	d1f3      	bne.n	6c7e <z_impl_k_futex_wake+0x2e>
	z_reschedule(&futex_data->lock, key);
    6c96:	4640      	mov	r0, r8
    6c98:	4649      	mov	r1, r9
    6c9a:	f7ff fd47 	bl	672c <z_reschedule>
	return woken;
    6c9e:	4620      	mov	r0, r4
}
    6ca0:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
		return -EINVAL;
    6ca4:	f06f 0015 	mvn.w	r0, #21
    6ca8:	e7fa      	b.n	6ca0 <z_impl_k_futex_wake+0x50>

00006caa <z_impl_k_futex_wait>:
{
    6caa:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    6cac:	4607      	mov	r7, r0
    6cae:	460e      	mov	r6, r1
    6cb0:	4615      	mov	r5, r2
    6cb2:	461c      	mov	r4, r3
	obj = z_object_find(futex);
    6cb4:	f7f9 fa12 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_FUTEX) {
    6cb8:	b338      	cbz	r0, 6d0a <z_impl_k_futex_wait+0x60>
    6cba:	7983      	ldrb	r3, [r0, #6]
    6cbc:	2b0f      	cmp	r3, #15
    6cbe:	d124      	bne.n	6d0a <z_impl_k_futex_wait+0x60>
	return obj->data.futex_data;
    6cc0:	6882      	ldr	r2, [r0, #8]
	if (futex_data == NULL) {
    6cc2:	b312      	cbz	r2, 6d0a <z_impl_k_futex_wait+0x60>
	key = k_spin_lock(&futex_data->lock);
    6cc4:	f102 0008 	add.w	r0, r2, #8
    6cc8:	f04f 0320 	mov.w	r3, #32
    6ccc:	f3ef 8111 	mrs	r1, BASEPRI
    6cd0:	f383 8811 	msr	BASEPRI, r3
    6cd4:	f3bf 8f6f 	isb	sy
	return __atomic_load_n(target, __ATOMIC_SEQ_CST);
    6cd8:	f3bf 8f5b 	dmb	ish
    6cdc:	683b      	ldr	r3, [r7, #0]
    6cde:	f3bf 8f5b 	dmb	ish
	if (atomic_get(&futex->val) != (atomic_val_t)expected) {
    6ce2:	429e      	cmp	r6, r3
    6ce4:	d007      	beq.n	6cf6 <z_impl_k_futex_wait+0x4c>
	__asm__ volatile(
    6ce6:	f381 8811 	msr	BASEPRI, r1
    6cea:	f3bf 8f6f 	isb	sy
		return -EAGAIN;
    6cee:	f06f 000a 	mvn.w	r0, #10
}
    6cf2:	b003      	add	sp, #12
    6cf4:	bdf0      	pop	{r4, r5, r6, r7, pc}
	ret = z_pend_curr(&futex_data->lock,
    6cf6:	e9cd 5400 	strd	r5, r4, [sp]
    6cfa:	f7fd f9fb 	bl	40f4 <z_pend_curr>
	if (ret == -EAGAIN) {
    6cfe:	f110 0f0b 	cmn.w	r0, #11
		ret = -ETIMEDOUT;
    6d02:	bf08      	it	eq
    6d04:	f06f 003b 	mvneq.w	r0, #59	; 0x3b
    6d08:	e7f3      	b.n	6cf2 <z_impl_k_futex_wait+0x48>
		return -EINVAL;
    6d0a:	f06f 0015 	mvn.w	r0, #21
    6d0e:	e7f0      	b.n	6cf2 <z_impl_k_futex_wait+0x48>

00006d10 <k_mem_domain_add_thread>:
{
    6d10:	4603      	mov	r3, r0
    6d12:	b510      	push	{r4, lr}
    6d14:	4608      	mov	r0, r1
	__asm__ volatile(
    6d16:	f04f 0220 	mov.w	r2, #32
    6d1a:	f3ef 8411 	mrs	r4, BASEPRI
    6d1e:	f382 8811 	msr	BASEPRI, r2
    6d22:	f3bf 8f6f 	isb	sy
	sys_dlist_append(&domain->mem_domain_q,
    6d26:	f101 0274 	add.w	r2, r1, #116	; 0x74
    6d2a:	f103 01c0 	add.w	r1, r3, #192	; 0xc0
	node->next = list;
    6d2e:	6741      	str	r1, [r0, #116]	; 0x74
	node->prev = list->tail;
    6d30:	f8d3 10c4 	ldr.w	r1, [r3, #196]	; 0xc4
    6d34:	6781      	str	r1, [r0, #120]	; 0x78
	list->tail->next = node;
    6d36:	f8d3 10c4 	ldr.w	r1, [r3, #196]	; 0xc4
    6d3a:	600a      	str	r2, [r1, #0]
	list->tail = node;
    6d3c:	f8c3 20c4 	str.w	r2, [r3, #196]	; 0xc4
	thread->mem_domain_info.mem_domain = domain;
    6d40:	67c3      	str	r3, [r0, #124]	; 0x7c
	arch_mem_domain_thread_add(thread);
    6d42:	f7fb f879 	bl	1e38 <arch_mem_domain_thread_add>
	__asm__ volatile(
    6d46:	f384 8811 	msr	BASEPRI, r4
    6d4a:	f3bf 8f6f 	isb	sy
}
    6d4e:	bd10      	pop	{r4, pc}

00006d50 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6d50:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6d54:	b923      	cbnz	r3, 6d60 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6d56:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6d5a:	f000 0001 	and.w	r0, r0, #1
    6d5e:	4770      	bx	lr
		return false;
    6d60:	2000      	movs	r0, #0
}
    6d62:	4770      	bx	lr

00006d64 <unref_check>:
{
    6d64:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
    6d66:	f04f 0320 	mov.w	r3, #32
    6d6a:	f3ef 8511 	mrs	r5, BASEPRI
    6d6e:	f383 8811 	msr	BASEPRI, r3
    6d72:	f3bf 8f6f 	isb	sy
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6d76:	094c      	lsrs	r4, r1, #5
	sys_bitfield_clear_bit((mem_addr_t)&ko->perms, index);
    6d78:	3004      	adds	r0, #4
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6d7a:	2201      	movs	r2, #1
	uint32_t temp = *(volatile uint32_t *)addr;
    6d7c:	f850 3024 	ldr.w	r3, [r0, r4, lsl #2]
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6d80:	f001 011f 	and.w	r1, r1, #31
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6d84:	fa02 f101 	lsl.w	r1, r2, r1
    6d88:	ea23 0101 	bic.w	r1, r3, r1
    6d8c:	f840 1024 	str.w	r1, [r0, r4, lsl #2]
	__asm__ volatile(
    6d90:	f385 8811 	msr	BASEPRI, r5
    6d94:	f3bf 8f6f 	isb	sy
}
    6d98:	bd30      	pop	{r4, r5, pc}

00006d9a <wordlist_cb>:
	if (sys_bitfield_test_bit((mem_addr_t)&ko->perms, ctx->parent_id) &&
    6d9a:	680b      	ldr	r3, [r1, #0]
{
    6d9c:	b530      	push	{r4, r5, lr}
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6d9e:	095a      	lsrs	r2, r3, #5
	if (sys_bitfield_test_bit((mem_addr_t)&ko->perms, ctx->parent_id) &&
    6da0:	1d04      	adds	r4, r0, #4
	uint32_t temp = *(volatile uint32_t *)addr;
    6da2:	f854 5022 	ldr.w	r5, [r4, r2, lsl #2]
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6da6:	f003 021f 	and.w	r2, r3, #31
	return temp & (1 << bit);
    6daa:	2301      	movs	r3, #1
    6dac:	fa03 f202 	lsl.w	r2, r3, r2
    6db0:	422a      	tst	r2, r5
    6db2:	d00d      	beq.n	6dd0 <wordlist_cb+0x36>
    6db4:	6800      	ldr	r0, [r0, #0]
    6db6:	688a      	ldr	r2, [r1, #8]
    6db8:	4290      	cmp	r0, r2
    6dba:	d009      	beq.n	6dd0 <wordlist_cb+0x36>
		sys_bitfield_set_bit((mem_addr_t)&ko->perms, ctx->child_id);
    6dbc:	684a      	ldr	r2, [r1, #4]
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6dbe:	0951      	lsrs	r1, r2, #5
    6dc0:	f002 021f 	and.w	r2, r2, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    6dc4:	f854 0021 	ldr.w	r0, [r4, r1, lsl #2]
	*(volatile uint32_t *)addr = temp | (1 << bit);
    6dc8:	4093      	lsls	r3, r2
    6dca:	4303      	orrs	r3, r0
    6dcc:	f844 3021 	str.w	r3, [r4, r1, lsl #2]
}
    6dd0:	bd30      	pop	{r4, r5, pc}

00006dd2 <clear_perms_cb>:
	unref_check(ko, id);
    6dd2:	f7ff bfc7 	b.w	6d64 <unref_check>

00006dd6 <thread_index_get>:
{
    6dd6:	b508      	push	{r3, lr}
	ko = z_object_find(thread);
    6dd8:	f7f9 f980 	bl	dc <z_object_find>
	if (ko == NULL) {
    6ddc:	b108      	cbz	r0, 6de2 <thread_index_get+0xc>
	return ko->data.thread_id;
    6dde:	6880      	ldr	r0, [r0, #8]
}
    6de0:	bd08      	pop	{r3, pc}
		return -1;
    6de2:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    6de6:	e7fb      	b.n	6de0 <thread_index_get+0xa>

00006de8 <handler_bad_syscall>:

static uintptr_t handler_bad_syscall(uintptr_t bad_id, uintptr_t arg2,
				     uintptr_t arg3, uintptr_t arg4,
				     uintptr_t arg5, uintptr_t arg6,
				     void *ssf)
{
    6de8:	b508      	push	{r3, lr}
    6dea:	f7ff ffb1 	bl	6d50 <arch_is_user_context>
	LOG_ERR("Bad system call id %" PRIuPTR " invoked", bad_id);
	arch_syscall_oops(ssf);
    6dee:	9804      	ldr	r0, [sp, #16]
    6df0:	f7ff f9ac 	bl	614c <arch_syscall_oops>

00006df4 <z_mrsh_adc_channel_setup>:
    6df4:	b508      	push	{r3, lr}
    6df6:	f7ff ffab 	bl	6d50 <arch_is_user_context>
    6dfa:	9804      	ldr	r0, [sp, #16]
    6dfc:	f7ff f9a6 	bl	614c <arch_syscall_oops>

00006e00 <z_priv_stack_find>:
{
    6e00:	b508      	push	{r3, lr}
	struct z_object *obj = z_object_find(stack);
    6e02:	f7f9 f96b 	bl	dc <z_object_find>
	return obj->data.stack_data->priv;
    6e06:	6883      	ldr	r3, [r0, #8]
}
    6e08:	6858      	ldr	r0, [r3, #4]
    6e0a:	bd08      	pop	{r3, pc}

00006e0c <z_thread_perms_set>:
{
    6e0c:	b510      	push	{r4, lr}
    6e0e:	4604      	mov	r4, r0
	int index = thread_index_get(thread);
    6e10:	4608      	mov	r0, r1
    6e12:	f7ff ffe0 	bl	6dd6 <thread_index_get>
	if (index != -1) {
    6e16:	1c43      	adds	r3, r0, #1
    6e18:	d00b      	beq.n	6e32 <z_thread_perms_set+0x26>
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6e1a:	0941      	lsrs	r1, r0, #5
		sys_bitfield_set_bit((mem_addr_t)&ko->perms, index);
    6e1c:	1d23      	adds	r3, r4, #4
    6e1e:	f000 001f 	and.w	r0, r0, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    6e22:	f853 4021 	ldr.w	r4, [r3, r1, lsl #2]
	*(volatile uint32_t *)addr = temp | (1 << bit);
    6e26:	2201      	movs	r2, #1
    6e28:	fa02 f000 	lsl.w	r0, r2, r0
    6e2c:	4320      	orrs	r0, r4
    6e2e:	f843 0021 	str.w	r0, [r3, r1, lsl #2]
}
    6e32:	bd10      	pop	{r4, pc}

00006e34 <z_thread_perms_clear>:
{
    6e34:	b570      	push	{r4, r5, r6, lr}
    6e36:	4604      	mov	r4, r0
	int index = thread_index_get(thread);
    6e38:	4608      	mov	r0, r1
    6e3a:	f7ff ffcc 	bl	6dd6 <thread_index_get>
	if (index != -1) {
    6e3e:	1c43      	adds	r3, r0, #1
	int index = thread_index_get(thread);
    6e40:	4601      	mov	r1, r0
	if (index != -1) {
    6e42:	d010      	beq.n	6e66 <z_thread_perms_clear+0x32>
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6e44:	0945      	lsrs	r5, r0, #5
		sys_bitfield_clear_bit((mem_addr_t)&ko->perms, index);
    6e46:	1d20      	adds	r0, r4, #4
    6e48:	f001 061f 	and.w	r6, r1, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    6e4c:	f850 3025 	ldr.w	r3, [r0, r5, lsl #2]
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6e50:	2201      	movs	r2, #1
    6e52:	40b2      	lsls	r2, r6
    6e54:	ea23 0302 	bic.w	r3, r3, r2
    6e58:	f840 3025 	str.w	r3, [r0, r5, lsl #2]
		unref_check(ko, index);
    6e5c:	4620      	mov	r0, r4
}
    6e5e:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		unref_check(ko, index);
    6e62:	f7ff bf7f 	b.w	6d64 <unref_check>
}
    6e66:	bd70      	pop	{r4, r5, r6, pc}

00006e68 <z_impl_k_object_access_grant>:
{
    6e68:	b510      	push	{r4, lr}
    6e6a:	460c      	mov	r4, r1
	struct z_object *ko = z_object_find(object);
    6e6c:	f7f9 f936 	bl	dc <z_object_find>
	if (ko != NULL) {
    6e70:	b120      	cbz	r0, 6e7c <z_impl_k_object_access_grant+0x14>
		z_thread_perms_set(ko, thread);
    6e72:	4621      	mov	r1, r4
}
    6e74:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		z_thread_perms_set(ko, thread);
    6e78:	f7ff bfc8 	b.w	6e0c <z_thread_perms_set>
}
    6e7c:	bd10      	pop	{r4, pc}

00006e7e <z_object_init>:
{
    6e7e:	b508      	push	{r3, lr}
	ko = z_object_find(obj);
    6e80:	f7f9 f92c 	bl	dc <z_object_find>
	if (ko == NULL) {
    6e84:	b118      	cbz	r0, 6e8e <z_object_init+0x10>
	ko->flags |= K_OBJ_FLAG_INITIALIZED;
    6e86:	79c3      	ldrb	r3, [r0, #7]
    6e88:	f043 0301 	orr.w	r3, r3, #1
    6e8c:	71c3      	strb	r3, [r0, #7]
}
    6e8e:	bd08      	pop	{r3, pc}

00006e90 <z_object_uninit>:
{
    6e90:	b508      	push	{r3, lr}
	ko = z_object_find(obj);
    6e92:	f7f9 f923 	bl	dc <z_object_find>
	if (ko == NULL) {
    6e96:	b118      	cbz	r0, 6ea0 <z_object_uninit+0x10>
	ko->flags &= ~K_OBJ_FLAG_INITIALIZED;
    6e98:	79c3      	ldrb	r3, [r0, #7]
    6e9a:	f023 0301 	bic.w	r3, r3, #1
    6e9e:	71c3      	strb	r3, [r0, #7]
}
    6ea0:	bd08      	pop	{r3, pc}

00006ea2 <z_user_from_copy>:
{
    6ea2:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    6ea4:	460d      	mov	r5, r1
    6ea6:	4616      	mov	r6, r2
    6ea8:	4607      	mov	r7, r0
			Z_SYSCALL_MEMORY_READ(src, size)) {
    6eaa:	2200      	movs	r2, #0
    6eac:	4631      	mov	r1, r6
    6eae:	4628      	mov	r0, r5
    6eb0:	f7ff f97a 	bl	61a8 <arch_buffer_validate>
    6eb4:	4604      	mov	r4, r0
    6eb6:	b120      	cbz	r0, 6ec2 <z_user_from_copy+0x20>
    6eb8:	f7ff ff4a 	bl	6d50 <arch_is_user_context>
	int ret = EFAULT;
    6ebc:	240e      	movs	r4, #14
}
    6ebe:	4620      	mov	r0, r4
    6ec0:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	(void)memcpy(dst, src, size);
    6ec2:	4632      	mov	r2, r6
    6ec4:	4629      	mov	r1, r5
    6ec6:	4638      	mov	r0, r7
    6ec8:	f7ff f990 	bl	61ec <memcpy>
	ret = 0;
    6ecc:	e7f7      	b.n	6ebe <z_user_from_copy+0x1c>

00006ece <z_user_string_copy>:
{
    6ece:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    6ed0:	460e      	mov	r6, r1
    6ed2:	4614      	mov	r4, r2
    6ed4:	4605      	mov	r5, r0
	return arch_user_string_nlen(src, maxlen, err);
    6ed6:	aa01      	add	r2, sp, #4
    6ed8:	4621      	mov	r1, r4
    6eda:	4630      	mov	r0, r6
    6edc:	f7fa fd78 	bl	19d0 <arch_user_string_nlen>
	if (err != 0) {
    6ee0:	9f01      	ldr	r7, [sp, #4]
    6ee2:	b997      	cbnz	r7, 6f0a <z_user_string_copy+0x3c>
	if (actual_len == maxlen) {
    6ee4:	4284      	cmp	r4, r0
    6ee6:	d104      	bne.n	6ef2 <z_user_string_copy+0x24>
    6ee8:	f7ff ff32 	bl	6d50 <arch_is_user_context>
		ret = EINVAL;
    6eec:	2016      	movs	r0, #22
}
    6eee:	b003      	add	sp, #12
    6ef0:	bdf0      	pop	{r4, r5, r6, r7, pc}
	return __builtin_add_overflow(a, b, result);
    6ef2:	2401      	movs	r4, #1
    6ef4:	1904      	adds	r4, r0, r4
    6ef6:	d2f7      	bcs.n	6ee8 <z_user_string_copy+0x1a>
	ret = z_user_from_copy(dst, src, actual_len);
    6ef8:	4622      	mov	r2, r4
	dst[actual_len - 1] = '\0';
    6efa:	442c      	add	r4, r5
	ret = z_user_from_copy(dst, src, actual_len);
    6efc:	4631      	mov	r1, r6
    6efe:	4628      	mov	r0, r5
    6f00:	f7ff ffcf 	bl	6ea2 <z_user_from_copy>
	dst[actual_len - 1] = '\0';
    6f04:	f804 7c01 	strb.w	r7, [r4, #-1]
    6f08:	e7f1      	b.n	6eee <z_user_string_copy+0x20>
		ret = EFAULT;
    6f0a:	200e      	movs	r0, #14
	return ret;
    6f0c:	e7ef      	b.n	6eee <z_user_string_copy+0x20>

00006f0e <k_mem_pool_malloc>:
{
    6f0e:	b5df      	push	{r0, r1, r2, r3, r4, r6, r7, lr}
    6f10:	2408      	movs	r4, #8
    6f12:	190a      	adds	r2, r1, r4
    6f14:	d208      	bcs.n	6f28 <k_mem_pool_malloc+0x1a>
	if (k_mem_pool_alloc(pool, &block, size, K_NO_WAIT) != 0) {
    6f16:	2600      	movs	r6, #0
    6f18:	2700      	movs	r7, #0
    6f1a:	e9cd 6700 	strd	r6, r7, [sp]
    6f1e:	eb0d 0104 	add.w	r1, sp, r4
    6f22:	f000 f890 	bl	7046 <k_mem_pool_alloc>
    6f26:	b110      	cbz	r0, 6f2e <k_mem_pool_malloc+0x20>
		return NULL;
    6f28:	2000      	movs	r0, #0
}
    6f2a:	b004      	add	sp, #16
    6f2c:	bdd0      	pop	{r4, r6, r7, pc}
	(void)memcpy(block.data, &block.id, sizeof(struct k_mem_block_id));
    6f2e:	9802      	ldr	r0, [sp, #8]
    6f30:	4622      	mov	r2, r4
    6f32:	a902      	add	r1, sp, #8
    6f34:	f7ff f95a 	bl	61ec <memcpy>
	return (char *)block.data + WB_UP(sizeof(struct k_mem_block_id));
    6f38:	9802      	ldr	r0, [sp, #8]
    6f3a:	3008      	adds	r0, #8
    6f3c:	e7f5      	b.n	6f2a <k_mem_pool_malloc+0x1c>

00006f3e <k_free>:
	if (ptr != NULL) {
    6f3e:	b110      	cbz	r0, 6f46 <k_free+0x8>
		k_mem_pool_free_id(ptr);
    6f40:	3808      	subs	r0, #8
    6f42:	f000 b899 	b.w	7078 <k_mem_pool_free_id>
}
    6f46:	4770      	bx	lr

00006f48 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6f48:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6f4c:	b923      	cbnz	r3, 6f58 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6f4e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6f52:	f000 0001 	and.w	r0, r0, #1
    6f56:	4770      	bx	lr
		return false;
    6f58:	2000      	movs	r0, #0
}
    6f5a:	4770      	bx	lr

00006f5c <validate_any_object>:
{
    6f5c:	b510      	push	{r4, lr}
	ko = z_object_find(obj);
    6f5e:	f7f9 f8bd 	bl	dc <z_object_find>
	ret = z_object_validate(ko, K_OBJ_ANY, _OBJ_INIT_ANY);
    6f62:	2201      	movs	r2, #1
    6f64:	2100      	movs	r1, #0
	ko = z_object_find(obj);
    6f66:	4604      	mov	r4, r0
	ret = z_object_validate(ko, K_OBJ_ANY, _OBJ_INIT_ANY);
    6f68:	f7fe fae6 	bl	5538 <z_object_validate>
	if (ret != 0) {
    6f6c:	2800      	cmp	r0, #0
}
    6f6e:	bf0c      	ite	eq
    6f70:	4620      	moveq	r0, r4
    6f72:	2000      	movne	r0, #0
    6f74:	bd10      	pop	{r4, pc}

00006f76 <k_heap_init>:
{
    6f76:	b410      	push	{r4}
    6f78:	f100 040c 	add.w	r4, r0, #12
	list->tail = (sys_dnode_t *)list;
    6f7c:	e9c0 4403 	strd	r4, r4, [r0, #12]
}
    6f80:	bc10      	pop	{r4}
	sys_heap_init(&h->heap, mem, bytes);
    6f82:	f7fe bf65 	b.w	5e50 <sys_heap_init>

00006f86 <k_heap_alloc>:

SYS_INIT(statics_init, PRE_KERNEL_1, CONFIG_KERNEL_INIT_PRIORITY_OBJECTS);

void *k_heap_alloc(struct k_heap *h, size_t bytes, k_timeout_t timeout)
{
    6f86:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    6f8a:	4604      	mov	r4, r0
    6f8c:	b085      	sub	sp, #20
    6f8e:	460e      	mov	r6, r1
	int64_t now, end = z_timeout_end_calc(timeout);
    6f90:	4610      	mov	r0, r2
    6f92:	4619      	mov	r1, r3
    6f94:	f7ff fddf 	bl	6b56 <z_timeout_end_calc>
	void *ret = NULL;
	k_spinlock_key_t key = k_spin_lock(&h->lock);
    6f98:	f104 0a14 	add.w	sl, r4, #20
	int64_t now, end = z_timeout_end_calc(timeout);
    6f9c:	4605      	mov	r5, r0
    6f9e:	460f      	mov	r7, r1
	__asm__ volatile(
    6fa0:	f04f 0220 	mov.w	r2, #32
    6fa4:	f3ef 8311 	mrs	r3, BASEPRI
    6fa8:	f382 8811 	msr	BASEPRI, r2
    6fac:	f3bf 8f6f 	isb	sy
		now = z_tick_get();
		if ((ret != NULL) || ((end - now) <= 0)) {
			break;
		}

		(void) z_pend_curr(&h->lock, key, &h->wait_q,
    6fb0:	f104 0b0c 	add.w	fp, r4, #12
		ret = sys_heap_alloc(&h->heap, bytes);
    6fb4:	4631      	mov	r1, r6
    6fb6:	4620      	mov	r0, r4
    6fb8:	9303      	str	r3, [sp, #12]
    6fba:	f7fe ff15 	bl	5de8 <sys_heap_alloc>
    6fbe:	9002      	str	r0, [sp, #8]
		now = z_tick_get();
    6fc0:	f7fe f83e 	bl	5040 <z_tick_get>
		if ((ret != NULL) || ((end - now) <= 0)) {
    6fc4:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    6fc8:	b13a      	cbz	r2, 6fda <k_heap_alloc+0x54>
	__asm__ volatile(
    6fca:	f383 8811 	msr	BASEPRI, r3
    6fce:	f3bf 8f6f 	isb	sy
		key = k_spin_lock(&h->lock);
	}

	k_spin_unlock(&h->lock, key);
	return ret;
}
    6fd2:	4610      	mov	r0, r2
    6fd4:	b005      	add	sp, #20
    6fd6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		if ((ret != NULL) || ((end - now) <= 0)) {
    6fda:	ebb5 0800 	subs.w	r8, r5, r0
    6fde:	eb67 0901 	sbc.w	r9, r7, r1
    6fe2:	f1b8 0f01 	cmp.w	r8, #1
    6fe6:	f179 0100 	sbcs.w	r1, r9, #0
    6fea:	dbee      	blt.n	6fca <k_heap_alloc+0x44>
		(void) z_pend_curr(&h->lock, key, &h->wait_q,
    6fec:	e9cd 8900 	strd	r8, r9, [sp]
    6ff0:	465a      	mov	r2, fp
    6ff2:	4619      	mov	r1, r3
    6ff4:	4650      	mov	r0, sl
    6ff6:	f7fd f87d 	bl	40f4 <z_pend_curr>
	__asm__ volatile(
    6ffa:	f04f 0220 	mov.w	r2, #32
    6ffe:	f3ef 8311 	mrs	r3, BASEPRI
    7002:	f382 8811 	msr	BASEPRI, r2
    7006:	f3bf 8f6f 	isb	sy
    700a:	e7d3      	b.n	6fb4 <k_heap_alloc+0x2e>

0000700c <k_heap_free>:

void k_heap_free(struct k_heap *h, void *mem)
{
    700c:	b538      	push	{r3, r4, r5, lr}
    700e:	4604      	mov	r4, r0
    7010:	f04f 0320 	mov.w	r3, #32
    7014:	f3ef 8511 	mrs	r5, BASEPRI
    7018:	f383 8811 	msr	BASEPRI, r3
    701c:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&h->lock);

	sys_heap_free(&h->heap, mem);
    7020:	f7fe fe8d 	bl	5d3e <sys_heap_free>

	if (z_unpend_all(&h->wait_q) != 0) {
    7024:	f104 000c 	add.w	r0, r4, #12
    7028:	f7ff fc6b 	bl	6902 <z_unpend_all>
    702c:	b130      	cbz	r0, 703c <k_heap_free+0x30>
		z_reschedule(&h->lock, key);
    702e:	4629      	mov	r1, r5
    7030:	f104 0014 	add.w	r0, r4, #20
	} else {
		k_spin_unlock(&h->lock, key);
	}
}
    7034:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&h->lock, key);
    7038:	f7ff bb78 	b.w	672c <z_reschedule>
	__asm__ volatile(
    703c:	f385 8811 	msr	BASEPRI, r5
    7040:	f3bf 8f6f 	isb	sy
}
    7044:	bd38      	pop	{r3, r4, r5, pc}

00007046 <k_mem_pool_alloc>:
 * backend.
 */

int k_mem_pool_alloc(struct k_mem_pool *p, struct k_mem_block *block,
		     size_t size, k_timeout_t timeout)
{
    7046:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    7048:	e9dd 6706 	ldrd	r6, r7, [sp, #24]
	block->id.heap = p->heap;
    704c:	6800      	ldr	r0, [r0, #0]
    704e:	6048      	str	r0, [r1, #4]
{
    7050:	4614      	mov	r4, r2
    7052:	460d      	mov	r5, r1
	block->data = k_heap_alloc(p->heap, size, timeout);
    7054:	4632      	mov	r2, r6
    7056:	463b      	mov	r3, r7
    7058:	4621      	mov	r1, r4
    705a:	f7ff ff94 	bl	6f86 <k_heap_alloc>
    705e:	6028      	str	r0, [r5, #0]

	/* The legacy API returns -EAGAIN on timeout expiration, but
	 * -ENOMEM if the timeout was K_NO_WAIT. Don't ask.
	 */
	if (size != 0 && block->data == NULL) {
    7060:	b144      	cbz	r4, 7074 <k_mem_pool_alloc+0x2e>
    7062:	b938      	cbnz	r0, 7074 <k_mem_pool_alloc+0x2e>
		return K_TIMEOUT_EQ(timeout, K_NO_WAIT) ? -ENOMEM : -EAGAIN;
    7064:	ea56 0307 	orrs.w	r3, r6, r7
    7068:	bf0c      	ite	eq
    706a:	f06f 000b 	mvneq.w	r0, #11
    706e:	f06f 000a 	mvnne.w	r0, #10
	} else {
		return 0;
	}
}
    7072:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		return 0;
    7074:	2000      	movs	r0, #0
    7076:	e7fc      	b.n	7072 <k_mem_pool_alloc+0x2c>

00007078 <k_mem_pool_free_id>:

void k_mem_pool_free_id(struct k_mem_block_id *id)
{
	k_heap_free(id->heap, id->data);
    7078:	e9d0 1000 	ldrd	r1, r0, [r0]
    707c:	f7ff bfc6 	b.w	700c <k_heap_free>

00007080 <_OffsetAbsSyms>:
#include "offsets_aarch64.c"
#else
#include "offsets_aarch32.c"
#endif

GEN_ABS_SYM_END
    7080:	4770      	bx	lr
