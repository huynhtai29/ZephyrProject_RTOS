
zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

00000000 <_vector_start>:

	return fd_entry->obj;
}

int z_reserve_fd(void)
{
   0:	20002c00 	.word	0x20002c00
#if defined(__ZEPHYR_SUPERVISOR__)
	ret = false;
#elif defined(__ZEPHYR_USER__)
	ret = true;
#else
	ret = arch_is_user_context();
   4:	00001861 	.word	0x00001861

extern int z_impl_k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout);
static inline int k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
   8:	000060f5 	.word	0x000060f5
static inline uintptr_t arch_syscall_invoke3(uintptr_t arg1, uintptr_t arg2,
					     uintptr_t arg3,
					     uintptr_t call_id)
{
	register uint32_t ret __asm__("r0") = arg1;
	register uint32_t r1 __asm__("r1") = arg2;
   c:	00001891 	.word	0x00001891
	register uint32_t r2 __asm__("r2") = arg3;
  10:	00001891 	.word	0x00001891
	register uint32_t r6 __asm__("r6") = call_id;

	__asm__ volatile("svc %[svid]\n"
  14:	00001891 	.word	0x00001891
	for (fd = 0; fd < ARRAY_SIZE(fdtable); fd++) {
  18:	00001891 	.word	0x00001891
	...
	errno = ENFILE;
  2c:	000014ad 	.word	0x000014ad
	return -1;
  30:	00001891 	.word	0x00001891
  34:	00000000 	.word	0x00000000
}

static inline uintptr_t arch_syscall_invoke1(uintptr_t arg1,
					     uintptr_t call_id)
{
	register uint32_t ret __asm__("r0") = arg1;
  38:	0000143d 	.word	0x0000143d
	register uint32_t r6 __asm__("r6") = call_id;

	__asm__ volatile("svc %[svid]\n"
  3c:	00006073 	.word	0x00006073

00000040 <_irq_vector_table>:
	}

	k_mutex_unlock(&fdtable_lock);

	return fd;
}
  40:	000016e5 000016e5 000016e5 000016e5     ................
		parm0.val = timeout;
		return (int) arch_syscall_invoke3(*(uintptr_t *)&mutex, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_MUTEX_LOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_lock(mutex, timeout);
  50:	000016e5 000016e5 000016e5 000016e5     ................
	if (z_syscall_trap()) {
		return (int) arch_syscall_invoke1(*(uintptr_t *)&mutex, K_SYSCALL_K_MUTEX_UNLOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_unlock(mutex);
  60:	000016e5 000016e5 000016e5 000016e5     ................
  70:	000016e5 000016e5 000016e5 000016e5     ................
  80:	000016e5 000016e5 000016e5 000016e5     ................
  90:	000016e5 000016e5 000016e5 000016e5     ................
  a0:	000016e5 000016e5 000016e5 000016e5     ................
  b0:	000016e5 000016e5 000016e5 000016e5     ................
  c0:	000016e5 000016e5 000016e5 000016e5     ................
  d0:	000016e5 000016e5 000016e5              ............

Disassembly of section text:

000000dc <z_object_find>:
#endif

Z_GENERIC_SECTION(.kobject_data.data) uint8_t _thread_idx_map[2] = { 0xc0,  0xff, };
      dc:	4b0a      	ldr	r3, [pc, #40]	; (108 <CONFIG_KOBJECT_TEXT_AREA+0x8>)
      de:	f3c0 2207 	ubfx	r2, r0, #8, #8
      e2:	b2c1      	uxtb	r1, r0
      e4:	5c9a      	ldrb	r2, [r3, r2]
      e6:	5c5b      	ldrb	r3, [r3, r1]
      e8:	4413      	add	r3, r2
"\x74\x34\x00\x20", {}, K_OBJ_MUTEX, 0 | K_OBJ_FLAG_INITIALIZED, { .unused = 0 }
      ea:	2b37      	cmp	r3, #55	; 0x37
      ec:	dc09      	bgt.n	102 <CONFIG_KOBJECT_TEXT_AREA+0x2>
"\xb4\x34\x00\x20", {}, K_OBJ_STACK, 0 | K_OBJ_FLAG_INITIALIZED, { .unused = 0 }
      ee:	220c      	movs	r2, #12
      f0:	4906      	ldr	r1, [pc, #24]	; (10c <CONFIG_KOBJECT_TEXT_AREA+0xc>)
      f2:	435a      	muls	r2, r3
      f4:	188b      	adds	r3, r1, r2
%%
      f6:	588a      	ldr	r2, [r1, r2]
struct z_object *z_object_gperf_find(void *obj)
      f8:	4290      	cmp	r0, r2
      fa:	bf0c      	ite	eq
      fc:	4618      	moveq	r0, r3
      fe:	2000      	movne	r0, #0
     100:	4770      	bx	lr
}
     102:	2000      	movs	r0, #0
     104:	4770      	bx	lr
     106:	bf00      	nop
     108:	00007921 	.word	0x00007921
     10c:	200034dc 	.word	0x200034dc

00000110 <z_object_gperf_wordlist_foreach>:
{
     110:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
     112:	4c07      	ldr	r4, [pc, #28]	; (130 <z_object_gperf_wordlist_foreach+0x20>)
     114:	4606      	mov	r6, r0
     116:	460f      	mov	r7, r1
    for (i = MIN_HASH_VALUE; i <= MAX_HASH_VALUE; i++) {
     118:	2500      	movs	r5, #0
        if (wordlist[i].name != NULL) {
     11a:	6823      	ldr	r3, [r4, #0]
     11c:	b113      	cbz	r3, 124 <z_object_gperf_wordlist_foreach+0x14>
            func(&wordlist[i], context);
     11e:	4639      	mov	r1, r7
     120:	4620      	mov	r0, r4
     122:	47b0      	blx	r6
    for (i = MIN_HASH_VALUE; i <= MAX_HASH_VALUE; i++) {
     124:	3501      	adds	r5, #1
     126:	2d38      	cmp	r5, #56	; 0x38
     128:	f104 040c 	add.w	r4, r4, #12
     12c:	d1f5      	bne.n	11a <z_object_gperf_wordlist_foreach+0xa>
}
     12e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
     130:	200034dc 	.word	0x200034dc

00000134 <_kobject_text_area_end>:
	...

000001dc <__aeabi_uldivmod>:
     1dc:	b953      	cbnz	r3, 1f4 <__aeabi_uldivmod+0x18>
     1de:	b94a      	cbnz	r2, 1f4 <__aeabi_uldivmod+0x18>
     1e0:	2900      	cmp	r1, #0
     1e2:	bf08      	it	eq
     1e4:	2800      	cmpeq	r0, #0
     1e6:	bf1c      	itt	ne
     1e8:	f04f 31ff 	movne.w	r1, #4294967295	; 0xffffffff
     1ec:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
     1f0:	f000 b96e 	b.w	4d0 <__aeabi_idiv0>
     1f4:	f1ad 0c08 	sub.w	ip, sp, #8
     1f8:	e96d ce04 	strd	ip, lr, [sp, #-16]!
     1fc:	f000 f806 	bl	20c <__udivmoddi4>
     200:	f8dd e004 	ldr.w	lr, [sp, #4]
     204:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
     208:	b004      	add	sp, #16
     20a:	4770      	bx	lr

0000020c <__udivmoddi4>:
     20c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
     210:	9d08      	ldr	r5, [sp, #32]
     212:	460e      	mov	r6, r1
     214:	4604      	mov	r4, r0
     216:	468c      	mov	ip, r1
     218:	2b00      	cmp	r3, #0
     21a:	f040 8081 	bne.w	320 <__udivmoddi4+0x114>
     21e:	428a      	cmp	r2, r1
     220:	4617      	mov	r7, r2
     222:	d945      	bls.n	2b0 <__udivmoddi4+0xa4>
     224:	fab2 f282 	clz	r2, r2
     228:	b14a      	cbz	r2, 23e <__udivmoddi4+0x32>
     22a:	f1c2 0120 	rsb	r1, r2, #32
     22e:	fa06 f302 	lsl.w	r3, r6, r2
     232:	fa20 f101 	lsr.w	r1, r0, r1
     236:	4097      	lsls	r7, r2
     238:	ea41 0c03 	orr.w	ip, r1, r3
     23c:	4094      	lsls	r4, r2
     23e:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     242:	0c23      	lsrs	r3, r4, #16
     244:	fbbc f6fe 	udiv	r6, ip, lr
     248:	b2b9      	uxth	r1, r7
     24a:	fb0e cc16 	mls	ip, lr, r6, ip
     24e:	ea43 430c 	orr.w	r3, r3, ip, lsl #16
     252:	fb06 f001 	mul.w	r0, r6, r1
     256:	4298      	cmp	r0, r3
     258:	d909      	bls.n	26e <__udivmoddi4+0x62>
     25a:	18fb      	adds	r3, r7, r3
     25c:	f106 3cff 	add.w	ip, r6, #4294967295	; 0xffffffff
     260:	f080 8115 	bcs.w	48e <CONFIG_MAIN_STACK_SIZE+0x8e>
     264:	4298      	cmp	r0, r3
     266:	f240 8112 	bls.w	48e <CONFIG_MAIN_STACK_SIZE+0x8e>
     26a:	3e02      	subs	r6, #2
     26c:	443b      	add	r3, r7
     26e:	1a1b      	subs	r3, r3, r0
     270:	b2a4      	uxth	r4, r4
     272:	fbb3 f0fe 	udiv	r0, r3, lr
     276:	fb0e 3310 	mls	r3, lr, r0, r3
     27a:	ea44 4403 	orr.w	r4, r4, r3, lsl #16
     27e:	fb00 f101 	mul.w	r1, r0, r1
     282:	42a1      	cmp	r1, r4
     284:	d909      	bls.n	29a <__udivmoddi4+0x8e>
     286:	193c      	adds	r4, r7, r4
     288:	f100 33ff 	add.w	r3, r0, #4294967295	; 0xffffffff
     28c:	f080 8101 	bcs.w	492 <CONFIG_MAIN_STACK_SIZE+0x92>
     290:	42a1      	cmp	r1, r4
     292:	f240 80fe 	bls.w	492 <CONFIG_MAIN_STACK_SIZE+0x92>
     296:	3802      	subs	r0, #2
     298:	443c      	add	r4, r7
     29a:	1a64      	subs	r4, r4, r1
     29c:	ea40 4006 	orr.w	r0, r0, r6, lsl #16
     2a0:	2100      	movs	r1, #0
     2a2:	b11d      	cbz	r5, 2ac <__udivmoddi4+0xa0>
     2a4:	40d4      	lsrs	r4, r2
     2a6:	2300      	movs	r3, #0
     2a8:	e9c5 4300 	strd	r4, r3, [r5]
     2ac:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
     2b0:	b902      	cbnz	r2, 2b4 <__udivmoddi4+0xa8>
     2b2:	deff      	udf	#255	; 0xff
     2b4:	fab2 f282 	clz	r2, r2
     2b8:	2a00      	cmp	r2, #0
     2ba:	d14f      	bne.n	35c <__udivmoddi4+0x150>
     2bc:	1bcb      	subs	r3, r1, r7
     2be:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     2c2:	fa1f f887 	uxth.w	r8, r7
     2c6:	2101      	movs	r1, #1
     2c8:	fbb3 fcfe 	udiv	ip, r3, lr
     2cc:	0c26      	lsrs	r6, r4, #16
     2ce:	fb0e 331c 	mls	r3, lr, ip, r3
     2d2:	ea46 4603 	orr.w	r6, r6, r3, lsl #16
     2d6:	fb08 f30c 	mul.w	r3, r8, ip
     2da:	42b3      	cmp	r3, r6
     2dc:	d907      	bls.n	2ee <__udivmoddi4+0xe2>
     2de:	19be      	adds	r6, r7, r6
     2e0:	f10c 30ff 	add.w	r0, ip, #4294967295	; 0xffffffff
     2e4:	d202      	bcs.n	2ec <__udivmoddi4+0xe0>
     2e6:	42b3      	cmp	r3, r6
     2e8:	f200 80eb 	bhi.w	4c2 <CONFIG_MAIN_STACK_SIZE+0xc2>
     2ec:	4684      	mov	ip, r0
     2ee:	1af6      	subs	r6, r6, r3
     2f0:	b2a3      	uxth	r3, r4
     2f2:	fbb6 f0fe 	udiv	r0, r6, lr
     2f6:	fb0e 6610 	mls	r6, lr, r0, r6
     2fa:	ea43 4406 	orr.w	r4, r3, r6, lsl #16
     2fe:	fb08 f800 	mul.w	r8, r8, r0
     302:	45a0      	cmp	r8, r4
     304:	d907      	bls.n	316 <__udivmoddi4+0x10a>
     306:	193c      	adds	r4, r7, r4
     308:	f100 33ff 	add.w	r3, r0, #4294967295	; 0xffffffff
     30c:	d202      	bcs.n	314 <__udivmoddi4+0x108>
     30e:	45a0      	cmp	r8, r4
     310:	f200 80d2 	bhi.w	4b8 <CONFIG_MAIN_STACK_SIZE+0xb8>
     314:	4618      	mov	r0, r3
     316:	eba4 0408 	sub.w	r4, r4, r8
     31a:	ea40 400c 	orr.w	r0, r0, ip, lsl #16
     31e:	e7c0      	b.n	2a2 <__udivmoddi4+0x96>
     320:	428b      	cmp	r3, r1
     322:	d908      	bls.n	336 <__udivmoddi4+0x12a>
     324:	2d00      	cmp	r5, #0
     326:	f000 80af 	beq.w	488 <CONFIG_MAIN_STACK_SIZE+0x88>
     32a:	2100      	movs	r1, #0
     32c:	e9c5 0600 	strd	r0, r6, [r5]
     330:	4608      	mov	r0, r1
     332:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
     336:	fab3 f183 	clz	r1, r3
     33a:	2900      	cmp	r1, #0
     33c:	d149      	bne.n	3d2 <__udivmoddi4+0x1c6>
     33e:	42b3      	cmp	r3, r6
     340:	d302      	bcc.n	348 <__udivmoddi4+0x13c>
     342:	4282      	cmp	r2, r0
     344:	f200 80bb 	bhi.w	4be <CONFIG_MAIN_STACK_SIZE+0xbe>
     348:	1a84      	subs	r4, r0, r2
     34a:	eb66 0303 	sbc.w	r3, r6, r3
     34e:	2001      	movs	r0, #1
     350:	469c      	mov	ip, r3
     352:	2d00      	cmp	r5, #0
     354:	d0aa      	beq.n	2ac <__udivmoddi4+0xa0>
     356:	e9c5 4c00 	strd	r4, ip, [r5]
     35a:	e7a7      	b.n	2ac <__udivmoddi4+0xa0>
     35c:	f1c2 0320 	rsb	r3, r2, #32
     360:	4097      	lsls	r7, r2
     362:	40d8      	lsrs	r0, r3
     364:	4091      	lsls	r1, r2
     366:	40de      	lsrs	r6, r3
     368:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     36c:	4308      	orrs	r0, r1
     36e:	ea4f 4c10 	mov.w	ip, r0, lsr #16
     372:	fbb6 f1fe 	udiv	r1, r6, lr
     376:	fa1f f887 	uxth.w	r8, r7
     37a:	fb0e 6611 	mls	r6, lr, r1, r6
     37e:	ea4c 4606 	orr.w	r6, ip, r6, lsl #16
     382:	fb01 f308 	mul.w	r3, r1, r8
     386:	42b3      	cmp	r3, r6
     388:	fa04 f402 	lsl.w	r4, r4, r2
     38c:	d909      	bls.n	3a2 <__udivmoddi4+0x196>
     38e:	19be      	adds	r6, r7, r6
     390:	f101 3cff 	add.w	ip, r1, #4294967295	; 0xffffffff
     394:	f080 808e 	bcs.w	4b4 <CONFIG_MAIN_STACK_SIZE+0xb4>
     398:	42b3      	cmp	r3, r6
     39a:	f240 808b 	bls.w	4b4 <CONFIG_MAIN_STACK_SIZE+0xb4>
     39e:	3902      	subs	r1, #2
     3a0:	443e      	add	r6, r7
     3a2:	1af3      	subs	r3, r6, r3
     3a4:	b286      	uxth	r6, r0
     3a6:	fbb3 f0fe 	udiv	r0, r3, lr
     3aa:	fb0e 3310 	mls	r3, lr, r0, r3
     3ae:	ea46 4603 	orr.w	r6, r6, r3, lsl #16
     3b2:	fb00 f308 	mul.w	r3, r0, r8
     3b6:	42b3      	cmp	r3, r6
     3b8:	d907      	bls.n	3ca <__udivmoddi4+0x1be>
     3ba:	19be      	adds	r6, r7, r6
     3bc:	f100 3cff 	add.w	ip, r0, #4294967295	; 0xffffffff
     3c0:	d274      	bcs.n	4ac <CONFIG_MAIN_STACK_SIZE+0xac>
     3c2:	42b3      	cmp	r3, r6
     3c4:	d972      	bls.n	4ac <CONFIG_MAIN_STACK_SIZE+0xac>
     3c6:	3802      	subs	r0, #2
     3c8:	443e      	add	r6, r7
     3ca:	1af3      	subs	r3, r6, r3
     3cc:	ea40 4101 	orr.w	r1, r0, r1, lsl #16
     3d0:	e77a      	b.n	2c8 <__udivmoddi4+0xbc>
     3d2:	f1c1 0720 	rsb	r7, r1, #32
     3d6:	fa03 f401 	lsl.w	r4, r3, r1
     3da:	fa22 f307 	lsr.w	r3, r2, r7
     3de:	431c      	orrs	r4, r3
     3e0:	fa20 f907 	lsr.w	r9, r0, r7
     3e4:	fa06 f301 	lsl.w	r3, r6, r1
     3e8:	ea4f 4c14 	mov.w	ip, r4, lsr #16
     3ec:	40fe      	lsrs	r6, r7
     3ee:	ea49 0903 	orr.w	r9, r9, r3
     3f2:	ea4f 4319 	mov.w	r3, r9, lsr #16
     3f6:	fbb6 fefc 	udiv	lr, r6, ip
     3fa:	fa1f f884 	uxth.w	r8, r4
     3fe:	fb0c 661e 	mls	r6, ip, lr, r6
     402:	ea43 4606 	orr.w	r6, r3, r6, lsl #16
     406:	fb0e fa08 	mul.w	sl, lr, r8
     40a:	45b2      	cmp	sl, r6
     40c:	fa02 f201 	lsl.w	r2, r2, r1
     410:	fa00 f301 	lsl.w	r3, r0, r1
     414:	d908      	bls.n	428 <CONFIG_MAIN_STACK_SIZE+0x28>
     416:	19a6      	adds	r6, r4, r6
     418:	f10e 30ff 	add.w	r0, lr, #4294967295	; 0xffffffff
     41c:	d248      	bcs.n	4b0 <CONFIG_MAIN_STACK_SIZE+0xb0>
     41e:	45b2      	cmp	sl, r6
     420:	d946      	bls.n	4b0 <CONFIG_MAIN_STACK_SIZE+0xb0>
     422:	f1ae 0e02 	sub.w	lr, lr, #2
     426:	4426      	add	r6, r4
     428:	eba6 060a 	sub.w	r6, r6, sl
     42c:	fa1f f989 	uxth.w	r9, r9
     430:	fbb6 f0fc 	udiv	r0, r6, ip
     434:	fb0c 6610 	mls	r6, ip, r0, r6
     438:	ea49 4606 	orr.w	r6, r9, r6, lsl #16
     43c:	fb00 f808 	mul.w	r8, r0, r8
     440:	45b0      	cmp	r8, r6
     442:	d907      	bls.n	454 <CONFIG_MAIN_STACK_SIZE+0x54>
     444:	19a6      	adds	r6, r4, r6
     446:	f100 3cff 	add.w	ip, r0, #4294967295	; 0xffffffff
     44a:	d22d      	bcs.n	4a8 <CONFIG_MAIN_STACK_SIZE+0xa8>
     44c:	45b0      	cmp	r8, r6
     44e:	d92b      	bls.n	4a8 <CONFIG_MAIN_STACK_SIZE+0xa8>
     450:	3802      	subs	r0, #2
     452:	4426      	add	r6, r4
     454:	ea40 400e 	orr.w	r0, r0, lr, lsl #16
     458:	eba6 0608 	sub.w	r6, r6, r8
     45c:	fba0 8902 	umull	r8, r9, r0, r2
     460:	454e      	cmp	r6, r9
     462:	46c4      	mov	ip, r8
     464:	46ce      	mov	lr, r9
     466:	d318      	bcc.n	49a <CONFIG_MAIN_STACK_SIZE+0x9a>
     468:	d015      	beq.n	496 <CONFIG_MAIN_STACK_SIZE+0x96>
     46a:	b375      	cbz	r5, 4ca <CONFIG_MAIN_STACK_SIZE+0xca>
     46c:	ebb3 020c 	subs.w	r2, r3, ip
     470:	eb66 060e 	sbc.w	r6, r6, lr
     474:	fa06 f707 	lsl.w	r7, r6, r7
     478:	fa22 f301 	lsr.w	r3, r2, r1
     47c:	40ce      	lsrs	r6, r1
     47e:	431f      	orrs	r7, r3
     480:	e9c5 7600 	strd	r7, r6, [r5]
     484:	2100      	movs	r1, #0
     486:	e711      	b.n	2ac <__udivmoddi4+0xa0>
     488:	4629      	mov	r1, r5
     48a:	4628      	mov	r0, r5
     48c:	e70e      	b.n	2ac <__udivmoddi4+0xa0>
     48e:	4666      	mov	r6, ip
     490:	e6ed      	b.n	26e <__udivmoddi4+0x62>
     492:	4618      	mov	r0, r3
     494:	e701      	b.n	29a <__udivmoddi4+0x8e>
     496:	4543      	cmp	r3, r8
     498:	d2e7      	bcs.n	46a <CONFIG_MAIN_STACK_SIZE+0x6a>
     49a:	ebb8 0c02 	subs.w	ip, r8, r2
     49e:	eb69 0404 	sbc.w	r4, r9, r4
     4a2:	3801      	subs	r0, #1
     4a4:	46a6      	mov	lr, r4
     4a6:	e7e0      	b.n	46a <CONFIG_MAIN_STACK_SIZE+0x6a>
     4a8:	4660      	mov	r0, ip
     4aa:	e7d3      	b.n	454 <CONFIG_MAIN_STACK_SIZE+0x54>
     4ac:	4660      	mov	r0, ip
     4ae:	e78c      	b.n	3ca <__udivmoddi4+0x1be>
     4b0:	4686      	mov	lr, r0
     4b2:	e7b9      	b.n	428 <CONFIG_MAIN_STACK_SIZE+0x28>
     4b4:	4661      	mov	r1, ip
     4b6:	e774      	b.n	3a2 <__udivmoddi4+0x196>
     4b8:	3802      	subs	r0, #2
     4ba:	443c      	add	r4, r7
     4bc:	e72b      	b.n	316 <__udivmoddi4+0x10a>
     4be:	4608      	mov	r0, r1
     4c0:	e747      	b.n	352 <__udivmoddi4+0x146>
     4c2:	f1ac 0c02 	sub.w	ip, ip, #2
     4c6:	443e      	add	r6, r7
     4c8:	e711      	b.n	2ee <__udivmoddi4+0xe2>
     4ca:	4629      	mov	r1, r5
     4cc:	e6ee      	b.n	2ac <__udivmoddi4+0xa0>
     4ce:	bf00      	nop

000004d0 <__aeabi_idiv0>:
     4d0:	4770      	bx	lr
     4d2:	bf00      	nop

000004d4 <Thread_send_a>:
};



extern void Thread_send_a()
{
     4d4:	b570      	push	{r4, r5, r6, lr}
     4d6:	b08e      	sub	sp, #56	; 0x38
	struct k_mbox_msg _send_msg;
	uint32_t _info = 150;
	char _buffer[] = "huynh tai";
	struct info_message _a;
	_a.date = 3;
     4d8:	4b11      	ldr	r3, [pc, #68]	; (520 <Thread_send_a+0x4c>)
     4da:	9301      	str	r3, [sp, #4]
	_a.month =8;
	_a.year = 2020;
     4dc:	2307      	movs	r3, #7
     4de:	f8ad 3008 	strh.w	r3, [sp, #8]
	{
		_send_msg.info = sizeof(struct info_message);
		_send_msg.size = sizeof(struct info_message);
		_send_msg.tx_data = &_a;
	//	_send_msg.tx_block.data = NULL;
		_send_msg.tx_target_thread = my_tid_receive_a;
     4e2:	4e10      	ldr	r6, [pc, #64]	; (524 <Thread_send_a+0x50>)
		k_mbox_put(&my_mbox,&_send_msg,K_FOREVER);
     4e4:	4d10      	ldr	r5, [pc, #64]	; (528 <Thread_send_a+0x54>)
		printk("\n\rhello I'm thread Send A");
     4e6:	4c11      	ldr	r4, [pc, #68]	; (52c <Thread_send_a+0x58>)
	_a.year = 2020;
     4e8:	2300      	movs	r3, #0
     4ea:	f88d 300a 	strb.w	r3, [sp, #10]
		_send_msg.info = sizeof(struct info_message);
     4ee:	2307      	movs	r3, #7
		_send_msg.size = sizeof(struct info_message);
     4f0:	e9cd 3304 	strd	r3, r3, [sp, #16]
		_send_msg.tx_data = &_a;
     4f4:	ab01      	add	r3, sp, #4
     4f6:	9306      	str	r3, [sp, #24]
		_send_msg.tx_target_thread = my_tid_receive_a;
     4f8:	6833      	ldr	r3, [r6, #0]
     4fa:	930b      	str	r3, [sp, #44]	; 0x2c
		k_mbox_put(&my_mbox,&_send_msg,K_FOREVER);
     4fc:	a903      	add	r1, sp, #12
     4fe:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
     502:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
     506:	4628      	mov	r0, r5
     508:	f002 feaa 	bl	3260 <k_mbox_put>
		printk("\n\rhello I'm thread Send A");
     50c:	4620      	mov	r0, r4
     50e:	f005 f9bf 	bl	5890 <printk>
 * @return Zero if the requested time has elapsed or the number of milliseconds
 * left to sleep, if thread was woken up by \ref k_wakeup call.
 */
static inline int32_t k_msleep(int32_t ms)
{
	return k_sleep(Z_TIMEOUT_MS(ms));
     512:	2100      	movs	r1, #0
     514:	f641 109a 	movw	r0, #6554	; 0x199a
     518:	f005 f8ba 	bl	5690 <k_sleep>
	while (1)
     51c:	e7e7      	b.n	4ee <Thread_send_a+0x1a>
     51e:	bf00      	nop
     520:	e4610803 	.word	0xe4610803
     524:	20000464 	.word	0x20000464
     528:	2000042c 	.word	0x2000042c
     52c:	00007794 	.word	0x00007794

00000530 <Thread_receive_a>:

	}
	
}
extern void Thread_receive_a()
{
     530:	b5f0      	push	{r4, r5, r6, r7, lr}
	struct sinhvien _sinhvien;
	while (1)
	{
	//	_receive_msg.info = _info;
		_receive_msg.size = sizeof(_a);
		_receive_msg.rx_source_thread = my_tid_send_a;
     532:	4d14      	ldr	r5, [pc, #80]	; (584 <Thread_receive_a+0x54>)
		k_mbox_get(&my_mbox, &_receive_msg, &_a, K_FOREVER);
     534:	4c14      	ldr	r4, [pc, #80]	; (588 <Thread_receive_a+0x58>)
{
     536:	b091      	sub	sp, #68	; 0x44
		k_mbox_get(&my_mbox, &_receive_msg, &_a, K_FOREVER);
     538:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
     53c:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
		_receive_msg.size = sizeof(_a);
     540:	2307      	movs	r3, #7
		k_mbox_get(&my_mbox, &_receive_msg, &_a, K_FOREVER);
     542:	aa03      	add	r2, sp, #12
		_receive_msg.size = sizeof(_a);
     544:	9306      	str	r3, [sp, #24]
		k_mbox_get(&my_mbox, &_receive_msg, &_a, K_FOREVER);
     546:	a905      	add	r1, sp, #20
		_receive_msg.rx_source_thread = my_tid_send_a;
     548:	682b      	ldr	r3, [r5, #0]
     54a:	930c      	str	r3, [sp, #48]	; 0x30
		k_mbox_get(&my_mbox, &_receive_msg, &_a, K_FOREVER);
     54c:	e9cd 6700 	strd	r6, r7, [sp]
     550:	4620      	mov	r0, r4
     552:	f002 fe8f 	bl	3274 <k_mbox_get>
		printk("\n\r info = %d",_receive_msg.info);
     556:	9907      	ldr	r1, [sp, #28]
     558:	480c      	ldr	r0, [pc, #48]	; (58c <Thread_receive_a+0x5c>)
     55a:	f005 f999 	bl	5890 <printk>
//		printk("\n\rage : %d name : %s",_sinhvien.age,_sinhvien.name);
		printk("\n\rhello I'm thread Receive A Info_message \n\r date: %d \n\r month :%d \n\r year : %d \n\r name : %d \n\r",_a.date,_a.month,_a.year,_a.name);
     55e:	f89d 300e 	ldrb.w	r3, [sp, #14]
     562:	f89d 100c 	ldrb.w	r1, [sp, #12]
     566:	9300      	str	r3, [sp, #0]
     568:	f89d 200d 	ldrb.w	r2, [sp, #13]
     56c:	f8dd 300f 	ldr.w	r3, [sp, #15]
     570:	4807      	ldr	r0, [pc, #28]	; (590 <Thread_receive_a+0x60>)
     572:	f005 f98d 	bl	5890 <printk>
     576:	2100      	movs	r1, #0
     578:	f641 109a 	movw	r0, #6554	; 0x199a
     57c:	f005 f888 	bl	5690 <k_sleep>
	while (1)
     580:	e7de      	b.n	540 <Thread_receive_a+0x10>
     582:	bf00      	nop
     584:	2000046c 	.word	0x2000046c
     588:	2000042c 	.word	0x2000042c
     58c:	000077ae 	.word	0x000077ae
     590:	000077bb 	.word	0x000077bb

00000594 <device_get_binding.constprop.0>:
#ifdef __cplusplus
extern "C" {
#endif

extern struct device * z_impl_device_get_binding(const char * name);
static inline struct device * device_get_binding(const char * name)
     594:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
     598:	f005 f870 	bl	567c <arch_is_user_context>
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
     59c:	b120      	cbz	r0, 5a8 <device_get_binding.constprop.0+0x14>
	register uint32_t ret __asm__("r0") = arg1;
     59e:	4805      	ldr	r0, [pc, #20]	; (5b4 <device_get_binding.constprop.0+0x20>)
	register uint32_t r6 __asm__("r6") = call_id;
     5a0:	2627      	movs	r6, #39	; 0x27
	__asm__ volatile("svc %[svid]\n"
     5a2:	df03      	svc	3
		return (struct device *) arch_syscall_invoke1(*(uintptr_t *)&name, K_SYSCALL_DEVICE_GET_BINDING);
	}
#endif
	compiler_barrier();
	return z_impl_device_get_binding(name);
}
     5a4:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	return z_impl_device_get_binding(name);
     5a8:	4802      	ldr	r0, [pc, #8]	; (5b4 <device_get_binding.constprop.0+0x20>)
}
     5aa:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_device_get_binding(name);
     5ae:	f002 bc5f 	b.w	2e70 <z_impl_device_get_binding>
     5b2:	bf00      	nop
     5b4:	0000781b 	.word	0x0000781b

000005b8 <Thread_send_b>:
{
     5b8:	b538      	push	{r3, r4, r5, lr}
		printk("\n\r BBBBBBBBBBBBBBBBBBBb");
     5ba:	4d04      	ldr	r5, [pc, #16]	; (5cc <Thread_send_b+0x14>)
		k_busy_wait(200000);
     5bc:	4c04      	ldr	r4, [pc, #16]	; (5d0 <Thread_send_b+0x18>)
		printk("\n\r BBBBBBBBBBBBBBBBBBBb");
     5be:	4628      	mov	r0, r5
     5c0:	f005 f966 	bl	5890 <printk>
		k_busy_wait(200000);
     5c4:	4620      	mov	r0, r4
     5c6:	f005 f904 	bl	57d2 <k_busy_wait>
	while (1)
     5ca:	e7f8      	b.n	5be <Thread_send_b+0x6>
     5cc:	00007822 	.word	0x00007822
     5d0:	00030d40 	.word	0x00030d40

000005d4 <Thread_receive_b>:
		k_msleep(200);
	}
	
}
extern void Thread_receive_b()
{
     5d4:	b510      	push	{r4, lr}
		k_msleep(200);
		*/
//		k_pipe_get(&my_pipe,_buffer,sizeof(_buffer),&byte_read,xmin,K_NO_WAIT);
//		printk("%s",_buffer);
//		k_msleep(200);
	printk("\n\r A");
     5d6:	4c04      	ldr	r4, [pc, #16]	; (5e8 <Thread_receive_b+0x14>)
     5d8:	4620      	mov	r0, r4
     5da:	f005 f959 	bl	5890 <printk>
	k_busy_wait(100);
     5de:	2064      	movs	r0, #100	; 0x64
     5e0:	f005 f8f7 	bl	57d2 <k_busy_wait>
	while (1)
     5e4:	e7f8      	b.n	5d8 <Thread_receive_b+0x4>
     5e6:	bf00      	nop
     5e8:	0000783a 	.word	0x0000783a

000005ec <main>:
	
}	
struct info_message _sv;
//char *a;
void main(void)
{	
     5ec:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
	_sv.name = 12;
     5f0:	4b64      	ldr	r3, [pc, #400]	; (784 <main+0x198>)
	_sv.year = 1122;
	_sv.date = 12;
	_sv.month = 1;
//	a = "nguyen huynh tai";
	/*-------------Thread Send-Receive----------------------*/
	my_tid_send_a = k_thread_create(&my_thread_data_send_a,my_stack_area_send_a,
     5f2:	4865      	ldr	r0, [pc, #404]	; (788 <main+0x19c>)
     5f4:	f8df 91f4 	ldr.w	r9, [pc, #500]	; 7ec <main+0x200>
                                 Thread_send_b,
                                 NULL, NULL, NULL,
                                 5, 0, K_NO_WAIT);
	k_thread_name_set(my_tid_send_b, "Thread_send_b");	

	my_tid_receive_a = k_thread_create(&my_thread_data_receive_a,my_stack_area_receive_a,
     5f8:	f8df 81f4 	ldr.w	r8, [pc, #500]	; 7f0 <main+0x204>
	_sv.year = 1122;
     5fc:	2162      	movs	r1, #98	; 0x62
     5fe:	70d9      	strb	r1, [r3, #3]
                                 5, 0, K_NO_WAIT);
     600:	2400      	movs	r4, #0
     602:	2500      	movs	r5, #0
	_sv.name = 12;
     604:	220c      	movs	r2, #12
	_sv.year = 1122;
     606:	2700      	movs	r7, #0
	_sv.month = 1;
     608:	2601      	movs	r6, #1
	_sv.year = 1122;
     60a:	2104      	movs	r1, #4
	_sv.name = 12;
     60c:	709a      	strb	r2, [r3, #2]
	_sv.year = 1122;
     60e:	7119      	strb	r1, [r3, #4]
	_sv.date = 12;
     610:	701a      	strb	r2, [r3, #0]
	_sv.year = 1122;
     612:	715f      	strb	r7, [r3, #5]
     614:	719f      	strb	r7, [r3, #6]
	_sv.month = 1;
     616:	705e      	strb	r6, [r3, #1]
	my_tid_send_a = k_thread_create(&my_thread_data_send_a,my_stack_area_send_a,
     618:	4a5c      	ldr	r2, [pc, #368]	; (78c <main+0x1a0>)
     61a:	495d      	ldr	r1, [pc, #372]	; (790 <main+0x1a4>)
     61c:	e9cd 4500 	strd	r4, r5, [sp]
     620:	f005 f87a 	bl	5718 <k_thread_create.constprop.0>
	k_thread_name_set(my_tid_send_a, "Thread_send_a");
     624:	495b      	ldr	r1, [pc, #364]	; (794 <main+0x1a8>)
	my_tid_send_a = k_thread_create(&my_thread_data_send_a,my_stack_area_send_a,
     626:	f8c9 0000 	str.w	r0, [r9]
	k_thread_name_set(my_tid_send_a, "Thread_send_a");
     62a:	f005 f8a0 	bl	576e <k_thread_name_set>
	my_tid_send_b = k_thread_create(&my_thread_data_send_b,my_stack_area_send_b,
     62e:	4a5a      	ldr	r2, [pc, #360]	; (798 <main+0x1ac>)
     630:	495a      	ldr	r1, [pc, #360]	; (79c <main+0x1b0>)
     632:	485b      	ldr	r0, [pc, #364]	; (7a0 <main+0x1b4>)
     634:	e9cd 4500 	strd	r4, r5, [sp]
     638:	f005 f86e 	bl	5718 <k_thread_create.constprop.0>
     63c:	4b59      	ldr	r3, [pc, #356]	; (7a4 <main+0x1b8>)
	k_thread_name_set(my_tid_send_b, "Thread_send_b");	
     63e:	495a      	ldr	r1, [pc, #360]	; (7a8 <main+0x1bc>)
	my_tid_send_b = k_thread_create(&my_thread_data_send_b,my_stack_area_send_b,
     640:	6018      	str	r0, [r3, #0]
	k_thread_name_set(my_tid_send_b, "Thread_send_b");	
     642:	f005 f894 	bl	576e <k_thread_name_set>
	my_tid_receive_a = k_thread_create(&my_thread_data_receive_a,my_stack_area_receive_a,
     646:	4a59      	ldr	r2, [pc, #356]	; (7ac <main+0x1c0>)
     648:	4959      	ldr	r1, [pc, #356]	; (7b0 <main+0x1c4>)
     64a:	485a      	ldr	r0, [pc, #360]	; (7b4 <main+0x1c8>)
     64c:	e9cd 4500 	strd	r4, r5, [sp]
     650:	f005 f862 	bl	5718 <k_thread_create.constprop.0>
                                 MY_STACK_SIZE,
                                 Thread_receive_a,
                                 NULL, NULL, NULL,
                                 5, 0, K_NO_WAIT);
	k_thread_name_set(my_tid_receive_a, "Thread_receive_a");	
     654:	4958      	ldr	r1, [pc, #352]	; (7b8 <main+0x1cc>)
	my_tid_receive_a = k_thread_create(&my_thread_data_receive_a,my_stack_area_receive_a,
     656:	f8c8 0000 	str.w	r0, [r8]
	k_thread_name_set(my_tid_receive_a, "Thread_receive_a");	
     65a:	f005 f888 	bl	576e <k_thread_name_set>
	my_tid_receive_b = k_thread_create(&my_thread_data_receive_b,my_stack_area_receive_b,
     65e:	4a57      	ldr	r2, [pc, #348]	; (7bc <main+0x1d0>)
     660:	4957      	ldr	r1, [pc, #348]	; (7c0 <main+0x1d4>)
     662:	4858      	ldr	r0, [pc, #352]	; (7c4 <main+0x1d8>)
     664:	e9cd 4500 	strd	r4, r5, [sp]
     668:	f005 f856 	bl	5718 <k_thread_create.constprop.0>
     66c:	4b56      	ldr	r3, [pc, #344]	; (7c8 <main+0x1dc>)
                                 MY_STACK_SIZE,
                                 Thread_receive_b,
                                 NULL, NULL, NULL,
                                 5, 0, K_NO_WAIT);
	k_thread_name_set(my_tid_receive_b, "Thread_receive_b");	
     66e:	4957      	ldr	r1, [pc, #348]	; (7cc <main+0x1e0>)
	my_tid_receive_b = k_thread_create(&my_thread_data_receive_b,my_stack_area_receive_b,
     670:	6018      	str	r0, [r3, #0]
	k_thread_name_set(my_tid_receive_b, "Thread_receive_b");	
     672:	f005 f87c 	bl	576e <k_thread_name_set>
	/*----------------------------------*/
	/*----------Mail Box----------------*/
	k_mbox_init(&my_mbox);
     676:	4856      	ldr	r0, [pc, #344]	; (7d0 <main+0x1e4>)
     678:	f005 fecf 	bl	641a <k_mbox_init>
	k_thread_suspend(my_tid_send_a);
     67c:	f8d9 0000 	ldr.w	r0, [r9]
     680:	f005 f816 	bl	56b0 <k_thread_suspend>
	k_thread_suspend(my_tid_receive_a);
     684:	f8d8 0000 	ldr.w	r0, [r8]
     688:	f005 f812 	bl	56b0 <k_thread_suspend>
//	k_thread_suspend(my_tid_receive_b);
	/*------------Pipe-----------------*/
	k_pipe_init(&my_pipe,buff,sizeof(buff));
     68c:	4951      	ldr	r1, [pc, #324]	; (7d4 <main+0x1e8>)
     68e:	4852      	ldr	r0, [pc, #328]	; (7d8 <main+0x1ec>)
     690:	2264      	movs	r2, #100	; 0x64
     692:	f005 ffc3 	bl	661c <k_pipe_init>
	struct device *dev;
	struct device *dev_led0;
	bool led_is_on = true;
	int ret;
	/*-----Configure nRF52832 from Library nrf52.h-------------*/
	NRF_P0->PIN_CNF[14] = (3 << 16) | (3 << 2);
     696:	f04f 43a0 	mov.w	r3, #1342177280	; 0x50000000
     69a:	4a50      	ldr	r2, [pc, #320]	; (7dc <main+0x1f0>)
     69c:	f8c3 2738 	str.w	r2, [r3, #1848]	; 0x738
    NRF_P0->PIN_CNF[15] = (3 << 16) | (3 << 2);
     6a0:	f8c3 273c 	str.w	r2, [r3, #1852]	; 0x73c
    NRF_P0->PIN_CNF[16] = (3 << 16) | (3 << 2);
     6a4:	f8c3 2740 	str.w	r2, [r3, #1856]	; 0x740
    NRF_P0->PIN_CNF[13] = (3 << 16) | (3 << 2); 
     6a8:	f8c3 2734 	str.w	r2, [r3, #1844]	; 0x734
	//NRF_P0->DIRSET = 0x001E0000;
    NRF_P0->PIN_CNF[6] = 0x03;
     6ac:	2203      	movs	r2, #3
     6ae:	f8c3 2718 	str.w	r2, [r3, #1816]	; 0x718
    NRF_P0->PIN_CNF[7] = 0;
     6b2:	f8c3 771c 	str.w	r7, [r3, #1820]	; 0x71c
    // Configure GPIOTE
    //EVENTS
    NRF_GPIOTE->INTENSET = (1 << 0);// Enable INTERRUPTION EVENT_IN[0]
    //NRF_GPIOTE->CONFIG[0] = (1 << 0) | (13 << 8) | (2 << 16); // Configure EVENT_IN[0]
    //NRF_GPIOTE->CONFIG[5] = (1 << 0) | (14 << 8) | (2 << 16); // Configure EVENT_IN[0]
    NRF_GPIOTE->CONFIG[6] = (1 << 0) | (15 << 8) | (2 << 16); // Configure EVENT_IN[0]
     6b6:	4a4a      	ldr	r2, [pc, #296]	; (7e0 <main+0x1f4>)
    NRF_GPIOTE->INTENSET = (1 << 0);// Enable INTERRUPTION EVENT_IN[0]
     6b8:	4b4a      	ldr	r3, [pc, #296]	; (7e4 <main+0x1f8>)
     6ba:	f8c3 6304 	str.w	r6, [r3, #772]	; 0x304
    NRF_GPIOTE->CONFIG[6] = (1 << 0) | (15 << 8) | (2 << 16); // Configure EVENT_IN[0]
     6be:	f8c3 2528 	str.w	r2, [r3, #1320]	; 0x528
    NRF_GPIOTE->CONFIG[7] = (1 << 0) | (16 << 8) | (2 << 16); // Configure EVENT_IN[0]
     6c2:	f502 7280 	add.w	r2, r2, #256	; 0x100
     6c6:	f8c3 252c 	str.w	r2, [r3, #1324]	; 0x52c
    // TASKS
    //NRF_GPIOTE->CONFIG[1] = (3 << 0) | (17 << 8) | (3 << 16) | (1 << 20);
    //NRF_GPIOTE->CONFIG[2] = (3 << 0) | (18 << 8) | (3 << 16) | (1 << 20);
    NRF_GPIOTE->CONFIG[3] = (3 << 0) | (19 << 8) | (3 << 16) | (1 << 20);
     6ca:	f502 1288 	add.w	r2, r2, #1114112	; 0x110000
     6ce:	f202 3202 	addw	r2, r2, #770	; 0x302
     6d2:	f8c3 251c 	str.w	r2, [r3, #1308]	; 0x51c
    NRF_GPIOTE->CONFIG[4] = (3 << 0) | (20 << 8) | (3 << 16) | (1 << 20);
     6d6:	f502 7280 	add.w	r2, r2, #256	; 0x100
     6da:	f8c3 2520 	str.w	r2, [r3, #1312]	; 0x520
    //NRF_PPI->CHENSET = (15 << 0);
    //NRF_PPI->CH[0].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[0];
    //NRF_PPI->CH[0].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[1];
    //NRF_PPI->CH[1].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[5];
    //NRF_PPI->CH[1].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[2];
    NRF_PPI->CH[2].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[6];
     6de:	f503 33c8 	add.w	r3, r3, #102400	; 0x19000
     6e2:	4a41      	ldr	r2, [pc, #260]	; (7e8 <main+0x1fc>)
     6e4:	f8c3 2520 	str.w	r2, [r3, #1312]	; 0x520
    NRF_PPI->CH[2].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[3];
     6e8:	f5a2 7286 	sub.w	r2, r2, #268	; 0x10c
     6ec:	f8c3 2524 	str.w	r2, [r3, #1316]	; 0x524
    NRF_PPI->CH[3].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[7];
     6f0:	f502 7288 	add.w	r2, r2, #272	; 0x110
     6f4:	f8c3 2528 	str.w	r2, [r3, #1320]	; 0x528
    NRF_PPI->CH[3].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[4];
     6f8:	f5a2 7286 	sub.w	r2, r2, #268	; 0x10c
     6fc:	f8c3 252c 	str.w	r2, [r3, #1324]	; 0x52c
    NRF_PPI->CHG[0] = (15 << 0);
     700:	220f      	movs	r2, #15
     702:	f8c3 2800 	str.w	r2, [r3, #2048]	; 0x800
    NRF_PPI->TASKS_CHG[0].EN = 1;
     706:	601e      	str	r6, [r3, #0]
	/*---------------------------------------------------------------*/
	dev = device_get_binding(LED1);
     708:	f7ff ff44 	bl	594 <device_get_binding.constprop.0>
	if (dev == NULL) {
     70c:	4604      	mov	r4, r0
     70e:	b3a8      	cbz	r0, 77c <main+0x190>
		return;
	}

	ret = gpio_pin_configure(dev, PIN, GPIO_OUTPUT_ACTIVE | FLAGS);
     710:	2112      	movs	r1, #18
     712:	f004 ffdd 	bl	56d0 <gpio_pin_configure.constprop.0>
	if (ret < 0) {
     716:	42b8      	cmp	r0, r7
     718:	db30      	blt.n	77c <main+0x190>
		return;
	}
	dev_led0 = device_get_binding(LED1);
     71a:	f7ff ff3b 	bl	594 <device_get_binding.constprop.0>
	if (dev_led0 == NULL) {
     71e:	4605      	mov	r5, r0
     720:	b360      	cbz	r0, 77c <main+0x190>
		return;
	}

	ret = gpio_pin_configure(dev_led0, PIN0, GPIO_OUTPUT_ACTIVE | FLAGS);
     722:	2111      	movs	r1, #17
     724:	f004 ffd4 	bl	56d0 <gpio_pin_configure.constprop.0>
	if (ret < 0) {
     728:	42b8      	cmp	r0, r7
     72a:	db27      	blt.n	77c <main+0x190>

	(void)cfg;
	__ASSERT((cfg->port_pin_mask & (gpio_port_pins_t)BIT(pin)) != 0U,
		 "Unsupported pin");

	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
     72c:	68e3      	ldr	r3, [r4, #12]
     72e:	681b      	ldr	r3, [r3, #0]
		return;
	}
	while (1) {

		gpio_pin_set(dev, PIN, (int)led_is_on);
     730:	4637      	mov	r7, r6
		value = (value != 0) ? 0 : 1;
     732:	f413 2f80 	tst.w	r3, #262144	; 0x40000
     736:	f086 0601 	eor.w	r6, r6, #1
     73a:	bf0c      	ite	eq
     73c:	463b      	moveq	r3, r7
     73e:	4633      	movne	r3, r6
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     740:	f44f 2180 	mov.w	r1, #262144	; 0x40000
     744:	4620      	mov	r0, r4
	if (value != 0)	{
     746:	b19b      	cbz	r3, 770 <main+0x184>
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     748:	f005 f821 	bl	578e <gpio_port_set_bits_raw>
	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
     74c:	68eb      	ldr	r3, [r5, #12]
     74e:	681b      	ldr	r3, [r3, #0]
		value = (value != 0) ? 0 : 1;
     750:	f413 3f00 	tst.w	r3, #131072	; 0x20000
     754:	bf08      	it	eq
     756:	4637      	moveq	r7, r6
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     758:	f44f 3100 	mov.w	r1, #131072	; 0x20000
     75c:	4628      	mov	r0, r5
	if (value != 0)	{
     75e:	b157      	cbz	r7, 776 <main+0x18a>
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     760:	f005 f815 	bl	578e <gpio_port_set_bits_raw>
     764:	2100      	movs	r1, #0
     766:	f44f 4000 	mov.w	r0, #32768	; 0x8000
     76a:	f004 ff91 	bl	5690 <k_sleep>
     76e:	e7dd      	b.n	72c <main+0x140>
		ret = gpio_port_clear_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     770:	f005 f81e 	bl	57b0 <gpio_port_clear_bits_raw>
     774:	e7ea      	b.n	74c <main+0x160>
     776:	f005 f81b 	bl	57b0 <gpio_port_clear_bits_raw>
     77a:	e7f3      	b.n	764 <main+0x178>
//		k_thread_resume(my_tid_receive_b);																																																																																																										


	}

}
     77c:	b003      	add	sp, #12
     77e:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
     782:	bf00      	nop
     784:	20000f2c 	.word	0x20000f2c
     788:	20000140 	.word	0x20000140
     78c:	000004d5 	.word	0x000004d5
     790:	20002c00 	.word	0x20002c00
     794:	0000783f 	.word	0x0000783f
     798:	000005b9 	.word	0x000005b9
     79c:	20002e00 	.word	0x20002e00
     7a0:	200001e0 	.word	0x200001e0
     7a4:	20000470 	.word	0x20000470
     7a8:	0000784d 	.word	0x0000784d
     7ac:	00000531 	.word	0x00000531
     7b0:	20003000 	.word	0x20003000
     7b4:	20000000 	.word	0x20000000
     7b8:	0000785b 	.word	0x0000785b
     7bc:	000005d5 	.word	0x000005d5
     7c0:	20003200 	.word	0x20003200
     7c4:	200000a0 	.word	0x200000a0
     7c8:	20000468 	.word	0x20000468
     7cc:	0000786c 	.word	0x0000786c
     7d0:	2000042c 	.word	0x2000042c
     7d4:	200003c8 	.word	0x200003c8
     7d8:	2000043c 	.word	0x2000043c
     7dc:	0003000c 	.word	0x0003000c
     7e0:	00020f01 	.word	0x00020f01
     7e4:	40006000 	.word	0x40006000
     7e8:	40006118 	.word	0x40006118
     7ec:	2000046c 	.word	0x2000046c
     7f0:	20000464 	.word	0x20000464

000007f4 <print_digits>:
}
#endif /* CONFIG_PRINTK */

static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
			 bool pad_before, char pad_char, int min_width)
{
     7f4:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
     7f8:	b087      	sub	sp, #28
     7fa:	460f      	mov	r7, r1
     7fc:	4619      	mov	r1, r3
	char buf[DIGITS_BUFLEN];
	int i;

	/* Print it backwards into the end of the buffer, low digits first */
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
		buf[i] = "0123456789abcdef"[num % base];
     7fe:	9b10      	ldr	r3, [sp, #64]	; 0x40
{
     800:	f89d b044 	ldrb.w	fp, [sp, #68]	; 0x44
     804:	f89d a048 	ldrb.w	sl, [sp, #72]	; 0x48
		buf[i] = "0123456789abcdef"[num % base];
     808:	4c1f      	ldr	r4, [pc, #124]	; (888 <CONFIG_HEAP_MEM_POOL_SIZE+0x88>)
{
     80a:	4606      	mov	r6, r0
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     80c:	2514      	movs	r5, #20
{
     80e:	4610      	mov	r0, r2
		buf[i] = "0123456789abcdef"[num % base];
     810:	4698      	mov	r8, r3
     812:	ea4f 79e3 	mov.w	r9, r3, asr #31
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     816:	ea50 0301 	orrs.w	r3, r0, r1
     81a:	d119      	bne.n	850 <CONFIG_HEAP_MEM_POOL_SIZE+0x50>
		num /= base;
	}

	if (i == DIGITS_BUFLEN - 1) {
     81c:	2d14      	cmp	r5, #20
		buf[i] = '0';
	} else {
		i++;
	}

	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     81e:	9c13      	ldr	r4, [sp, #76]	; 0x4c
		i++;
     820:	bf14      	ite	ne
     822:	3501      	addne	r5, #1
		buf[i] = '0';
     824:	2330      	moveq	r3, #48	; 0x30
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     826:	442c      	add	r4, r5
		buf[i] = '0';
     828:	bf08      	it	eq
     82a:	f88d 3014 	strbeq.w	r3, [sp, #20]
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     82e:	2c15      	cmp	r4, #21
     830:	d01b      	beq.n	86a <CONFIG_HEAP_MEM_POOL_SIZE+0x6a>
     832:	3c15      	subs	r4, #21

	for (/**/; pad > 0 && pad_before; pad--) {
     834:	2c00      	cmp	r4, #0
     836:	dc1a      	bgt.n	86e <CONFIG_HEAP_MEM_POOL_SIZE+0x6e>
		out(pad_char, ctx);
	}
	for (/**/; i < DIGITS_BUFLEN; i++) {
		out(buf[i], ctx);
     838:	f81d 0005 	ldrb.w	r0, [sp, r5]
     83c:	4639      	mov	r1, r7
	for (/**/; i < DIGITS_BUFLEN; i++) {
     83e:	3501      	adds	r5, #1
		out(buf[i], ctx);
     840:	47b0      	blx	r6
	for (/**/; i < DIGITS_BUFLEN; i++) {
     842:	2d15      	cmp	r5, #21
     844:	d1f8      	bne.n	838 <CONFIG_HEAP_MEM_POOL_SIZE+0x38>
	}
	for (/**/; pad > 0; pad--) {
     846:	2c00      	cmp	r4, #0
     848:	dc19      	bgt.n	87e <CONFIG_HEAP_MEM_POOL_SIZE+0x7e>
		out(pad_char, ctx);
	}
}
     84a:	b007      	add	sp, #28
     84c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		buf[i] = "0123456789abcdef"[num % base];
     850:	4642      	mov	r2, r8
     852:	464b      	mov	r3, r9
     854:	f7ff fcc2 	bl	1dc <__aeabi_uldivmod>
     858:	5ca2      	ldrb	r2, [r4, r2]
     85a:	f80d 2005 	strb.w	r2, [sp, r5]
     85e:	4684      	mov	ip, r0
     860:	460b      	mov	r3, r1
		num /= base;
     862:	4660      	mov	r0, ip
     864:	4619      	mov	r1, r3
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     866:	3d01      	subs	r5, #1
     868:	e7d5      	b.n	816 <CONFIG_HEAP_MEM_POOL_SIZE+0x16>
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     86a:	2400      	movs	r4, #0
	for (/**/; i < DIGITS_BUFLEN; i++) {
     86c:	e7e4      	b.n	838 <CONFIG_HEAP_MEM_POOL_SIZE+0x38>
	for (/**/; pad > 0 && pad_before; pad--) {
     86e:	f1bb 0f00 	cmp.w	fp, #0
     872:	d0e1      	beq.n	838 <CONFIG_HEAP_MEM_POOL_SIZE+0x38>
		out(pad_char, ctx);
     874:	4639      	mov	r1, r7
     876:	4650      	mov	r0, sl
     878:	47b0      	blx	r6
	for (/**/; pad > 0 && pad_before; pad--) {
     87a:	3c01      	subs	r4, #1
     87c:	e7da      	b.n	834 <CONFIG_HEAP_MEM_POOL_SIZE+0x34>
		out(pad_char, ctx);
     87e:	4639      	mov	r1, r7
     880:	4650      	mov	r0, sl
     882:	47b0      	blx	r6
	for (/**/; pad > 0; pad--) {
     884:	3c01      	subs	r4, #1
     886:	e7de      	b.n	846 <CONFIG_HEAP_MEM_POOL_SIZE+0x46>
     888:	0000787d 	.word	0x0000787d

0000088c <char_out>:

static int char_out(int c, void *ctx_p)
{
	struct out_context *ctx = ctx_p;

	ctx->count++;
     88c:	680b      	ldr	r3, [r1, #0]
     88e:	3301      	adds	r3, #1
     890:	600b      	str	r3, [r1, #0]
	return _char_out(c);
     892:	4b01      	ldr	r3, [pc, #4]	; (898 <char_out+0xc>)
     894:	681b      	ldr	r3, [r3, #0]
     896:	4718      	bx	r3
     898:	20003400 	.word	0x20003400

0000089c <__printk_hook_install>:
	_char_out = fn;
     89c:	4b01      	ldr	r3, [pc, #4]	; (8a4 <__printk_hook_install+0x8>)
     89e:	6018      	str	r0, [r3, #0]
}
     8a0:	4770      	bx	lr
     8a2:	bf00      	nop
     8a4:	20003400 	.word	0x20003400

000008a8 <z_vprintk>:
{
     8a8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	char length_mod = 0;
     8ac:	2600      	movs	r6, #0
{
     8ae:	b087      	sub	sp, #28
     8b0:	4605      	mov	r5, r0
     8b2:	468b      	mov	fp, r1
     8b4:	461c      	mov	r4, r3
	while (*fmt) {
     8b6:	f102 39ff 	add.w	r9, r2, #4294967295	; 0xffffffff
	int min_width = -1;
     8ba:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
	enum pad_type padding = PAD_NONE;
     8be:	4637      	mov	r7, r6
			might_format = 0;
     8c0:	2300      	movs	r3, #0
					break;
     8c2:	e007      	b.n	8d4 <z_vprintk+0x2c>
		if (!might_format) {
     8c4:	b96b      	cbnz	r3, 8e2 <z_vprintk+0x3a>
			if (*fmt != '%') {
     8c6:	2825      	cmp	r0, #37	; 0x25
     8c8:	f000 80fc 	beq.w	ac4 <z_vprintk+0x21c>
				out((int)*fmt, ctx);
     8cc:	4659      	mov	r1, fp
     8ce:	9304      	str	r3, [sp, #16]
     8d0:	47a8      	blx	r5
     8d2:	9b04      	ldr	r3, [sp, #16]
	while (*fmt) {
     8d4:	f819 0f01 	ldrb.w	r0, [r9, #1]!
     8d8:	2800      	cmp	r0, #0
     8da:	d1f3      	bne.n	8c4 <z_vprintk+0x1c>
}
     8dc:	b007      	add	sp, #28
     8de:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			switch (*fmt) {
     8e2:	287a      	cmp	r0, #122	; 0x7a
     8e4:	d80a      	bhi.n	8fc <z_vprintk+0x54>
     8e6:	2862      	cmp	r0, #98	; 0x62
     8e8:	d810      	bhi.n	90c <z_vprintk+0x64>
     8ea:	2830      	cmp	r0, #48	; 0x30
     8ec:	d052      	beq.n	994 <z_vprintk+0xec>
     8ee:	d845      	bhi.n	97c <z_vprintk+0xd4>
     8f0:	2825      	cmp	r0, #37	; 0x25
     8f2:	f000 80e5 	beq.w	ac0 <z_vprintk+0x218>
     8f6:	282d      	cmp	r0, #45	; 0x2d
     8f8:	f000 80ea 	beq.w	ad0 <z_vprintk+0x228>
					out((int)'%', ctx);
     8fc:	4659      	mov	r1, fp
     8fe:	2025      	movs	r0, #37	; 0x25
     900:	47a8      	blx	r5
					out((int)*fmt, ctx);
     902:	f899 0000 	ldrb.w	r0, [r9]
     906:	4659      	mov	r1, fp
     908:	47a8      	blx	r5
     90a:	e7d9      	b.n	8c0 <z_vprintk+0x18>
     90c:	f1a0 0263 	sub.w	r2, r0, #99	; 0x63
     910:	2a17      	cmp	r2, #23
     912:	d8f3      	bhi.n	8fc <z_vprintk+0x54>
     914:	a101      	add	r1, pc, #4	; (adr r1, 91c <z_vprintk+0x74>)
     916:	f851 f022 	ldr.w	pc, [r1, r2, lsl #2]
     91a:	bf00      	nop
     91c:	00000ab9 	.word	0x00000ab9
     920:	000009dd 	.word	0x000009dd
     924:	000008fd 	.word	0x000008fd
     928:	000008fd 	.word	0x000008fd
     92c:	000008fd 	.word	0x000008fd
     930:	000009bf 	.word	0x000009bf
     934:	000009dd 	.word	0x000009dd
     938:	000008fd 	.word	0x000008fd
     93c:	000008fd 	.word	0x000008fd
     940:	000009bf 	.word	0x000009bf
     944:	000008fd 	.word	0x000008fd
     948:	000008fd 	.word	0x000008fd
     94c:	000008fd 	.word	0x000008fd
     950:	00000a41 	.word	0x00000a41
     954:	000008fd 	.word	0x000008fd
     958:	000008fd 	.word	0x000008fd
     95c:	00000a83 	.word	0x00000a83
     960:	000008fd 	.word	0x000008fd
     964:	000009dd 	.word	0x000009dd
     968:	000008fd 	.word	0x000008fd
     96c:	000008fd 	.word	0x000008fd
     970:	00000985 	.word	0x00000985
     974:	000008fd 	.word	0x000008fd
     978:	000009bf 	.word	0x000009bf
			switch (*fmt) {
     97c:	2839      	cmp	r0, #57	; 0x39
     97e:	d915      	bls.n	9ac <z_vprintk+0x104>
     980:	2858      	cmp	r0, #88	; 0x58
     982:	d1bb      	bne.n	8fc <z_vprintk+0x54>
				if (*fmt == 'p') {
     984:	f899 3000 	ldrb.w	r3, [r9]
     988:	2b70      	cmp	r3, #112	; 0x70
     98a:	d163      	bne.n	a54 <z_vprintk+0x1ac>
					x = va_arg(ap, unsigned int);
     98c:	f854 2b04 	ldr.w	r2, [r4], #4
     990:	2300      	movs	r3, #0
     992:	e06a      	b.n	a6a <z_vprintk+0x1c2>
				if (min_width < 0 && padding == PAD_NONE) {
     994:	f1b8 0f00 	cmp.w	r8, #0
     998:	da0b      	bge.n	9b2 <z_vprintk+0x10a>
     99a:	2f00      	cmp	r7, #0
     99c:	f000 809a 	beq.w	ad4 <z_vprintk+0x22c>
					min_width = *fmt - '0';
     9a0:	f1a0 0830 	sub.w	r8, r0, #48	; 0x30
					padding = PAD_SPACE_BEFORE;
     9a4:	2f00      	cmp	r7, #0
     9a6:	bf08      	it	eq
     9a8:	2702      	moveq	r7, #2
     9aa:	e793      	b.n	8d4 <z_vprintk+0x2c>
				if (min_width < 0) {
     9ac:	f1b8 0f00 	cmp.w	r8, #0
     9b0:	dbf6      	blt.n	9a0 <z_vprintk+0xf8>
					min_width = 10 * min_width + *fmt - '0';
     9b2:	220a      	movs	r2, #10
     9b4:	fb02 0808 	mla	r8, r2, r8, r0
     9b8:	f1a8 0830 	sub.w	r8, r8, #48	; 0x30
     9bc:	e7f2      	b.n	9a4 <z_vprintk+0xfc>
				if (*fmt == 'h' && length_mod == 'h') {
     9be:	2868      	cmp	r0, #104	; 0x68
     9c0:	d103      	bne.n	9ca <z_vprintk+0x122>
     9c2:	2e68      	cmp	r6, #104	; 0x68
     9c4:	d106      	bne.n	9d4 <z_vprintk+0x12c>
					length_mod = 'H';
     9c6:	2648      	movs	r6, #72	; 0x48
     9c8:	e784      	b.n	8d4 <z_vprintk+0x2c>
				} else if (*fmt == 'l' && length_mod == 'l') {
     9ca:	286c      	cmp	r0, #108	; 0x6c
     9cc:	d102      	bne.n	9d4 <z_vprintk+0x12c>
     9ce:	2e6c      	cmp	r6, #108	; 0x6c
     9d0:	f000 8082 	beq.w	ad8 <z_vprintk+0x230>
				} else if (length_mod == 0) {
     9d4:	2e00      	cmp	r6, #0
     9d6:	d191      	bne.n	8fc <z_vprintk+0x54>
     9d8:	4606      	mov	r6, r0
     9da:	e77b      	b.n	8d4 <z_vprintk+0x2c>
				if (length_mod == 'z') {
     9dc:	2e7a      	cmp	r6, #122	; 0x7a
     9de:	d103      	bne.n	9e8 <z_vprintk+0x140>
					d = va_arg(ap, int);
     9e0:	f854 2b04 	ldr.w	r2, [r4], #4
     9e4:	17d3      	asrs	r3, r2, #31
     9e6:	e008      	b.n	9fa <z_vprintk+0x152>
				} else if (length_mod == 'l') {
     9e8:	2e6c      	cmp	r6, #108	; 0x6c
     9ea:	d0f9      	beq.n	9e0 <z_vprintk+0x138>
				} else if (length_mod == 'L') {
     9ec:	2e4c      	cmp	r6, #76	; 0x4c
     9ee:	d1f7      	bne.n	9e0 <z_vprintk+0x138>
					long long lld = va_arg(ap, long long);
     9f0:	3407      	adds	r4, #7
     9f2:	f024 0407 	bic.w	r4, r4, #7
					d = (printk_val_t) lld;
     9f6:	e8f4 2302 	ldrd	r2, r3, [r4], #8
				if (*fmt != 'u' && negative(d)) {
     9fa:	2875      	cmp	r0, #117	; 0x75
     9fc:	d00f      	beq.n	a1e <z_vprintk+0x176>
     9fe:	2a00      	cmp	r2, #0
     a00:	f173 0100 	sbcs.w	r1, r3, #0
     a04:	da0b      	bge.n	a1e <z_vprintk+0x176>
					out((int)'-', ctx);
     a06:	4659      	mov	r1, fp
     a08:	202d      	movs	r0, #45	; 0x2d
     a0a:	e9cd 2304 	strd	r2, r3, [sp, #16]
     a0e:	47a8      	blx	r5
					d = -d;
     a10:	e9dd 2304 	ldrd	r2, r3, [sp, #16]
     a14:	4252      	negs	r2, r2
     a16:	eb63 0343 	sbc.w	r3, r3, r3, lsl #1
					min_width--;
     a1a:	f108 38ff 	add.w	r8, r8, #4294967295	; 0xffffffff
	print_digits(out, ctx, num, 10, padding != PAD_SPACE_AFTER,
     a1e:	1ef9      	subs	r1, r7, #3
     a20:	bf18      	it	ne
     a22:	2101      	movne	r1, #1
     a24:	2f01      	cmp	r7, #1
     a26:	bf0c      	ite	eq
     a28:	2030      	moveq	r0, #48	; 0x30
     a2a:	2020      	movne	r0, #32
     a2c:	e9cd 0802 	strd	r0, r8, [sp, #8]
     a30:	9101      	str	r1, [sp, #4]
     a32:	210a      	movs	r1, #10
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
     a34:	9100      	str	r1, [sp, #0]
     a36:	4628      	mov	r0, r5
     a38:	4659      	mov	r1, fp
     a3a:	f7ff fedb 	bl	7f4 <print_digits>
     a3e:	e73f      	b.n	8c0 <z_vprintk+0x18>
				out('0', ctx);
     a40:	4659      	mov	r1, fp
     a42:	2030      	movs	r0, #48	; 0x30
     a44:	47a8      	blx	r5
				out('x', ctx);
     a46:	4659      	mov	r1, fp
     a48:	2078      	movs	r0, #120	; 0x78
     a4a:	47a8      	blx	r5
				min_width = sizeof(void *) * 2;
     a4c:	f04f 0808 	mov.w	r8, #8
				padding = PAD_ZERO_BEFORE;
     a50:	2701      	movs	r7, #1
     a52:	e797      	b.n	984 <z_vprintk+0xdc>
				} else if (length_mod == 'l') {
     a54:	2e6c      	cmp	r6, #108	; 0x6c
     a56:	d099      	beq.n	98c <z_vprintk+0xe4>
				} else if (length_mod == 'L') {
     a58:	2e4c      	cmp	r6, #76	; 0x4c
     a5a:	d197      	bne.n	98c <z_vprintk+0xe4>
					x = va_arg(ap, unsigned long long);
     a5c:	1de3      	adds	r3, r4, #7
     a5e:	f023 0307 	bic.w	r3, r3, #7
     a62:	461c      	mov	r4, r3
     a64:	685b      	ldr	r3, [r3, #4]
     a66:	f854 2b08 	ldr.w	r2, [r4], #8
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
     a6a:	1ef9      	subs	r1, r7, #3
     a6c:	bf18      	it	ne
     a6e:	2101      	movne	r1, #1
     a70:	2f01      	cmp	r7, #1
     a72:	bf0c      	ite	eq
     a74:	2030      	moveq	r0, #48	; 0x30
     a76:	2020      	movne	r0, #32
     a78:	9101      	str	r1, [sp, #4]
     a7a:	e9cd 0802 	strd	r0, r8, [sp, #8]
     a7e:	2110      	movs	r1, #16
     a80:	e7d8      	b.n	a34 <z_vprintk+0x18c>
				char *s = va_arg(ap, char *);
     a82:	46a2      	mov	sl, r4
     a84:	f85a 3b04 	ldr.w	r3, [sl], #4
				while (*s) {
     a88:	461c      	mov	r4, r3
     a8a:	4621      	mov	r1, r4
     a8c:	f814 0b01 	ldrb.w	r0, [r4], #1
     a90:	b940      	cbnz	r0, aa4 <z_vprintk+0x1fc>
				if (padding == PAD_SPACE_AFTER) {
     a92:	2f03      	cmp	r7, #3
     a94:	d122      	bne.n	adc <z_vprintk+0x234>
					int remaining = min_width - (s - start);
     a96:	1acc      	subs	r4, r1, r3
     a98:	eba8 0404 	sub.w	r4, r8, r4
					while (remaining-- > 0) {
     a9c:	2c00      	cmp	r4, #0
     a9e:	dc06      	bgt.n	aae <z_vprintk+0x206>
				char *s = va_arg(ap, char *);
     aa0:	4654      	mov	r4, sl
     aa2:	e70d      	b.n	8c0 <z_vprintk+0x18>
					out((int)(*s++), ctx);
     aa4:	4659      	mov	r1, fp
     aa6:	9304      	str	r3, [sp, #16]
     aa8:	47a8      	blx	r5
     aaa:	9b04      	ldr	r3, [sp, #16]
     aac:	e7ed      	b.n	a8a <z_vprintk+0x1e2>
						out(' ', ctx);
     aae:	4659      	mov	r1, fp
     ab0:	2020      	movs	r0, #32
     ab2:	47a8      	blx	r5
     ab4:	3c01      	subs	r4, #1
     ab6:	e7f1      	b.n	a9c <z_vprintk+0x1f4>
				out(c, ctx);
     ab8:	f854 0b04 	ldr.w	r0, [r4], #4
     abc:	4659      	mov	r1, fp
     abe:	e723      	b.n	908 <z_vprintk+0x60>
				out((int)'%', ctx);
     ac0:	4659      	mov	r1, fp
     ac2:	e721      	b.n	908 <z_vprintk+0x60>
				length_mod = 0;
     ac4:	461e      	mov	r6, r3
				padding = PAD_NONE;
     ac6:	461f      	mov	r7, r3
				min_width = -1;
     ac8:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
				might_format = 1;
     acc:	2301      	movs	r3, #1
     ace:	e701      	b.n	8d4 <z_vprintk+0x2c>
			switch (*fmt) {
     ad0:	2703      	movs	r7, #3
     ad2:	e6ff      	b.n	8d4 <z_vprintk+0x2c>
					padding = PAD_ZERO_BEFORE;
     ad4:	2701      	movs	r7, #1
     ad6:	e6fd      	b.n	8d4 <z_vprintk+0x2c>
					length_mod = 'L';
     ad8:	264c      	movs	r6, #76	; 0x4c
     ada:	e6fb      	b.n	8d4 <z_vprintk+0x2c>
				char *s = va_arg(ap, char *);
     adc:	4654      	mov	r4, sl
			might_format = 0;
     ade:	4603      	mov	r3, r0
     ae0:	e6f8      	b.n	8d4 <z_vprintk+0x2c>
     ae2:	bf00      	nop

00000ae4 <z_impl_k_str_out>:
#endif
}
#endif /* CONFIG_USERSPACE */

void z_impl_k_str_out(char *c, size_t n)
{
     ae4:	b570      	push	{r4, r5, r6, lr}
#ifdef CONFIG_PRINTK_SYNC
	k_spinlock_key_t key = k_spin_lock(&lock);
#endif

	for (i = 0; i < n; i++) {
		_char_out(c[i]);
     ae6:	4e05      	ldr	r6, [pc, #20]	; (afc <z_impl_k_str_out+0x18>)
     ae8:	4604      	mov	r4, r0
     aea:	1845      	adds	r5, r0, r1
	for (i = 0; i < n; i++) {
     aec:	42ac      	cmp	r4, r5
     aee:	d100      	bne.n	af2 <z_impl_k_str_out+0xe>
	}

#ifdef CONFIG_PRINTK_SYNC
	k_spin_unlock(&lock, key);
#endif
}
     af0:	bd70      	pop	{r4, r5, r6, pc}
		_char_out(c[i]);
     af2:	6833      	ldr	r3, [r6, #0]
     af4:	f814 0b01 	ldrb.w	r0, [r4], #1
     af8:	4798      	blx	r3
	for (i = 0; i < n; i++) {
     afa:	e7f7      	b.n	aec <z_impl_k_str_out+0x8>
     afc:	20003400 	.word	0x20003400

00000b00 <vprintk>:
{
     b00:	b530      	push	{r4, r5, lr}
     b02:	b08b      	sub	sp, #44	; 0x2c
     b04:	4604      	mov	r4, r0
     b06:	460d      	mov	r5, r1
 * @return true if the CPU is currently running with user permissions
 */
static inline bool _is_user_context(void)
{
#ifdef CONFIG_USERSPACE
	return arch_is_user_context();
     b08:	f004 fe91 	bl	582e <arch_is_user_context>
	if (_is_user_context()) {
     b0c:	b188      	cbz	r0, b32 <vprintk+0x32>
		struct buf_out_context ctx = { 0 };
     b0e:	2228      	movs	r2, #40	; 0x28
     b10:	2100      	movs	r1, #0
     b12:	4668      	mov	r0, sp
     b14:	f005 fb5b 	bl	61ce <memset>
		z_vprintk(buf_char_out, &ctx, fmt, ap);
     b18:	462b      	mov	r3, r5
     b1a:	480a      	ldr	r0, [pc, #40]	; (b44 <vprintk+0x44>)
     b1c:	4622      	mov	r2, r4
     b1e:	4669      	mov	r1, sp
     b20:	f7ff fec2 	bl	8a8 <z_vprintk>
		if (ctx.buf_count) {
     b24:	9b01      	ldr	r3, [sp, #4]
     b26:	b113      	cbz	r3, b2e <vprintk+0x2e>
			buf_flush(&ctx);
     b28:	4668      	mov	r0, sp
     b2a:	f004 fe8c 	bl	5846 <buf_flush>
}
     b2e:	b00b      	add	sp, #44	; 0x2c
     b30:	bd30      	pop	{r4, r5, pc}
		struct out_context ctx = { 0 };
     b32:	9000      	str	r0, [sp, #0]
		z_vprintk(char_out, &ctx, fmt, ap);
     b34:	460b      	mov	r3, r1
     b36:	4804      	ldr	r0, [pc, #16]	; (b48 <vprintk+0x48>)
     b38:	4622      	mov	r2, r4
     b3a:	4669      	mov	r1, sp
     b3c:	f7ff feb4 	bl	8a8 <z_vprintk>
}
     b40:	e7f5      	b.n	b2e <vprintk+0x2e>
     b42:	bf00      	nop
     b44:	0000586f 	.word	0x0000586f
     b48:	0000088d 	.word	0x0000088d

00000b4c <z_mrsh_k_str_out>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_str_out(char * c, size_t n);
uintptr_t z_mrsh_k_str_out(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     b4c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
     b4e:	4d0e      	ldr	r5, [pc, #56]	; (b88 <z_mrsh_k_str_out+0x3c>)
     b50:	9a08      	ldr	r2, [sp, #32]
     b52:	68ab      	ldr	r3, [r5, #8]
     b54:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_str_out(char *c, size_t n)
{
	Z_OOPS(Z_SYSCALL_MEMORY_READ(c, n));
     b58:	2200      	movs	r2, #0
{
     b5a:	4606      	mov	r6, r0
     b5c:	460f      	mov	r7, r1
     b5e:	f005 fae9 	bl	6134 <arch_buffer_validate>
     b62:	4604      	mov	r4, r0
     b64:	b130      	cbz	r0, b74 <z_mrsh_k_str_out+0x28>
     b66:	f004 fe62 	bl	582e <arch_is_user_context>
     b6a:	68ab      	ldr	r3, [r5, #8]
     b6c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
     b70:	f005 fab2 	bl	60d8 <arch_syscall_oops>
	z_impl_k_str_out((char *)c, n);
     b74:	4630      	mov	r0, r6
     b76:	4639      	mov	r1, r7
     b78:	f7ff ffb4 	bl	ae4 <z_impl_k_str_out>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_str_out(*(char **)&arg0, *(size_t*)&arg1)
;
	_current->syscall_frame = NULL;
     b7c:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
     b7e:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
     b80:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
     b84:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
     b86:	bf00      	nop
     b88:	20000eec 	.word	0x20000eec

00000b8c <process_event>:
 * regions.
 */
static void process_event(struct onoff_manager *mgr,
			  int evt,
			  k_spinlock_key_t key)
{
     b8c:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	sys_slist_t clients;
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     b90:	f8b0 9018 	ldrh.w	r9, [r0, #24]
	__ASSERT_NO_MSG(evt != EVT_NOP);

	/* If this is a nested call record the event for processing in
	 * the top invocation.
	 */
	if (processing) {
     b94:	f019 0808 	ands.w	r8, r9, #8
{
     b98:	4604      	mov	r4, r0
	if (processing) {
     b9a:	d00d      	beq.n	bb8 <process_event+0x2c>
		if (evt == EVT_COMPLETE) {
     b9c:	2901      	cmp	r1, #1
			mgr->flags |= ONOFF_FLAG_COMPLETE;
     b9e:	bf0c      	ite	eq
     ba0:	f049 0910 	orreq.w	r9, r9, #16
		} else {
			__ASSERT_NO_MSG(evt == EVT_RECHECK);

			mgr->flags |= ONOFF_FLAG_RECHECK;
     ba4:	f049 0920 	orrne.w	r9, r9, #32
     ba8:	f8a0 9018 	strh.w	r9, [r0, #24]
	__asm__ volatile(
		"cpsie i;"
		"isb"
		: : : "memory");
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__asm__ volatile(
     bac:	f382 8811 	msr	BASEPRI, r2
     bb0:	f3bf 8f6f 	isb	sy
		state = mgr->flags & ONOFF_STATE_MASK;
	} while (evt != EVT_NOP);

out:
	k_spin_unlock(&mgr->lock, key);
}
     bb4:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     bb8:	f009 0907 	and.w	r9, r9, #7
		if (evt == EVT_RECHECK) {
     bbc:	2902      	cmp	r1, #2
     bbe:	d107      	bne.n	bd0 <process_event+0x44>
			evt = process_recheck(mgr);
     bc0:	4620      	mov	r0, r4
     bc2:	f004 fe72 	bl	58aa <process_recheck>
		if (evt == EVT_NOP) {
     bc6:	2800      	cmp	r0, #0
     bc8:	d0f0      	beq.n	bac <process_event+0x20>
		if (evt == EVT_COMPLETE) {
     bca:	2801      	cmp	r0, #1
     bcc:	8b23      	ldrh	r3, [r4, #24]
     bce:	d150      	bne.n	c72 <process_event+0xe6>
			res = mgr->last_res;
     bd0:	6967      	ldr	r7, [r4, #20]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     bd2:	8b21      	ldrh	r1, [r4, #24]
	if (res < 0) {
     bd4:	2f00      	cmp	r7, #0
     bd6:	da15      	bge.n	c04 <process_event+0x78>
		*clients = mgr->clients;
     bd8:	6825      	ldr	r5, [r4, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     bda:	f021 0107 	bic.w	r1, r1, #7
 * @param list A pointer on the list to initialize
 */
static inline void sys_slist_init(sys_slist_t *list)
{
	list->head = NULL;
	list->tail = NULL;
     bde:	e9c4 8800 	strd	r8, r8, [r4]
     be2:	f041 0101 	orr.w	r1, r1, #1
	mgr->flags = (state & ONOFF_STATE_MASK)
     be6:	8321      	strh	r1, [r4, #24]
		onoff_transition_fn transit = NULL;
     be8:	2600      	movs	r6, #0
		bool do_monitors = (state != (mgr->flags & ONOFF_STATE_MASK))
     bea:	8b21      	ldrh	r1, [r4, #24]
     bec:	f001 0a07 	and.w	sl, r1, #7
				   && !sys_slist_is_empty(&mgr->monitors);
     bf0:	45ca      	cmp	sl, r9
     bf2:	d002      	beq.n	bfa <process_event+0x6e>
		if (do_monitors
     bf4:	68a3      	ldr	r3, [r4, #8]
     bf6:	2b00      	cmp	r3, #0
     bf8:	d15c      	bne.n	cb4 <process_event+0x128>
		    || !sys_slist_is_empty(&clients)
     bfa:	b90d      	cbnz	r5, c00 <process_event+0x74>
		    || (transit != NULL)) {
     bfc:	2e00      	cmp	r6, #0
     bfe:	d074      	beq.n	cea <process_event+0x15e>
     c00:	2300      	movs	r3, #0
     c02:	e058      	b.n	cb6 <process_event+0x12a>
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     c04:	f001 0307 	and.w	r3, r1, #7
		   || (state == ONOFF_STATE_RESETTING)) {
     c08:	1f58      	subs	r0, r3, #5
	} else if ((state == ONOFF_STATE_TO_ON)
     c0a:	2801      	cmp	r0, #1
     c0c:	d820      	bhi.n	c50 <process_event+0xc4>
		*clients = mgr->clients;
     c0e:	f021 0107 	bic.w	r1, r1, #7
		if (state == ONOFF_STATE_TO_ON) {
     c12:	2b06      	cmp	r3, #6
		*clients = mgr->clients;
     c14:	6825      	ldr	r5, [r4, #0]
	list->head = NULL;
     c16:	b289      	uxth	r1, r1
	list->tail = NULL;
     c18:	e9c4 8800 	strd	r8, r8, [r4]
		if (state == ONOFF_STATE_TO_ON) {
     c1c:	d10c      	bne.n	c38 <process_event+0xac>
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
     c1e:	2d00      	cmp	r5, #0
     c20:	462b      	mov	r3, r5
     c22:	bf38      	it	cc
     c24:	2300      	movcc	r3, #0
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
     c26:	b12b      	cbz	r3, c34 <process_event+0xa8>
				mgr->refs += 1U;
     c28:	8b60      	ldrh	r0, [r4, #26]
 *
 * @return a pointer on the next node (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_next_no_check(sys_snode_t *node);

Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
     c2a:	681b      	ldr	r3, [r3, #0]
     c2c:	3001      	adds	r0, #1
     c2e:	8360      	strh	r0, [r4, #26]
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
     c30:	2b00      	cmp	r3, #0
     c32:	d1f8      	bne.n	c26 <process_event+0x9a>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c34:	f041 0102 	orr.w	r1, r1, #2
	mgr->flags = (state & ONOFF_STATE_MASK)
     c38:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
     c3a:	4620      	mov	r0, r4
     c3c:	f004 fe35 	bl	58aa <process_recheck>
     c40:	4606      	mov	r6, r0
     c42:	2800      	cmp	r0, #0
     c44:	d0d1      	beq.n	bea <process_event+0x5e>
			mgr->flags |= ONOFF_FLAG_RECHECK;
     c46:	8b23      	ldrh	r3, [r4, #24]
     c48:	f043 0320 	orr.w	r3, r3, #32
     c4c:	8323      	strh	r3, [r4, #24]
     c4e:	e7cb      	b.n	be8 <process_event+0x5c>
	} else if (state == ONOFF_STATE_TO_OFF) {
     c50:	2b04      	cmp	r3, #4
     c52:	d10c      	bne.n	c6e <process_event+0xe2>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c54:	f021 0107 	bic.w	r1, r1, #7
     c58:	b289      	uxth	r1, r1
	mgr->flags = (state & ONOFF_STATE_MASK)
     c5a:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
     c5c:	4620      	mov	r0, r4
     c5e:	f004 fe24 	bl	58aa <process_recheck>
     c62:	4605      	mov	r5, r0
     c64:	2800      	cmp	r0, #0
     c66:	d0bf      	beq.n	be8 <process_event+0x5c>
			mgr->flags |= ONOFF_FLAG_RECHECK;
     c68:	f041 0120 	orr.w	r1, r1, #32
     c6c:	8321      	strh	r1, [r4, #24]
     c6e:	2500      	movs	r5, #0
     c70:	e7ba      	b.n	be8 <process_event+0x5c>
		} else if (evt == EVT_START) {
     c72:	2803      	cmp	r0, #3
     c74:	d109      	bne.n	c8a <process_event+0xfe>
			transit = mgr->transitions->start;
     c76:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c78:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->start;
     c7c:	680e      	ldr	r6, [r1, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c7e:	f043 0306 	orr.w	r3, r3, #6
	mgr->flags = (state & ONOFF_STATE_MASK)
     c82:	8323      	strh	r3, [r4, #24]
}
     c84:	2500      	movs	r5, #0
		res = 0;
     c86:	462f      	mov	r7, r5
     c88:	e7af      	b.n	bea <process_event+0x5e>
		} else if (evt == EVT_STOP) {
     c8a:	2804      	cmp	r0, #4
     c8c:	d106      	bne.n	c9c <process_event+0x110>
			transit = mgr->transitions->stop;
     c8e:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c90:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->stop;
     c94:	684e      	ldr	r6, [r1, #4]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c96:	f043 0304 	orr.w	r3, r3, #4
     c9a:	e7f2      	b.n	c82 <process_event+0xf6>
		} else if (evt == EVT_RESET) {
     c9c:	2805      	cmp	r0, #5
     c9e:	d106      	bne.n	cae <process_event+0x122>
			transit = mgr->transitions->reset;
     ca0:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     ca2:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->reset;
     ca6:	688e      	ldr	r6, [r1, #8]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     ca8:	f043 0305 	orr.w	r3, r3, #5
     cac:	e7e9      	b.n	c82 <process_event+0xf6>
     cae:	2500      	movs	r5, #0
		onoff_transition_fn transit = NULL;
     cb0:	462e      	mov	r6, r5
     cb2:	e7e8      	b.n	c86 <process_event+0xfa>
				   && !sys_slist_is_empty(&mgr->monitors);
     cb4:	2301      	movs	r3, #1
			uint32_t flags = mgr->flags | ONOFF_FLAG_PROCESSING;
     cb6:	f041 0108 	orr.w	r1, r1, #8
			mgr->flags = flags;
     cba:	8321      	strh	r1, [r4, #24]
     cbc:	f382 8811 	msr	BASEPRI, r2
     cc0:	f3bf 8f6f 	isb	sy
			if (do_monitors) {
     cc4:	bb03      	cbnz	r3, d08 <process_event+0x17c>
			if (!sys_slist_is_empty(&clients)) {
     cc6:	2d00      	cmp	r5, #0
     cc8:	d140      	bne.n	d4c <process_event+0x1c0>
			if (transit != NULL) {
     cca:	b116      	cbz	r6, cd2 <process_event+0x146>
				transit(mgr, transition_complete);
     ccc:	4925      	ldr	r1, [pc, #148]	; (d64 <process_event+0x1d8>)
     cce:	4620      	mov	r0, r4
     cd0:	47b0      	blx	r6
	__asm__ volatile(
     cd2:	f04f 0320 	mov.w	r3, #32
     cd6:	f3ef 8211 	mrs	r2, BASEPRI
     cda:	f383 8811 	msr	BASEPRI, r3
     cde:	f3bf 8f6f 	isb	sy
			mgr->flags &= ~ONOFF_FLAG_PROCESSING;
     ce2:	8b23      	ldrh	r3, [r4, #24]
     ce4:	f023 0308 	bic.w	r3, r3, #8
     ce8:	8323      	strh	r3, [r4, #24]
		if ((mgr->flags & ONOFF_FLAG_COMPLETE) != 0) {
     cea:	8b23      	ldrh	r3, [r4, #24]
     cec:	06d9      	lsls	r1, r3, #27
     cee:	d531      	bpl.n	d54 <process_event+0x1c8>
			mgr->flags &= ~ONOFF_FLAG_COMPLETE;
     cf0:	f023 0310 	bic.w	r3, r3, #16
     cf4:	8323      	strh	r3, [r4, #24]
			evt = EVT_COMPLETE;
     cf6:	2101      	movs	r1, #1
		state = mgr->flags & ONOFF_STATE_MASK;
     cf8:	f8b4 9018 	ldrh.w	r9, [r4, #24]
     cfc:	f009 0907 	and.w	r9, r9, #7
	} while (evt != EVT_NOP);
     d00:	2900      	cmp	r1, #0
     d02:	f47f af5b 	bne.w	bbc <process_event+0x30>
out:
     d06:	e751      	b.n	bac <process_event+0x20>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
     d08:	68a1      	ldr	r1, [r4, #8]
     d0a:	2900      	cmp	r1, #0
     d0c:	d0db      	beq.n	cc6 <process_event+0x13a>
	return node->next;
     d0e:	680b      	ldr	r3, [r1, #0]
		mon->callback(mgr, mon, state, res);
     d10:	f8d1 b004 	ldr.w	fp, [r1, #4]
     d14:	2b00      	cmp	r3, #0
     d16:	bf38      	it	cc
     d18:	2300      	movcc	r3, #0
     d1a:	4699      	mov	r9, r3
     d1c:	4652      	mov	r2, sl
     d1e:	463b      	mov	r3, r7
     d20:	4620      	mov	r0, r4
     d22:	47d8      	blx	fp
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
     d24:	f1b9 0f00 	cmp.w	r9, #0
     d28:	d0cd      	beq.n	cc6 <process_event+0x13a>
     d2a:	f8d9 3000 	ldr.w	r3, [r9]
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
     d2e:	4649      	mov	r1, r9
     d30:	e7ee      	b.n	d10 <process_event+0x184>
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
     d32:	4639      	mov	r1, r7
     d34:	f10b 0004 	add.w	r0, fp, #4
 *
 * @return A pointer to the first node of the list
 */
static inline sys_snode_t *sys_slist_get_not_empty(sys_slist_t *list);

Z_GENLIST_GET_NOT_EMPTY(slist, snode)
     d38:	682d      	ldr	r5, [r5, #0]
     d3a:	f004 fd6b 	bl	5814 <sys_notify_finalize>
	if (cb) {
     d3e:	4681      	mov	r9, r0
     d40:	b120      	cbz	r0, d4c <process_event+0x1c0>
		cb(mgr, cli, state, res);
     d42:	463b      	mov	r3, r7
     d44:	4652      	mov	r2, sl
     d46:	4659      	mov	r1, fp
     d48:	4620      	mov	r0, r4
     d4a:	47c8      	blx	r9
     d4c:	46ab      	mov	fp, r5
	while (!sys_slist_is_empty(list)) {
     d4e:	2d00      	cmp	r5, #0
     d50:	d1ef      	bne.n	d32 <process_event+0x1a6>
     d52:	e7ba      	b.n	cca <process_event+0x13e>
		} else if ((mgr->flags & ONOFF_FLAG_RECHECK) != 0) {
     d54:	f013 0120 	ands.w	r1, r3, #32
			mgr->flags &= ~ONOFF_FLAG_RECHECK;
     d58:	bf1e      	ittt	ne
     d5a:	f023 0320 	bicne.w	r3, r3, #32
     d5e:	8323      	strhne	r3, [r4, #24]
			evt = EVT_RECHECK;
     d60:	2102      	movne	r1, #2
     d62:	e7c9      	b.n	cf8 <process_event+0x16c>
     d64:	00005901 	.word	0x00005901

00000d68 <z_mrsh_z_sys_mutex_kernel_lock>:
#include <syscalls/mutex.h>

extern int z_vrfy_z_sys_mutex_kernel_lock(struct sys_mutex * mutex, k_timeout_t timeout);
uintptr_t z_mrsh_z_sys_mutex_kernel_lock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     d68:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
     d6a:	4c0e      	ldr	r4, [pc, #56]	; (da4 <z_mrsh_z_sys_mutex_kernel_lock+0x3c>)
     d6c:	68a3      	ldr	r3, [r4, #8]
{
     d6e:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
     d70:	9a08      	ldr	r2, [sp, #32]
     d72:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
     d76:	460f      	mov	r7, r1
{
	/* sys_mutex memory is never touched, just used to lookup the
	 * underlying k_mutex, but we don't want threads using mutexes
	 * that are outside their memory domain
	 */
	return Z_SYSCALL_MEMORY_WRITE(addr, sizeof(struct sys_mutex));
     d78:	2201      	movs	r2, #1
     d7a:	2104      	movs	r1, #4
     d7c:	4605      	mov	r5, r0
     d7e:	f005 f9d9 	bl	6134 <arch_buffer_validate>
     d82:	b140      	cbz	r0, d96 <z_mrsh_z_sys_mutex_kernel_lock+0x2e>
     d84:	f005 f87c 	bl	5e80 <arch_is_user_context>

static inline int z_vrfy_z_sys_mutex_kernel_lock(struct sys_mutex *mutex,
						 k_timeout_t timeout)
{
	if (check_sys_mutex_addr(mutex)) {
		return -EACCES;
     d88:	f06f 000c 	mvn.w	r0, #12
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_z_sys_mutex_kernel_lock(*(struct sys_mutex **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
     d8c:	68a3      	ldr	r3, [r4, #8]
     d8e:	2200      	movs	r2, #0
     d90:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
     d94:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	}

	return z_impl_z_sys_mutex_kernel_lock(mutex, timeout);
     d96:	463a      	mov	r2, r7
     d98:	4633      	mov	r3, r6
     d9a:	4628      	mov	r0, r5
     d9c:	f005 f87a 	bl	5e94 <z_impl_z_sys_mutex_kernel_lock>
     da0:	e7f4      	b.n	d8c <z_mrsh_z_sys_mutex_kernel_lock+0x24>
     da2:	bf00      	nop
     da4:	20000eec 	.word	0x20000eec

00000da8 <z_impl_z_sys_mutex_kernel_unlock>:
}
#include <syscalls/z_sys_mutex_kernel_lock_mrsh.c>

int z_impl_z_sys_mutex_kernel_unlock(struct sys_mutex *mutex)
{
     da8:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	obj = z_object_find(mutex);
     dac:	f7ff f996 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_SYS_MUTEX) {
     db0:	b1c0      	cbz	r0, de4 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
     db2:	7983      	ldrb	r3, [r0, #6]
     db4:	2b0e      	cmp	r3, #14
     db6:	d115      	bne.n	de4 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
	return obj->data.mutex;
     db8:	6882      	ldr	r2, [r0, #8]
	struct k_mutex *kernel_mutex = get_k_mutex(mutex);

	if (kernel_mutex == NULL || kernel_mutex->lock_count == 0) {
     dba:	b19a      	cbz	r2, de4 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
     dbc:	68d3      	ldr	r3, [r2, #12]
     dbe:	b18b      	cbz	r3, de4 <z_impl_z_sys_mutex_kernel_unlock+0x3c>
		return -EINVAL;
	}

	if (kernel_mutex->owner != _current) {
     dc0:	4b0b      	ldr	r3, [pc, #44]	; (df0 <z_impl_z_sys_mutex_kernel_unlock+0x48>)
     dc2:	6891      	ldr	r1, [r2, #8]
     dc4:	689b      	ldr	r3, [r3, #8]
     dc6:	4299      	cmp	r1, r3
     dc8:	d10f      	bne.n	dea <z_impl_z_sys_mutex_kernel_unlock+0x42>
	ret = arch_is_user_context();
     dca:	f005 f859 	bl	5e80 <arch_is_user_context>
	if (z_syscall_trap()) {
     dce:	b128      	cbz	r0, ddc <z_impl_z_sys_mutex_kernel_unlock+0x34>
	register uint32_t ret __asm__("r0") = arg1;
     dd0:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
     dd2:	266d      	movs	r6, #109	; 0x6d
	__asm__ volatile("svc %[svid]\n"
     dd4:	df03      	svc	3
		return -EPERM;
	}

	k_mutex_unlock(kernel_mutex);
	return 0;
     dd6:	2000      	movs	r0, #0
}
     dd8:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return z_impl_k_mutex_unlock(mutex);
     ddc:	4610      	mov	r0, r2
     dde:	f002 fb87 	bl	34f0 <z_impl_k_mutex_unlock>
     de2:	e7f8      	b.n	dd6 <z_impl_z_sys_mutex_kernel_unlock+0x2e>
		return -EINVAL;
     de4:	f06f 0015 	mvn.w	r0, #21
     de8:	e7f6      	b.n	dd8 <z_impl_z_sys_mutex_kernel_unlock+0x30>
		return -EPERM;
     dea:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
     dee:	e7f3      	b.n	dd8 <z_impl_z_sys_mutex_kernel_unlock+0x30>
     df0:	20000eec 	.word	0x20000eec

00000df4 <z_mrsh_z_sys_mutex_kernel_unlock>:
#include <syscalls/mutex.h>

extern int z_vrfy_z_sys_mutex_kernel_unlock(struct sys_mutex * mutex);
uintptr_t z_mrsh_z_sys_mutex_kernel_unlock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     df4:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
     df6:	4c0c      	ldr	r4, [pc, #48]	; (e28 <z_mrsh_z_sys_mutex_kernel_unlock+0x34>)
     df8:	9a06      	ldr	r2, [sp, #24]
     dfa:	68a3      	ldr	r3, [r4, #8]
	return Z_SYSCALL_MEMORY_WRITE(addr, sizeof(struct sys_mutex));
     dfc:	2104      	movs	r1, #4
     dfe:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
     e02:	2201      	movs	r2, #1
{
     e04:	4605      	mov	r5, r0
     e06:	f005 f995 	bl	6134 <arch_buffer_validate>
     e0a:	b140      	cbz	r0, e1e <z_mrsh_z_sys_mutex_kernel_unlock+0x2a>
	return arch_is_user_context();
     e0c:	f005 f838 	bl	5e80 <arch_is_user_context>

static inline int z_vrfy_z_sys_mutex_kernel_unlock(struct sys_mutex *mutex)
{
	if (check_sys_mutex_addr(mutex)) {
		return -EACCES;
     e10:	f06f 000c 	mvn.w	r0, #12
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_z_sys_mutex_kernel_unlock(*(struct sys_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
     e14:	68a3      	ldr	r3, [r4, #8]
     e16:	2200      	movs	r2, #0
     e18:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
     e1c:	bd38      	pop	{r3, r4, r5, pc}
	}

	return z_impl_z_sys_mutex_kernel_unlock(mutex);
     e1e:	4628      	mov	r0, r5
     e20:	f7ff ffc2 	bl	da8 <z_impl_z_sys_mutex_kernel_unlock>
     e24:	e7f6      	b.n	e14 <z_mrsh_z_sys_mutex_kernel_unlock+0x20>
     e26:	bf00      	nop
     e28:	20000eec 	.word	0x20000eec

00000e2c <console_out>:
		return c;
	}

#endif  /* CONFIG_UART_CONSOLE_DEBUG_SERVER_HOOKS */

	if ('\n' == c) {
     e2c:	280a      	cmp	r0, #10
{
     e2e:	b538      	push	{r3, r4, r5, lr}
     e30:	4d06      	ldr	r5, [pc, #24]	; (e4c <console_out+0x20>)
     e32:	4604      	mov	r4, r0
	if ('\n' == c) {
     e34:	d103      	bne.n	e3e <console_out+0x12>
		uart_poll_out(uart_console_dev, '\r');
     e36:	6828      	ldr	r0, [r5, #0]
     e38:	210d      	movs	r1, #13
     e3a:	f005 f84c 	bl	5ed6 <uart_poll_out>
	}
	uart_poll_out(uart_console_dev, c);
     e3e:	6828      	ldr	r0, [r5, #0]
     e40:	b2e1      	uxtb	r1, r4
     e42:	f005 f848 	bl	5ed6 <uart_poll_out>

	return c;
}
     e46:	4620      	mov	r0, r4
     e48:	bd38      	pop	{r3, r4, r5, pc}
     e4a:	bf00      	nop
     e4c:	20000474 	.word	0x20000474

00000e50 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(struct device *arg)
{
     e50:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
static inline bool arch_is_user_context(void)
{
	uint32_t value;

	/* check for handler mode */
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
     e54:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
     e58:	b98b      	cbnz	r3, e7e <uart_console_init+0x2e>
		return false;
	}

	/* if not handler mode, return mode information */
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
     e5a:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
     e5e:	07db      	lsls	r3, r3, #31
     e60:	d50d      	bpl.n	e7e <uart_console_init+0x2e>
	register uint32_t ret __asm__("r0") = arg1;
     e62:	4809      	ldr	r0, [pc, #36]	; (e88 <uart_console_init+0x38>)
	register uint32_t r6 __asm__("r6") = call_id;
     e64:	2627      	movs	r6, #39	; 0x27
	__asm__ volatile("svc %[svid]\n"
     e66:	df03      	svc	3

	ARG_UNUSED(arg);

	uart_console_dev = device_get_binding(CONFIG_UART_CONSOLE_ON_DEV_NAME);
     e68:	4b08      	ldr	r3, [pc, #32]	; (e8c <uart_console_init+0x3c>)
     e6a:	6018      	str	r0, [r3, #0]
	__stdout_hook_install(console_out);
     e6c:	4808      	ldr	r0, [pc, #32]	; (e90 <uart_console_init+0x40>)
     e6e:	f001 f855 	bl	1f1c <__stdout_hook_install>
	__printk_hook_install(console_out);
     e72:	4807      	ldr	r0, [pc, #28]	; (e90 <uart_console_init+0x40>)
     e74:	f7ff fd12 	bl	89c <__printk_hook_install>
#endif

	uart_console_hook_install();

	return 0;
}
     e78:	2000      	movs	r0, #0
     e7a:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	return z_impl_device_get_binding(name);
     e7e:	4802      	ldr	r0, [pc, #8]	; (e88 <uart_console_init+0x38>)
     e80:	f001 fff6 	bl	2e70 <z_impl_device_get_binding>
     e84:	e7f0      	b.n	e68 <uart_console_init+0x18>
     e86:	bf00      	nop
     e88:	0000788e 	.word	0x0000788e
     e8c:	20000474 	.word	0x20000474
     e90:	00000e2d 	.word	0x00000e2d

00000e94 <onoff_stop>:
	return (clock_control_subsys_t)offset;
}

static void onoff_stop(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
     e94:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	struct nrf_clock_control_data *data =
     e98:	4f0e      	ldr	r7, [pc, #56]	; (ed4 <onoff_stop+0x40>)
     e9a:	68fa      	ldr	r2, [r7, #12]
	size_t offset = (size_t)(mgr - data->mgr);
     e9c:	1a84      	subs	r4, r0, r2
     e9e:	10a3      	asrs	r3, r4, #2
     ea0:	4c0d      	ldr	r4, [pc, #52]	; (ed8 <onoff_stop+0x44>)
     ea2:	435c      	muls	r4, r3
{
     ea4:	4605      	mov	r5, r0
     ea6:	b2e4      	uxtb	r4, r4
	err = set_off_state(&subdata->flags, ctx);
     ea8:	200c      	movs	r0, #12
     eaa:	fb00 2004 	mla	r0, r0, r4, r2
{
     eae:	460e      	mov	r6, r1
	err = set_off_state(&subdata->flags, ctx);
     eb0:	2140      	movs	r1, #64	; 0x40
     eb2:	4408      	add	r0, r1
     eb4:	f005 f83c 	bl	5f30 <set_off_state>
	if (err < 0) {
     eb8:	1e01      	subs	r1, r0, #0
     eba:	db05      	blt.n	ec8 <onoff_stop+0x34>
	get_sub_config(dev, type)->stop();
     ebc:	687b      	ldr	r3, [r7, #4]
     ebe:	eb03 04c4 	add.w	r4, r3, r4, lsl #3
     ec2:	6863      	ldr	r3, [r4, #4]
     ec4:	4798      	blx	r3
	return 0;
     ec6:	2100      	movs	r1, #0
	int res;

	res = stop(DEVICE_GET(clock_nrf), get_subsys(mgr), CTX_ONOFF);
	notify(mgr, res);
     ec8:	4628      	mov	r0, r5
     eca:	4633      	mov	r3, r6
}
     ecc:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	notify(mgr, res);
     ed0:	4718      	bx	r3
     ed2:	bf00      	nop
     ed4:	20003420 	.word	0x20003420
     ed8:	b6db6db7 	.word	0xb6db6db7

00000edc <onoff_start>:
	notify(mgr, 0);
}

static void onoff_start(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
     edc:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	struct nrf_clock_control_data *data =
     ee0:	f8df 8050 	ldr.w	r8, [pc, #80]	; f34 <onoff_start+0x58>
     ee4:	f8d8 600c 	ldr.w	r6, [r8, #12]
	size_t offset = (size_t)(mgr - data->mgr);
     ee8:	1b84      	subs	r4, r0, r6
     eea:	10a3      	asrs	r3, r4, #2
     eec:	4c0f      	ldr	r4, [pc, #60]	; (f2c <onoff_start+0x50>)
     eee:	435c      	muls	r4, r3
     ef0:	b2e4      	uxtb	r4, r4
	err = set_starting_state(&subdata->flags, ctx);
     ef2:	250c      	movs	r5, #12
     ef4:	4365      	muls	r5, r4
{
     ef6:	4681      	mov	r9, r0
	err = set_starting_state(&subdata->flags, ctx);
     ef8:	f105 0040 	add.w	r0, r5, #64	; 0x40
{
     efc:	460f      	mov	r7, r1
	err = set_starting_state(&subdata->flags, ctx);
     efe:	4430      	add	r0, r6
     f00:	2140      	movs	r1, #64	; 0x40
     f02:	f005 f82e 	bl	5f62 <set_starting_state>
	if (err < 0) {
     f06:	1e01      	subs	r1, r0, #0
     f08:	db0a      	blt.n	f20 <onoff_start+0x44>
	subdata->cb = data->cb;
     f0a:	4a09      	ldr	r2, [pc, #36]	; (f30 <onoff_start+0x54>)
     f0c:	1973      	adds	r3, r6, r5
	subdata->user_data = data->user_data;
     f0e:	e9c3 270e 	strd	r2, r7, [r3, #56]	; 0x38
	 get_sub_config(dev, type)->start();
     f12:	f8d8 3004 	ldr.w	r3, [r8, #4]
     f16:	f853 3034 	ldr.w	r3, [r3, r4, lsl #3]
	err = async_start(DEVICE_GET(clock_nrf), get_subsys(mgr),
			  &data, CTX_ONOFF);
	if (err < 0) {
		notify(mgr, err);
	}
}
     f1a:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	 get_sub_config(dev, type)->start();
     f1e:	4718      	bx	r3
		notify(mgr, err);
     f20:	4648      	mov	r0, r9
     f22:	463b      	mov	r3, r7
}
     f24:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
		notify(mgr, err);
     f28:	4718      	bx	r3
     f2a:	bf00      	nop
     f2c:	b6db6db7 	.word	0xb6db6db7
     f30:	00005fc5 	.word	0x00005fc5
     f34:	20003420 	.word	0x20003420

00000f38 <clk_init>:
	static const struct onoff_transitions transitions = {
		.start = onoff_start,
		.stop = onoff_stop
	};

	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
     f38:	2200      	movs	r2, #0
{
     f3a:	b570      	push	{r4, r5, r6, lr}
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
     f3c:	2101      	movs	r1, #1
{
     f3e:	4604      	mov	r4, r0
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
     f40:	4610      	mov	r0, r2
     f42:	f000 fafb 	bl	153c <z_arm_irq_priority_set>
		    nrf_power_clock_isr, 0, 0);

	irq_enable(DT_INST_IRQN(0));
     f46:	2000      	movs	r0, #0
     f48:	f000 fae8 	bl	151c <arch_irq_enable>
    return false;
}

NRF_STATIC_INLINE void nrf_clock_lf_src_set(NRF_CLOCK_Type * p_reg, nrf_clock_lfclk_t source)
{
    p_reg->LFCLKSRC = (uint32_t)(source);
     f4c:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
	clock_irqs_enable();

	for (enum clock_control_nrf_type i = 0;
		i < CLOCK_CONTROL_NRF_TYPE_COUNT; i++) {
		struct nrf_clock_control_sub_data *subdata =
						get_sub_data(dev, i);
     f50:	68e6      	ldr	r6, [r4, #12]

		err = onoff_manager_init(get_onoff_manager(dev, i),
     f52:	490c      	ldr	r1, [pc, #48]	; (f84 <clk_init+0x4c>)
    p_reg->INTENSET = mask;
     f54:	2203      	movs	r2, #3
    p_reg->LFCLKSRC = (uint32_t)(source);
     f56:	2501      	movs	r5, #1
     f58:	f8c3 5518 	str.w	r5, [r3, #1304]	; 0x518
     f5c:	4630      	mov	r0, r6
    p_reg->INTENSET = mask;
     f5e:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
     f62:	f004 fcdb 	bl	591c <onoff_manager_init>
					 &transitions);
		if (err < 0) {
     f66:	2800      	cmp	r0, #0
     f68:	db0a      	blt.n	f80 <clk_init+0x48>
			return err;
		}

		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
     f6a:	6435      	str	r5, [r6, #64]	; 0x40
						get_sub_data(dev, i);
     f6c:	68e4      	ldr	r4, [r4, #12]
		err = onoff_manager_init(get_onoff_manager(dev, i),
     f6e:	4905      	ldr	r1, [pc, #20]	; (f84 <clk_init+0x4c>)
     f70:	f104 001c 	add.w	r0, r4, #28
     f74:	f004 fcd2 	bl	591c <onoff_manager_init>
		if (err < 0) {
     f78:	2800      	cmp	r0, #0
		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
     f7a:	bfa4      	itt	ge
     f7c:	64e5      	strge	r5, [r4, #76]	; 0x4c
	}

	return 0;
     f7e:	2000      	movge	r0, #0
}
     f80:	bd70      	pop	{r4, r5, r6, pc}
     f82:	bf00      	nop
     f84:	000072dc 	.word	0x000072dc

00000f88 <clkstarted_handle.constprop.0>:
static void clkstarted_handle(struct device *dev,
     f88:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	struct nrf_clock_control_sub_data *sub_data = get_sub_data(dev, type);
     f8c:	4e0b      	ldr	r6, [pc, #44]	; (fbc <clkstarted_handle.constprop.0+0x34>)
static void clkstarted_handle(struct device *dev,
     f8e:	4601      	mov	r1, r0
	clock_control_cb_t callback = sub_data->cb;
     f90:	230c      	movs	r3, #12
	struct nrf_clock_control_sub_data *sub_data = get_sub_data(dev, type);
     f92:	68f0      	ldr	r0, [r6, #12]
	clock_control_cb_t callback = sub_data->cb;
     f94:	434b      	muls	r3, r1
     f96:	18c4      	adds	r4, r0, r3
	void *user_data = sub_data->user_data;
     f98:	e9d4 570e 	ldrd	r5, r7, [r4, #56]	; 0x38
	sub_data->cb = NULL;
     f9c:	2200      	movs	r2, #0
	set_on_state(&sub_data->flags);
     f9e:	3340      	adds	r3, #64	; 0x40
	sub_data->cb = NULL;
     fa0:	63a2      	str	r2, [r4, #56]	; 0x38
	set_on_state(&sub_data->flags);
     fa2:	4418      	add	r0, r3
     fa4:	f004 fffb 	bl	5f9e <set_on_state>
	if (callback) {
     fa8:	b12d      	cbz	r5, fb6 <clkstarted_handle.constprop.0+0x2e>
		callback(dev, (clock_control_subsys_t)type, user_data);
     faa:	463a      	mov	r2, r7
     fac:	4630      	mov	r0, r6
     fae:	462b      	mov	r3, r5
}
     fb0:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		callback(dev, (clock_control_subsys_t)type, user_data);
     fb4:	4718      	bx	r3
}
     fb6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
     fba:	bf00      	nop
     fbc:	20003420 	.word	0x20003420

00000fc0 <generic_hfclk_start>:
{
     fc0:	b508      	push	{r3, lr}
     fc2:	f04f 0320 	mov.w	r3, #32
     fc6:	f3ef 8111 	mrs	r1, BASEPRI
     fca:	f383 8811 	msr	BASEPRI, r3
     fce:	f3bf 8f6f 	isb	sy
	hfclk_users |= HF_USER_GENERIC;
     fd2:	4a13      	ldr	r2, [pc, #76]	; (1020 <generic_hfclk_start+0x60>)
     fd4:	6813      	ldr	r3, [r2, #0]
     fd6:	f043 0002 	orr.w	r0, r3, #2
	if (hfclk_users & HF_USER_BT) {
     fda:	f013 0301 	ands.w	r3, r3, #1
	hfclk_users |= HF_USER_GENERIC;
     fde:	6010      	str	r0, [r2, #0]
	if (hfclk_users & HF_USER_BT) {
     fe0:	d00e      	beq.n	1000 <generic_hfclk_start+0x40>
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
     fe2:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
     fe6:	f8d2 340c 	ldr.w	r3, [r2, #1036]	; 0x40c
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
     fea:	f8d2 240c 	ldr.w	r2, [r2, #1036]	; 0x40c
		if (type == NRF_CLOCK_HFCLK_HIGH_ACCURACY) {
     fee:	f013 0301 	ands.w	r3, r3, #1
     ff2:	d005      	beq.n	1000 <generic_hfclk_start+0x40>
	struct nrf_clock_control_data *data =
     ff4:	4b0b      	ldr	r3, [pc, #44]	; (1024 <generic_hfclk_start+0x64>)
	return &data->subsys[CLOCK_CONTROL_NRF_TYPE_HFCLK].flags;
     ff6:	68d8      	ldr	r0, [r3, #12]
			set_on_state(get_hf_flags());
     ff8:	3040      	adds	r0, #64	; 0x40
     ffa:	f004 ffd0 	bl	5f9e <set_on_state>
			already_started = true;
     ffe:	2301      	movs	r3, #1
	__asm__ volatile(
    1000:	f381 8811 	msr	BASEPRI, r1
    1004:	f3bf 8f6f 	isb	sy
	if (already_started) {
    1008:	b123      	cbz	r3, 1014 <generic_hfclk_start+0x54>
}
    100a:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		clkstarted_handle(DEVICE_GET(clock_nrf),
    100e:	2000      	movs	r0, #0
    1010:	f7ff bfba 	b.w	f88 <clkstarted_handle.constprop.0>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    1014:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    1018:	2201      	movs	r2, #1
    101a:	601a      	str	r2, [r3, #0]
}
    101c:	bd08      	pop	{r3, pc}
    101e:	bf00      	nop
    1020:	200004d8 	.word	0x200004d8
    1024:	20003420 	.word	0x20003420

00001028 <lfclk_stop>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    1028:	4b05      	ldr	r3, [pc, #20]	; (1040 <lfclk_stop+0x18>)
    102a:	2200      	movs	r2, #0
    102c:	601a      	str	r2, [r3, #0]
{
    102e:	b082      	sub	sp, #8
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    1030:	681b      	ldr	r3, [r3, #0]
    1032:	9301      	str	r3, [sp, #4]
    (void)dummy;
    1034:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    1036:	4b03      	ldr	r3, [pc, #12]	; (1044 <lfclk_stop+0x1c>)
    1038:	2201      	movs	r2, #1
    103a:	601a      	str	r2, [r3, #0]
}
    103c:	b002      	add	sp, #8
    103e:	4770      	bx	lr
    1040:	40000104 	.word	0x40000104
    1044:	4000000c 	.word	0x4000000c

00001048 <generic_hfclk_stop>:
 * @return Previous value of @a target.
 */
#ifdef CONFIG_ATOMIC_OPERATIONS_BUILTIN
static inline atomic_val_t atomic_and(atomic_t *target, atomic_val_t value)
{
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    1048:	4a0d      	ldr	r2, [pc, #52]	; (1080 <generic_hfclk_stop+0x38>)
    104a:	f3bf 8f5b 	dmb	ish
{
    104e:	b082      	sub	sp, #8
    1050:	e852 3f00 	ldrex	r3, [r2]
    1054:	f023 0102 	bic.w	r1, r3, #2
    1058:	e842 1000 	strex	r0, r1, [r2]
    105c:	2800      	cmp	r0, #0
    105e:	d1f7      	bne.n	1050 <generic_hfclk_stop+0x8>
    1060:	f3bf 8f5b 	dmb	ish
	if (atomic_and(&hfclk_users, ~HF_USER_GENERIC) & HF_USER_BT) {
    1064:	f013 0301 	ands.w	r3, r3, #1
    1068:	d107      	bne.n	107a <generic_hfclk_stop+0x32>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    106a:	4a06      	ldr	r2, [pc, #24]	; (1084 <generic_hfclk_stop+0x3c>)
    106c:	6013      	str	r3, [r2, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    106e:	6813      	ldr	r3, [r2, #0]
    1070:	9301      	str	r3, [sp, #4]
    (void)dummy;
    1072:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    1074:	4b04      	ldr	r3, [pc, #16]	; (1088 <generic_hfclk_stop+0x40>)
    1076:	2201      	movs	r2, #1
    1078:	601a      	str	r2, [r3, #0]
}
    107a:	b002      	add	sp, #8
    107c:	4770      	bx	lr
    107e:	bf00      	nop
    1080:	200004d8 	.word	0x200004d8
    1084:	40000100 	.word	0x40000100
    1088:	40000004 	.word	0x40000004

0000108c <lfclk_start>:
{
    108c:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	if (!once) {
    1090:	4c0a      	ldr	r4, [pc, #40]	; (10bc <lfclk_start+0x30>)
    1092:	7822      	ldrb	r2, [r4, #0]
    1094:	b942      	cbnz	r2, 10a8 <lfclk_start+0x1c>
	ret = arch_is_user_context();
    1096:	f004 ff38 	bl	5f0a <arch_is_user_context>
	if (z_syscall_trap()) {
    109a:	b150      	cbz	r0, 10b2 <lfclk_start+0x26>
	register uint32_t ret __asm__("r0") = arg1;
    109c:	f44f 70a5 	mov.w	r0, #330	; 0x14a
	register uint32_t r6 __asm__("r6") = call_id;
    10a0:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    10a2:	df03      	svc	3
		once = true;
    10a4:	2301      	movs	r3, #1
    10a6:	7023      	strb	r3, [r4, #0]
    10a8:	4b05      	ldr	r3, [pc, #20]	; (10c0 <lfclk_start+0x34>)
    10aa:	2201      	movs	r2, #1
    10ac:	601a      	str	r2, [r3, #0]
}
    10ae:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	z_impl_k_busy_wait(usec_to_wait);
    10b2:	f44f 70a5 	mov.w	r0, #330	; 0x14a
    10b6:	f005 fd6f 	bl	6b98 <z_impl_k_busy_wait>
    10ba:	e7f3      	b.n	10a4 <lfclk_start+0x18>
    10bc:	20000f33 	.word	0x20000f33
    10c0:	40000008 	.word	0x40000008

000010c4 <api_blocking_start>:
{
    10c4:	e92d 4170 	stmdb	sp!, {r4, r5, r6, r8, lr}
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10c8:	2301      	movs	r3, #1
{
    10ca:	b089      	sub	sp, #36	; 0x24
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10cc:	2500      	movs	r5, #0
    10ce:	e9cd 5306 	strd	r5, r3, [sp, #24]
	struct clock_control_async_data data = {
    10d2:	4b0f      	ldr	r3, [pc, #60]	; (1110 <api_blocking_start+0x4c>)
    10d4:	9501      	str	r5, [sp, #4]
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10d6:	ac04      	add	r4, sp, #16
	err = api_start(dev, subsys, &data);
    10d8:	aa01      	add	r2, sp, #4
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10da:	e9cd 4404 	strd	r4, r4, [sp, #16]
	struct clock_control_async_data data = {
    10de:	e9cd 3402 	strd	r3, r4, [sp, #8]
	err = api_start(dev, subsys, &data);
    10e2:	f004 ffa8 	bl	6036 <api_start>
	if (err < 0) {
    10e6:	2800      	cmp	r0, #0
    10e8:	db08      	blt.n	10fc <api_blocking_start+0x38>
    10ea:	f004 ff0e 	bl	5f0a <arch_is_user_context>

extern int z_impl_k_sem_take(struct k_sem * sem, k_timeout_t timeout);
static inline int k_sem_take(struct k_sem * sem, k_timeout_t timeout)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    10ee:	b140      	cbz	r0, 1102 <api_blocking_start+0x3e>
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
		parm0.val = timeout;
		return (int) arch_syscall_invoke3(*(uintptr_t *)&sem, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_SEM_TAKE);
    10f0:	4620      	mov	r0, r4
	register uint32_t r1 __asm__("r1") = arg2;
    10f2:	f44f 4180 	mov.w	r1, #16384	; 0x4000
	register uint32_t r2 __asm__("r2") = arg3;
    10f6:	462a      	mov	r2, r5
	register uint32_t r6 __asm__("r6") = call_id;
    10f8:	2687      	movs	r6, #135	; 0x87
	__asm__ volatile("svc %[svid]\n"
    10fa:	df03      	svc	3
}
    10fc:	b009      	add	sp, #36	; 0x24
    10fe:	e8bd 8170 	ldmia.w	sp!, {r4, r5, r6, r8, pc}
	}
#endif
	compiler_barrier();
	return z_impl_k_sem_take(sem, timeout);
    1102:	f44f 4280 	mov.w	r2, #16384	; 0x4000
    1106:	2300      	movs	r3, #0
    1108:	4620      	mov	r0, r4
    110a:	f003 fc9f 	bl	4a4c <z_impl_k_sem_take>
	return k_sem_take(&sem, K_MSEC(500));
    110e:	e7f5      	b.n	10fc <api_blocking_start+0x38>
    1110:	00005fd7 	.word	0x00005fd7

00001114 <nrf_power_clock_isr>:
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    1114:	4b18      	ldr	r3, [pc, #96]	; (1178 <nrf_power_clock_isr+0x64>)
	}
#endif
}

void nrf_power_clock_isr(void *arg)
{
    1116:	b507      	push	{r0, r1, r2, lr}
    1118:	681a      	ldr	r2, [r3, #0]
	bool ret = nrf_clock_event_check(NRF_CLOCK, evt) &&
    111a:	b1b2      	cbz	r2, 114a <nrf_power_clock_isr+0x36>
    return p_reg->INTENSET & mask;
    111c:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    1120:	f8d2 2304 	ldr.w	r2, [r2, #772]	; 0x304
	if (ret) {
    1124:	07d0      	lsls	r0, r2, #31
    1126:	d510      	bpl.n	114a <nrf_power_clock_isr+0x36>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    1128:	2200      	movs	r2, #0
    112a:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    112c:	681b      	ldr	r3, [r3, #0]
    112e:	9300      	str	r3, [sp, #0]
    (void)dummy;
    1130:	9b00      	ldr	r3, [sp, #0]
	struct device *dev = DEVICE_GET(clock_nrf);

	if (clock_event_check_and_clean(NRF_CLOCK_EVENT_HFCLKSTARTED,
					NRF_CLOCK_INT_HF_STARTED_MASK)) {
		struct nrf_clock_control_sub_data *data =
				get_sub_data(dev, CLOCK_CONTROL_NRF_TYPE_HFCLK);
    1132:	4b12      	ldr	r3, [pc, #72]	; (117c <nrf_power_clock_isr+0x68>)
		 * HFCLKSTARTED may be generated twice.
		 *
		 * Also software should be notified about clock being on only
		 * if generic request occured.
		 */
		if ((GET_STATUS(data->flags) == CLOCK_CONTROL_STATUS_STARTING)
    1134:	68db      	ldr	r3, [r3, #12]
    1136:	6c18      	ldr	r0, [r3, #64]	; 0x40
    1138:	f010 0007 	ands.w	r0, r0, #7
    113c:	d105      	bne.n	114a <nrf_power_clock_isr+0x36>
			&& (hfclk_users & HF_USER_GENERIC)) {
    113e:	4b10      	ldr	r3, [pc, #64]	; (1180 <nrf_power_clock_isr+0x6c>)
    1140:	681b      	ldr	r3, [r3, #0]
    1142:	0799      	lsls	r1, r3, #30
    1144:	d501      	bpl.n	114a <nrf_power_clock_isr+0x36>
			clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_HFCLK);
    1146:	f7ff ff1f 	bl	f88 <clkstarted_handle.constprop.0>
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    114a:	4b0e      	ldr	r3, [pc, #56]	; (1184 <nrf_power_clock_isr+0x70>)
    114c:	681a      	ldr	r2, [r3, #0]
	bool ret = nrf_clock_event_check(NRF_CLOCK, evt) &&
    114e:	b182      	cbz	r2, 1172 <nrf_power_clock_isr+0x5e>
    return p_reg->INTENSET & mask;
    1150:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    1154:	f8d2 2304 	ldr.w	r2, [r2, #772]	; 0x304
	if (ret) {
    1158:	0792      	lsls	r2, r2, #30
    115a:	d50a      	bpl.n	1172 <nrf_power_clock_isr+0x5e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    115c:	2200      	movs	r2, #0
    115e:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    1160:	681b      	ldr	r3, [r3, #0]
    1162:	9301      	str	r3, [sp, #4]
    (void)dummy;
    1164:	9b01      	ldr	r3, [sp, #4]
					NRF_CLOCK_INT_LF_STARTED_MASK)) {
		if (IS_ENABLED(
			CONFIG_CLOCK_CONTROL_NRF_K32SRC_RC_CALIBRATION)) {
			z_nrf_clock_calibration_lfclk_started();
		}
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    1166:	2001      	movs	r0, #1
	usb_power_isr();

	if (IS_ENABLED(CONFIG_CLOCK_CONTROL_NRF_K32SRC_RC_CALIBRATION)) {
		z_nrf_clock_calibration_isr();
	}
}
    1168:	b003      	add	sp, #12
    116a:	f85d eb04 	ldr.w	lr, [sp], #4
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    116e:	f7ff bf0b 	b.w	f88 <clkstarted_handle.constprop.0>
}
    1172:	b003      	add	sp, #12
    1174:	f85d fb04 	ldr.w	pc, [sp], #4
    1178:	40000100 	.word	0x40000100
    117c:	20003420 	.word	0x20003420
    1180:	200004d8 	.word	0x200004d8
    1184:	40000104 	.word	0x40000104

00001188 <z_nrf_clock_control_lf_on>:
{
    1188:	b510      	push	{r4, lr}
	return __atomic_exchange_n(target, value, __ATOMIC_SEQ_CST);
    118a:	4911      	ldr	r1, [pc, #68]	; (11d0 <z_nrf_clock_control_lf_on+0x48>)
    118c:	f3bf 8f5b 	dmb	ish
    1190:	4604      	mov	r4, r0
    1192:	2201      	movs	r2, #1
    1194:	e851 3f00 	ldrex	r3, [r1]
    1198:	e841 2000 	strex	r0, r2, [r1]
    119c:	2800      	cmp	r0, #0
    119e:	d1f9      	bne.n	1194 <z_nrf_clock_control_lf_on+0xc>
    11a0:	f3bf 8f5b 	dmb	ish
	if (atomic_set(&on, 1) == 0) {
    11a4:	b943      	cbnz	r3, 11b8 <z_nrf_clock_control_lf_on+0x30>
				get_onoff_manager(DEVICE_GET(clock_nrf),
    11a6:	490b      	ldr	r1, [pc, #44]	; (11d4 <z_nrf_clock_control_lf_on+0x4c>)
	return &data->mgr[type];
    11a8:	68c8      	ldr	r0, [r1, #12]
 */
static inline void sys_notify_init_spinwait(struct sys_notify *notify)
{
	__ASSERT_NO_MSG(notify != NULL);

	*notify = (struct sys_notify){
    11aa:	490b      	ldr	r1, [pc, #44]	; (11d8 <z_nrf_clock_control_lf_on+0x50>)
		err = onoff_request(mgr, &cli);
    11ac:	301c      	adds	r0, #28
    11ae:	604b      	str	r3, [r1, #4]
    11b0:	60cb      	str	r3, [r1, #12]
    11b2:	608a      	str	r2, [r1, #8]
    11b4:	f004 fbc5 	bl	5942 <onoff_request>
	switch (start_mode) {
    11b8:	2c01      	cmp	r4, #1
    11ba:	d006      	beq.n	11ca <z_nrf_clock_control_lf_on+0x42>
    11bc:	2c02      	cmp	r4, #2
    11be:	d106      	bne.n	11ce <z_nrf_clock_control_lf_on+0x46>
		lfclk_spinwait(CLOCK_CONTROL_NRF_K32SRC);
    11c0:	2001      	movs	r0, #1
}
    11c2:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		lfclk_spinwait(NRF_CLOCK_LFCLK_RC);
    11c6:	f004 bf15 	b.w	5ff4 <lfclk_spinwait>
    11ca:	2000      	movs	r0, #0
    11cc:	e7f9      	b.n	11c2 <z_nrf_clock_control_lf_on+0x3a>
}
    11ce:	bd10      	pop	{r4, pc}
    11d0:	200004dc 	.word	0x200004dc
    11d4:	20003420 	.word	0x20003420
    11d8:	20000478 	.word	0x20000478

000011dc <handle_next_cycle_case>:
 * counter progresses during that time it means that 1 cycle elapsed and
 * interrupt is set pending.
 */
static void handle_next_cycle_case(uint32_t t)
{
	set_comparator(t + 2);
    11dc:	1c82      	adds	r2, r0, #2

#ifndef NRF_DECLARE_ONLY

NRF_STATIC_INLINE  void nrf_rtc_cc_set(NRF_RTC_Type * p_reg, uint32_t ch, uint32_t cc_val)
{
    p_reg->CC[ch] = cc_val;
    11de:	4b08      	ldr	r3, [pc, #32]	; (1200 <handle_next_cycle_case+0x24>)
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    11e0:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    11e4:	f8c3 2540 	str.w	r2, [r3, #1344]	; 0x540
#endif
}

NRF_STATIC_INLINE uint32_t nrf_rtc_counter_get(NRF_RTC_Type const * p_reg)
{
     return p_reg->COUNTER;
    11e8:	f8d3 2504 	ldr.w	r2, [r3, #1284]	; 0x504
	while (t != counter()) {
    11ec:	4290      	cmp	r0, r2
    11ee:	d100      	bne.n	11f2 <handle_next_cycle_case+0x16>
		 * generated. Trigger interrupt.
		 */
		t = counter();
		set_comparator(t + 2);
	}
}
    11f0:	4770      	bx	lr
    11f2:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
		set_comparator(t + 2);
    11f6:	1c82      	adds	r2, r0, #2
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    11f8:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    11fc:	e7f2      	b.n	11e4 <handle_next_cycle_case+0x8>
    11fe:	bf00      	nop
    1200:	40011000 	.word	0x40011000

00001204 <event_clear>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    1204:	4b04      	ldr	r3, [pc, #16]	; (1218 <event_clear+0x14>)
    1206:	2200      	movs	r2, #0
{
    1208:	b082      	sub	sp, #8
    120a:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    120c:	681b      	ldr	r3, [r3, #0]
    120e:	9301      	str	r3, [sp, #4]
    (void)dummy;
    1210:	9b01      	ldr	r3, [sp, #4]
}
    1212:	b002      	add	sp, #8
    1214:	4770      	bx	lr
    1216:	bf00      	nop
    1218:	40011140 	.word	0x40011140

0000121c <rtc_nrf_isr>:
 * probably better abstract that at some point (e.g. query and reset
 * it by pointer at runtime, maybe?) so we don't have this leaky
 * symbol.
 */
void rtc_nrf_isr(void *arg)
{
    121c:	b508      	push	{r3, lr}
	ARG_UNUSED(arg);
	event_clear();
    121e:	f7ff fff1 	bl	1204 <event_clear>
    return p_reg->CC[ch];
    1222:	4b07      	ldr	r3, [pc, #28]	; (1240 <rtc_nrf_isr+0x24>)

	uint32_t t = get_comparator();
	uint32_t dticks = counter_sub(t, last_count) / CYC_PER_TICK;
    1224:	4a07      	ldr	r2, [pc, #28]	; (1244 <rtc_nrf_isr+0x28>)
    1226:	f8d3 0540 	ldr.w	r0, [r3, #1344]	; 0x540
    122a:	6813      	ldr	r3, [r2, #0]
	return (a - b) & COUNTER_MAX;
    122c:	1ac0      	subs	r0, r0, r3
    122e:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000

	last_count += dticks * CYC_PER_TICK;
    1232:	4403      	add	r3, r0
    1234:	6013      	str	r3, [r2, #0]
		 */
		set_absolute_alarm(last_count + CYC_PER_TICK);
	}

	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
}
    1236:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
    123a:	f004 b855 	b.w	52e8 <z_clock_announce>
    123e:	bf00      	nop
    1240:	40011000 	.word	0x40011000
    1244:	200004e0 	.word	0x200004e0

00001248 <z_clock_driver_init>:

int z_clock_driver_init(struct device *device)
{
    1248:	b538      	push	{r3, r4, r5, lr}
}

NRF_STATIC_INLINE void nrf_rtc_prescaler_set(NRF_RTC_Type * p_reg, uint32_t val)
{
    NRFX_ASSERT(val <= (RTC_PRESCALER_PRESCALER_Msk >> RTC_PRESCALER_PRESCALER_Pos));
    p_reg->PRESCALER = val;
    124a:	4d10      	ldr	r5, [pc, #64]	; (128c <z_clock_driver_init+0x44>)
    124c:	2400      	movs	r4, #0
    124e:	f8c5 4508 	str.w	r4, [r5, #1288]	; 0x508
	ARG_UNUSED(device);

	/* TODO: replace with counter driver to access RTC */
	nrf_rtc_prescaler_set(RTC, 0);
	event_clear();
    1252:	f7ff ffd7 	bl	1204 <event_clear>
 */
__STATIC_INLINE void __NVIC_ClearPendingIRQ(IRQn_Type IRQn)
{
  if ((int32_t)(IRQn) >= 0)
  {
    NVIC->ICPR[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    1256:	4b0e      	ldr	r3, [pc, #56]	; (1290 <z_clock_driver_init+0x48>)
    1258:	f44f 3200 	mov.w	r2, #131072	; 0x20000
    125c:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
    p_reg->INTENSET = mask;
    1260:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    1264:	f8c5 3304 	str.w	r3, [r5, #772]	; 0x304
	NVIC_ClearPendingIRQ(RTC_IRQn);
	int_enable();

	IRQ_CONNECT(RTC_IRQn, 1, rtc_nrf_isr, 0, 0);
    1268:	4622      	mov	r2, r4
    126a:	2101      	movs	r1, #1
    126c:	2011      	movs	r0, #17
    126e:	f000 f965 	bl	153c <z_arm_irq_priority_set>
	irq_enable(RTC_IRQn);
    1272:	2011      	movs	r0, #17
    1274:	f000 f952 	bl	151c <arch_irq_enable>
    return (uint32_t)p_reg + task;
}

NRF_STATIC_INLINE void nrf_rtc_task_trigger(NRF_RTC_Type * p_reg, nrf_rtc_task_t task)
{
    *(__IO uint32_t *)((uint32_t)p_reg + task) = 1;
    1278:	4a06      	ldr	r2, [pc, #24]	; (1294 <z_clock_driver_init+0x4c>)
    127a:	2301      	movs	r3, #1
    127c:	6013      	str	r3, [r2, #0]

	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		set_comparator(counter() + CYC_PER_TICK);
	}

	z_nrf_clock_control_lf_on(NRF_LFCLK_START_MODE_NOWAIT);
    127e:	4620      	mov	r0, r4
    1280:	602b      	str	r3, [r5, #0]
    1282:	f7ff ff81 	bl	1188 <z_nrf_clock_control_lf_on>

	return 0;
}
    1286:	4620      	mov	r0, r4
    1288:	bd38      	pop	{r3, r4, r5, pc}
    128a:	bf00      	nop
    128c:	40011000 	.word	0x40011000
    1290:	e000e100 	.word	0xe000e100
    1294:	40011008 	.word	0x40011008

00001298 <z_clock_set_timeout>:

void z_clock_set_timeout(int32_t ticks, bool idle)
{
    1298:	e92d 4178 	stmdb	sp!, {r3, r4, r5, r6, r8, lr}
	}

	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);

	uint32_t unannounced = counter_sub(counter(), last_count);
    129c:	4b30      	ldr	r3, [pc, #192]	; (1360 <z_clock_set_timeout+0xc8>)
     return p_reg->COUNTER;
    129e:	4c31      	ldr	r4, [pc, #196]	; (1364 <z_clock_set_timeout+0xcc>)
    12a0:	6819      	ldr	r1, [r3, #0]
    12a2:	f8d4 2504 	ldr.w	r2, [r4, #1284]	; 0x504
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    12a6:	4d30      	ldr	r5, [pc, #192]	; (1368 <z_clock_set_timeout+0xd0>)
	return (a - b) & COUNTER_MAX;
    12a8:	1a52      	subs	r2, r2, r1
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    12aa:	f1b0 3fff 	cmp.w	r0, #4294967295	; 0xffffffff
    12ae:	bf08      	it	eq
    12b0:	4628      	moveq	r0, r5
	/* If we haven't announced for more than half the 24-bit wrap
	 * duration, then force an announce to avoid loss of a wrap
	 * event.  This can happen if new timeouts keep being set
	 * before the existing one triggers the interrupt.
	 */
	if (unannounced >= COUNTER_HALF_SPAN) {
    12b2:	0216      	lsls	r6, r2, #8
	return (a - b) & COUNTER_MAX;
    12b4:	f022 437f 	bic.w	r3, r2, #4278190080	; 0xff000000
	if (unannounced >= COUNTER_HALF_SPAN) {
    12b8:	d43b      	bmi.n	1332 <z_clock_set_timeout+0x9a>
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);
    12ba:	3801      	subs	r0, #1
    12bc:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    12c0:	42a8      	cmp	r0, r5
    12c2:	bfa8      	it	ge
    12c4:	4628      	movge	r0, r5
	}

	/* Get the cycles from last_count to the tick boundary after
	 * the requested ticks have passed starting now.
	 */
	cyc = ticks * CYC_PER_TICK + 1 + unannounced;
    12c6:	3301      	adds	r3, #1
    p_reg->INTENCLR = mask;
    12c8:	f44f 3680 	mov.w	r6, #65536	; 0x10000
    12cc:	4418      	add	r0, r3
    12ce:	f8c4 6308 	str.w	r6, [r4, #776]	; 0x308
	 */
	if (cyc > MAX_CYCLES) {
		cyc = MAX_CYCLES;
	}

	cyc += last_count;
    12d2:	42a8      	cmp	r0, r5
    12d4:	bf94      	ite	ls
    12d6:	180d      	addls	r5, r1, r0
    12d8:	194d      	addhi	r5, r1, r5
     return p_reg->COUNTER;
    12da:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
    return p_reg->CC[ch];
    12de:	f8d4 1540 	ldr.w	r1, [r4, #1344]	; 0x540
	event_clear();
    12e2:	f7ff ff8f 	bl	1204 <event_clear>
	return (a - b) & COUNTER_MAX;
    12e6:	1a09      	subs	r1, r1, r0
    12e8:	f021 417f 	bic.w	r1, r1, #4278190080	; 0xff000000
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    12ec:	f020 437f 	bic.w	r3, r0, #4278190080	; 0xff000000
	if (counter_sub(prev_val, now) == 1) {
    12f0:	2901      	cmp	r1, #1
    p_reg->CC[ch] = cc_val;
    12f2:	f8c4 3540 	str.w	r3, [r4, #1344]	; 0x540
}

NRF_STATIC_INLINE void nrf_rtc_event_enable(NRF_RTC_Type * p_reg, uint32_t mask)
{
    p_reg->EVTENSET = mask;
    12f6:	f8c4 6344 	str.w	r6, [r4, #836]	; 0x344
    12fa:	d10b      	bne.n	1314 <z_clock_set_timeout+0x7c>
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    12fc:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    1300:	b9cb      	cbnz	r3, 1336 <z_clock_set_timeout+0x9e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    1302:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    1306:	07da      	lsls	r2, r3, #31
    1308:	d515      	bpl.n	1336 <z_clock_set_timeout+0x9e>
	register uint32_t ret __asm__("r0") = arg1;
    130a:	200f      	movs	r0, #15
	register uint32_t r6 __asm__("r6") = call_id;
    130c:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    130e:	df03      	svc	3
		event_clear();
    1310:	f7ff ff78 	bl	1204 <event_clear>
    1314:	4b15      	ldr	r3, [pc, #84]	; (136c <z_clock_set_timeout+0xd4>)
    1316:	f44f 3200 	mov.w	r2, #131072	; 0x20000
    131a:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
     return p_reg->COUNTER;
    131e:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    1322:	1a2b      	subs	r3, r5, r0
    1324:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
	if (diff == 1) {
    1328:	2b01      	cmp	r3, #1
    132a:	d108      	bne.n	133e <z_clock_set_timeout+0xa6>
		handle_next_cycle_case(t);
    132c:	f7ff ff56 	bl	11dc <handle_next_cycle_case>
    1330:	e00f      	b.n	1352 <z_clock_set_timeout+0xba>
		ticks = 0;
    1332:	2000      	movs	r0, #0
    1334:	e7c7      	b.n	12c6 <z_clock_set_timeout+0x2e>
	z_impl_k_busy_wait(usec_to_wait);
    1336:	200f      	movs	r0, #15
    1338:	f005 fc2e 	bl	6b98 <z_impl_k_busy_wait>
    133c:	e7e8      	b.n	1310 <z_clock_set_timeout+0x78>
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    133e:	f025 437f 	bic.w	r3, r5, #4278190080	; 0xff000000
    p_reg->CC[ch] = cc_val;
    1342:	f8c4 3540 	str.w	r3, [r4, #1344]	; 0x540
     return p_reg->COUNTER;
    1346:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    134a:	1a2d      	subs	r5, r5, r0
    134c:	3d02      	subs	r5, #2
	if (diff > MAX_CYCLES) {
    134e:	022b      	lsls	r3, r5, #8
    1350:	d4ec      	bmi.n	132c <z_clock_set_timeout+0x94>
    p_reg->INTENSET = mask;
    1352:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    1356:	f8c4 3304 	str.w	r3, [r4, #772]	; 0x304
	set_protected_absolute_alarm(cyc);
}
    135a:	e8bd 8178 	ldmia.w	sp!, {r3, r4, r5, r6, r8, pc}
    135e:	bf00      	nop
    1360:	200004e0 	.word	0x200004e0
    1364:	40011000 	.word	0x40011000
    1368:	007fffff 	.word	0x007fffff
    136c:	e000e100 	.word	0xe000e100

00001370 <z_clock_elapsed>:
	__asm__ volatile(
    1370:	f04f 0220 	mov.w	r2, #32
    1374:	f3ef 8311 	mrs	r3, BASEPRI
    1378:	f382 8811 	msr	BASEPRI, r2
    137c:	f3bf 8f6f 	isb	sy
     return p_reg->COUNTER;
    1380:	4a06      	ldr	r2, [pc, #24]	; (139c <z_clock_elapsed+0x2c>)
    1382:	f8d2 0504 	ldr.w	r0, [r2, #1284]	; 0x504
	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		return 0;
	}

	k_spinlock_key_t key = k_spin_lock(&lock);
	uint32_t ret = counter_sub(counter(), last_count) / CYC_PER_TICK;
    1386:	4a06      	ldr	r2, [pc, #24]	; (13a0 <z_clock_elapsed+0x30>)
	return (a - b) & COUNTER_MAX;
    1388:	6812      	ldr	r2, [r2, #0]
    138a:	1a80      	subs	r0, r0, r2
    138c:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000
	__asm__ volatile(
    1390:	f383 8811 	msr	BASEPRI, r3
    1394:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&lock, key);
	return ret;
}
    1398:	4770      	bx	lr
    139a:	bf00      	nop
    139c:	40011000 	.word	0x40011000
    13a0:	200004e0 	.word	0x200004e0

000013a4 <_DoInit>:
*
*/
#define INIT()  do {                                            \
                  if (_SEGGER_RTT.acID[0] == '\0') { _DoInit(); }  \
                } while (0)
static void _DoInit(void) {
    13a4:	b510      	push	{r4, lr}
  SEGGER_RTT_CB* p;
  //
  // Initialize control block
  //
  p = &_SEGGER_RTT;
  p->MaxNumUpBuffers    = SEGGER_RTT_MAX_NUM_UP_BUFFERS;
    13a6:	4c11      	ldr	r4, [pc, #68]	; (13ec <_DoInit+0x48>)
  p->MaxNumDownBuffers  = SEGGER_RTT_MAX_NUM_DOWN_BUFFERS;
  //
  // Initialize up buffer 0
  //
  p->aUp[0].sName         = "Terminal";
    13a8:	4a11      	ldr	r2, [pc, #68]	; (13f0 <_DoInit+0x4c>)
    13aa:	61a2      	str	r2, [r4, #24]
  p->MaxNumUpBuffers    = SEGGER_RTT_MAX_NUM_UP_BUFFERS;
    13ac:	2303      	movs	r3, #3
  p->MaxNumDownBuffers  = SEGGER_RTT_MAX_NUM_DOWN_BUFFERS;
    13ae:	e9c4 3304 	strd	r3, r3, [r4, #16]
  p->aUp[0].pBuffer       = _acUpBuffer;
    13b2:	4b10      	ldr	r3, [pc, #64]	; (13f4 <_DoInit+0x50>)
    13b4:	61e3      	str	r3, [r4, #28]
  p->aUp[0].WrOff         = 0u;
  p->aUp[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
  //
  // Initialize down buffer 0
  //
  p->aDown[0].sName         = "Terminal";
    13b6:	6622      	str	r2, [r4, #96]	; 0x60
  p->aUp[0].SizeOfBuffer  = sizeof(_acUpBuffer);
    13b8:	f44f 6380 	mov.w	r3, #1024	; 0x400
  p->aDown[0].pBuffer       = _acDownBuffer;
    13bc:	4a0e      	ldr	r2, [pc, #56]	; (13f8 <_DoInit+0x54>)
  //
  // Finish initialization of the control block.
  // Copy Id string in three steps to make sure "SEGGER RTT" is not found
  // in initializer memory (usually flash) by J-Link
  //
  strcpy(&p->acID[7], "RTT");
    13be:	490f      	ldr	r1, [pc, #60]	; (13fc <_DoInit+0x58>)
  p->aUp[0].SizeOfBuffer  = sizeof(_acUpBuffer);
    13c0:	6223      	str	r3, [r4, #32]
  p->aDown[0].pBuffer       = _acDownBuffer;
    13c2:	6662      	str	r2, [r4, #100]	; 0x64
  p->aUp[0].RdOff         = 0u;
    13c4:	2300      	movs	r3, #0
  p->aDown[0].SizeOfBuffer  = sizeof(_acDownBuffer);
    13c6:	2210      	movs	r2, #16
  strcpy(&p->acID[7], "RTT");
    13c8:	1de0      	adds	r0, r4, #7
  p->aUp[0].RdOff         = 0u;
    13ca:	62a3      	str	r3, [r4, #40]	; 0x28
  p->aUp[0].WrOff         = 0u;
    13cc:	6263      	str	r3, [r4, #36]	; 0x24
  p->aUp[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
    13ce:	62e3      	str	r3, [r4, #44]	; 0x2c
  p->aDown[0].RdOff         = 0u;
    13d0:	6723      	str	r3, [r4, #112]	; 0x70
  p->aDown[0].WrOff         = 0u;
    13d2:	66e3      	str	r3, [r4, #108]	; 0x6c
  p->aDown[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
    13d4:	6763      	str	r3, [r4, #116]	; 0x74
  p->aDown[0].SizeOfBuffer  = sizeof(_acDownBuffer);
    13d6:	66a2      	str	r2, [r4, #104]	; 0x68
  strcpy(&p->acID[7], "RTT");
    13d8:	f004 feb8 	bl	614c <strcpy>
  strcpy(&p->acID[0], "SEGGER");
    13dc:	4908      	ldr	r1, [pc, #32]	; (1400 <_DoInit+0x5c>)
    13de:	4620      	mov	r0, r4
    13e0:	f004 feb4 	bl	614c <strcpy>
  p->acID[6] = ' ';
    13e4:	2320      	movs	r3, #32
    13e6:	71a3      	strb	r3, [r4, #6]
}
    13e8:	bd10      	pop	{r4, pc}
    13ea:	bf00      	nop
    13ec:	200004e4 	.word	0x200004e4
    13f0:	000078a5 	.word	0x000078a5
    13f4:	20000f44 	.word	0x20000f44
    13f8:	20000f34 	.word	0x20000f34
    13fc:	000078ae 	.word	0x000078ae
    1400:	000078b2 	.word	0x000078b2

00001404 <arch_swap>:
#ifdef CONFIG_EXECUTION_BENCHMARKING
	read_timer_start_of_swap();
#endif

	/* store off key and return value */
	_current->arch.basepri = key;
    1404:	4a0a      	ldr	r2, [pc, #40]	; (1430 <arch_swap+0x2c>)
	_current->arch.swap_return_value = _k_neg_eagain;
    1406:	490b      	ldr	r1, [pc, #44]	; (1434 <arch_swap+0x30>)
	_current->arch.basepri = key;
    1408:	6893      	ldr	r3, [r2, #8]
	_current->arch.swap_return_value = _k_neg_eagain;
    140a:	6809      	ldr	r1, [r1, #0]
    140c:	f8c3 1090 	str.w	r1, [r3, #144]	; 0x90

#if defined(CONFIG_CPU_CORTEX_M)
	/* set pending bit to make sure we will take a PendSV exception */
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    1410:	4909      	ldr	r1, [pc, #36]	; (1438 <arch_swap+0x34>)
	_current->arch.basepri = key;
    1412:	f8c3 008c 	str.w	r0, [r3, #140]	; 0x8c
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    1416:	684b      	ldr	r3, [r1, #4]
    1418:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
    141c:	604b      	str	r3, [r1, #4]
    141e:	2300      	movs	r3, #0
    1420:	f383 8811 	msr	BASEPRI, r3
    1424:	f3bf 8f6f 	isb	sy
#endif

	/* Context switch is performed here. Returning implies the
	 * thread has been context-switched-in again.
	 */
	return _current->arch.swap_return_value;
    1428:	6893      	ldr	r3, [r2, #8]
}
    142a:	f8d3 0090 	ldr.w	r0, [r3, #144]	; 0x90
    142e:	4770      	bx	lr
    1430:	20000eec 	.word	0x20000eec
    1434:	00007360 	.word	0x00007360
    1438:	e000ed00 	.word	0xe000ed00

0000143c <z_arm_pendsv>:
    pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_TRACING */

    /* load _kernel into r1 and current k_thread into r2 */
    ldr r1, =_kernel
    143c:	4919      	ldr	r1, [pc, #100]	; (14a4 <z_arm_pendsv+0x68>)
    ldr r2, [r1, #_kernel_offset_to_current]
    143e:	688a      	ldr	r2, [r1, #8]

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
    1440:	f04f 0038 	mov.w	r0, #56	; 0x38
    add r0, r2
    1444:	4410      	add	r0, r2

    /* save callee-saved + psp in thread */
#if defined(CONFIG_CPU_CORTEX_M)
    mrs ip, PSP
    1446:	f3ef 8c09 	mrs	ip, PSP
    mov r6, r11
    mov r7, ip
    /* store r8-12 */
    stmea r0!, {r3-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    stmia r0, {v1-v8, ip}
    144a:	e880 1ff0 	stmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}

    /* Protect the kernel state while we play with the thread lists */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    144e:	2020      	movs	r0, #32
    msr BASEPRI, r0
    1450:	f380 8811 	msr	BASEPRI, r0
    isb /* Make the effect of disabling interrupts be realized immediately */
    1454:	f3bf 8f6f 	isb	sy
     * the new thread is context-switched in since all decisions
     * to pend PendSV have been taken with the current kernel
     * state and this is what we're handling currently.
     */
#if defined(CONFIG_CPU_CORTEX_M)
    ldr v4, =_SCS_ICSR
    1458:	4f13      	ldr	r7, [pc, #76]	; (14a8 <z_arm_pendsv+0x6c>)
    ldr v3, =_SCS_ICSR_UNPENDSV
    145a:	f04f 6600 	mov.w	r6, #134217728	; 0x8000000
#endif

    /* _kernel is still in r1 */

    /* fetch the thread to run from the ready queue cache */
    ldr r2, [r1, #_kernel_offset_to_ready_q_cache]
    145e:	6a4a      	ldr	r2, [r1, #36]	; 0x24

    str r2, [r1, #_kernel_offset_to_current]
    1460:	608a      	str	r2, [r1, #8]
     * has been handled.
     */

    /* _SCS_ICSR is still in v4 and _SCS_ICSR_UNPENDSV in v3 */
#if defined(CONFIG_CPU_CORTEX_M)
    str v3, [v4, #0]
    1462:	603e      	str	r6, [r7, #0]

    ldr r0, [r4]
    movs.n r3, #0
    str r3, [r4]
#else
    ldr r0, [r2, #_thread_offset_to_basepri]
    1464:	f8d2 008c 	ldr.w	r0, [r2, #140]	; 0x8c
    movs r3, #0
    1468:	2300      	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
    146a:	f8c2 308c 	str.w	r3, [r2, #140]	; 0x8c
    /* restore r4-r7, go back 9*4 bytes to the start of the stored block */
    subs r0, #36
    ldmia r0!, {r4-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* restore BASEPRI for the incoming thread */
    msr BASEPRI, r0
    146e:	f380 8811 	msr	BASEPRI, r0
    isb
#endif

#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
    /* Re-program dynamic memory map */
    push {r2,lr}
    1472:	b504      	push	{r2, lr}
    mov r0, r2 /* _current thread */
    1474:	4610      	mov	r0, r2
    bl z_arm_configure_dynamic_mpu_regions
    1476:	f000 fbd5 	bl	1c24 <z_arm_configure_dynamic_mpu_regions>
    pop {r2,lr}
    147a:	e8bd 4004 	ldmia.w	sp!, {r2, lr}
#endif

#ifdef CONFIG_USERSPACE
    /* restore mode */
    ldr r0, [r2, #_thread_offset_to_mode]
    147e:	f8d2 0094 	ldr.w	r0, [r2, #148]	; 0x94
    mrs r3, CONTROL
    1482:	f3ef 8314 	mrs	r3, CONTROL
    bic r3, #1
    1486:	f023 0301 	bic.w	r3, r3, #1
    orr r3, r0
    148a:	ea43 0300 	orr.w	r3, r3, r0
    msr CONTROL, r3
    148e:	f383 8814 	msr	CONTROL, r3

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    1492:	f3bf 8f6f 	isb	sy

#endif

    /* load callee-saved + psp from thread */
    add r0, r2, #_thread_offset_to_callee_saved
    1496:	f102 0038 	add.w	r0, r2, #56	; 0x38
    ldmia r0, {v1-v8, ip}
    149a:	e890 1ff0 	ldmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
    msr PSP, ip
    149e:	f38c 8809 	msr	PSP, ip

    /*
     * Cortex-M: return from PendSV exception
     * Cortex-R: return to the caller (_IntExit or z_arm_svc)
     */
    bx lr
    14a2:	4770      	bx	lr
    ldr r1, =_kernel
    14a4:	20000eec 	.word	0x20000eec
    ldr v4, =_SCS_ICSR
    14a8:	e000ed04 	.word	0xe000ed04

000014ac <z_arm_svc>:
  bne _stack_frame_endif
_stack_frame_msp:
  mrs r0, MSP
_stack_frame_endif:
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst lr, #0x4    /* did we come from thread mode ? */
    14ac:	f01e 0f04 	tst.w	lr, #4
    ite eq  /* if zero (equal), came from handler mode */
    14b0:	bf0c      	ite	eq
        mrseq r0, MSP   /* handler mode, stack frame is on MSP */
    14b2:	f3ef 8008 	mrseq	r0, MSP
        mrsne r0, PSP   /* thread mode, stack frame is on PSP */
    14b6:	f3ef 8009 	mrsne	r0, PSP
#endif


    /* Figure out what SVC call number was invoked */

    ldr r1, [r0, #24]   /* grab address of PC from stack frame */
    14ba:	6981      	ldr	r1, [r0, #24]
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    subs r1, r1, #2
    ldrb r1, [r1]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldrb r1, [r1, #-2]
    14bc:	f811 1c02 	ldrb.w	r1, [r1, #-2]
    * 1: irq_offload (if configured)
    * 2: kernel panic or oops (software generated fatal exception)
    * 3: System call (if user mode supported)
    */
#if defined(CONFIG_USERSPACE)
    mrs r2, CONTROL
    14c0:	f3ef 8214 	mrs	r2, CONTROL

    cmp r1, #3
    14c4:	2903      	cmp	r1, #3
    beq _do_syscall
    14c6:	d008      	beq.n	14da <_do_syscall>
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    movs r3, #0x1
    tst r2, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst r2, #0x1
    14c8:	f012 0f01 	tst.w	r2, #1
#endif
    bne _oops
    14cc:	d101      	bne.n	14d2 <_oops>

#endif /* CONFIG_USERSPACE */

    cmp r1, #2
    14ce:	2902      	cmp	r1, #2
    beq _oops
    14d0:	d0ff      	beq.n	14d2 <_oops>

000014d2 <_oops>:
    /* exception return is done in z_arm_int_exit() */
    b z_arm_int_exit
#endif

_oops:
    push {r0, lr}
    14d2:	b501      	push	{r0, lr}
    bl z_do_kernel_oops
    14d4:	f004 fdf4 	bl	60c0 <z_do_kernel_oops>
    /* return from SVC exception is done here */
    pop {r0, pc}
    14d8:	bd01      	pop	{r0, pc}

000014da <_do_syscall>:
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    movs r3, #24
    ldr r1, [r0, r3]   /* grab address of PC from stack frame */
    mov r8, r1
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r8, [r0, #24]   /* grab address of PC from stack frame */
    14da:	f8d0 8018 	ldr.w	r8, [r0, #24]
#endif
    ldr r1, =z_arm_do_syscall
    14de:	490d      	ldr	r1, [pc, #52]	; (1514 <valid_syscall_id+0x24>)
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    str r1, [r0, r3]   /* overwrite the PC to point to z_arm_do_syscall */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    str r1, [r0, #24]   /* overwrite the PC to point to z_arm_do_syscall */
    14e0:	6181      	str	r1, [r0, #24]
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    ldr r3, =K_SYSCALL_LIMIT
    cmp r6, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* validate syscall limit */
    ldr ip, =K_SYSCALL_LIMIT
    14e2:	f44f 7c86 	mov.w	ip, #268	; 0x10c
    cmp r6, ip
    14e6:	4566      	cmp	r6, ip
#endif
    /* The supplied syscall_id must be lower than the limit
     * (Requires unsigned integer comparison)
     */
    blo valid_syscall_id
    14e8:	d302      	bcc.n	14f0 <valid_syscall_id>

    /* bad syscall id.  Set arg1 to bad id and set call_id to SYSCALL_BAD */
    str r6, [r0]
    14ea:	6006      	str	r6, [r0, #0]
    ldr r6, =K_SYSCALL_BAD
    14ec:	f240 160b 	movw	r6, #267	; 0x10b

000014f0 <valid_syscall_id>:

    /* Bad syscalls treated as valid syscalls with ID K_SYSCALL_BAD. */

valid_syscall_id:
    ldr r0, =_kernel
    14f0:	4809      	ldr	r0, [pc, #36]	; (1518 <valid_syscall_id+0x28>)
    ldr r0, [r0, #_kernel_offset_to_current]
    14f2:	6880      	ldr	r0, [r0, #8]
    dsb
    /* set mode to privileged, r2 still contains value from CONTROL */
    movs r3, #1
    bics r2, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r1, [r0, #_thread_offset_to_mode]
    14f4:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    bic r1, #1
    14f8:	f021 0101 	bic.w	r1, r1, #1
    /* Store (privileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    14fc:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
    dsb
    1500:	f3bf 8f4f 	dsb	sy
    /* set mode to privileged, r2 still contains value from CONTROL */
    bic r2, #1
    1504:	f022 0201 	bic.w	r2, r2, #1
#endif
    msr CONTROL, r2
    1508:	f382 8814 	msr	CONTROL, r2

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    150c:	f3bf 8f6f 	isb	sy
    ldr r1, [r0, #_thread_offset_to_stack_info_start]    /* stack_info.start */
    msr PSPLIM, r1
#endif /* CONFIG_BUILTIN_STACK_GUARD */

    /* return from SVC to the modified LR - z_arm_do_syscall */
    bx lr
    1510:	4770      	bx	lr
    1512:	0000      	.short	0x0000
    ldr r1, =z_arm_do_syscall
    1514:	000017a9 	.word	0x000017a9
    ldr r0, =_kernel
    1518:	20000eec 	.word	0x20000eec

0000151c <arch_irq_enable>:
#define REG_FROM_IRQ(irq) (irq / NUM_IRQS_PER_REG)
#define BIT_FROM_IRQ(irq) (irq % NUM_IRQS_PER_REG)

void arch_irq_enable(unsigned int irq)
{
	NVIC_EnableIRQ((IRQn_Type)irq);
    151c:	b243      	sxtb	r3, r0
  if ((int32_t)(IRQn) >= 0)
    151e:	2b00      	cmp	r3, #0
    1520:	db08      	blt.n	1534 <arch_irq_enable+0x18>
    NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    1522:	2201      	movs	r2, #1
    1524:	f000 001f 	and.w	r0, r0, #31
    1528:	fa02 f000 	lsl.w	r0, r2, r0
    152c:	095b      	lsrs	r3, r3, #5
    152e:	4a02      	ldr	r2, [pc, #8]	; (1538 <arch_irq_enable+0x1c>)
    1530:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
}
    1534:	4770      	bx	lr
    1536:	bf00      	nop
    1538:	e000e100 	.word	0xe000e100

0000153c <z_arm_irq_priority_set>:
	 */
	__ASSERT(prio <= (BIT(NUM_IRQ_PRIO_BITS) - 1),
		 "invalid priority %d! values must be less than %lu\n",
		 prio - _IRQ_PRIO_OFFSET,
		 BIT(NUM_IRQ_PRIO_BITS) - (_IRQ_PRIO_OFFSET));
	NVIC_SetPriority((IRQn_Type)irq, prio);
    153c:	b243      	sxtb	r3, r0
  \param [in]  priority  Priority to set.
  \note    The priority cannot be set for every processor exception.
 */
__STATIC_INLINE void __NVIC_SetPriority(IRQn_Type IRQn, uint32_t priority)
{
  if ((int32_t)(IRQn) >= 0)
    153e:	2b00      	cmp	r3, #0
  {
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1540:	bfa8      	it	ge
    1542:	f103 4360 	addge.w	r3, r3, #3758096384	; 0xe0000000
	prio += _IRQ_PRIO_OFFSET;
    1546:	f101 0101 	add.w	r1, r1, #1
  }
  else
  {
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    154a:	bfb8      	it	lt
    154c:	4b06      	ldrlt	r3, [pc, #24]	; (1568 <z_arm_irq_priority_set+0x2c>)
    154e:	ea4f 1141 	mov.w	r1, r1, lsl #5
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1552:	bfac      	ite	ge
    1554:	f503 4361 	addge.w	r3, r3, #57600	; 0xe100
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1558:	f000 000f 	andlt.w	r0, r0, #15
    155c:	b2c9      	uxtb	r1, r1
    155e:	bfb4      	ite	lt
    1560:	5419      	strblt	r1, [r3, r0]
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1562:	f883 1300 	strbge.w	r1, [r3, #768]	; 0x300
}
    1566:	4770      	bx	lr
    1568:	e000ed14 	.word	0xe000ed14

0000156c <arch_user_mode_enter>:
					void *p1, void *p2, void *p3)
{

	/* Set up privileged stack before entering user mode */
	_current->arch.priv_stack_start =
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    156c:	4c0c      	ldr	r4, [pc, #48]	; (15a0 <arch_user_mode_enter+0x34>)
{
    156e:	4698      	mov	r8, r3
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    1570:	68a3      	ldr	r3, [r4, #8]
{
    1572:	b583      	push	{r0, r1, r7, lr}
    1574:	4605      	mov	r5, r0
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    1576:	f8d3 0080 	ldr.w	r0, [r3, #128]	; 0x80
{
    157a:	4617      	mov	r7, r2
    157c:	460e      	mov	r6, r1
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    157e:	f005 fc9e 	bl	6ebe <z_priv_stack_find>
	_current->arch.priv_stack_start =
    1582:	68a4      	ldr	r4, [r4, #8]
#else
	_current->arch.priv_stack_start += MPU_GUARD_ALIGN_AND_SIZE;
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */
#endif /* CONFIG_MPU_STACK_GUARD */

	z_arm_userspace_enter(user_entry, p1, p2, p3,
    1584:	e9d4 321b 	ldrd	r3, r2, [r4, #108]	; 0x6c
    1588:	1a9b      	subs	r3, r3, r2
	_current->arch.priv_stack_start =
    158a:	f8c4 0098 	str.w	r0, [r4, #152]	; 0x98
	z_arm_userspace_enter(user_entry, p1, p2, p3,
    158e:	9301      	str	r3, [sp, #4]
    1590:	6ea3      	ldr	r3, [r4, #104]	; 0x68
    1592:	9300      	str	r3, [sp, #0]
    1594:	463a      	mov	r2, r7
    1596:	4643      	mov	r3, r8
    1598:	4631      	mov	r1, r6
    159a:	4628      	mov	r0, r5
    159c:	f000 f8c2 	bl	1724 <z_arm_userspace_enter>
    15a0:	20000eec 	.word	0x20000eec

000015a4 <arch_new_thread>:
{
    15a4:	b530      	push	{r4, r5, lr}
	if ((thread->base.user_options & K_USER) != 0) {
    15a6:	7b01      	ldrb	r1, [r0, #12]
	iframe->a1 = (uint32_t)entry;
    15a8:	f842 3c20 	str.w	r3, [r2, #-32]
	iframe->a2 = (uint32_t)p1;
    15ac:	9b03      	ldr	r3, [sp, #12]
    15ae:	f842 3c1c 	str.w	r3, [r2, #-28]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    15b2:	4d0e      	ldr	r5, [pc, #56]	; (15ec <arch_new_thread+0x48>)
	iframe->a3 = (uint32_t)p2;
    15b4:	9b04      	ldr	r3, [sp, #16]
    15b6:	f842 3c18 	str.w	r3, [r2, #-24]
	if ((thread->base.user_options & K_USER) != 0) {
    15ba:	f011 0f04 	tst.w	r1, #4
	iframe->a4 = (uint32_t)p3;
    15be:	9b05      	ldr	r3, [sp, #20]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    15c0:	490b      	ldr	r1, [pc, #44]	; (15f0 <arch_new_thread+0x4c>)
	iframe->a4 = (uint32_t)p3;
    15c2:	f842 3c14 	str.w	r3, [r2, #-20]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    15c6:	bf18      	it	ne
    15c8:	4629      	movne	r1, r5
	iframe->xpsr =
    15ca:	f04f 7380 	mov.w	r3, #16777216	; 0x1000000
    15ce:	f842 3c04 	str.w	r3, [r2, #-4]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
    15d2:	f1a2 0420 	sub.w	r4, r2, #32
	thread->arch.basepri = 0;
    15d6:	2300      	movs	r3, #0
	iframe->pc &= 0xfffffffe;
    15d8:	f021 0101 	bic.w	r1, r1, #1
    15dc:	f842 1c08 	str.w	r1, [r2, #-8]
	thread->arch.priv_stack_start = 0;
    15e0:	e9c0 3325 	strd	r3, r3, [r0, #148]	; 0x94
	thread->callee_saved.psp = (uint32_t)iframe;
    15e4:	6584      	str	r4, [r0, #88]	; 0x58
	thread->arch.basepri = 0;
    15e6:	f8c0 308c 	str.w	r3, [r0, #140]	; 0x8c
}
    15ea:	bd30      	pop	{r4, r5, pc}
    15ec:	0000156d 	.word	0x0000156d
    15f0:	000059e3 	.word	0x000059e3

000015f4 <z_check_thread_stack_fail>:
 * @return The lowest allowed stack frame pointer, if error is a
 *         thread stack corruption, otherwise return 0.
 */
uint32_t z_check_thread_stack_fail(const uint32_t fault_addr, const uint32_t psp)
{
	const struct k_thread *thread = _current;
    15f4:	4b10      	ldr	r3, [pc, #64]	; (1638 <z_check_thread_stack_fail+0x44>)
    15f6:	689b      	ldr	r3, [r3, #8]
{
    15f8:	b510      	push	{r4, lr}
    15fa:	4604      	mov	r4, r0

	if (!thread) {
    15fc:	b1bb      	cbz	r3, 162e <z_check_thread_stack_fail+0x3a>
#else
	uint32_t guard_len = MPU_GUARD_ALIGN_AND_SIZE;
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */

#if defined(CONFIG_USERSPACE)
	if (thread->arch.priv_stack_start) {
    15fe:	f8d3 0098 	ldr.w	r0, [r3, #152]	; 0x98
    1602:	b168      	cbz	r0, 1620 <z_check_thread_stack_fail+0x2c>
 */
__STATIC_FORCEINLINE uint32_t __get_CONTROL(void)
{
  uint32_t result;

  __ASM volatile ("MRS %0, control" : "=r" (result) );
    1604:	f3ef 8214 	mrs	r2, CONTROL
		/* User thread */
		if ((__get_CONTROL() & CONTROL_nPRIV_Msk) == 0) {
    1608:	f012 0201 	ands.w	r2, r2, #1
    160c:	d105      	bne.n	161a <z_check_thread_stack_fail+0x26>
			/* User thread in privilege mode */
			if (IS_MPU_GUARD_VIOLATION(
    160e:	3416      	adds	r4, #22
    1610:	d10f      	bne.n	1632 <z_check_thread_stack_fail+0x3e>
		/* Thread stack corruption */
		return thread->stack_info.start;
	}
#endif /* CONFIG_USERSPACE */

	return 0;
    1612:	4288      	cmp	r0, r1
    1614:	bf98      	it	ls
    1616:	2000      	movls	r0, #0
}
    1618:	bd10      	pop	{r4, pc}
			if (psp < (uint32_t)thread->stack_obj) {
    161a:	f8d3 0080 	ldr.w	r0, [r3, #128]	; 0x80
    161e:	e7f8      	b.n	1612 <z_check_thread_stack_fail+0x1e>
		if (IS_MPU_GUARD_VIOLATION(thread->stack_info.start -
    1620:	3416      	adds	r4, #22
    1622:	d1f9      	bne.n	1618 <z_check_thread_stack_fail+0x24>
    1624:	6e9b      	ldr	r3, [r3, #104]	; 0x68
    1626:	428b      	cmp	r3, r1
    1628:	bf88      	it	hi
    162a:	4618      	movhi	r0, r3
    162c:	e7f4      	b.n	1618 <z_check_thread_stack_fail+0x24>
	return 0;
    162e:	4618      	mov	r0, r3
    1630:	e7f2      	b.n	1618 <z_check_thread_stack_fail+0x24>
    1632:	4610      	mov	r0, r2
    1634:	e7f0      	b.n	1618 <z_check_thread_stack_fail+0x24>
    1636:	bf00      	nop
    1638:	20000eec 	.word	0x20000eec

0000163c <arch_switch_to_main_thread>:
}
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */

void arch_switch_to_main_thread(struct k_thread *main_thread, char *stack_ptr,
				k_thread_entry_t _main)
{
    163c:	b508      	push	{r3, lr}
    163e:	4604      	mov	r4, r0
    1640:	460e      	mov	r6, r1
    1642:	4615      	mov	r5, r2
	 * to set up access permissions for fixed memory sections, such
	 * as Application Memory or No-Cacheable SRAM area.
	 *
	 * This function is invoked once, upon system initialization.
	 */
	z_arm_configure_static_mpu_regions();
    1644:	f000 fad2 	bl	1bec <z_arm_configure_static_mpu_regions>
#endif
	_current = main_thread;
    1648:	4b08      	ldr	r3, [pc, #32]	; (166c <arch_switch_to_main_thread+0x30>)
#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
	/*
	 * If stack protection is enabled, make sure to set it
	 * before jumping to thread entry function
	 */
	z_arm_configure_dynamic_mpu_regions(main_thread);
    164a:	4620      	mov	r0, r4
	_current = main_thread;
    164c:	609c      	str	r4, [r3, #8]
	z_arm_configure_dynamic_mpu_regions(main_thread);
    164e:	f000 fae9 	bl	1c24 <z_arm_configure_dynamic_mpu_regions>

	/*
	 * Set PSP to the highest address of the main stack
	 * before enabling interrupts and jumping to main.
	 */
	__asm__ volatile (
    1652:	4628      	mov	r0, r5
    1654:	f386 8809 	msr	PSP, r6
    1658:	2100      	movs	r1, #0
    165a:	b663      	cpsie	if
    165c:	f381 8811 	msr	BASEPRI, r1
    1660:	f3bf 8f6f 	isb	sy
    1664:	2200      	movs	r2, #0
    1666:	2300      	movs	r3, #0
    1668:	f004 f9bb 	bl	59e2 <z_thread_entry>
	:
	: "r" (_main), "r" (stack_ptr)
	: "r0" /* not to be overwritten by msr PSP, %1 */
	);

	CODE_UNREACHABLE;
    166c:	20000eec 	.word	0x20000eec

00001670 <z_arm_cpu_idle_init>:
 * void z_arm_cpu_idle_init(void);
 */

SECTION_FUNC(TEXT, z_arm_cpu_idle_init)
#if defined(CONFIG_CPU_CORTEX_M)
	ldr	r1, =_SCB_SCR
    1670:	4901      	ldr	r1, [pc, #4]	; (1678 <z_arm_cpu_idle_init+0x8>)
	movs.n	r2, #_SCR_INIT_BITS
    1672:	2210      	movs	r2, #16
	str	r2, [r1]
    1674:	600a      	str	r2, [r1, #0]
#endif
	bx	lr
    1676:	4770      	bx	lr
	ldr	r1, =_SCB_SCR
    1678:	e000ed10 	.word	0xe000ed10

0000167c <arch_cpu_idle>:
	 * before entering low power state.
	 *
	 * Set PRIMASK before configuring BASEPRI to prevent interruption
	 * before wake-up.
	 */
	cpsid	i
    167c:	b672      	cpsid	i

	/*
	 * Set wake-up interrupt priority to the lowest and synchronise to
	 * ensure that this is visible to the WFI instruction.
	 */
	eors.n	r0, r0
    167e:	4040      	eors	r0, r0
	msr	BASEPRI, r0
    1680:	f380 8811 	msr	BASEPRI, r0
	isb
    1684:	f3bf 8f6f 	isb	sy

	/*
	 * Wait for all memory transactions to complete before entering low
	 * power state.
	 */
	dsb
    1688:	f3bf 8f4f 	dsb	sy

	/* Enter low power state */
	wfi
    168c:	bf30      	wfi

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
    168e:	b662      	cpsie	i
	isb
    1690:	f3bf 8f6f 	isb	sy

	bx	lr
    1694:	4770      	bx	lr
    1696:	bf00      	nop

00001698 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
    1698:	bf30      	wfi
    b z_SysNmiOnReset
    169a:	f7ff bffd 	b.w	1698 <z_SysNmiOnReset>
    169e:	bf00      	nop

000016a0 <z_arm_prep_c>:
#else
#define VECTOR_ADDRESS CONFIG_SRAM_BASE_ADDRESS
#endif
static inline void relocate_vector_table(void)
{
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    16a0:	4a0e      	ldr	r2, [pc, #56]	; (16dc <z_arm_prep_c+0x3c>)
 * This routine prepares for the execution of and runs C code.
 *
 * @return N/A
 */
void z_arm_prep_c(void)
{
    16a2:	b508      	push	{r3, lr}
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    16a4:	4b0e      	ldr	r3, [pc, #56]	; (16e0 <z_arm_prep_c+0x40>)
    16a6:	f022 027f 	bic.w	r2, r2, #127	; 0x7f
    16aa:	609a      	str	r2, [r3, #8]
  \details Acts as a special kind of Data Memory Barrier.
           It completes when all explicit memory accesses before this instruction complete.
 */
__STATIC_FORCEINLINE void __DSB(void)
{
  __ASM volatile ("dsb 0xF":::"memory");
    16ac:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    16b0:	f3bf 8f6f 	isb	sy
	SCB->CPACR &= (~(CPACR_CP10_Msk | CPACR_CP11_Msk));
    16b4:	f8d3 2088 	ldr.w	r2, [r3, #136]	; 0x88
    16b8:	f422 0270 	bic.w	r2, r2, #15728640	; 0xf00000
    16bc:	f8c3 2088 	str.w	r2, [r3, #136]	; 0x88
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    16c0:	f3ef 8314 	mrs	r3, CONTROL
	__set_CONTROL(__get_CONTROL() & (~(CONTROL_FPCA_Msk)));
    16c4:	f023 0304 	bic.w	r3, r3, #4
  __ASM volatile ("MSR control, %0" : : "r" (control) : "memory");
    16c8:	f383 8814 	msr	CONTROL, r3
	relocate_vector_table();
#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
    16cc:	f001 fc32 	bl	2f34 <z_bss_zero>
	z_data_copy();
    16d0:	f001 fc3a 	bl	2f48 <z_data_copy>
#if defined(CONFIG_ARMV7_R) && defined(CONFIG_INIT_STACKS)
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
    16d4:	f000 fa58 	bl	1b88 <z_arm_interrupt_init>
	z_cstart();
    16d8:	f001 fc80 	bl	2fdc <z_cstart>
    16dc:	00000000 	.word	0x00000000
    16e0:	e000ed00 	.word	0xe000ed00

000016e4 <_isr_wrapper>:
 * @return N/A
 */
SECTION_FUNC(TEXT, _isr_wrapper)

#if defined(CONFIG_CPU_CORTEX_M)
	push {r0,lr}		/* r0, lr are now the first items on the stack */
    16e4:	b501      	push	{r0, lr}
	 * Disable interrupts to prevent nesting while exiting idle state. This
	 * is only necessary for the Cortex-M because it is the only ARM
	 * architecture variant that automatically enables interrupts when
	 * entering an ISR.
	 */
	cpsid i  /* PRIMASK = 1 */
    16e6:	b672      	cpsid	i
#endif

	/* is this a wakeup from idle ? */
	ldr r2, =_kernel
    16e8:	4a0b      	ldr	r2, [pc, #44]	; (1718 <_isr_wrapper+0x34>)
	/* requested idle duration, in ticks */
	ldr r0, [r2, #_kernel_offset_to_idle]
    16ea:	6a10      	ldr	r0, [r2, #32]
	cmp r0, #0
    16ec:	2800      	cmp	r0, #0
	str r1, [r2, #_kernel_offset_to_idle]
	bl z_sys_power_save_idle_exit
_idle_state_cleared:

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	ittt ne
    16ee:	bf1e      	ittt	ne
	movne	r1, #0
    16f0:	2100      	movne	r1, #0
		/* clear kernel idle state */
		strne	r1, [r2, #_kernel_offset_to_idle]
    16f2:	6211      	strne	r1, [r2, #32]
		blne	z_sys_power_save_idle_exit
    16f4:	f004 fe5f 	blne	63b6 <z_sys_power_save_idle_exit>
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
	cpsie i		/* re-enable interrupts (PRIMASK = 0) */
    16f8:	b662      	cpsie	i
#endif

#endif /* CONFIG_SYS_POWER_MANAGEMENT */

#if defined(CONFIG_CPU_CORTEX_M)
	mrs r0, IPSR	/* get exception number */
    16fa:	f3ef 8005 	mrs	r0, IPSR
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	ldr r1, =16
	subs r0, r1	/* get IRQ number */
	lsls r0, #3	/* table is 8-byte wide */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	sub r0, r0, #16	/* get IRQ number */
    16fe:	f1a0 0010 	sub.w	r0, r0, #16
	lsl r0, r0, #3	/* table is 8-byte wide */
    1702:	ea4f 00c0 	mov.w	r0, r0, lsl #3
	 * interface function.
	 */
	cpsie i
#endif /* !CONFIG_CPU_CORTEX_M */

	ldr r1, =_sw_isr_table
    1706:	4905      	ldr	r1, [pc, #20]	; (171c <_isr_wrapper+0x38>)
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
    1708:	4401      	add	r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
    170a:	c909      	ldmia	r1!, {r0, r3}
#ifdef CONFIG_EXECUTION_BENCHMARKING
	push {r0, r3}	/* Save r0 and r3 into stack */
	bl read_timer_end_of_isr
	pop {r0, r3}	/* Restore r0 and r3 regs */
#endif /* CONFIG_EXECUTION_BENCHMARKING */
	blx r3		/* call ISR */
    170c:	4798      	blx	r3

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	pop {r0, r3}
	mov lr, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	pop {r0, lr}
    170e:	e8bd 4001 	ldmia.w	sp!, {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
    1712:	4903      	ldr	r1, [pc, #12]	; (1720 <_isr_wrapper+0x3c>)
	bx r1
    1714:	4708      	bx	r1
    1716:	0000      	.short	0x0000
	ldr r2, =_kernel
    1718:	20000eec 	.word	0x20000eec
	ldr r1, =_sw_isr_table
    171c:	00007178 	.word	0x00007178
	ldr r1, =z_arm_int_exit
    1720:	00001b6d 	.word	0x00001b6d

00001724 <z_arm_userspace_enter>:
 * z_arm_userspace_enter(user_entry, p1, p2, p3,
 *                        stack_info.start, stack_info.size);
 */
SECTION_FUNC(TEXT,z_arm_userspace_enter)
    /* move user_entry to lr */
    mov lr, r0
    1724:	4686      	mov	lr, r0

    /* prepare to set stack to privileged stack */
    ldr r0, =_kernel
    1726:	481e      	ldr	r0, [pc, #120]	; (17a0 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1728:	6880      	ldr	r0, [r0, #8]
    ldr r1, =CONFIG_PRIVILEGED_STACK_SIZE
    add r0, r0, r1
    /* Restore p1 from ip */
    mov r1, ip
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r0, [r0, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    172a:	f8d0 0098 	ldr.w	r0, [r0, #152]	; 0x98
    ldr ip, =CONFIG_PRIVILEGED_STACK_SIZE
    172e:	f44f 6c80 	mov.w	ip, #1024	; 0x400
    add r0, r0, ip
    1732:	4460      	add	r0, ip

    /* store current stack pointer to ip
     * the current stack pointer is needed to retrieve
     * stack_info.start and stack_info.size
     */
    mov ip, sp
    1734:	46ec      	mov	ip, sp
     * modifying PSP via MSR instruction is not subject to stack limit
     * checking, so we do not need to clear PSPLIM before setting PSP.
     * The operation is safe since, by design, the privileged stack is
     * located in memory higher than the default (user) thread stack.
     */
    msr PSP, r0
    1736:	f380 8809 	msr	PSP, r0
    ldr r0, [r0, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    msr PSPLIM, r0
#endif

    /* push args to stack */
    push {r1,r2,r3,lr}
    173a:	b50e      	push	{r1, r2, r3, lr}
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    mov r1, ip
    push {r0,r1}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    push {r0,ip}
    173c:	e92d 1001 	stmdb	sp!, {r0, ip}
     *
     * Note that the risk for overflow is higher if using the normal thread
     * stack, since we do not control how much stack is actually left, when
     * user invokes z_arm_userspace_enter().
     */
    ldr r0, =_kernel
    1740:	4817      	ldr	r0, [pc, #92]	; (17a0 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1742:	6880      	ldr	r0, [r0, #8]
    bl z_arm_configure_dynamic_mpu_regions
    1744:	f000 fa6e 	bl	1c24 <z_arm_configure_dynamic_mpu_regions>
    ldr r3, [r3, #4]
    mov ip, r3

    push {r0,r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r0,ip}
    1748:	e8bd 1001 	ldmia.w	sp!, {r0, ip}

    /* load up stack info from user stack */
    ldr r0, [ip]
    174c:	f8dc 0000 	ldr.w	r0, [ip]
    ldr ip, [ip, #4]
    1750:	f8dc c004 	ldr.w	ip, [ip, #4]

    push {r0,ip}
    1754:	e92d 1001 	stmdb	sp!, {r0, ip}
#endif

    /* clear the user stack area to clean out privileged data */
    /* from right past the guard right up to the end */
    mov r2, ip
    1758:	4662      	mov	r2, ip
#ifdef CONFIG_INIT_STACKS
    ldr r1,=0xaaaaaaaa
#else
    eors.n r1, r1
    175a:	4049      	eors	r1, r1
#endif
    bl memset
    175c:	f004 fd37 	bl	61ce <memset>

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    pop {r0, r1}
    mov ip, r1
#elif (defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE))
    pop {r0,ip}
    1760:	e8bd 1001 	ldmia.w	sp!, {r0, ip}
#endif

    /* r0 contains user stack start, ip contains user stack size */
    add r0, r0, ip   /* calculate top of stack */
    1764:	4460      	add	r0, ip
    mov ip, r4
    pop {r1,r2,r3,r4}
    mov lr, r4
    mov r4, ip
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r1,r2,r3,lr}
    1766:	e8bd 400e 	ldmia.w	sp!, {r1, r2, r3, lr}

    pop {r0, ip}
#endif

    /* set stack to user stack */
    msr PSP, r0
    176a:	f380 8809 	msr	PSP, r0
    msr BASEPRI, ip
    isb
#endif

    /* restore r0 */
    mov r0, lr
    176e:	4670      	mov	r0, lr
    mov ip, r3
    /* Store (unprivileged) mode in thread's mode state variable */
    ldr r2, =_thread_offset_to_mode
    str r1, [r0, r2]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    push {r0, r1}
    1770:	b403      	push	{r0, r1}
    ldr r0, =_kernel
    1772:	480b      	ldr	r0, [pc, #44]	; (17a0 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1774:	6880      	ldr	r0, [r0, #8]
    ldr r1, [r0, #_thread_offset_to_mode]
    1776:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    orrs r1, r1, #1
    177a:	f051 0101 	orrs.w	r1, r1, #1
    mrs ip, CONTROL
    177e:	f3ef 8c14 	mrs	ip, CONTROL
    orrs ip, ip, #1
    1782:	f05c 0c01 	orrs.w	ip, ip, #1
    /* Store (unprivileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    1786:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
#endif
    dsb
    178a:	f3bf 8f4f 	dsb	sy
    msr CONTROL, ip
    178e:	f38c 8814 	msr	CONTROL, ip

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    1792:	f3bf 8f6f 	isb	sy
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    pop {r0, r1, r2, r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r0, r1}
    1796:	bc03      	pop	{r0, r1}
    push {r0, r1}
    ldr r0, =z_thread_entry
    mov ip, r0
    pop {r0, r1}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr ip, =z_thread_entry
    1798:	f8df c008 	ldr.w	ip, [pc, #8]	; 17a4 <z_arm_userspace_enter+0x80>
#endif
    bx ip
    179c:	4760      	bx	ip
    179e:	0000      	.short	0x0000
    ldr r0, =_kernel
    17a0:	20000eec 	.word	0x20000eec
    ldr ip, =z_thread_entry
    17a4:	000059e3 	.word	0x000059e3

000017a8 <z_arm_do_syscall>:
    pop {r0, r1}

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)

    /* setup privileged stack */
    ldr ip, =_kernel
    17a8:	f8df c088 	ldr.w	ip, [pc, #136]	; 1834 <dispatch_syscall+0x5a>
    ldr ip, [ip, #_kernel_offset_to_current]
    17ac:	f8dc c008 	ldr.w	ip, [ip, #8]
    ldr ip, [ip, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    17b0:	f8dc c098 	ldr.w	ip, [ip, #152]	; 0x98
    add ip, #CONFIG_PRIVILEGED_STACK_SIZE
    17b4:	f50c 6c80 	add.w	ip, ip, #1024	; 0x400

    /* Store current SP and LR at the beginning of the priv stack */
    subs ip, #8
    17b8:	f1bc 0c08 	subs.w	ip, ip, #8
    str sp, [ip, #0]
    17bc:	f8cc d000 	str.w	sp, [ip]
    str lr, [ip, #4]
    17c0:	f8cc e004 	str.w	lr, [ip, #4]
#endif

    /* switch to privileged stack */
    msr PSP, ip
    17c4:	f38c 8809 	msr	PSP, ip
    mov lr, r0
    /* Restore r0 */
    mov r0, ip

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr ip, =K_SYSCALL_BAD
    17c8:	f240 1c0b 	movw	ip, #267	; 0x10b
    cmp r6, ip
    17cc:	4566      	cmp	r6, ip
    bne valid_syscall
    17ce:	d103      	bne.n	17d8 <valid_syscall>

    /* BAD SYSCALL path */
    /* fixup stack frame on the privileged stack, adding ssf */
    mov ip, sp
    17d0:	46ec      	mov	ip, sp
    push {r4,r5,ip,lr}
    17d2:	e92d 5030 	stmdb	sp!, {r4, r5, ip, lr}
    b dispatch_syscall
    17d6:	e000      	b.n	17da <dispatch_syscall>

000017d8 <valid_syscall>:

valid_syscall:
    /* push args to complete stack frame */
    push {r4,r5}
    17d8:	b430      	push	{r4, r5}

000017da <dispatch_syscall>:

dispatch_syscall:
    ldr ip, =_k_syscall_table
    17da:	f8df c05c 	ldr.w	ip, [pc, #92]	; 1838 <dispatch_syscall+0x5e>
    lsl r6, #2
    17de:	ea4f 0686 	mov.w	r6, r6, lsl #2
    add ip, r6
    17e2:	44b4      	add	ip, r6
    ldr ip, [ip]	/* load table address */
    17e4:	f8dc c000 	ldr.w	ip, [ip]
    /* execute function from dispatch table */
    blx ip
    17e8:	47e0      	blx	ip

    /* restore LR */
    ldr lr, [sp,#12]
    17ea:	f8dd e00c 	ldr.w	lr, [sp, #12]
    /* Restore r0 */
    mov r0, ip

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* set stack back to unprivileged stack */
    ldr ip, [sp,#8]
    17ee:	f8dd c008 	ldr.w	ip, [sp, #8]
    msr PSP, ip
    17f2:	f38c 8809 	msr	PSP, ip
    /* Restore interrupt lock status */
    msr BASEPRI, r2
    isb
#endif

    push {r0, r1}
    17f6:	b403      	push	{r0, r1}
    mrs r2, CONTROL
    orrs r2, r2, r3
    msr CONTROL, r2
    pop {r2, r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r0, =_kernel
    17f8:	480e      	ldr	r0, [pc, #56]	; (1834 <dispatch_syscall+0x5a>)
    ldr r0, [r0, #_kernel_offset_to_current]
    17fa:	6880      	ldr	r0, [r0, #8]
    ldr r1, [r0, #_thread_offset_to_mode]
    17fc:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    orrs r1, r1, #1
    1800:	f051 0101 	orrs.w	r1, r1, #1
    /* Store (unprivileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    1804:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
    dsb
    1808:	f3bf 8f4f 	dsb	sy
    /* drop privileges by setting bit 0 in CONTROL */
    mrs ip, CONTROL
    180c:	f3ef 8c14 	mrs	ip, CONTROL
    orrs ip, ip, #1
    1810:	f05c 0c01 	orrs.w	ip, ip, #1
    msr CONTROL, ip
    1814:	f38c 8814 	msr	CONTROL, ip

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    1818:	f3bf 8f6f 	isb	sy
    pop {r0, r1}
    181c:	bc03      	pop	{r0, r1}

    /* Zero out volatile (caller-saved) registers so as to not leak state from
     * kernel mode. The C calling convention for the syscall handler will
     * restore the others to original values.
     */
    mov r1, #0
    181e:	f04f 0100 	mov.w	r1, #0
    mov r2, #0
    1822:	f04f 0200 	mov.w	r2, #0
    mov r3, #0
    1826:	f04f 0300 	mov.w	r3, #0

    /*
     * return back to original function that called SVC, add 1 to force thumb
     * mode
     */
    mov ip, r8
    182a:	46c4      	mov	ip, r8
    orrs ip, ip, #1
    182c:	f05c 0c01 	orrs.w	ip, ip, #1

#endif
    bx ip
    1830:	4760      	bx	ip
    1832:	0000      	.short	0x0000
    ldr ip, =_kernel
    1834:	20000eec 	.word	0x20000eec
    ldr ip, =_k_syscall_table
    1838:	00007364 	.word	0x00007364

0000183c <arch_user_string_nlen>:

/*
 * size_t arch_user_string_nlen(const char *s, size_t maxsize, int *err_arg)
 */
SECTION_FUNC(TEXT, arch_user_string_nlen)
    push {r0, r1, r2, r4, r5, lr}
    183c:	b537      	push	{r0, r1, r2, r4, r5, lr}

    /* sp+4 is error value, init to -1 */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    ldr r3, =-1
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    mov.w r3, #-1
    183e:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
#endif
    str	r3, [sp, #4]
    1842:	9301      	str	r3, [sp, #4]

    /* Perform string length calculation */
    movs r3, #0		/* r3 is the counter */
    1844:	2300      	movs	r3, #0

00001846 <z_arm_user_string_nlen_fault_start>:

strlen_loop:
z_arm_user_string_nlen_fault_start:
    /* r0 contains the string. r5 = *(r0 + r3]). This could fault. */
    ldrb r5, [r0, r3]
    1846:	5cc5      	ldrb	r5, [r0, r3]

00001848 <z_arm_user_string_nlen_fault_end>:
z_arm_user_string_nlen_fault_end:
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cmp r5, #0
    beq strlen_done
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    cbz	r5, strlen_done
    1848:	b11d      	cbz	r5, 1852 <strlen_done>
#endif
    cmp	r3, r1
    184a:	428b      	cmp	r3, r1
    beq.n strlen_done
    184c:	d001      	beq.n	1852 <strlen_done>

    adds r3, #1
    184e:	3301      	adds	r3, #1
    b.n	strlen_loop
    1850:	e7f9      	b.n	1846 <z_arm_user_string_nlen_fault_start>

00001852 <strlen_done>:

strlen_done:
    /* Move length calculation from r3 to r0 (return value register) */
    mov	r0, r3
    1852:	4618      	mov	r0, r3

    /* Clear error value since we succeeded */
    movs r1, #0
    1854:	2100      	movs	r1, #0
    str	r1, [sp, #4]
    1856:	9101      	str	r1, [sp, #4]

00001858 <z_arm_user_string_nlen_fixup>:

z_arm_user_string_nlen_fixup:
    /* Write error value to err pointer parameter */
    ldr	r1, [sp, #4]
    1858:	9901      	ldr	r1, [sp, #4]
    str	r1, [r2, #0]
    185a:	6011      	str	r1, [r2, #0]

    add	sp, #12
    185c:	b003      	add	sp, #12
    pop	{r4, r5, pc}
    185e:	bd30      	pop	{r4, r5, pc}

00001860 <__start>:
 * search for a __start symbol instead, so create that alias here.
 */
SECTION_SUBSEC_FUNC(TEXT,_reset_section,__start)

#if defined(CONFIG_PLATFORM_SPECIFIC_INIT)
    bl z_platform_init
    1860:	f004 fce5 	bl	622e <z_platform_init>

    /* lock interrupts: will get unlocked when switch to main task */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    1864:	2020      	movs	r0, #32
    msr BASEPRI, r0
    1866:	f380 8811 	msr	BASEPRI, r0

    /*
     * Set PSP and use it to boot without using MSP, so that it
     * gets set to z_interrupt_stacks during initialization.
     */
    ldr r0, =z_interrupt_stacks
    186a:	4808      	ldr	r0, [pc, #32]	; (188c <__start+0x2c>)
    ldr r1, =CONFIG_ISR_STACK_SIZE
    186c:	f44f 6100 	mov.w	r1, #2048	; 0x800
    adds r0, r0, r1
    1870:	1840      	adds	r0, r0, r1
    msr PSP, r0
    1872:	f380 8809 	msr	PSP, r0
    mrs r0, CONTROL
    1876:	f3ef 8014 	mrs	r0, CONTROL
    movs r1, #2
    187a:	2102      	movs	r1, #2
    orrs r0, r1 /* CONTROL_SPSEL_Msk */
    187c:	4308      	orrs	r0, r1
    msr CONTROL, r0
    187e:	f380 8814 	msr	CONTROL, r0
    /*
     * When changing the stack pointer, software must use an ISB instruction
     * immediately after the MSR instruction. This ensures that instructions
     * after the ISB instruction execute using the new stack pointer.
     */
    isb
    1882:	f3bf 8f6f 	isb	sy
    /*
     * 'bl' jumps the furthest of the branch instructions that are
     * supported on all platforms. So it is used when jumping to z_arm_prep_c
     * (even though we do not intend to return).
     */
    bl z_arm_prep_c
    1886:	f7ff ff0b 	bl	16a0 <z_arm_prep_c>
    188a:	0000      	.short	0x0000
    ldr r0, =z_interrupt_stacks
    188c:	20001c70 	.word	0x20001c70

00001890 <z_arm_bus_fault>:
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
SECTION_SUBSEC_FUNC(TEXT,__fault,z_arm_exc_spurious)

	mrs r0, MSP
    1890:	f3ef 8008 	mrs	r0, MSP
	mrs r1, PSP
    1894:	f3ef 8109 	mrs	r1, PSP
	mov r2, lr /* EXC_RETURN */
    1898:	4672      	mov	r2, lr

	push {r0, lr}
    189a:	b501      	push	{r0, lr}

	bl z_arm_fault
    189c:	f000 f8dc 	bl	1a58 <z_arm_fault>

	pop {r0, pc}
    18a0:	bd01      	pop	{r0, pc}
    18a2:	bf00      	nop

000018a4 <mem_manage_fault>:
 *
 * @return error code to identify the fatal error reason
 */
static uint32_t mem_manage_fault(z_arch_esf_t *esf, int from_hard_fault,
			      bool *recoverable)
{
    18a4:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	uint32_t mmfar = -EINVAL;

	PR_FAULT_INFO("***** MPU FAULT *****");

	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    18a6:	4c2a      	ldr	r4, [pc, #168]	; (1950 <mem_manage_fault+0xac>)
{
    18a8:	4605      	mov	r5, r0
    18aa:	4616      	mov	r6, r2
	return arch_is_user_context();
    18ac:	f004 fc29 	bl	6102 <arch_is_user_context>
	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    18b0:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18b2:	06d8      	lsls	r0, r3, #27
    18b4:	d501      	bpl.n	18ba <mem_manage_fault+0x16>
    18b6:	f004 fc24 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  Stacking error (context area might be"
			" not valid)");
	}
	if ((SCB->CFSR & SCB_CFSR_MUNSTKERR_Msk) != 0) {
    18ba:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18bc:	071a      	lsls	r2, r3, #28
    18be:	d501      	bpl.n	18c4 <mem_manage_fault+0x20>
    18c0:	f004 fc1f 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  Unstacking error");
	}
	if ((SCB->CFSR & SCB_CFSR_DACCVIOL_Msk) != 0) {
    18c4:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18c6:	079b      	lsls	r3, r3, #30
    18c8:	d530      	bpl.n	192c <mem_manage_fault+0x88>
    18ca:	f004 fc1a 	bl	6102 <arch_is_user_context>
		 * The MMFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another higher
		 * priority exception might change the MMFAR value.
		 */
		mmfar = SCB->MMFAR;
    18ce:	6b62      	ldr	r2, [r4, #52]	; 0x34

		if ((SCB->CFSR & SCB_CFSR_MMARVALID_Msk) != 0) {
    18d0:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18d2:	0618      	lsls	r0, r3, #24
    18d4:	d506      	bpl.n	18e4 <mem_manage_fault+0x40>
    18d6:	f004 fc14 	bl	6102 <arch_is_user_context>
			PR_EXC("  MMFAR Address: 0x%x", mmfar);
			if (from_hard_fault) {
    18da:	b119      	cbz	r1, 18e4 <mem_manage_fault+0x40>
				/* clear SCB_MMAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_MMARVALID_Msk;
    18dc:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18de:	f023 0380 	bic.w	r3, r3, #128	; 0x80
    18e2:	62a3      	str	r3, [r4, #40]	; 0x28
			}
		}
	}
	if ((SCB->CFSR & SCB_CFSR_IACCVIOL_Msk) != 0) {
    18e4:	491a      	ldr	r1, [pc, #104]	; (1950 <mem_manage_fault+0xac>)
    18e6:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    18e8:	07db      	lsls	r3, r3, #31
    18ea:	d501      	bpl.n	18f0 <mem_manage_fault+0x4c>
    18ec:	f004 fc09 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  Instruction Access Violation");
	}
#if defined(CONFIG_ARMV7_M_ARMV8_M_FP)
	if ((SCB->CFSR & SCB_CFSR_MLSPERR_Msk) != 0) {
    18f0:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    18f2:	069c      	lsls	r4, r3, #26
    18f4:	d501      	bpl.n	18fa <mem_manage_fault+0x56>
    18f6:	f004 fc04 	bl	6102 <arch_is_user_context>
	 * if the memory violation error is a stack corruption.
	 *
	 * By design, being a Stacking MemManage fault is a necessary
	 * and sufficient condition for a thread stack corruption.
	 */
	if (SCB->CFSR & SCB_CFSR_MSTKERR_Msk) {
    18fa:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    18fc:	06d8      	lsls	r0, r3, #27
    18fe:	d418      	bmi.n	1932 <mem_manage_fault+0x8e>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    1900:	2000      	movs	r0, #0
		"Stacking error without stack guard / User-mode support\n");
#endif /* CONFIG_MPU_STACK_GUARD || CONFIG_USERSPACE */
	}

	/* clear MMFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;
    1902:	4a13      	ldr	r2, [pc, #76]	; (1950 <mem_manage_fault+0xac>)
    1904:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1906:	f043 03ff 	orr.w	r3, r3, #255	; 0xff
    190a:	6293      	str	r3, [r2, #40]	; 0x28
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    190c:	4b11      	ldr	r3, [pc, #68]	; (1954 <mem_manage_fault+0xb0>)
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    190e:	69aa      	ldr	r2, [r5, #24]
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1910:	f023 0301 	bic.w	r3, r3, #1
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1914:	4293      	cmp	r3, r2
    1916:	d819      	bhi.n	194c <mem_manage_fault+0xa8>
    1918:	4b0f      	ldr	r3, [pc, #60]	; (1958 <mem_manage_fault+0xb4>)
    191a:	f023 0301 	bic.w	r3, r3, #1
    191e:	4293      	cmp	r3, r2
    1920:	d914      	bls.n	194c <mem_manage_fault+0xa8>
			esf->basic.pc = (uint32_t)(exceptions[i].fixup);
    1922:	4b0e      	ldr	r3, [pc, #56]	; (195c <mem_manage_fault+0xb8>)
    1924:	61ab      	str	r3, [r5, #24]
			return true;
    1926:	2301      	movs	r3, #1

	/* Assess whether system shall ignore/recover from this MPU fault. */
	*recoverable = memory_fault_recoverable(esf);
    1928:	7033      	strb	r3, [r6, #0]

	return reason;
}
    192a:	bd70      	pop	{r4, r5, r6, pc}
	uint32_t mmfar = -EINVAL;
    192c:	f06f 0215 	mvn.w	r2, #21
    1930:	e7d8      	b.n	18e4 <mem_manage_fault+0x40>
		if (SCB->ICSR & SCB_ICSR_RETTOBASE_Msk) {
    1932:	684b      	ldr	r3, [r1, #4]
    1934:	051b      	lsls	r3, r3, #20
    1936:	d5e3      	bpl.n	1900 <mem_manage_fault+0x5c>
			uint32_t min_stack_ptr = z_check_thread_stack_fail(mmfar,
    1938:	4629      	mov	r1, r5
    193a:	4610      	mov	r0, r2
    193c:	f7ff fe5a 	bl	15f4 <z_check_thread_stack_fail>
			if (min_stack_ptr) {
    1940:	2800      	cmp	r0, #0
    1942:	d0dd      	beq.n	1900 <mem_manage_fault+0x5c>
  __ASM volatile ("MSR psp, %0" : : "r" (topOfProcStack) : );
    1944:	f380 8809 	msr	PSP, r0
				reason = K_ERR_STACK_CHK_FAIL;
    1948:	2002      	movs	r0, #2
    194a:	e7da      	b.n	1902 <mem_manage_fault+0x5e>
	return false;
    194c:	2300      	movs	r3, #0
    194e:	e7eb      	b.n	1928 <mem_manage_fault+0x84>
    1950:	e000ed00 	.word	0xe000ed00
    1954:	00001847 	.word	0x00001847
    1958:	00001849 	.word	0x00001849
    195c:	00001859 	.word	0x00001859

00001960 <usage_fault.isra.0>:
 *
 * See z_arm_fault_dump() for example.
 *
 * @return error code to identify the fatal error reason
 */
static uint32_t usage_fault(const z_arch_esf_t *esf)
    1960:	b508      	push	{r3, lr}
    1962:	f004 fbce 	bl	6102 <arch_is_user_context>
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** USAGE FAULT *****");

	/* bits are sticky: they stack and must be reset */
	if ((SCB->CFSR & SCB_CFSR_DIVBYZERO_Msk) != 0) {
    1966:	4a14      	ldr	r2, [pc, #80]	; (19b8 <usage_fault.isra.0+0x58>)
    1968:	6a93      	ldr	r3, [r2, #40]	; 0x28
    196a:	0198      	lsls	r0, r3, #6
    196c:	d501      	bpl.n	1972 <usage_fault.isra.0+0x12>
    196e:	f004 fbc8 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  Division by zero");
	}
	if ((SCB->CFSR & SCB_CFSR_UNALIGNED_Msk) != 0) {
    1972:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1974:	01d9      	lsls	r1, r3, #7
    1976:	d501      	bpl.n	197c <usage_fault.isra.0+0x1c>
    1978:	f004 fbc3 	bl	6102 <arch_is_user_context>
		 */
		reason = K_ERR_STACK_CHK_FAIL;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
	}
#endif /* CONFIG_ARMV8_M_MAINLINE */
	if ((SCB->CFSR & SCB_CFSR_NOCP_Msk) != 0) {
    197c:	6a93      	ldr	r3, [r2, #40]	; 0x28
    197e:	031b      	lsls	r3, r3, #12
    1980:	d501      	bpl.n	1986 <usage_fault.isra.0+0x26>
    1982:	f004 fbbe 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  No coprocessor instructions");
	}
	if ((SCB->CFSR & SCB_CFSR_INVPC_Msk) != 0) {
    1986:	4a0c      	ldr	r2, [pc, #48]	; (19b8 <usage_fault.isra.0+0x58>)
    1988:	6a93      	ldr	r3, [r2, #40]	; 0x28
    198a:	0358      	lsls	r0, r3, #13
    198c:	d501      	bpl.n	1992 <usage_fault.isra.0+0x32>
    198e:	f004 fbb8 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  Illegal load of EXC_RETURN into PC");
	}
	if ((SCB->CFSR & SCB_CFSR_INVSTATE_Msk) != 0) {
    1992:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1994:	0399      	lsls	r1, r3, #14
    1996:	d501      	bpl.n	199c <usage_fault.isra.0+0x3c>
    1998:	f004 fbb3 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  Illegal use of the EPSR");
	}
	if ((SCB->CFSR & SCB_CFSR_UNDEFINSTR_Msk) != 0) {
    199c:	6a93      	ldr	r3, [r2, #40]	; 0x28
    199e:	03db      	lsls	r3, r3, #15
    19a0:	d501      	bpl.n	19a6 <usage_fault.isra.0+0x46>
    19a2:	f004 fbae 	bl	6102 <arch_is_user_context>
		PR_FAULT_INFO("  Attempt to execute undefined instruction");
	}

	/* clear UFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    19a6:	4a04      	ldr	r2, [pc, #16]	; (19b8 <usage_fault.isra.0+0x58>)
    19a8:	6a93      	ldr	r3, [r2, #40]	; 0x28
    19aa:	ea6f 4303 	mvn.w	r3, r3, lsl #16
    19ae:	ea6f 4313 	mvn.w	r3, r3, lsr #16
    19b2:	6293      	str	r3, [r2, #40]	; 0x28

	return reason;
}
    19b4:	2000      	movs	r0, #0
    19b6:	bd08      	pop	{r3, pc}
    19b8:	e000ed00 	.word	0xe000ed00

000019bc <bus_fault>:
{
    19bc:	b538      	push	{r3, r4, r5, lr}
	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    19be:	4c22      	ldr	r4, [pc, #136]	; (1a48 <bus_fault+0x8c>)
{
    19c0:	4605      	mov	r5, r0
    19c2:	f004 fb9e 	bl	6102 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    19c6:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19c8:	04d8      	lsls	r0, r3, #19
    19ca:	d501      	bpl.n	19d0 <bus_fault+0x14>
    19cc:	f004 fb99 	bl	6102 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_UNSTKERR_Msk) {
    19d0:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19d2:	051b      	lsls	r3, r3, #20
    19d4:	d501      	bpl.n	19da <bus_fault+0x1e>
    19d6:	f004 fb94 	bl	6102 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_PRECISERR_Msk) {
    19da:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19dc:	0598      	lsls	r0, r3, #22
    19de:	d50c      	bpl.n	19fa <bus_fault+0x3e>
    19e0:	f004 fb8f 	bl	6102 <arch_is_user_context>
		STORE_xFAR(bfar, SCB->BFAR);
    19e4:	6ba3      	ldr	r3, [r4, #56]	; 0x38
		if ((SCB->CFSR & SCB_CFSR_BFARVALID_Msk) != 0) {
    19e6:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19e8:	041b      	lsls	r3, r3, #16
    19ea:	d506      	bpl.n	19fa <bus_fault+0x3e>
    19ec:	f004 fb89 	bl	6102 <arch_is_user_context>
			if (from_hard_fault) {
    19f0:	b119      	cbz	r1, 19fa <bus_fault+0x3e>
				SCB->CFSR &= ~SCB_CFSR_BFARVALID_Msk;
    19f2:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19f4:	f423 4300 	bic.w	r3, r3, #32768	; 0x8000
    19f8:	62a3      	str	r3, [r4, #40]	; 0x28
	if (SCB->CFSR & SCB_CFSR_IMPRECISERR_Msk) {
    19fa:	4913      	ldr	r1, [pc, #76]	; (1a48 <bus_fault+0x8c>)
    19fc:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    19fe:	055c      	lsls	r4, r3, #21
    1a00:	d501      	bpl.n	1a06 <bus_fault+0x4a>
    1a02:	f004 fb7e 	bl	6102 <arch_is_user_context>
	if ((SCB->CFSR & SCB_CFSR_IBUSERR_Msk) != 0) {
    1a06:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a08:	05d8      	lsls	r0, r3, #23
    1a0a:	d516      	bpl.n	1a3a <bus_fault+0x7e>
    1a0c:	f004 fb79 	bl	6102 <arch_is_user_context>
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
    1a10:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a12:	f443 437f 	orr.w	r3, r3, #65280	; 0xff00
    1a16:	628b      	str	r3, [r1, #40]	; 0x28
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1a18:	4b0c      	ldr	r3, [pc, #48]	; (1a4c <bus_fault+0x90>)
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1a1a:	69a9      	ldr	r1, [r5, #24]
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1a1c:	f023 0301 	bic.w	r3, r3, #1
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1a20:	428b      	cmp	r3, r1
    1a22:	d80e      	bhi.n	1a42 <bus_fault+0x86>
    1a24:	4b0a      	ldr	r3, [pc, #40]	; (1a50 <bus_fault+0x94>)
    1a26:	f023 0301 	bic.w	r3, r3, #1
    1a2a:	428b      	cmp	r3, r1
    1a2c:	d909      	bls.n	1a42 <bus_fault+0x86>
			esf->basic.pc = (uint32_t)(exceptions[i].fixup);
    1a2e:	4b09      	ldr	r3, [pc, #36]	; (1a54 <bus_fault+0x98>)
    1a30:	61ab      	str	r3, [r5, #24]
			return true;
    1a32:	2301      	movs	r3, #1
	*recoverable = memory_fault_recoverable(esf);
    1a34:	7013      	strb	r3, [r2, #0]
}
    1a36:	2000      	movs	r0, #0
    1a38:	bd38      	pop	{r3, r4, r5, pc}
	} else if (SCB->CFSR & SCB_CFSR_LSPERR_Msk) {
    1a3a:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a3c:	049b      	lsls	r3, r3, #18
    1a3e:	d4e5      	bmi.n	1a0c <bus_fault+0x50>
    1a40:	e7e6      	b.n	1a10 <bus_fault+0x54>
	return false;
    1a42:	2300      	movs	r3, #0
    1a44:	e7f6      	b.n	1a34 <bus_fault+0x78>
    1a46:	bf00      	nop
    1a48:	e000ed00 	.word	0xe000ed00
    1a4c:	00001847 	.word	0x00001847
    1a50:	00001849 	.word	0x00001849
    1a54:	00001859 	.word	0x00001859

00001a58 <z_arm_fault>:
 * @param psp PSP value immediately after the exception occurred
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 *
 */
void z_arm_fault(uint32_t msp, uint32_t psp, uint32_t exc_return)
{
    1a58:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    1a5a:	4b3c      	ldr	r3, [pc, #240]	; (1b4c <z_arm_fault+0xf4>)
    1a5c:	685c      	ldr	r4, [r3, #4]
{
    1a5e:	b08a      	sub	sp, #40	; 0x28
    1a60:	460d      	mov	r5, r1
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    1a62:	f3c4 0408 	ubfx	r4, r4, #0, #9
    1a66:	2600      	movs	r6, #0
    1a68:	f386 8811 	msr	BASEPRI, r6
    1a6c:	f3bf 8f6f 	isb	sy
	if ((exc_return & EXC_RETURN_INDICATOR_PREFIX) !=
    1a70:	f002 437f 	and.w	r3, r2, #4278190080	; 0xff000000
    1a74:	f1b3 4f7f 	cmp.w	r3, #4278190080	; 0xff000000
    1a78:	d105      	bne.n	1a86 <z_arm_fault+0x2e>
	if ((exc_return & EXC_RETURN_MODE_THREAD) &&
    1a7a:	f002 030c 	and.w	r3, r2, #12
    1a7e:	2b08      	cmp	r3, #8
    1a80:	d103      	bne.n	1a8a <z_arm_fault+0x32>
    1a82:	f004 fb3e 	bl	6102 <arch_is_user_context>
		return NULL;
    1a86:	4635      	mov	r5, r6
    1a88:	e003      	b.n	1a92 <z_arm_fault+0x3a>
		if (exc_return & EXC_RETURN_MODE_THREAD) {
    1a8a:	0712      	lsls	r2, r2, #28
    1a8c:	d401      	bmi.n	1a92 <z_arm_fault+0x3a>
			ptr_esf = (z_arch_esf_t *)msp;
    1a8e:	4605      	mov	r5, r0
			*nested_exc = true;
    1a90:	2601      	movs	r6, #1
	*recoverable = false;
    1a92:	2200      	movs	r2, #0
    1a94:	1ee3      	subs	r3, r4, #3
    1a96:	f88d 2007 	strb.w	r2, [sp, #7]
	switch (fault) {
    1a9a:	2b03      	cmp	r3, #3
    1a9c:	d80c      	bhi.n	1ab8 <z_arm_fault+0x60>
    1a9e:	e8df f003 	tbb	[pc, r3]
    1aa2:	4802      	.short	0x4802
    1aa4:	454c      	.short	0x454c
    1aa6:	f004 fb2c 	bl	6102 <arch_is_user_context>
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    1aaa:	4b28      	ldr	r3, [pc, #160]	; (1b4c <z_arm_fault+0xf4>)
	*recoverable = false;
    1aac:	f88d 2007 	strb.w	r2, [sp, #7]
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    1ab0:	6adc      	ldr	r4, [r3, #44]	; 0x2c
    1ab2:	f014 0402 	ands.w	r4, r4, #2
    1ab6:	d003      	beq.n	1ac0 <z_arm_fault+0x68>
    1ab8:	f004 fb23 	bl	6102 <arch_is_user_context>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    1abc:	2400      	movs	r4, #0
}
    1abe:	e00e      	b.n	1ade <z_arm_fault+0x86>
	} else if ((SCB->HFSR & SCB_HFSR_FORCED_Msk) != 0) {
    1ac0:	6adb      	ldr	r3, [r3, #44]	; 0x2c
    1ac2:	005b      	lsls	r3, r3, #1
    1ac4:	d50b      	bpl.n	1ade <z_arm_fault+0x86>
    1ac6:	f004 fb1c 	bl	6102 <arch_is_user_context>
		if (SCB_MMFSR != 0) {
    1aca:	4b21      	ldr	r3, [pc, #132]	; (1b50 <z_arm_fault+0xf8>)
    1acc:	781b      	ldrb	r3, [r3, #0]
    1ace:	b1f3      	cbz	r3, 1b0e <z_arm_fault+0xb6>
			reason = mem_manage_fault(esf, 1, recoverable);
    1ad0:	f10d 0207 	add.w	r2, sp, #7
    1ad4:	2101      	movs	r1, #1
		reason = mem_manage_fault(esf, 0, recoverable);
    1ad6:	4628      	mov	r0, r5
    1ad8:	f7ff fee4 	bl	18a4 <mem_manage_fault>
		reason = usage_fault(esf);
    1adc:	4604      	mov	r4, r0
	 esf = get_esf(msp, psp, exc_return, &nested_exc);
	__ASSERT(esf != NULL,
		"ESF could not be retrieved successfully. Shall never occur.");

	reason = fault_handle(esf, fault, &recoverable);
	if (recoverable) {
    1ade:	f89d 3007 	ldrb.w	r3, [sp, #7]
    1ae2:	b993      	cbnz	r3, 1b0a <z_arm_fault+0xb2>
		return;
	}

	/* Copy ESF */
	memcpy(&esf_copy, esf, sizeof(z_arch_esf_t));
    1ae4:	2220      	movs	r2, #32
    1ae6:	4629      	mov	r1, r5
    1ae8:	a802      	add	r0, sp, #8
    1aea:	f004 fb45 	bl	6178 <memcpy>
	/* Overwrite stacked IPSR to mark a nested exception,
	 * or a return to Thread mode. Note that this may be
	 * required, if the retrieved ESF contents are invalid
	 * due to, for instance, a stacking error.
	 */
	if (nested_exc) {
    1aee:	9b09      	ldr	r3, [sp, #36]	; 0x24
    1af0:	b33e      	cbz	r6, 1b42 <z_arm_fault+0xea>
		if ((esf_copy.basic.xpsr & IPSR_ISR_Msk) == 0) {
    1af2:	f3c3 0208 	ubfx	r2, r3, #0, #9
    1af6:	b922      	cbnz	r2, 1b02 <z_arm_fault+0xaa>
			esf_copy.basic.xpsr |= IPSR_ISR_Msk;
    1af8:	ea6f 2353 	mvn.w	r3, r3, lsr #9
    1afc:	ea6f 2343 	mvn.w	r3, r3, lsl #9
		}
	} else {
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    1b00:	9309      	str	r3, [sp, #36]	; 0x24
	}

	z_arm_fatal_error(reason, &esf_copy);
    1b02:	a902      	add	r1, sp, #8
    1b04:	4620      	mov	r0, r4
    1b06:	f004 facb 	bl	60a0 <z_arm_fatal_error>
}
    1b0a:	b00a      	add	sp, #40	; 0x28
    1b0c:	bd70      	pop	{r4, r5, r6, pc}
		} else if (SCB_BFSR != 0) {
    1b0e:	4b11      	ldr	r3, [pc, #68]	; (1b54 <z_arm_fault+0xfc>)
    1b10:	781b      	ldrb	r3, [r3, #0]
    1b12:	b133      	cbz	r3, 1b22 <z_arm_fault+0xca>
			reason = bus_fault(esf, 1, recoverable);
    1b14:	f10d 0207 	add.w	r2, sp, #7
    1b18:	2101      	movs	r1, #1
		reason = bus_fault(esf, 0, recoverable);
    1b1a:	4628      	mov	r0, r5
    1b1c:	f7ff ff4e 	bl	19bc <bus_fault>
    1b20:	e7dc      	b.n	1adc <z_arm_fault+0x84>
		} else if (SCB_UFSR != 0) {
    1b22:	4b0d      	ldr	r3, [pc, #52]	; (1b58 <z_arm_fault+0x100>)
    1b24:	881b      	ldrh	r3, [r3, #0]
    1b26:	b29b      	uxth	r3, r3
    1b28:	2b00      	cmp	r3, #0
    1b2a:	d0d8      	beq.n	1ade <z_arm_fault+0x86>
		reason = usage_fault(esf);
    1b2c:	f7ff ff18 	bl	1960 <usage_fault.isra.0>
    1b30:	e7d4      	b.n	1adc <z_arm_fault+0x84>
		reason = mem_manage_fault(esf, 0, recoverable);
    1b32:	f10d 0207 	add.w	r2, sp, #7
    1b36:	2100      	movs	r1, #0
    1b38:	e7cd      	b.n	1ad6 <z_arm_fault+0x7e>
		reason = bus_fault(esf, 0, recoverable);
    1b3a:	f10d 0207 	add.w	r2, sp, #7
    1b3e:	2100      	movs	r1, #0
    1b40:	e7eb      	b.n	1b1a <z_arm_fault+0xc2>
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    1b42:	f423 73ff 	bic.w	r3, r3, #510	; 0x1fe
    1b46:	f023 0301 	bic.w	r3, r3, #1
    1b4a:	e7d9      	b.n	1b00 <z_arm_fault+0xa8>
    1b4c:	e000ed00 	.word	0xe000ed00
    1b50:	e000ed28 	.word	0xe000ed28
    1b54:	e000ed29 	.word	0xe000ed29
    1b58:	e000ed2a 	.word	0xe000ed2a

00001b5c <z_arm_fault_init>:
 */
void z_arm_fault_init(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	SCB->CCR |= SCB_CCR_DIV_0_TRP_Msk;
    1b5c:	4a02      	ldr	r2, [pc, #8]	; (1b68 <z_arm_fault_init+0xc>)
    1b5e:	6953      	ldr	r3, [r2, #20]
    1b60:	f043 0310 	orr.w	r3, r3, #16
    1b64:	6153      	str	r3, [r2, #20]
	 * Stack to attempt to descend into secure region, in which case a
	 * Secure Hard Fault will occur and we can track the fault from there.
	 */
	SCB->CCR |= SCB_CCR_STKOFHFNMIGN_Msk;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
}
    1b66:	4770      	bx	lr
    1b68:	e000ed00 	.word	0xe000ed00

00001b6c <z_arm_exc_exit>:
 */

SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)

#ifdef CONFIG_PREEMPT_ENABLED
	ldr r3, =_kernel
    1b6c:	4b04      	ldr	r3, [pc, #16]	; (1b80 <_EXIT_EXC+0x2>)

	ldr r1, [r3, #_kernel_offset_to_current]
    1b6e:	6899      	ldr	r1, [r3, #8]
	ldr r0, [r3, #_kernel_offset_to_ready_q_cache]
    1b70:	6a58      	ldr	r0, [r3, #36]	; 0x24
	cmp r0, r1
    1b72:	4288      	cmp	r0, r1
	beq _EXIT_EXC
    1b74:	d003      	beq.n	1b7e <_EXIT_EXC>

	/* context switch required, pend the PendSV exception */
	ldr r1, =_SCS_ICSR
    1b76:	4903      	ldr	r1, [pc, #12]	; (1b84 <_EXIT_EXC+0x6>)
	ldr r2, =_SCS_ICSR_PENDSV
    1b78:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
	str r2, [r1]
    1b7c:	600a      	str	r2, [r1, #0]

00001b7e <_EXIT_EXC>:
#else
	pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_STACK_SENTINEL */

	bx lr
    1b7e:	4770      	bx	lr
	ldr r3, =_kernel
    1b80:	20000eec 	.word	0x20000eec
	ldr r1, =_SCS_ICSR
    1b84:	e000ed04 	.word	0xe000ed04

00001b88 <z_arm_interrupt_init>:
    1b88:	4804      	ldr	r0, [pc, #16]	; (1b9c <z_arm_interrupt_init+0x14>)
 * @return N/A
 */

void z_arm_interrupt_init(void)
{
	int irq = 0;
    1b8a:	2300      	movs	r3, #0
    1b8c:	2120      	movs	r1, #32
    1b8e:	18c2      	adds	r2, r0, r3

	for (; irq < CONFIG_NUM_IRQS; irq++) {
    1b90:	3301      	adds	r3, #1
    1b92:	2b27      	cmp	r3, #39	; 0x27
    1b94:	f882 1300 	strb.w	r1, [r2, #768]	; 0x300
    1b98:	d1f9      	bne.n	1b8e <z_arm_interrupt_init+0x6>
		NVIC_SetPriority((IRQn_Type)irq, _IRQ_PRIO_OFFSET);
	}
}
    1b9a:	4770      	bx	lr
    1b9c:	e000e100 	.word	0xe000e100

00001ba0 <z_impl_k_thread_abort>:
#include <sys/__assert.h>

extern void z_thread_single_abort(struct k_thread *thread);

void z_impl_k_thread_abort(k_tid_t thread)
{
    1ba0:	b538      	push	{r3, r4, r5, lr}
    1ba2:	4604      	mov	r4, r0
	__asm__ volatile(
    1ba4:	f04f 0320 	mov.w	r3, #32
    1ba8:	f3ef 8511 	mrs	r5, BASEPRI
    1bac:	f383 8811 	msr	BASEPRI, r3
    1bb0:	f3bf 8f6f 	isb	sy
	key = irq_lock();

	__ASSERT(!(thread->base.user_options & K_ESSENTIAL),
		 "essential thread aborted");

	z_thread_single_abort(thread);
    1bb4:	f002 fbb0 	bl	4318 <z_thread_single_abort>
	z_thread_monitor_exit(thread);

	if (_current == thread) {
    1bb8:	4b0a      	ldr	r3, [pc, #40]	; (1be4 <z_impl_k_thread_abort+0x44>)
    1bba:	689b      	ldr	r3, [r3, #8]
    1bbc:	42a3      	cmp	r3, r4
    1bbe:	d10b      	bne.n	1bd8 <z_impl_k_thread_abort+0x38>
		if ((SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk) == 0) {
    1bc0:	4b09      	ldr	r3, [pc, #36]	; (1be8 <z_impl_k_thread_abort+0x48>)
    1bc2:	685a      	ldr	r2, [r3, #4]
    1bc4:	f3c2 0208 	ubfx	r2, r2, #0, #9
    1bc8:	b912      	cbnz	r2, 1bd0 <z_impl_k_thread_abort+0x30>
	int ret;
	z_check_stack_sentinel();
#ifndef CONFIG_ARM
	sys_trace_thread_switched_out();
#endif
	ret = arch_swap(key);
    1bca:	4628      	mov	r0, r5
    1bcc:	f7ff fc1a 	bl	1404 <arch_swap>
			(void)z_swap_irqlock(key);
			CODE_UNREACHABLE;
		} else {
			SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    1bd0:	685a      	ldr	r2, [r3, #4]
    1bd2:	f042 5280 	orr.w	r2, r2, #268435456	; 0x10000000
    1bd6:	605a      	str	r2, [r3, #4]
		}
	}

	/* The abort handler might have altered the ready queue. */
	z_reschedule_irqlock(key);
    1bd8:	4628      	mov	r0, r5
}
    1bda:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule_irqlock(key);
    1bde:	f004 be4f 	b.w	6880 <z_reschedule_irqlock>
    1be2:	bf00      	nop
    1be4:	20000eec 	.word	0x20000eec
    1be8:	e000ed00 	.word	0xe000ed00

00001bec <z_arm_configure_static_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_static_mpu_regions(void)
{
    1bec:	b51f      	push	{r0, r1, r2, r3, r4, lr}
		.size = (uint32_t)&_nocache_ram_size,
		.attr = K_MEM_PARTITION_P_RW_U_NA_NOCACHE,
		};
#endif /* CONFIG_NOCACHE_MEMORY */
#if defined(CONFIG_ARCH_HAS_RAMFUNC_SUPPORT)
		const struct k_mem_partition ramfunc_region =
    1bee:	4b08      	ldr	r3, [pc, #32]	; (1c10 <z_arm_configure_static_mpu_regions+0x24>)
    1bf0:	9301      	str	r3, [sp, #4]
    1bf2:	4b08      	ldr	r3, [pc, #32]	; (1c14 <z_arm_configure_static_mpu_regions+0x28>)
    1bf4:	9302      	str	r3, [sp, #8]
    1bf6:	4b08      	ldr	r3, [pc, #32]	; (1c18 <z_arm_configure_static_mpu_regions+0x2c>)
    1bf8:	9303      	str	r3, [sp, #12]

	/* Define a constant array of k_mem_partition objects
	 * to hold the configuration of the respective static
	 * MPU regions.
	 */
	const struct k_mem_partition *static_regions[] = {
    1bfa:	ab01      	add	r3, sp, #4
    1bfc:	9300      	str	r3, [sp, #0]
	/* Configure the static MPU regions within firmware SRAM boundaries.
	 * Start address of the image is given by _image_ram_start. The end
	 * of the firmware SRAM area is marked by __kernel_ram_end, taking
	 * into account the unused SRAM area, as well.
	 */
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    1bfe:	4a07      	ldr	r2, [pc, #28]	; (1c1c <z_arm_configure_static_mpu_regions+0x30>)
    1c00:	4b07      	ldr	r3, [pc, #28]	; (1c20 <z_arm_configure_static_mpu_regions+0x34>)
    1c02:	2101      	movs	r1, #1
    1c04:	4668      	mov	r0, sp
    1c06:	f000 f93d 	bl	1e84 <arm_core_mpu_configure_static_mpu_regions>
	};

	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
		ARRAY_SIZE(dyn_region_areas));
#endif /* CONFIG_MPU_REQUIRES_NON_OVERLAPPING_REGIONS */
}
    1c0a:	b005      	add	sp, #20
    1c0c:	f85d fb04 	ldr.w	pc, [sp], #4
    1c10:	20000000 	.word	0x20000000
    1c14:	00000000 	.word	0x00000000
    1c18:	060b0000 	.word	0x060b0000
    1c1c:	20000000 	.word	0x20000000
    1c20:	20010000 	.word	0x20010000

00001c24 <z_arm_configure_dynamic_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_dynamic_mpu_regions(struct k_thread *thread)
{
    1c24:	b570      	push	{r4, r5, r6, lr}
    1c26:	4604      	mov	r4, r0
    1c28:	b094      	sub	sp, #80	; 0x50
    1c2a:	f004 fa74 	bl	6116 <arch_is_user_context>
#if defined(CONFIG_USERSPACE)
	struct k_mem_partition thread_stack;

	/* Memory domain */
	LOG_DBG("configure thread %p's domain", thread);
	struct k_mem_domain *mem_domain = thread->mem_domain_info.mem_domain;
    1c2e:	6fe1      	ldr	r1, [r4, #124]	; 0x7c

	if (mem_domain) {
    1c30:	b1d1      	cbz	r1, 1c68 <z_arm_configure_dynamic_mpu_regions+0x44>
    1c32:	f004 fa70 	bl	6116 <arch_is_user_context>
		LOG_DBG("configure domain: %p", mem_domain);
		uint32_t num_partitions = mem_domain->num_partitions;
    1c36:	f891 50c8 	ldrb.w	r5, [r1, #200]	; 0xc8
    1c3a:	f004 fa6c 	bl	6116 <arch_is_user_context>
		struct k_mem_partition partition;
		int i;

		LOG_DBG("configure domain: %p", mem_domain);

		for (i = 0; i < CONFIG_MAX_DOMAIN_PARTITIONS; i++) {
    1c3e:	460a      	mov	r2, r1
    1c40:	f101 06c0 	add.w	r6, r1, #192	; 0xc0
	uint8_t region_num = 0U;
    1c44:	2100      	movs	r1, #0
			partition = mem_domain->partitions[i];
			if (partition.size == 0) {
    1c46:	6853      	ldr	r3, [r2, #4]
    1c48:	b15b      	cbz	r3, 1c62 <z_arm_configure_dynamic_mpu_regions+0x3e>
    1c4a:	f004 fa64 	bl	6116 <arch_is_user_context>
			}
			LOG_DBG("set region 0x%lx 0x%x",
				partition.start, partition.size);
			__ASSERT(region_num < _MAX_DYNAMIC_MPU_REGIONS_NUM,
				"Out-of-bounds error for dynamic region map.");
			dynamic_regions[region_num] =
    1c4e:	ab14      	add	r3, sp, #80	; 0x50
    1c50:	eb03 0381 	add.w	r3, r3, r1, lsl #2
				&mem_domain->partitions[i];

			region_num++;
			num_partitions--;
			if (num_partitions == 0U) {
    1c54:	3d01      	subs	r5, #1
			region_num++;
    1c56:	f101 0101 	add.w	r1, r1, #1
			dynamic_regions[region_num] =
    1c5a:	f843 2c44 	str.w	r2, [r3, #-68]
			region_num++;
    1c5e:	b2c9      	uxtb	r1, r1
			if (num_partitions == 0U) {
    1c60:	d002      	beq.n	1c68 <z_arm_configure_dynamic_mpu_regions+0x44>
		for (i = 0; i < CONFIG_MAX_DOMAIN_PARTITIONS; i++) {
    1c62:	320c      	adds	r2, #12
    1c64:	4296      	cmp	r6, r2
    1c66:	d1ee      	bne.n	1c46 <z_arm_configure_dynamic_mpu_regions+0x22>
    1c68:	f004 fa55 	bl	6116 <arch_is_user_context>
			}
		}
	}
	/* Thread user stack */
	LOG_DBG("configure user thread %p's context", thread);
	if (thread->arch.priv_stack_start) {
    1c6c:	f8d4 3098 	ldr.w	r3, [r4, #152]	; 0x98
    1c70:	b183      	cbz	r3, 1c94 <z_arm_configure_dynamic_mpu_regions+0x70>
		/* K_USER thread stack needs a region */
		uint32_t base = (uint32_t)thread->stack_obj;
		uint32_t size = thread->stack_info.size +
    1c72:	e9d4 031a 	ldrd	r0, r3, [r4, #104]	; 0x68
		uint32_t base = (uint32_t)thread->stack_obj;
    1c76:	f8d4 2080 	ldr.w	r2, [r4, #128]	; 0x80
		uint32_t size = thread->stack_info.size +
    1c7a:	4403      	add	r3, r0
    1c7c:	1a9b      	subs	r3, r3, r2
			(thread->stack_info.start - base);

		__ASSERT(region_num < _MAX_DYNAMIC_MPU_REGIONS_NUM,
			"Out-of-bounds error for dynamic region map.");
		thread_stack = (const struct k_mem_partition)
    1c7e:	e9cd 2300 	strd	r2, r3, [sp]
    1c82:	4b07      	ldr	r3, [pc, #28]	; (1ca0 <z_arm_configure_dynamic_mpu_regions+0x7c>)
    1c84:	9302      	str	r3, [sp, #8]
			{base, size, K_MEM_PARTITION_P_RW_U_RW};

		dynamic_regions[region_num] = &thread_stack;
    1c86:	ab14      	add	r3, sp, #80	; 0x50
    1c88:	eb03 0381 	add.w	r3, r3, r1, lsl #2

		region_num++;
    1c8c:	3101      	adds	r1, #1
		dynamic_regions[region_num] = &thread_stack;
    1c8e:	f843 dc44 	str.w	sp, [r3, #-68]
		region_num++;
    1c92:	b2c9      	uxtb	r1, r1

	region_num++;
#endif /* CONFIG_MPU_STACK_GUARD */

	/* Configure the dynamic MPU regions */
	arm_core_mpu_configure_dynamic_mpu_regions(
    1c94:	a803      	add	r0, sp, #12
    1c96:	f000 f91b 	bl	1ed0 <arm_core_mpu_configure_dynamic_mpu_regions>
		(const struct k_mem_partition **)dynamic_regions,
		region_num);
}
    1c9a:	b014      	add	sp, #80	; 0x50
    1c9c:	bd70      	pop	{r4, r5, r6, pc}
    1c9e:	bf00      	nop
    1ca0:	130b0000 	.word	0x130b0000

00001ca4 <arch_mem_domain_thread_add>:
	return ARM_CORE_MPU_MAX_DOMAIN_PARTITIONS_GET(available_regions);
}

void arch_mem_domain_thread_add(struct k_thread *thread)
{
	if (_current != thread) {
    1ca4:	4b03      	ldr	r3, [pc, #12]	; (1cb4 <arch_mem_domain_thread_add+0x10>)
    1ca6:	689b      	ldr	r3, [r3, #8]
    1ca8:	4283      	cmp	r3, r0
    1caa:	d101      	bne.n	1cb0 <arch_mem_domain_thread_add+0xc>

	/* Request to configure memory domain for a thread.
	 * This triggers re-programming of the entire dynamic
	 * memory map.
	 */
	z_arm_configure_dynamic_mpu_regions(thread);
    1cac:	f7ff bfba 	b.w	1c24 <z_arm_configure_dynamic_mpu_regions>
}
    1cb0:	4770      	bx	lr
    1cb2:	bf00      	nop
    1cb4:	20000eec 	.word	0x20000eec

00001cb8 <is_enabled_region>:
    1cb8:	f04f 0320 	mov.w	r3, #32
    1cbc:	f3ef 8211 	mrs	r2, BASEPRI
    1cc0:	f383 8811 	msr	BASEPRI, r3
    1cc4:	f3bf 8f6f 	isb	sy
	/* Lock IRQs to ensure RNR value is correct when reading RASR. */
	unsigned int key;
	uint32_t rasr;

	key = irq_lock();
	MPU->RNR = index;
    1cc8:	4b04      	ldr	r3, [pc, #16]	; (1cdc <is_enabled_region+0x24>)
    1cca:	6098      	str	r0, [r3, #8]
	rasr = MPU->RASR;
    1ccc:	6918      	ldr	r0, [r3, #16]
	__asm__ volatile(
    1cce:	f382 8811 	msr	BASEPRI, r2
    1cd2:	f3bf 8f6f 	isb	sy
	irq_unlock(key);

	return (rasr & MPU_RASR_ENABLE_Msk) ? 1 : 0;
}
    1cd6:	f000 0001 	and.w	r0, r0, #1
    1cda:	4770      	bx	lr
    1cdc:	e000ed90 	.word	0xe000ed90

00001ce0 <mpu_configure_region>:
/* This internal function programs an MPU region
 * of a given configuration at a given MPU index.
 */
static int mpu_configure_region(const uint8_t index,
	const struct k_mem_partition *new_region)
{
    1ce0:	b538      	push	{r3, r4, r5, lr}
    1ce2:	4604      	mov	r4, r0
    1ce4:	f004 fa28 	bl	6138 <arch_is_user_context>

	LOG_DBG("Configure MPU region at index 0x%x", index);

	/* Populate internal ARM MPU region configuration structure. */
	region_conf.base = new_region->start;
	get_region_attr_from_k_mem_partition_info(&region_conf.attr,
    1ce8:	e9d1 5300 	ldrd	r5, r3, [r1]
	if (size <= 32U) {
    1cec:	2b20      	cmp	r3, #32
    1cee:	6889      	ldr	r1, [r1, #8]
    1cf0:	d912      	bls.n	1d18 <mpu_configure_region+0x38>
	if (size > (1UL << 31)) {
    1cf2:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
    1cf6:	d811      	bhi.n	1d1c <mpu_configure_region+0x3c>
	return ((32 - __builtin_clz(size - 1) - 2 + 1) << MPU_RASR_SIZE_Pos) &
    1cf8:	3b01      	subs	r3, #1
    1cfa:	fab3 f383 	clz	r3, r3
    1cfe:	f1c3 031f 	rsb	r3, r3, #31
    1d02:	005b      	lsls	r3, r3, #1
	if (index > (get_num_regions() - 1)) {
    1d04:	2c07      	cmp	r4, #7
	p_attr->rasr = attr->rasr_attr | size_to_mpu_rasr_size(size);
    1d06:	ea41 0103 	orr.w	r1, r1, r3
    1d0a:	d909      	bls.n	1d20 <mpu_configure_region+0x40>
    1d0c:	f004 fa14 	bl	6138 <arch_is_user_context>
		return -EINVAL;
    1d10:	f06f 0415 	mvn.w	r4, #21
		&new_region->attr, new_region->start, new_region->size);

	/* Allocate and program region */
	return region_allocate_and_init(index,
		(const struct arm_mpu_region *)&region_conf);
}
    1d14:	4620      	mov	r0, r4
    1d16:	bd38      	pop	{r3, r4, r5, pc}
		return REGION_32B;
    1d18:	2308      	movs	r3, #8
    1d1a:	e7f3      	b.n	1d04 <mpu_configure_region+0x24>
		return REGION_4G;
    1d1c:	233e      	movs	r3, #62	; 0x3e
    1d1e:	e7f1      	b.n	1d04 <mpu_configure_region+0x24>
    1d20:	f004 fa0a 	bl	6138 <arch_is_user_context>
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1d24:	f025 051f 	bic.w	r5, r5, #31
	MPU->RNR = index;
    1d28:	4805      	ldr	r0, [pc, #20]	; (1d40 <mpu_configure_region+0x60>)
				| MPU_RBAR_VALID_Msk | index;
    1d2a:	4325      	orrs	r5, r4
    1d2c:	f045 0510 	orr.w	r5, r5, #16
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1d30:	f041 0101 	orr.w	r1, r1, #1
	MPU->RNR = index;
    1d34:	6084      	str	r4, [r0, #8]
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1d36:	60c5      	str	r5, [r0, #12]
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1d38:	6101      	str	r1, [r0, #16]
    1d3a:	f004 f9fd 	bl	6138 <arch_is_user_context>
	return region_allocate_and_init(index,
    1d3e:	e7e9      	b.n	1d14 <mpu_configure_region+0x34>
    1d40:	e000ed90 	.word	0xe000ed90

00001d44 <arm_core_mpu_enable>:
void arm_core_mpu_enable(void)
{
	/* Enable MPU and use the default memory map as a
	 * background region for privileged software access.
	 */
	MPU->CTRL = MPU_CTRL_ENABLE_Msk | MPU_CTRL_PRIVDEFENA_Msk;
    1d44:	4b03      	ldr	r3, [pc, #12]	; (1d54 <arm_core_mpu_enable+0x10>)
    1d46:	2205      	movs	r2, #5
    1d48:	605a      	str	r2, [r3, #4]
  __ASM volatile ("dsb 0xF":::"memory");
    1d4a:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    1d4e:	f3bf 8f6f 	isb	sy

	/* Make sure that all the registers are set before proceeding */
	__DSB();
	__ISB();
}
    1d52:	4770      	bx	lr
    1d54:	e000ed90 	.word	0xe000ed90

00001d58 <arm_core_mpu_disable>:
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
    1d58:	f3bf 8f5f 	dmb	sy
{
	/* Force any outstanding transfers to complete before disabling MPU */
	__DMB();

	/* Disable MPU */
	MPU->CTRL = 0;
    1d5c:	4b01      	ldr	r3, [pc, #4]	; (1d64 <arm_core_mpu_disable+0xc>)
    1d5e:	2200      	movs	r2, #0
    1d60:	605a      	str	r2, [r3, #4]
}
    1d62:	4770      	bx	lr
    1d64:	e000ed90 	.word	0xe000ed90

00001d68 <arm_mpu_init>:
 */
static int arm_mpu_init(struct device *arg)
{
	uint32_t r_index;

	if (mpu_config.num_regions > get_num_regions()) {
    1d68:	4915      	ldr	r1, [pc, #84]	; (1dc0 <arm_mpu_init+0x58>)
{
    1d6a:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (mpu_config.num_regions > get_num_regions()) {
    1d6c:	680c      	ldr	r4, [r1, #0]
    1d6e:	2c08      	cmp	r4, #8
    1d70:	d822      	bhi.n	1db8 <arm_mpu_init+0x50>
	MPU->RNR = index;
    1d72:	4d14      	ldr	r5, [pc, #80]	; (1dc4 <arm_mpu_init+0x5c>)
    1d74:	f004 f9e0 	bl	6138 <arch_is_user_context>
	/* Architecture-specific configuration */
	mpu_init();

	/* Program fixed regions configured at SOC definition. */
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    1d78:	260c      	movs	r6, #12
	arm_core_mpu_disable();
    1d7a:	f7ff ffed 	bl	1d58 <arm_core_mpu_disable>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    1d7e:	2200      	movs	r2, #0
    1d80:	4294      	cmp	r4, r2
    1d82:	d105      	bne.n	1d90 <arm_mpu_init+0x28>
	}

	/* Update the number of programmed MPU regions. */
	static_regions_num = mpu_config.num_regions;
    1d84:	4b10      	ldr	r3, [pc, #64]	; (1dc8 <arm_mpu_init+0x60>)
    1d86:	701c      	strb	r4, [r3, #0]


	arm_core_mpu_enable();
    1d88:	f7ff ffdc 	bl	1d44 <arm_core_mpu_enable>
	__ASSERT(
		(MPU->TYPE & MPU_TYPE_DREGION_Msk) >> MPU_TYPE_DREGION_Pos ==
		NUM_MPU_REGIONS,
		"Invalid number of MPU regions\n");
#endif /* CORTEX_M0PLUS || CPU_CORTEX_M3 || CPU_CORTEX_M4 */
	return 0;
    1d8c:	2000      	movs	r0, #0
}
    1d8e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    1d90:	fb06 f302 	mul.w	r3, r6, r2
    1d94:	6848      	ldr	r0, [r1, #4]
    1d96:	60aa      	str	r2, [r5, #8]
    1d98:	18c7      	adds	r7, r0, r3
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1d9a:	58c3      	ldr	r3, [r0, r3]
    1d9c:	f023 031f 	bic.w	r3, r3, #31
				| MPU_RBAR_VALID_Msk | index;
    1da0:	4313      	orrs	r3, r2
    1da2:	f043 0310 	orr.w	r3, r3, #16
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1da6:	60eb      	str	r3, [r5, #12]
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1da8:	68bb      	ldr	r3, [r7, #8]
    1daa:	f043 0301 	orr.w	r3, r3, #1
    1dae:	612b      	str	r3, [r5, #16]
    1db0:	f004 f9c2 	bl	6138 <arch_is_user_context>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    1db4:	3201      	adds	r2, #1
    1db6:	e7e3      	b.n	1d80 <arm_mpu_init+0x18>
		return -1;
    1db8:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    1dbc:	e7e7      	b.n	1d8e <arm_mpu_init+0x26>
    1dbe:	bf00      	nop
    1dc0:	000072e8 	.word	0x000072e8
    1dc4:	e000ed90 	.word	0xe000ed90
    1dc8:	20001344 	.word	0x20001344

00001dcc <arm_core_mpu_get_max_available_dyn_regions>:
	return get_num_regions() - static_regions_num;
    1dcc:	4b02      	ldr	r3, [pc, #8]	; (1dd8 <arm_core_mpu_get_max_available_dyn_regions+0xc>)
    1dce:	7818      	ldrb	r0, [r3, #0]
}
    1dd0:	f1c0 0008 	rsb	r0, r0, #8
    1dd4:	4770      	bx	lr
    1dd6:	bf00      	nop
    1dd8:	20001344 	.word	0x20001344

00001ddc <arm_core_mpu_buffer_validate>:
{
    1ddc:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    1de0:	2900      	cmp	r1, #0
	/* Lock IRQs to ensure RNR value is correct when reading RBAR, RASR. */
	unsigned int key;
	uint32_t rbar, rasr;

	key = irq_lock();
	MPU->RNR = r_index;
    1de2:	4e27      	ldr	r6, [pc, #156]	; (1e80 <arm_core_mpu_buffer_validate+0xa4>)
	r_addr_start = rbar & MPU_RBAR_ADDR_Msk;
	r_size_lshift = ((rasr & MPU_RASR_SIZE_Msk) >>
			MPU_RASR_SIZE_Pos) + 1;
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;

	size = size == 0 ? 0 : size - 1;
    1de4:	f101 35ff 	add.w	r5, r1, #4294967295	; 0xffffffff
    1de8:	4604      	mov	r4, r0
    1dea:	4617      	mov	r7, r2
static inline int mpu_buffer_validate(void *addr, size_t size, int write)
{
	int32_t r_index;

	/* Iterate all mpu regions in reversed order */
	for (r_index = get_num_regions() - 1; r_index >= 0;  r_index--) {
    1dec:	bf08      	it	eq
    1dee:	2500      	moveq	r5, #0
    1df0:	2107      	movs	r1, #7
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;
    1df2:	f04f 0801 	mov.w	r8, #1
		if (!is_enabled_region(r_index) ||
    1df6:	4608      	mov	r0, r1
    1df8:	f7ff ff5e 	bl	1cb8 <is_enabled_region>
    1dfc:	2800      	cmp	r0, #0
    1dfe:	d037      	beq.n	1e70 <arm_core_mpu_buffer_validate+0x94>
	__asm__ volatile(
    1e00:	f04f 0320 	mov.w	r3, #32
    1e04:	f3ef 8011 	mrs	r0, BASEPRI
    1e08:	f383 8811 	msr	BASEPRI, r3
    1e0c:	f3bf 8f6f 	isb	sy
	MPU->RNR = r_index;
    1e10:	60b1      	str	r1, [r6, #8]
	rbar = MPU->RBAR;
    1e12:	68f2      	ldr	r2, [r6, #12]
	rasr = MPU->RASR;
    1e14:	6933      	ldr	r3, [r6, #16]
	__asm__ volatile(
    1e16:	f380 8811 	msr	BASEPRI, r0
    1e1a:	f3bf 8f6f 	isb	sy
	return __builtin_add_overflow(a, b, result);
}

static inline bool u32_add_overflow(uint32_t a, uint32_t b, uint32_t *result)
{
	return __builtin_add_overflow(a, b, result);
    1e1e:	1960      	adds	r0, r4, r5
    1e20:	d226      	bcs.n	1e70 <arm_core_mpu_buffer_validate+0x94>
	r_addr_start = rbar & MPU_RBAR_ADDR_Msk;
    1e22:	f022 021f 	bic.w	r2, r2, #31
	if ((start >= r_addr_start) && (end <= r_addr_end)) {
    1e26:	4294      	cmp	r4, r2
    1e28:	d322      	bcc.n	1e70 <arm_core_mpu_buffer_validate+0x94>
	r_size_lshift = ((rasr & MPU_RASR_SIZE_Msk) >>
    1e2a:	f3c3 0344 	ubfx	r3, r3, #1, #5
    1e2e:	3301      	adds	r3, #1
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;
    1e30:	fa08 f303 	lsl.w	r3, r8, r3
    1e34:	3a01      	subs	r2, #1
    1e36:	4413      	add	r3, r2
	if ((start >= r_addr_start) && (end <= r_addr_end)) {
    1e38:	4283      	cmp	r3, r0
    1e3a:	d319      	bcc.n	1e70 <arm_core_mpu_buffer_validate+0x94>
	__asm__ volatile(
    1e3c:	f04f 0320 	mov.w	r3, #32
    1e40:	f3ef 8211 	mrs	r2, BASEPRI
    1e44:	f383 8811 	msr	BASEPRI, r3
    1e48:	f3bf 8f6f 	isb	sy
	MPU->RNR = r_index;
    1e4c:	60b1      	str	r1, [r6, #8]
	rasr = MPU->RASR;
    1e4e:	6933      	ldr	r3, [r6, #16]
	__asm__ volatile(
    1e50:	f382 8811 	msr	BASEPRI, r2
    1e54:	f3bf 8f6f 	isb	sy
	return (rasr & MPU_RASR_AP_Msk) >> MPU_RASR_AP_Pos;
    1e58:	0e19      	lsrs	r1, r3, #24
    1e5a:	f3c3 6302 	ubfx	r3, r3, #24, #3
	if (write) {
    1e5e:	b167      	cbz	r7, 1e7a <arm_core_mpu_buffer_validate+0x9e>
		return r_ap == P_RW_U_RW;
    1e60:	3b03      	subs	r3, #3
    1e62:	4259      	negs	r1, r3
    1e64:	4159      	adcs	r1, r3
		/* For ARM MPU, higher region number takes priority.
		 * Since we iterate all mpu regions in reversed order, so
		 * we can stop the iteration immediately once we find the
		 * matched region that grants permission or denies access.
		 */
		if (is_user_accessible_region(r_index, write)) {
    1e66:	fab1 f181 	clz	r1, r1
    1e6a:	0949      	lsrs	r1, r1, #5
    1e6c:	4249      	negs	r1, r1
	return mpu_buffer_validate(addr, size, write);
    1e6e:	e001      	b.n	1e74 <arm_core_mpu_buffer_validate+0x98>
	for (r_index = get_num_regions() - 1; r_index >= 0;  r_index--) {
    1e70:	3901      	subs	r1, #1
    1e72:	d2c0      	bcs.n	1df6 <arm_core_mpu_buffer_validate+0x1a>
}
    1e74:	4608      	mov	r0, r1
    1e76:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return r_ap & MPU_USER_READ_ACCESSIBLE_Msk;
    1e7a:	f001 0102 	and.w	r1, r1, #2
    1e7e:	e7f2      	b.n	1e66 <arm_core_mpu_buffer_validate+0x8a>
    1e80:	e000ed90 	.word	0xe000ed90

00001e84 <arm_core_mpu_configure_static_mpu_regions>:
{
    1e84:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
static int mpu_configure_static_mpu_regions(const struct k_mem_partition
	*static_regions[], const uint8_t regions_num,
	const uint32_t background_area_base,
	const uint32_t background_area_end)
{
	int mpu_reg_index = static_regions_num;
    1e86:	4c11      	ldr	r4, [pc, #68]	; (1ecc <arm_core_mpu_configure_static_mpu_regions+0x48>)
    1e88:	4607      	mov	r7, r0
	int reg_index = start_reg_index;
    1e8a:	7820      	ldrb	r0, [r4, #0]
{
    1e8c:	460e      	mov	r6, r1
	for (i = 0; i < regions_num; i++) {
    1e8e:	2500      	movs	r5, #0
    1e90:	42b5      	cmp	r5, r6
    1e92:	da11      	bge.n	1eb8 <arm_core_mpu_configure_static_mpu_regions+0x34>
		if (regions[i]->size == 0U) {
    1e94:	f857 1025 	ldr.w	r1, [r7, r5, lsl #2]
    1e98:	684b      	ldr	r3, [r1, #4]
    1e9a:	b1ab      	cbz	r3, 1ec8 <arm_core_mpu_configure_static_mpu_regions+0x44>
		((part->size & (part->size - 1)) == 0U)
    1e9c:	1e5a      	subs	r2, r3, #1
		&&
    1e9e:	4213      	tst	r3, r2
    1ea0:	d10c      	bne.n	1ebc <arm_core_mpu_configure_static_mpu_regions+0x38>
		&&
    1ea2:	2b1f      	cmp	r3, #31
    1ea4:	d90a      	bls.n	1ebc <arm_core_mpu_configure_static_mpu_regions+0x38>
		((part->start & (part->size - 1)) == 0U);
    1ea6:	680b      	ldr	r3, [r1, #0]
		&&
    1ea8:	421a      	tst	r2, r3
    1eaa:	d107      	bne.n	1ebc <arm_core_mpu_configure_static_mpu_regions+0x38>
		reg_index = mpu_configure_region(reg_index, regions[i]);
    1eac:	b2c0      	uxtb	r0, r0
    1eae:	f7ff ff17 	bl	1ce0 <mpu_configure_region>
		if (reg_index == -EINVAL) {
    1eb2:	f110 0f16 	cmn.w	r0, #22
    1eb6:	d106      	bne.n	1ec6 <arm_core_mpu_configure_static_mpu_regions+0x42>
	ARG_UNUSED(background_area_end);

	mpu_reg_index = mpu_configure_regions(static_regions,
		regions_num, mpu_reg_index, true);

	static_regions_num = mpu_reg_index;
    1eb8:	7020      	strb	r0, [r4, #0]
}
    1eba:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    1ebc:	f004 f93c 	bl	6138 <arch_is_user_context>
			return -EINVAL;
    1ec0:	f06f 0015 	mvn.w	r0, #21
    1ec4:	e7f8      	b.n	1eb8 <arm_core_mpu_configure_static_mpu_regions+0x34>
		reg_index++;
    1ec6:	3001      	adds	r0, #1
	for (i = 0; i < regions_num; i++) {
    1ec8:	3501      	adds	r5, #1
    1eca:	e7e1      	b.n	1e90 <arm_core_mpu_configure_static_mpu_regions+0xc>
    1ecc:	20001344 	.word	0x20001344

00001ed0 <arm_core_mpu_configure_dynamic_mpu_regions>:
{
    1ed0:	b538      	push	{r3, r4, r5, lr}
 * performed, the error signal is propagated to the caller of the function.
 */
static int mpu_configure_dynamic_mpu_regions(const struct k_mem_partition
	*dynamic_regions[], uint8_t regions_num)
{
	int mpu_reg_index = static_regions_num;
    1ed2:	4b10      	ldr	r3, [pc, #64]	; (1f14 <arm_core_mpu_configure_dynamic_mpu_regions+0x44>)
    1ed4:	4605      	mov	r5, r0
	int reg_index = start_reg_index;
    1ed6:	7818      	ldrb	r0, [r3, #0]
{
    1ed8:	460c      	mov	r4, r1
	for (i = 0; i < regions_num; i++) {
    1eda:	2200      	movs	r2, #0
    1edc:	42a2      	cmp	r2, r4
    1ede:	db07      	blt.n	1ef0 <arm_core_mpu_configure_dynamic_mpu_regions+0x20>
	 */

	mpu_reg_index = mpu_configure_regions(dynamic_regions,
		regions_num, mpu_reg_index, false);

	if (mpu_reg_index != -EINVAL) {
    1ee0:	f110 0f16 	cmn.w	r0, #22
    1ee4:	d003      	beq.n	1eee <arm_core_mpu_configure_dynamic_mpu_regions+0x1e>
/** Clear and disable the given MPU region.
* \param rnr Region number to be cleared.
*/
__STATIC_INLINE void ARM_MPU_ClrRegion(uint32_t rnr)
{
  MPU->RNR = rnr;
    1ee6:	4a0c      	ldr	r2, [pc, #48]	; (1f18 <arm_core_mpu_configure_dynamic_mpu_regions+0x48>)
  MPU->RASR = 0U;
    1ee8:	2100      	movs	r1, #0

		/* Disable the non-programmed MPU regions. */
		for (int i = mpu_reg_index; i < get_num_regions(); i++) {
    1eea:	2807      	cmp	r0, #7
    1eec:	dd0d      	ble.n	1f0a <arm_core_mpu_configure_dynamic_mpu_regions+0x3a>
}
    1eee:	bd38      	pop	{r3, r4, r5, pc}
		if (regions[i]->size == 0U) {
    1ef0:	f855 1022 	ldr.w	r1, [r5, r2, lsl #2]
    1ef4:	684b      	ldr	r3, [r1, #4]
    1ef6:	b133      	cbz	r3, 1f06 <arm_core_mpu_configure_dynamic_mpu_regions+0x36>
		reg_index = mpu_configure_region(reg_index, regions[i]);
    1ef8:	b2c0      	uxtb	r0, r0
    1efa:	f7ff fef1 	bl	1ce0 <mpu_configure_region>
		if (reg_index == -EINVAL) {
    1efe:	f110 0f16 	cmn.w	r0, #22
    1f02:	d0f4      	beq.n	1eee <arm_core_mpu_configure_dynamic_mpu_regions+0x1e>
		reg_index++;
    1f04:	3001      	adds	r0, #1
	for (i = 0; i < regions_num; i++) {
    1f06:	3201      	adds	r2, #1
    1f08:	e7e8      	b.n	1edc <arm_core_mpu_configure_dynamic_mpu_regions+0xc>
  MPU->RNR = rnr;
    1f0a:	6090      	str	r0, [r2, #8]
  MPU->RASR = 0U;
    1f0c:	6111      	str	r1, [r2, #16]
    1f0e:	3001      	adds	r0, #1
    1f10:	e7eb      	b.n	1eea <arm_core_mpu_configure_dynamic_mpu_regions+0x1a>
    1f12:	bf00      	nop
    1f14:	20001344 	.word	0x20001344
    1f18:	e000ed90 	.word	0xe000ed90

00001f1c <__stdout_hook_install>:

static int (*_stdout_hook)(int) = _stdout_hook_default;

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
    1f1c:	4b01      	ldr	r3, [pc, #4]	; (1f24 <__stdout_hook_install+0x8>)
    1f1e:	6018      	str	r0, [r3, #0]
}
    1f20:	4770      	bx	lr
    1f22:	bf00      	nop
    1f24:	20003404 	.word	0x20003404

00001f28 <z_impl_zephyr_fputc>:

int z_impl_zephyr_fputc(int c, FILE *stream)
{
	return (stdout == stream) ? _stdout_hook(c) : EOF;
    1f28:	2902      	cmp	r1, #2
    1f2a:	d102      	bne.n	1f32 <z_impl_zephyr_fputc+0xa>
    1f2c:	4b02      	ldr	r3, [pc, #8]	; (1f38 <z_impl_zephyr_fputc+0x10>)
    1f2e:	681b      	ldr	r3, [r3, #0]
    1f30:	4718      	bx	r3
}
    1f32:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    1f36:	4770      	bx	lr
    1f38:	20003404 	.word	0x20003404

00001f3c <z_mrsh_zephyr_fputc>:
#include <syscalls/libc-hooks.h>

extern int z_vrfy_zephyr_fputc(int c, FILE * stream);
uintptr_t z_mrsh_zephyr_fputc(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    1f3c:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    1f3e:	4c06      	ldr	r4, [pc, #24]	; (1f58 <z_mrsh_zephyr_fputc+0x1c>)
    1f40:	9a04      	ldr	r2, [sp, #16]
    1f42:	68a3      	ldr	r3, [r4, #8]
    1f44:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_zephyr_fputc(int c, FILE *stream)
{
	return z_impl_zephyr_fputc(c, stream);
    1f48:	f7ff ffee 	bl	1f28 <z_impl_zephyr_fputc>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_zephyr_fputc(*(int*)&arg0, *(FILE **)&arg1)
;
	_current->syscall_frame = NULL;
    1f4c:	68a3      	ldr	r3, [r4, #8]
    1f4e:	2200      	movs	r2, #0
    1f50:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    1f54:	bd10      	pop	{r4, pc}
    1f56:	bf00      	nop
    1f58:	20000eec 	.word	0x20000eec

00001f5c <z_impl_zephyr_fwrite>:
{
	size_t i;
	size_t j;
	const unsigned char *p;

	if ((stream != stdout) || (nitems == 0) || (size == 0)) {
    1f5c:	2b02      	cmp	r3, #2
{
    1f5e:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    1f62:	4606      	mov	r6, r0
    1f64:	460c      	mov	r4, r1
    1f66:	4615      	mov	r5, r2
	if ((stream != stdout) || (nitems == 0) || (size == 0)) {
    1f68:	d115      	bne.n	1f96 <z_impl_zephyr_fwrite+0x3a>
    1f6a:	b1b2      	cbz	r2, 1f9a <z_impl_zephyr_fwrite+0x3e>
    1f6c:	b181      	cbz	r1, 1f90 <z_impl_zephyr_fwrite+0x34>
	p = ptr;
	i = nitems;
	do {
		j = size;
		do {
			if (_stdout_hook((int) *p++) == EOF) {
    1f6e:	f8df 9030 	ldr.w	r9, [pc, #48]	; 1fa0 <z_impl_zephyr_fwrite+0x44>
    1f72:	4617      	mov	r7, r2
		j = size;
    1f74:	46b0      	mov	r8, r6
    1f76:	4426      	add	r6, r4
			if (_stdout_hook((int) *p++) == EOF) {
    1f78:	f8d9 3000 	ldr.w	r3, [r9]
    1f7c:	f818 0b01 	ldrb.w	r0, [r8], #1
    1f80:	4798      	blx	r3
    1f82:	3001      	adds	r0, #1
    1f84:	d003      	beq.n	1f8e <z_impl_zephyr_fwrite+0x32>
				goto done;
			}
			j--;
		} while (j > 0);
    1f86:	4546      	cmp	r6, r8
    1f88:	d1f6      	bne.n	1f78 <z_impl_zephyr_fwrite+0x1c>

		i--;
	} while (i > 0);
    1f8a:	3f01      	subs	r7, #1
    1f8c:	d1f2      	bne.n	1f74 <z_impl_zephyr_fwrite+0x18>

done:
	return (nitems - i);
    1f8e:	1bec      	subs	r4, r5, r7
}
    1f90:	4620      	mov	r0, r4
    1f92:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
		return 0;
    1f96:	2400      	movs	r4, #0
    1f98:	e7fa      	b.n	1f90 <z_impl_zephyr_fwrite+0x34>
    1f9a:	4614      	mov	r4, r2
    1f9c:	e7f8      	b.n	1f90 <z_impl_zephyr_fwrite+0x34>
    1f9e:	bf00      	nop
    1fa0:	20003404 	.word	0x20003404

00001fa4 <z_mrsh_zephyr_fwrite>:
#include <syscalls/libc-hooks.h>

extern size_t z_vrfy_zephyr_fwrite(const void *_MLIBC_RESTRICT ptr, size_t size, size_t nitems, FILE *_MLIBC_RESTRICT stream);
uintptr_t z_mrsh_zephyr_fwrite(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    1fa4:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    1fa8:	4f12      	ldr	r7, [pc, #72]	; (1ff4 <z_mrsh_zephyr_fwrite+0x50>)
{
    1faa:	469a      	mov	sl, r3
	_current->syscall_frame = ssf;
    1fac:	68bb      	ldr	r3, [r7, #8]
{
    1fae:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
    1fb0:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    1fb2:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return __builtin_mul_overflow(a, b, result);
}

static inline bool size_mul_overflow(size_t a, size_t b, size_t *result)
{
	return __builtin_mul_overflow(a, b, result);
    1fb6:	fba6 3401 	umull	r3, r4, r6, r1
{
    1fba:	4680      	mov	r8, r0
    1fbc:	460d      	mov	r5, r1
    1fbe:	46b9      	mov	r9, r7
    1fc0:	b92c      	cbnz	r4, 1fce <z_mrsh_zephyr_fwrite+0x2a>
static inline size_t z_vrfy_zephyr_fwrite(const void *_MLIBC_RESTRICT ptr,
					  size_t size, size_t nitems,
					  FILE *_MLIBC_RESTRICT stream)
{

	Z_OOPS(Z_SYSCALL_MEMORY_ARRAY_READ(ptr, nitems, size));
    1fc2:	4622      	mov	r2, r4
    1fc4:	4619      	mov	r1, r3
    1fc6:	f004 f8b5 	bl	6134 <arch_buffer_validate>
    1fca:	4604      	mov	r4, r0
    1fcc:	b138      	cbz	r0, 1fde <z_mrsh_zephyr_fwrite+0x3a>
    1fce:	f004 f921 	bl	6214 <arch_is_user_context>
    1fd2:	f8d9 3008 	ldr.w	r3, [r9, #8]
    1fd6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    1fda:	f004 f87d 	bl	60d8 <arch_syscall_oops>
	return z_impl_zephyr_fwrite((const void *_MLIBC_RESTRICT)ptr, size,
    1fde:	4653      	mov	r3, sl
    1fe0:	4632      	mov	r2, r6
    1fe2:	4629      	mov	r1, r5
    1fe4:	4640      	mov	r0, r8
    1fe6:	f7ff ffb9 	bl	1f5c <z_impl_zephyr_fwrite>
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	size_t ret = z_vrfy_zephyr_fwrite(*(const void *_MLIBC_RESTRICT*)&arg0, *(size_t*)&arg1, *(size_t*)&arg2, *(FILE *_MLIBC_RESTRICT*)&arg3)
;
	_current->syscall_frame = NULL;
    1fea:	68bb      	ldr	r3, [r7, #8]
    1fec:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    1ff0:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    1ff4:	20000eec 	.word	0x20000eec

00001ff8 <nordicsemi_nrf52_init>:
	__asm__ volatile(
    1ff8:	f04f 0320 	mov.w	r3, #32
    1ffc:	f3ef 8211 	mrs	r2, BASEPRI
    2000:	f383 8811 	msr	BASEPRI, r3
    2004:	f3bf 8f6f 	isb	sy

	key = irq_lock();

#ifdef CONFIG_NRF_ENABLE_ICACHE
	/* Enable the instruction cache */
	NRF_NVMC->ICACHECNF = NVMC_ICACHECNF_CACHEEN_Msk;
    2008:	4906      	ldr	r1, [pc, #24]	; (2024 <nordicsemi_nrf52_init+0x2c>)
    200a:	2301      	movs	r3, #1
    200c:	f8c1 3540 	str.w	r3, [r1, #1344]	; 0x540
#endif

#if NRF_POWER_HAS_DCDCEN
NRF_STATIC_INLINE void nrf_power_dcdcen_set(NRF_POWER_Type * p_reg, bool enable)
{
    p_reg->DCDCEN = (enable ? POWER_DCDCEN_DCDCEN_Enabled : POWER_DCDCEN_DCDCEN_Disabled) <<
    2010:	f04f 4180 	mov.w	r1, #1073741824	; 0x40000000
    2014:	f8c1 3578 	str.w	r3, [r1, #1400]	; 0x578
	__asm__ volatile(
    2018:	f382 8811 	msr	BASEPRI, r2
    201c:	f3bf 8f6f 	isb	sy
	NMI_INIT();

	irq_unlock(key);

	return 0;
}
    2020:	2000      	movs	r0, #0
    2022:	4770      	bx	lr
    2024:	4001e000 	.word	0x4001e000

00002028 <arch_busy_wait>:

#else // NRFX_CHECK(NRFX_DELAY_DWT_BASED)

NRF_STATIC_INLINE void nrfx_coredep_delay_us(uint32_t time_us)
{
    if (time_us == 0)
    2028:	b120      	cbz	r0, 2034 <arch_busy_wait+0xc>
    };

    typedef void (* delay_func_t)(uint32_t);
    const delay_func_t delay_cycles =
        // Set LSB to 1 to execute the code in the Thumb mode.
        (delay_func_t)((((uint32_t)delay_machine_code) | 1));
    202a:	4b03      	ldr	r3, [pc, #12]	; (2038 <arch_busy_wait+0x10>)
    uint32_t cycles = time_us * NRFX_DELAY_CPU_FREQ_MHZ;
    delay_cycles(cycles);
    202c:	0180      	lsls	r0, r0, #6
    202e:	f043 0301 	orr.w	r3, r3, #1
    2032:	4718      	bx	r3

void arch_busy_wait(uint32_t time_us)
{
	nrfx_coredep_delay_us(time_us);
}
    2034:	4770      	bx	lr
    2036:	bf00      	nop
    2038:	000072b0 	.word	0x000072b0

0000203c <gpio_nrfx_init>:
}

#define GPIOTE_NODE DT_INST(0, nordic_nrf_gpiote)

static int gpio_nrfx_init(struct device *port)
{
    203c:	b508      	push	{r3, lr}
	static bool gpio_initialized;

	if (!gpio_initialized) {
    203e:	4b09      	ldr	r3, [pc, #36]	; (2064 <gpio_nrfx_init+0x28>)
    2040:	781a      	ldrb	r2, [r3, #0]
    2042:	b96a      	cbnz	r2, 2060 <gpio_nrfx_init+0x24>
		gpio_initialized = true;
    2044:	2101      	movs	r1, #1
    2046:	7019      	strb	r1, [r3, #0]
		IRQ_CONNECT(DT_IRQN(GPIOTE_NODE), DT_IRQ(GPIOTE_NODE, priority),
    2048:	2006      	movs	r0, #6
    204a:	2105      	movs	r1, #5
    204c:	f7ff fa76 	bl	153c <z_arm_irq_priority_set>
			    gpiote_event_handler, NULL, 0);

		irq_enable(DT_IRQN(GPIOTE_NODE));
    2050:	2006      	movs	r0, #6
    2052:	f7ff fa63 	bl	151c <arch_irq_enable>
    return ((uint32_t)p_reg + event);
}

NRF_STATIC_INLINE void nrf_gpiote_int_enable(NRF_GPIOTE_Type * p_reg, uint32_t mask)
{
    p_reg->INTENSET = mask;
    2056:	4b04      	ldr	r3, [pc, #16]	; (2068 <gpio_nrfx_init+0x2c>)
    2058:	f04f 4200 	mov.w	r2, #2147483648	; 0x80000000
    205c:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
		nrf_gpiote_int_enable(NRF_GPIOTE, NRF_GPIOTE_INT_PORT_MASK);
	}

	return 0;
}
    2060:	2000      	movs	r0, #0
    2062:	bd08      	pop	{r3, pc}
    2064:	20001345 	.word	0x20001345
    2068:	40006000 	.word	0x40006000

0000206c <gpio_nrfx_config>:
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    206c:	4b2b      	ldr	r3, [pc, #172]	; (211c <gpio_nrfx_config+0xb0>)
{
    206e:	b5f0      	push	{r4, r5, r6, r7, lr}
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    2070:	6846      	ldr	r6, [r0, #4]
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    2072:	482b      	ldr	r0, [pc, #172]	; (2120 <gpio_nrfx_config+0xb4>)
    2074:	4013      	ands	r3, r2
    2076:	4283      	cmp	r3, r0
    2078:	d040      	beq.n	20fc <gpio_nrfx_config+0x90>
    207a:	d80d      	bhi.n	2098 <gpio_nrfx_config+0x2c>
    207c:	2b06      	cmp	r3, #6
    207e:	d015      	beq.n	20ac <gpio_nrfx_config+0x40>
    2080:	d805      	bhi.n	208e <gpio_nrfx_config+0x22>
    2082:	b19b      	cbz	r3, 20ac <gpio_nrfx_config+0x40>
    2084:	2b02      	cmp	r3, #2
    2086:	d03b      	beq.n	2100 <gpio_nrfx_config+0x94>
    2088:	f06f 0015 	mvn.w	r0, #21
    208c:	e035      	b.n	20fa <gpio_nrfx_config+0x8e>
    208e:	f5b3 1f80 	cmp.w	r3, #1048576	; 0x100000
    2092:	d1f9      	bne.n	2088 <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_H0S1;
    2094:	2301      	movs	r3, #1
    2096:	e009      	b.n	20ac <gpio_nrfx_config+0x40>
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    2098:	4822      	ldr	r0, [pc, #136]	; (2124 <gpio_nrfx_config+0xb8>)
    209a:	4283      	cmp	r3, r0
    209c:	d032      	beq.n	2104 <gpio_nrfx_config+0x98>
    209e:	f5b3 0fa0 	cmp.w	r3, #5242880	; 0x500000
    20a2:	d031      	beq.n	2108 <gpio_nrfx_config+0x9c>
    20a4:	f5b3 0f80 	cmp.w	r3, #4194304	; 0x400000
    20a8:	d1ee      	bne.n	2088 <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_S0H1;
    20aa:	2302      	movs	r3, #2
	if ((flags & GPIO_PULL_UP) != 0) {
    20ac:	06d0      	lsls	r0, r2, #27
		pull = NRF_GPIO_PIN_NOPULL;
    20ae:	bf54      	ite	pl
    20b0:	f3c2 1540 	ubfxpl	r5, r2, #5, #1
		pull = NRF_GPIO_PIN_PULLUP;
    20b4:	2503      	movmi	r5, #3
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    20b6:	f482 7480 	eor.w	r4, r2, #256	; 0x100
	if ((flags & GPIO_OUTPUT) != 0) {
    20ba:	0597      	lsls	r7, r2, #22
	dir = ((flags & GPIO_OUTPUT) != 0)
    20bc:	f3c2 2040 	ubfx	r0, r2, #9, #1
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    20c0:	f3c4 2400 	ubfx	r4, r4, #8, #1
	if ((flags & GPIO_OUTPUT) != 0) {
    20c4:	d507      	bpl.n	20d6 <gpio_nrfx_config+0x6a>
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    20c6:	f412 6f00 	tst.w	r2, #2048	; 0x800
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    20ca:	6877      	ldr	r7, [r6, #4]
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    20cc:	d01e      	beq.n	210c <gpio_nrfx_config+0xa0>
			nrf_gpio_port_out_set(reg, BIT(pin));
    20ce:	2201      	movs	r2, #1
    20d0:	408a      	lsls	r2, r1
}


NRF_STATIC_INLINE void nrf_gpio_port_out_set(NRF_GPIO_Type * p_reg, uint32_t set_mask)
{
    p_reg->OUTSET = set_mask;
    20d2:	f8c7 2508 	str.w	r2, [r7, #1288]	; 0x508
	nrf_gpio_cfg(NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin),
    20d6:	7a32      	ldrb	r2, [r6, #8]
    20d8:	f001 011f 	and.w	r1, r1, #31
    20dc:	ea41 1142 	orr.w	r1, r1, r2, lsl #5
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    20e0:	ea40 0244 	orr.w	r2, r0, r4, lsl #1
    20e4:	ea42 2303 	orr.w	r3, r2, r3, lsl #8
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    20e8:	f501 71e0 	add.w	r1, r1, #448	; 0x1c0
    20ec:	f04f 42a0 	mov.w	r2, #1342177280	; 0x50000000
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    20f0:	ea43 0385 	orr.w	r3, r3, r5, lsl #2
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    20f4:	f842 3021 	str.w	r3, [r2, r1, lsl #2]
	return 0;
    20f8:	2000      	movs	r0, #0
}
    20fa:	bdf0      	pop	{r4, r5, r6, r7, pc}
		drive = NRF_GPIO_PIN_H0D1;
    20fc:	2307      	movs	r3, #7
    20fe:	e7d5      	b.n	20ac <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0S1;
    2100:	2304      	movs	r3, #4
    2102:	e7d3      	b.n	20ac <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0H1;
    2104:	2305      	movs	r3, #5
    2106:	e7d1      	b.n	20ac <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_H0H1;
    2108:	2303      	movs	r3, #3
    210a:	e7cf      	b.n	20ac <gpio_nrfx_config+0x40>
		} else if ((flags & GPIO_OUTPUT_INIT_LOW) != 0) {
    210c:	0552      	lsls	r2, r2, #21
			nrf_gpio_port_out_clear(reg, BIT(pin));
    210e:	bf42      	ittt	mi
    2110:	2201      	movmi	r2, #1
    2112:	408a      	lslmi	r2, r1
}


NRF_STATIC_INLINE void nrf_gpio_port_out_clear(NRF_GPIO_Type * p_reg, uint32_t clr_mask)
{
    p_reg->OUTCLR = clr_mask;
    2114:	f8c7 250c 	strmi.w	r2, [r7, #1292]	; 0x50c
}
    2118:	e7dd      	b.n	20d6 <gpio_nrfx_config+0x6a>
    211a:	bf00      	nop
    211c:	00f00006 	.word	0x00f00006
    2120:	00100006 	.word	0x00100006
    2124:	00400002 	.word	0x00400002

00002128 <gpio_nrfx_pin_interrupt_configure>:
{
    2128:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
	struct gpio_nrfx_data *data = get_port_data(port);
    212a:	68c4      	ldr	r4, [r0, #12]
	uint32_t abs_pin = NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin);
    212c:	6840      	ldr	r0, [r0, #4]
    212e:	7a00      	ldrb	r0, [r0, #8]
    2130:	f001 051f 	and.w	r5, r1, #31
	if ((mode == GPIO_INT_MODE_EDGE) &&
    2134:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    2138:	ea45 1540 	orr.w	r5, r5, r0, lsl #5
    213c:	d10a      	bne.n	2154 <gpio_nrfx_pin_interrupt_configure+0x2c>
    return (nrf_gpio_pin_dir_t)((reg->PIN_CNF[pin_number] &
    213e:	f505 70e0 	add.w	r0, r5, #448	; 0x1c0
    2142:	f04f 46a0 	mov.w	r6, #1342177280	; 0x50000000
    2146:	f856 0020 	ldr.w	r0, [r6, r0, lsl #2]
    214a:	07c7      	lsls	r7, r0, #31
    214c:	d507      	bpl.n	215e <gpio_nrfx_pin_interrupt_configure+0x36>
		return -ENOTSUP;
    214e:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2152:	e0b4      	b.n	22be <gpio_nrfx_pin_interrupt_configure+0x196>
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    2154:	f5b2 5f00 	cmp.w	r2, #8192	; 0x2000
    2158:	68e0      	ldr	r0, [r4, #12]
    215a:	f000 80b2 	beq.w	22c2 <gpio_nrfx_pin_interrupt_configure+0x19a>
    215e:	68e6      	ldr	r6, [r4, #12]
    2160:	2001      	movs	r0, #1
    2162:	4088      	lsls	r0, r1
    2164:	4330      	orrs	r0, r6
    2166:	6966      	ldr	r6, [r4, #20]
    2168:	60e0      	str	r0, [r4, #12]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    216a:	2001      	movs	r0, #1
    216c:	4088      	lsls	r0, r1
    216e:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    2172:	69a2      	ldr	r2, [r4, #24]
    2174:	bf0c      	ite	eq
    2176:	4306      	orreq	r6, r0
    2178:	4386      	bicne	r6, r0
	WRITE_BIT(data->double_edge, pin, trig == GPIO_INT_TRIG_BOTH);
    217a:	f5b3 2fc0 	cmp.w	r3, #393216	; 0x60000
    217e:	bf0c      	ite	eq
    2180:	4302      	orreq	r2, r0
    2182:	4382      	bicne	r2, r0
    2184:	61a2      	str	r2, [r4, #24]
    2186:	6922      	ldr	r2, [r4, #16]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    2188:	6166      	str	r6, [r4, #20]
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    218a:	f5b3 2f80 	cmp.w	r3, #262144	; 0x40000
    218e:	bf0c      	ite	eq
    2190:	4310      	orreq	r0, r2
    2192:	ea22 0000 	bicne.w	r0, r2, r0
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_int_enable_check(NRF_GPIOTE_Type const * p_reg, uint32_t mask)
{
    return p_reg->INTENSET & mask;
    2196:	4a5b      	ldr	r2, [pc, #364]	; (2304 <gpio_nrfx_pin_interrupt_configure+0x1dc>)
    2198:	6120      	str	r0, [r4, #16]
    219a:	f8d2 0304 	ldr.w	r0, [r2, #772]	; 0x304
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    219e:	2300      	movs	r3, #0
    21a0:	b2c0      	uxtb	r0, r0
                        ((polarity << GPIOTE_CONFIG_POLARITY_Pos) & GPIOTE_CONFIG_POLARITY_Msk);
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_event_pin_get(NRF_GPIOTE_Type const * p_reg, uint32_t idx)
{
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    21a2:	f503 76a2 	add.w	r6, r3, #324	; 0x144
    21a6:	f852 6026 	ldr.w	r6, [r2, r6, lsl #2]
    21aa:	f3c6 2604 	ubfx	r6, r6, #8, #5
		if ((nrf_gpiote_event_pin_get(NRF_GPIOTE, i) == abs_pin)
    21ae:	42b5      	cmp	r5, r6
    21b0:	f040 808c 	bne.w	22cc <gpio_nrfx_pin_interrupt_configure+0x1a4>
		    && (intenset & BIT(i))) {
    21b4:	fa20 f603 	lsr.w	r6, r0, r3
    21b8:	07f6      	lsls	r6, r6, #31
    21ba:	f140 8087 	bpl.w	22cc <gpio_nrfx_pin_interrupt_configure+0x1a4>
			(void)atomic_and(mask, ~BIT(i));
    21be:	2001      	movs	r0, #1
    21c0:	4098      	lsls	r0, r3
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    21c2:	4e51      	ldr	r6, [pc, #324]	; (2308 <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    21c4:	f3bf 8f5b 	dmb	ish
    21c8:	43c7      	mvns	r7, r0
    21ca:	e856 cf00 	ldrex	ip, [r6]
    21ce:	ea0c 0c07 	and.w	ip, ip, r7
    21d2:	e846 ce00 	strex	lr, ip, [r6]
    21d6:	f1be 0f00 	cmp.w	lr, #0
    21da:	d1f6      	bne.n	21ca <gpio_nrfx_pin_interrupt_configure+0xa2>
    21dc:	f3bf 8f5b 	dmb	ish
   p_reg->CONFIG[idx] &= ~GPIOTE_CONFIG_MODE_Event;
    21e0:	009b      	lsls	r3, r3, #2
    21e2:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    21e6:	f503 43c0 	add.w	r3, r3, #24576	; 0x6000
    21ea:	f8d3 6510 	ldr.w	r6, [r3, #1296]	; 0x510
    21ee:	f026 0601 	bic.w	r6, r6, #1
    21f2:	f8c3 6510 	str.w	r6, [r3, #1296]	; 0x510
    p_reg->INTENCLR = mask;
    21f6:	f8c2 0308 	str.w	r0, [r2, #776]	; 0x308
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    21fa:	00aa      	lsls	r2, r5, #2
    21fc:	f102 42a0 	add.w	r2, r2, #1342177280	; 0x50000000
	if (data->pin_int_en & BIT(pin)) {
    2200:	68e0      	ldr	r0, [r4, #12]
    2202:	f8d2 3700 	ldr.w	r3, [r2, #1792]	; 0x700
    2206:	40c8      	lsrs	r0, r1
    2208:	f423 3340 	bic.w	r3, r3, #196608	; 0x30000
    220c:	f010 0001 	ands.w	r0, r0, #1
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    2210:	f8c2 3700 	str.w	r3, [r2, #1792]	; 0x700
    2214:	d053      	beq.n	22be <gpio_nrfx_pin_interrupt_configure+0x196>
		if (data->trig_edge & BIT(pin)) {
    2216:	6960      	ldr	r0, [r4, #20]
    2218:	40c8      	lsrs	r0, r1
    221a:	f010 0001 	ands.w	r0, r0, #1
    221e:	d060      	beq.n	22e2 <gpio_nrfx_pin_interrupt_configure+0x1ba>
			if (data->double_edge & BIT(pin)) {
    2220:	69a3      	ldr	r3, [r4, #24]
	return __atomic_fetch_or(target, value, __ATOMIC_SEQ_CST);
    2222:	4a39      	ldr	r2, [pc, #228]	; (2308 <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    2224:	40cb      	lsrs	r3, r1
    2226:	07db      	lsls	r3, r3, #31
			} else if ((data->int_active_level & BIT(pin)) != 0U) {
    2228:	bf5f      	itttt	pl
    222a:	6923      	ldrpl	r3, [r4, #16]
    222c:	fa23 f101 	lsrpl.w	r1, r3, r1
    2230:	f001 0101 	andpl.w	r1, r1, #1
    2234:	f1c1 0102 	rsbpl	r1, r1, #2
    2238:	bf54      	ite	pl
    223a:	b2c9      	uxtbpl	r1, r1
				pol = NRF_GPIOTE_POLARITY_TOGGLE;
    223c:	2103      	movmi	r1, #3
    223e:	2300      	movs	r3, #0
		atomic_val_t prev = atomic_or(mask, BIT(channel));
    2240:	2601      	movs	r6, #1
    2242:	fa06 f403 	lsl.w	r4, r6, r3
    2246:	f3bf 8f5b 	dmb	ish
    224a:	e852 0f00 	ldrex	r0, [r2]
    224e:	ea40 0704 	orr.w	r7, r0, r4
    2252:	e842 7c00 	strex	ip, r7, [r2]
    2256:	f1bc 0f00 	cmp.w	ip, #0
    225a:	d1f6      	bne.n	224a <gpio_nrfx_pin_interrupt_configure+0x122>
    225c:	f3bf 8f5b 	dmb	ish
		if ((prev & BIT(channel)) == 0) {
    2260:	40d8      	lsrs	r0, r3
    2262:	f010 0001 	ands.w	r0, r0, #1
    2266:	d136      	bne.n	22d6 <gpio_nrfx_pin_interrupt_configure+0x1ae>
  p_reg->CONFIG[idx] &= ~(GPIOTE_CONFIG_PORT_PIN_Msk | GPIOTE_CONFIG_POLARITY_Msk);
    2268:	009a      	lsls	r2, r3, #2
    226a:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    226e:	f502 42c0 	add.w	r2, r2, #24576	; 0x6000
			nrf_gpiote_event_t evt =
    2272:	3340      	adds	r3, #64	; 0x40
    2274:	f8d2 6510 	ldr.w	r6, [r2, #1296]	; 0x510
    2278:	f426 3647 	bic.w	r6, r6, #203776	; 0x31c00
    227c:	f426 7640 	bic.w	r6, r6, #768	; 0x300
    2280:	009b      	lsls	r3, r3, #2
    2282:	f8c2 6510 	str.w	r6, [r2, #1296]	; 0x510
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    2286:	022d      	lsls	r5, r5, #8
    return ((uint32_t)p_reg + event);
    2288:	b29b      	uxth	r3, r3
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    228a:	f8d2 6510 	ldr.w	r6, [r2, #1296]	; 0x510
    228e:	f405 55f8 	and.w	r5, r5, #7936	; 0x1f00
    return ((uint32_t)p_reg + event);
    2292:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    2296:	f503 43c0 	add.w	r3, r3, #24576	; 0x6000
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    229a:	ea45 4501 	orr.w	r5, r5, r1, lsl #16
    229e:	4335      	orrs	r5, r6
    22a0:	f8c2 5510 	str.w	r5, [r2, #1296]	; 0x510
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    22a4:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    22a6:	681b      	ldr	r3, [r3, #0]
    22a8:	9301      	str	r3, [sp, #4]
    (void)dummy;
    22aa:	9b01      	ldr	r3, [sp, #4]
   p_reg->CONFIG[idx] |= GPIOTE_CONFIG_MODE_Event;
    22ac:	f8d2 3510 	ldr.w	r3, [r2, #1296]	; 0x510
    22b0:	f043 0301 	orr.w	r3, r3, #1
    22b4:	f8c2 3510 	str.w	r3, [r2, #1296]	; 0x510
    p_reg->INTENSET = mask;
    22b8:	4b12      	ldr	r3, [pc, #72]	; (2304 <gpio_nrfx_pin_interrupt_configure+0x1dc>)
    22ba:	f8c3 4304 	str.w	r4, [r3, #772]	; 0x304
}
    22be:	b003      	add	sp, #12
    22c0:	bdf0      	pop	{r4, r5, r6, r7, pc}
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    22c2:	2601      	movs	r6, #1
    22c4:	408e      	lsls	r6, r1
    22c6:	ea20 0006 	bic.w	r0, r0, r6
    22ca:	e74c      	b.n	2166 <gpio_nrfx_pin_interrupt_configure+0x3e>
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    22cc:	3301      	adds	r3, #1
    22ce:	2b08      	cmp	r3, #8
    22d0:	f47f af67 	bne.w	21a2 <gpio_nrfx_pin_interrupt_configure+0x7a>
    22d4:	e791      	b.n	21fa <gpio_nrfx_pin_interrupt_configure+0xd2>
	for (uint8_t channel = 0; channel < GPIOTE_CH_NUM; ++channel) {
    22d6:	3301      	adds	r3, #1
    22d8:	2b08      	cmp	r3, #8
    22da:	d1b2      	bne.n	2242 <gpio_nrfx_pin_interrupt_configure+0x11a>
	return -ENODEV;
    22dc:	f06f 0012 	mvn.w	r0, #18
    22e0:	e7ed      	b.n	22be <gpio_nrfx_pin_interrupt_configure+0x196>
	if ((BIT(pin) & data->int_active_level) != 0U) {
    22e2:	6923      	ldr	r3, [r4, #16]
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    22e4:	f8d2 5700 	ldr.w	r5, [r2, #1792]	; 0x700
    22e8:	fa23 f101 	lsr.w	r1, r3, r1
    22ec:	f001 0101 	and.w	r1, r1, #1
    22f0:	f1c1 0103 	rsb	r1, r1, #3
    22f4:	f425 3340 	bic.w	r3, r5, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    22f8:	ea43 4101 	orr.w	r1, r3, r1, lsl #16
    22fc:	f8c2 1700 	str.w	r1, [r2, #1792]	; 0x700
}
    2300:	e7dd      	b.n	22be <gpio_nrfx_pin_interrupt_configure+0x196>
    2302:	bf00      	nop
    2304:	40006000 	.word	0x40006000
    2308:	200005a8 	.word	0x200005a8

0000230c <gpiote_event_handler>:
{
    230c:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    230e:	494e      	ldr	r1, [pc, #312]	; (2448 <gpiote_event_handler+0x13c>)
    2310:	680d      	ldr	r5, [r1, #0]
	if (port_event) {
    2312:	2d00      	cmp	r5, #0
    2314:	d061      	beq.n	23da <gpiote_event_handler+0xce>
	struct gpio_nrfx_data *data = get_port_data(port);
    2316:	4b4d      	ldr	r3, [pc, #308]	; (244c <gpiote_event_handler+0x140>)
    2318:	68da      	ldr	r2, [r3, #12]
	const struct gpio_nrfx_cfg *cfg = get_port_cfg(port);
    231a:	f8d3 c004 	ldr.w	ip, [r3, #4]
	uint32_t out = data->pin_int_en;
    231e:	68d3      	ldr	r3, [r2, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    2320:	e9d2 0405 	ldrd	r0, r4, [r2, #20]
    2324:	4320      	orrs	r0, r4
    2326:	ea23 0300 	bic.w	r3, r3, r0
	uint32_t port_in = nrf_gpio_port_in_read(cfg->port);
    232a:	f8dc 0004 	ldr.w	r0, [ip, #4]
	uint32_t pin_states = ~(port_in ^ data->int_active_level);
    232e:	6912      	ldr	r2, [r2, #16]
    return p_reg->IN;
    2330:	f8d0 4510 	ldr.w	r4, [r0, #1296]	; 0x510
    2334:	4054      	eors	r4, r2
	uint32_t out = pin_states & level_pins;
    2336:	ea23 0404 	bic.w	r4, r3, r4
	uint32_t bit = 1U << pin;
    233a:	2001      	movs	r0, #1
	uint32_t pin = 0U;
    233c:	2600      	movs	r6, #0
	while (level_pins) {
    233e:	2b00      	cmp	r3, #0
    2340:	d135      	bne.n	23ae <gpiote_event_handler+0xa2>
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2342:	600b      	str	r3, [r1, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    2344:	680b      	ldr	r3, [r1, #0]
    2346:	9300      	str	r3, [sp, #0]
    (void)dummy;
    2348:	9b00      	ldr	r3, [sp, #0]
    return p_reg->INTENSET & mask;
    234a:	4841      	ldr	r0, [pc, #260]	; (2450 <gpiote_event_handler+0x144>)
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    234c:	2300      	movs	r3, #0
		if (nrf_gpiote_int_enable_check(NRF_GPIOTE, BIT(i)) &&
    234e:	2601      	movs	r6, #1
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2350:	461f      	mov	r7, r3
    return p_reg->INTENSET & mask;
    2352:	f8d0 2304 	ldr.w	r2, [r0, #772]	; 0x304
    2356:	fa06 f103 	lsl.w	r1, r6, r3
    235a:	4211      	tst	r1, r2
    235c:	d013      	beq.n	2386 <gpiote_event_handler+0x7a>
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    235e:	009a      	lsls	r2, r3, #2
    2360:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    2364:	f502 42c2 	add.w	r2, r2, #24832	; 0x6100
    2368:	6811      	ldr	r1, [r2, #0]
    236a:	b161      	cbz	r1, 2386 <gpiote_event_handler+0x7a>
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    236c:	f503 71a2 	add.w	r1, r3, #324	; 0x144
    2370:	f850 1021 	ldr.w	r1, [r0, r1, lsl #2]
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2374:	6017      	str	r7, [r2, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    2376:	6812      	ldr	r2, [r2, #0]
    2378:	9201      	str	r2, [sp, #4]
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    237a:	f3c1 2104 	ubfx	r1, r1, #8, #5
			fired_triggers[abs_pin / 32U] |= BIT(abs_pin % 32);
    237e:	fa06 f101 	lsl.w	r1, r6, r1
    (void)dummy;
    2382:	9a01      	ldr	r2, [sp, #4]
    2384:	430c      	orrs	r4, r1
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    2386:	3301      	adds	r3, #1
    2388:	2b08      	cmp	r3, #8
    238a:	d1e2      	bne.n	2352 <gpiote_event_handler+0x46>
	if (fired_triggers[0]) {
    238c:	bb3c      	cbnz	r4, 23de <gpiote_event_handler+0xd2>
	if (port_event) {
    238e:	b165      	cbz	r5, 23aa <gpiote_event_handler+0x9e>
	const struct gpio_nrfx_data *data = get_port_data(port);
    2390:	4b2e      	ldr	r3, [pc, #184]	; (244c <gpiote_event_handler+0x140>)
    2392:	68d8      	ldr	r0, [r3, #12]
	const struct gpio_nrfx_cfg *cfg = get_port_cfg(port);
    2394:	685e      	ldr	r6, [r3, #4]
	uint32_t out = data->pin_int_en;
    2396:	68c1      	ldr	r1, [r0, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    2398:	e9d0 3205 	ldrd	r3, r2, [r0, #20]
    239c:	4313      	orrs	r3, r2
    239e:	ea21 0103 	bic.w	r1, r1, r3
	uint32_t bit = 1U << pin;
    23a2:	2401      	movs	r4, #1
	uint32_t pin = 0U;
    23a4:	2500      	movs	r5, #0
	while (level_pins) {
    23a6:	2900      	cmp	r1, #0
    23a8:	d131      	bne.n	240e <gpiote_event_handler+0x102>
}
    23aa:	b003      	add	sp, #12
    23ac:	bdf0      	pop	{r4, r5, r6, r7, pc}
		if (level_pins & bit) {
    23ae:	4203      	tst	r3, r0
    23b0:	d010      	beq.n	23d4 <gpiote_event_handler+0xc8>
			uint32_t abs_pin = NRF_GPIO_PIN_MAP(cfg->port_num, pin);
    23b2:	f89c 7008 	ldrb.w	r7, [ip, #8]
    23b6:	f006 021f 	and.w	r2, r6, #31
    23ba:	ea42 1247 	orr.w	r2, r2, r7, lsl #5
    23be:	0092      	lsls	r2, r2, #2
    23c0:	f102 42a0 	add.w	r2, r2, #1342177280	; 0x50000000
			level_pins &= ~bit;
    23c4:	ea23 0300 	bic.w	r3, r3, r0
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    23c8:	f8d2 7700 	ldr.w	r7, [r2, #1792]	; 0x700
    23cc:	f427 3740 	bic.w	r7, r7, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    23d0:	f8c2 7700 	str.w	r7, [r2, #1792]	; 0x700
		++pin;
    23d4:	3601      	adds	r6, #1
		bit <<= 1;
    23d6:	0040      	lsls	r0, r0, #1
    23d8:	e7b1      	b.n	233e <gpiote_event_handler+0x32>
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    23da:	462c      	mov	r4, r5
    23dc:	e7b5      	b.n	234a <gpiote_event_handler+0x3e>
	struct gpio_nrfx_data *data = get_port_data(port);
    23de:	4f1b      	ldr	r7, [pc, #108]	; (244c <gpiote_event_handler+0x140>)
					struct device *port,
					uint32_t pins)
{
	struct gpio_callback *cb, *tmp;

	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    23e0:	68fb      	ldr	r3, [r7, #12]
    23e2:	6859      	ldr	r1, [r3, #4]
    23e4:	2900      	cmp	r1, #0
    23e6:	d0d2      	beq.n	238e <gpiote_event_handler+0x82>
	return node->next;
    23e8:	680e      	ldr	r6, [r1, #0]
    23ea:	2e00      	cmp	r6, #0
    23ec:	bf38      	it	cc
    23ee:	2600      	movcc	r6, #0
		if (cb->pin_mask & pins) {
    23f0:	688a      	ldr	r2, [r1, #8]
    23f2:	4022      	ands	r2, r4
    23f4:	d002      	beq.n	23fc <gpiote_event_handler+0xf0>
			__ASSERT(cb->handler, "No callback handler!");
			cb->handler(port, cb, cb->pin_mask & pins);
    23f6:	684b      	ldr	r3, [r1, #4]
    23f8:	4638      	mov	r0, r7
    23fa:	4798      	blx	r3
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    23fc:	2e00      	cmp	r6, #0
    23fe:	d0c6      	beq.n	238e <gpiote_event_handler+0x82>
    2400:	6833      	ldr	r3, [r6, #0]
    2402:	2b00      	cmp	r3, #0
    2404:	bf38      	it	cc
    2406:	2300      	movcc	r3, #0
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    2408:	4631      	mov	r1, r6
    240a:	461e      	mov	r6, r3
    240c:	e7f0      	b.n	23f0 <gpiote_event_handler+0xe4>
		if (level_pins & bit) {
    240e:	420c      	tst	r4, r1
    2410:	d017      	beq.n	2442 <gpiote_event_handler+0x136>
			uint32_t abs_pin = NRF_GPIO_PIN_MAP(cfg->port_num, pin);
    2412:	7a32      	ldrb	r2, [r6, #8]
    2414:	f005 031f 	and.w	r3, r5, #31
    2418:	ea43 1342 	orr.w	r3, r3, r2, lsl #5
    241c:	009b      	lsls	r3, r3, #2
	if ((BIT(pin) & data->int_active_level) != 0U) {
    241e:	6902      	ldr	r2, [r0, #16]
    2420:	f103 43a0 	add.w	r3, r3, #1342177280	; 0x50000000
    2424:	40ea      	lsrs	r2, r5
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    2426:	f8d3 7700 	ldr.w	r7, [r3, #1792]	; 0x700
    242a:	f002 0201 	and.w	r2, r2, #1
    242e:	f1c2 0203 	rsb	r2, r2, #3
    2432:	f427 3740 	bic.w	r7, r7, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    2436:	ea47 4202 	orr.w	r2, r7, r2, lsl #16
    243a:	f8c3 2700 	str.w	r2, [r3, #1792]	; 0x700
			level_pins &= ~bit;
    243e:	ea21 0104 	bic.w	r1, r1, r4
		++pin;
    2442:	3501      	adds	r5, #1
		bit <<= 1;
    2444:	0064      	lsls	r4, r4, #1
    2446:	e7ae      	b.n	23a6 <gpiote_event_handler+0x9a>
    2448:	4000617c 	.word	0x4000617c
    244c:	20003450 	.word	0x20003450
    2450:	40006000 	.word	0x40006000

00002454 <z_mrsh_gpio_config>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
uintptr_t z_mrsh_gpio_config(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2454:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    2458:	f8df 804c 	ldr.w	r8, [pc, #76]	; 24a8 <z_mrsh_gpio_config+0x54>
    245c:	f8d8 3008 	ldr.w	r3, [r8, #8]
{
    2460:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    2462:	9a08      	ldr	r2, [sp, #32]
    2464:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_config(*(struct device **)&arg0, *(gpio_pin_t*)&arg1, *(gpio_flags_t*)&arg2)
    2468:	b2ce      	uxtb	r6, r1
{
    246a:	4604      	mov	r4, r0
#include <syscall_handler.h>

static inline int z_vrfy_gpio_config(struct device *port,
				     gpio_pin_t pin, gpio_flags_t flags)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, pin_configure));
    246c:	f7fd fe36 	bl	dc <z_object_find>
					 enum k_objects otype,
					 enum _obj_init_check init)
{
	int ret;

	ret = z_object_validate(ko, otype, init);
    2470:	2200      	movs	r2, #0
    2472:	211b      	movs	r1, #27
    2474:	f003 f86c 	bl	5550 <z_object_validate>
    2478:	4642      	mov	r2, r8
    247a:	4605      	mov	r5, r0
    247c:	b130      	cbz	r0, 248c <z_mrsh_gpio_config+0x38>
    247e:	f003 ff2a 	bl	62d6 <arch_is_user_context>
    2482:	6893      	ldr	r3, [r2, #8]
    2484:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2488:	f003 fe26 	bl	60d8 <arch_syscall_oops>
    248c:	68a3      	ldr	r3, [r4, #8]
    248e:	681b      	ldr	r3, [r3, #0]
    2490:	2b00      	cmp	r3, #0
    2492:	d0f4      	beq.n	247e <z_mrsh_gpio_config+0x2a>
	return api->pin_configure(port, pin, flags);
    2494:	463a      	mov	r2, r7
    2496:	4631      	mov	r1, r6
    2498:	4620      	mov	r0, r4
    249a:	4798      	blx	r3
;
	_current->syscall_frame = NULL;
    249c:	f8d8 3008 	ldr.w	r3, [r8, #8]
    24a0:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    24a4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    24a8:	20000eec 	.word	0x20000eec

000024ac <z_mrsh_gpio_port_get_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_get_raw(struct device * port, gpio_port_value_t * value);
uintptr_t z_mrsh_gpio_port_get_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    24ac:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    24ae:	4e17      	ldr	r6, [pc, #92]	; (250c <z_mrsh_gpio_port_get_raw+0x60>)
    24b0:	9a08      	ldr	r2, [sp, #32]
    24b2:	68b3      	ldr	r3, [r6, #8]
    24b4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    24b8:	460d      	mov	r5, r1
    24ba:	4604      	mov	r4, r0
#include <syscalls/gpio_config_mrsh.c>

static inline int z_vrfy_gpio_port_get_raw(struct device *port,
					   gpio_port_value_t *value)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_get_raw));
    24bc:	f7fd fe0e 	bl	dc <z_object_find>
    24c0:	2200      	movs	r2, #0
    24c2:	211b      	movs	r1, #27
    24c4:	f003 f844 	bl	5550 <z_object_validate>
    24c8:	4632      	mov	r2, r6
    24ca:	b178      	cbz	r0, 24ec <z_mrsh_gpio_port_get_raw+0x40>
    24cc:	f003 ff03 	bl	62d6 <arch_is_user_context>
    24d0:	6893      	ldr	r3, [r2, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(value, sizeof(gpio_port_value_t)));
    24d2:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    24d6:	f003 fdff 	bl	60d8 <arch_syscall_oops>
	return api->port_get_raw(port, value);
    24da:	68a3      	ldr	r3, [r4, #8]
    24dc:	4629      	mov	r1, r5
    24de:	685b      	ldr	r3, [r3, #4]
    24e0:	4620      	mov	r0, r4
    24e2:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_get_raw(*(struct device **)&arg0, *(gpio_port_value_t **)&arg1)
;
	_current->syscall_frame = NULL;
    24e4:	68b3      	ldr	r3, [r6, #8]
    24e6:	f8c3 7084 	str.w	r7, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    24ea:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_get_raw));
    24ec:	68a3      	ldr	r3, [r4, #8]
    24ee:	685b      	ldr	r3, [r3, #4]
    24f0:	2b00      	cmp	r3, #0
    24f2:	d0eb      	beq.n	24cc <z_mrsh_gpio_port_get_raw+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(value, sizeof(gpio_port_value_t)));
    24f4:	2201      	movs	r2, #1
    24f6:	2104      	movs	r1, #4
    24f8:	4628      	mov	r0, r5
    24fa:	f003 fe1b 	bl	6134 <arch_buffer_validate>
    24fe:	4607      	mov	r7, r0
    2500:	2800      	cmp	r0, #0
    2502:	d0ea      	beq.n	24da <z_mrsh_gpio_port_get_raw+0x2e>
    2504:	f003 fee7 	bl	62d6 <arch_is_user_context>
    2508:	68b3      	ldr	r3, [r6, #8]
    250a:	e7e2      	b.n	24d2 <z_mrsh_gpio_port_get_raw+0x26>
    250c:	20000eec 	.word	0x20000eec

00002510 <z_mrsh_gpio_port_set_masked_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_set_masked_raw(struct device * port, gpio_port_pins_t mask, gpio_port_value_t value);
uintptr_t z_mrsh_gpio_port_set_masked_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2510:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    2514:	f8df 804c 	ldr.w	r8, [pc, #76]	; 2564 <z_mrsh_gpio_port_set_masked_raw+0x54>
    2518:	f8d8 3008 	ldr.w	r3, [r8, #8]
{
    251c:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    251e:	9a08      	ldr	r2, [sp, #32]
    2520:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2524:	460e      	mov	r6, r1
    2526:	4604      	mov	r4, r0
#include <syscalls/gpio_port_get_raw_mrsh.c>

static inline int z_vrfy_gpio_port_set_masked_raw(struct device *port,
		gpio_port_pins_t mask, gpio_port_value_t value)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_set_masked_raw));
    2528:	f7fd fdd8 	bl	dc <z_object_find>
    252c:	2200      	movs	r2, #0
    252e:	211b      	movs	r1, #27
    2530:	f003 f80e 	bl	5550 <z_object_validate>
    2534:	4642      	mov	r2, r8
    2536:	4605      	mov	r5, r0
    2538:	b130      	cbz	r0, 2548 <z_mrsh_gpio_port_set_masked_raw+0x38>
    253a:	f003 fecc 	bl	62d6 <arch_is_user_context>
    253e:	6893      	ldr	r3, [r2, #8]
    2540:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2544:	f003 fdc8 	bl	60d8 <arch_syscall_oops>
    2548:	68a3      	ldr	r3, [r4, #8]
    254a:	689b      	ldr	r3, [r3, #8]
    254c:	2b00      	cmp	r3, #0
    254e:	d0f4      	beq.n	253a <z_mrsh_gpio_port_set_masked_raw+0x2a>
	return api->port_set_masked_raw(port, mask, value);
    2550:	463a      	mov	r2, r7
    2552:	4631      	mov	r1, r6
    2554:	4620      	mov	r0, r4
    2556:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_set_masked_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1, *(gpio_port_value_t*)&arg2)
;
	_current->syscall_frame = NULL;
    2558:	f8d8 3008 	ldr.w	r3, [r8, #8]
    255c:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2560:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    2564:	20000eec 	.word	0x20000eec

00002568 <z_mrsh_gpio_port_set_bits_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_set_bits_raw(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_set_bits_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2568:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    256a:	4f11      	ldr	r7, [pc, #68]	; (25b0 <z_mrsh_gpio_port_set_bits_raw+0x48>)
    256c:	9a08      	ldr	r2, [sp, #32]
    256e:	68bb      	ldr	r3, [r7, #8]
    2570:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2574:	460e      	mov	r6, r1
    2576:	4604      	mov	r4, r0
#include <syscalls/gpio_port_set_masked_raw_mrsh.c>

static inline int z_vrfy_gpio_port_set_bits_raw(struct device *port,
						gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_set_bits_raw));
    2578:	f7fd fdb0 	bl	dc <z_object_find>
    257c:	2200      	movs	r2, #0
    257e:	211b      	movs	r1, #27
    2580:	f002 ffe6 	bl	5550 <z_object_validate>
    2584:	463a      	mov	r2, r7
    2586:	4605      	mov	r5, r0
    2588:	b130      	cbz	r0, 2598 <z_mrsh_gpio_port_set_bits_raw+0x30>
    258a:	f003 fea4 	bl	62d6 <arch_is_user_context>
    258e:	6893      	ldr	r3, [r2, #8]
    2590:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2594:	f003 fda0 	bl	60d8 <arch_syscall_oops>
    2598:	68a3      	ldr	r3, [r4, #8]
    259a:	68db      	ldr	r3, [r3, #12]
    259c:	2b00      	cmp	r3, #0
    259e:	d0f4      	beq.n	258a <z_mrsh_gpio_port_set_bits_raw+0x22>
	return api->port_set_bits_raw(port, pins);
    25a0:	4631      	mov	r1, r6
    25a2:	4620      	mov	r0, r4
    25a4:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_set_bits_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    25a6:	68bb      	ldr	r3, [r7, #8]
    25a8:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    25ac:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    25ae:	bf00      	nop
    25b0:	20000eec 	.word	0x20000eec

000025b4 <z_mrsh_gpio_port_clear_bits_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_clear_bits_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    25b4:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    25b6:	4f11      	ldr	r7, [pc, #68]	; (25fc <z_mrsh_gpio_port_clear_bits_raw+0x48>)
    25b8:	9a08      	ldr	r2, [sp, #32]
    25ba:	68bb      	ldr	r3, [r7, #8]
    25bc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    25c0:	460e      	mov	r6, r1
    25c2:	4604      	mov	r4, r0
#include <syscalls/gpio_port_set_bits_raw_mrsh.c>

static inline int z_vrfy_gpio_port_clear_bits_raw(struct device *port,
						  gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_clear_bits_raw));
    25c4:	f7fd fd8a 	bl	dc <z_object_find>
    25c8:	2200      	movs	r2, #0
    25ca:	211b      	movs	r1, #27
    25cc:	f002 ffc0 	bl	5550 <z_object_validate>
    25d0:	463a      	mov	r2, r7
    25d2:	4605      	mov	r5, r0
    25d4:	b130      	cbz	r0, 25e4 <z_mrsh_gpio_port_clear_bits_raw+0x30>
    25d6:	f003 fe7e 	bl	62d6 <arch_is_user_context>
    25da:	6893      	ldr	r3, [r2, #8]
    25dc:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    25e0:	f003 fd7a 	bl	60d8 <arch_syscall_oops>
    25e4:	68a3      	ldr	r3, [r4, #8]
    25e6:	691b      	ldr	r3, [r3, #16]
    25e8:	2b00      	cmp	r3, #0
    25ea:	d0f4      	beq.n	25d6 <z_mrsh_gpio_port_clear_bits_raw+0x22>
	return api->port_clear_bits_raw(port, pins);
    25ec:	4631      	mov	r1, r6
    25ee:	4620      	mov	r0, r4
    25f0:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_clear_bits_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    25f2:	68bb      	ldr	r3, [r7, #8]
    25f4:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    25f8:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    25fa:	bf00      	nop
    25fc:	20000eec 	.word	0x20000eec

00002600 <z_mrsh_gpio_port_toggle_bits>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_toggle_bits(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_toggle_bits(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2600:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2602:	4f11      	ldr	r7, [pc, #68]	; (2648 <z_mrsh_gpio_port_toggle_bits+0x48>)
    2604:	9a08      	ldr	r2, [sp, #32]
    2606:	68bb      	ldr	r3, [r7, #8]
    2608:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    260c:	460e      	mov	r6, r1
    260e:	4604      	mov	r4, r0
#include <syscalls/gpio_port_clear_bits_raw_mrsh.c>

static inline int z_vrfy_gpio_port_toggle_bits(struct device *port,
					       gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_toggle_bits));
    2610:	f7fd fd64 	bl	dc <z_object_find>
    2614:	2200      	movs	r2, #0
    2616:	211b      	movs	r1, #27
    2618:	f002 ff9a 	bl	5550 <z_object_validate>
    261c:	463a      	mov	r2, r7
    261e:	4605      	mov	r5, r0
    2620:	b130      	cbz	r0, 2630 <z_mrsh_gpio_port_toggle_bits+0x30>
    2622:	f003 fe58 	bl	62d6 <arch_is_user_context>
    2626:	6893      	ldr	r3, [r2, #8]
    2628:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    262c:	f003 fd54 	bl	60d8 <arch_syscall_oops>
    2630:	68a3      	ldr	r3, [r4, #8]
    2632:	695b      	ldr	r3, [r3, #20]
    2634:	2b00      	cmp	r3, #0
    2636:	d0f4      	beq.n	2622 <z_mrsh_gpio_port_toggle_bits+0x22>
	return api->port_toggle_bits(port, pins);
    2638:	4631      	mov	r1, r6
    263a:	4620      	mov	r0, r4
    263c:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_toggle_bits(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    263e:	68bb      	ldr	r3, [r7, #8]
    2640:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2644:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    2646:	bf00      	nop
    2648:	20000eec 	.word	0x20000eec

0000264c <z_mrsh_gpio_pin_interrupt_configure>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_pin_interrupt_configure(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
uintptr_t z_mrsh_gpio_pin_interrupt_configure(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    264c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    2650:	4d19      	ldr	r5, [pc, #100]	; (26b8 <z_mrsh_gpio_pin_interrupt_configure+0x6c>)
    2652:	68ab      	ldr	r3, [r5, #8]
{
    2654:	4614      	mov	r4, r2
	_current->syscall_frame = ssf;
    2656:	9a08      	ldr	r2, [sp, #32]
    2658:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_pin_interrupt_configure(*(struct device **)&arg0, *(gpio_pin_t*)&arg1, *(gpio_flags_t*)&arg2)
    265c:	fa5f f881 	uxtb.w	r8, r1
{
    2660:	4607      	mov	r7, r0

static inline int z_vrfy_gpio_pin_interrupt_configure(struct device *port,
						      gpio_pin_t pin,
						      gpio_flags_t flags)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, pin_interrupt_configure));
    2662:	f7fd fd3b 	bl	dc <z_object_find>
    2666:	2200      	movs	r2, #0
    2668:	211b      	movs	r1, #27
    266a:	f002 ff71 	bl	5550 <z_object_validate>
    266e:	b130      	cbz	r0, 267e <z_mrsh_gpio_pin_interrupt_configure+0x32>
    2670:	f003 fe31 	bl	62d6 <arch_is_user_context>
    2674:	68ab      	ldr	r3, [r5, #8]
    2676:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    267a:	f003 fd2d 	bl	60d8 <arch_syscall_oops>
    267e:	68bb      	ldr	r3, [r7, #8]
    2680:	699e      	ldr	r6, [r3, #24]
    2682:	2e00      	cmp	r6, #0
    2684:	d0f4      	beq.n	2670 <z_mrsh_gpio_pin_interrupt_configure+0x24>
	if (((flags & GPIO_INT_LEVELS_LOGICAL) != 0) &&
    2686:	0423      	lsls	r3, r4, #16
    2688:	d508      	bpl.n	269c <z_mrsh_gpio_pin_interrupt_configure+0x50>
	    ((data->invert & (gpio_port_pins_t)BIT(pin)) != 0)) {
    268a:	68fa      	ldr	r2, [r7, #12]
    268c:	2301      	movs	r3, #1
    268e:	6812      	ldr	r2, [r2, #0]
    2690:	fa03 f308 	lsl.w	r3, r3, r8
	if (((flags & GPIO_INT_LEVELS_LOGICAL) != 0) &&
    2694:	4213      	tst	r3, r2
		flags ^= (GPIO_INT_LOW_0 | GPIO_INT_HIGH_1);
    2696:	bf18      	it	ne
    2698:	f484 24c0 	eorne.w	r4, r4, #393216	; 0x60000
	return api->pin_interrupt_configure(port, pin, mode, trig);
    269c:	f404 23c0 	and.w	r3, r4, #393216	; 0x60000
    26a0:	f404 32b0 	and.w	r2, r4, #90112	; 0x16000
    26a4:	4641      	mov	r1, r8
    26a6:	4638      	mov	r0, r7
    26a8:	47b0      	blx	r6
;
	_current->syscall_frame = NULL;
    26aa:	68ab      	ldr	r3, [r5, #8]
    26ac:	2200      	movs	r2, #0
    26ae:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    26b2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    26b6:	bf00      	nop
    26b8:	20000eec 	.word	0x20000eec

000026bc <z_mrsh_gpio_get_pending_int>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_get_pending_int(struct device * dev);
uintptr_t z_mrsh_gpio_get_pending_int(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    26bc:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    26be:	4e10      	ldr	r6, [pc, #64]	; (2700 <z_mrsh_gpio_get_pending_int+0x44>)
    26c0:	9a06      	ldr	r2, [sp, #24]
    26c2:	68b3      	ldr	r3, [r6, #8]
    26c4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    26c8:	4604      	mov	r4, r0
}
#include <syscalls/gpio_pin_interrupt_configure_mrsh.c>

static inline int z_vrfy_gpio_get_pending_int(struct device *dev)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(dev, get_pending_int));
    26ca:	f7fd fd07 	bl	dc <z_object_find>
    26ce:	2200      	movs	r2, #0
    26d0:	211b      	movs	r1, #27
    26d2:	f002 ff3d 	bl	5550 <z_object_validate>
    26d6:	4632      	mov	r2, r6
    26d8:	4605      	mov	r5, r0
    26da:	b130      	cbz	r0, 26ea <z_mrsh_gpio_get_pending_int+0x2e>
    26dc:	f003 fdfb 	bl	62d6 <arch_is_user_context>
    26e0:	6893      	ldr	r3, [r2, #8]
    26e2:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    26e6:	f003 fcf7 	bl	60d8 <arch_syscall_oops>
    26ea:	68a3      	ldr	r3, [r4, #8]
    26ec:	6a1b      	ldr	r3, [r3, #32]
    26ee:	2b00      	cmp	r3, #0
    26f0:	d0f4      	beq.n	26dc <z_mrsh_gpio_get_pending_int+0x20>

	if (api->get_pending_int == NULL) {
		return -ENOTSUP;
	}

	return api->get_pending_int(dev);
    26f2:	4620      	mov	r0, r4
    26f4:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_get_pending_int(*(struct device **)&arg0)
;
	_current->syscall_frame = NULL;
    26f6:	68b3      	ldr	r3, [r6, #8]
    26f8:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    26fc:	bd70      	pop	{r4, r5, r6, pc}
    26fe:	bf00      	nop
    2700:	20000eec 	.word	0x20000eec

00002704 <uart_nrfx_err_check>:
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_uart_errorsrc_get_and_clear(NRF_UART_Type * p_reg)
{
    uint32_t errsrc_mask = p_reg->ERRORSRC;
    2704:	4b02      	ldr	r3, [pc, #8]	; (2710 <uart_nrfx_err_check+0xc>)
    2706:	f8d3 0480 	ldr.w	r0, [r3, #1152]	; 0x480
    p_reg->ERRORSRC = errsrc_mask;
    270a:	f8c3 0480 	str.w	r0, [r3, #1152]	; 0x480
/** Console I/O function */
static int uart_nrfx_err_check(struct device *dev)
{
	/* register bitfields maps to the defines in uart.h */
	return nrf_uart_errorsrc_get_and_clear(uart0_addr);
}
    270e:	4770      	bx	lr
    2710:	40002000 	.word	0x40002000

00002714 <uart_nrfx_configure>:

static int uart_nrfx_configure(struct device *dev,
			       const struct uart_config *cfg)
{
    2714:	b530      	push	{r4, r5, lr}
		break;
	default:
		return -ENOTSUP;
	}
#else
	if (cfg->stop_bits != UART_CFG_STOP_BITS_1) {
    2716:	794b      	ldrb	r3, [r1, #5]
    2718:	2b01      	cmp	r3, #1
    271a:	d11e      	bne.n	275a <uart_nrfx_configure+0x46>
		return -ENOTSUP;
	}
#endif

	if (cfg->data_bits != UART_CFG_DATA_BITS_8) {
    271c:	798b      	ldrb	r3, [r1, #6]
    271e:	2b03      	cmp	r3, #3
    2720:	d11b      	bne.n	275a <uart_nrfx_configure+0x46>
		return -ENOTSUP;
	}

	switch (cfg->flow_ctrl) {
    2722:	79ca      	ldrb	r2, [r1, #7]
    2724:	b10a      	cbz	r2, 272a <uart_nrfx_configure+0x16>
    2726:	2a01      	cmp	r2, #1
    2728:	d117      	bne.n	275a <uart_nrfx_configure+0x46>
	}

#if defined(UART_CONFIG_PARITYTYPE_Msk)
	uart_cfg.paritytype = NRF_UART_PARITYTYPE_EVEN;
#endif
	switch (cfg->parity) {
    272a:	790c      	ldrb	r4, [r1, #4]
    272c:	b114      	cbz	r4, 2734 <uart_nrfx_configure+0x20>
    272e:	2c02      	cmp	r4, #2
    2730:	d113      	bne.n	275a <uart_nrfx_configure+0x46>
    2732:	240e      	movs	r4, #14
#endif
	default:
		return -ENOTSUP;
	}

	if (baudrate_set(dev, cfg->baudrate) != 0) {
    2734:	680b      	ldr	r3, [r1, #0]
	switch (baudrate) {
    2736:	f5b3 4f16 	cmp.w	r3, #38400	; 0x9600
    273a:	d05f      	beq.n	27fc <uart_nrfx_configure+0xe8>
    273c:	d82b      	bhi.n	2796 <uart_nrfx_configure+0x82>
    273e:	f5b3 5f16 	cmp.w	r3, #9600	; 0x2580
    2742:	d05d      	beq.n	2800 <uart_nrfx_configure+0xec>
    2744:	d814      	bhi.n	2770 <uart_nrfx_configure+0x5c>
    2746:	f5b3 6f96 	cmp.w	r3, #1200	; 0x4b0
    274a:	d05b      	beq.n	2804 <uart_nrfx_configure+0xf0>
    274c:	d808      	bhi.n	2760 <uart_nrfx_configure+0x4c>
    274e:	f5b3 7f96 	cmp.w	r3, #300	; 0x12c
    2752:	d05a      	beq.n	280a <uart_nrfx_configure+0xf6>
    2754:	f5b3 7f16 	cmp.w	r3, #600	; 0x258
    2758:	d05a      	beq.n	2810 <uart_nrfx_configure+0xfc>
    275a:	f06f 0022 	mvn.w	r0, #34	; 0x22
    275e:	e04c      	b.n	27fa <uart_nrfx_configure+0xe6>
    2760:	f5b3 6f16 	cmp.w	r3, #2400	; 0x960
    2764:	d057      	beq.n	2816 <uart_nrfx_configure+0x102>
    2766:	f5b3 5f96 	cmp.w	r3, #4800	; 0x12c0
    276a:	d1f6      	bne.n	275a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_4800;
    276c:	4b34      	ldr	r3, [pc, #208]	; (2840 <uart_nrfx_configure+0x12c>)
    276e:	e039      	b.n	27e4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2770:	f5b3 4fe1 	cmp.w	r3, #28800	; 0x7080
    2774:	d052      	beq.n	281c <uart_nrfx_configure+0x108>
    2776:	d807      	bhi.n	2788 <uart_nrfx_configure+0x74>
    2778:	f5b3 5f61 	cmp.w	r3, #14400	; 0x3840
    277c:	d050      	beq.n	2820 <uart_nrfx_configure+0x10c>
    277e:	f5b3 4f96 	cmp.w	r3, #19200	; 0x4b00
    2782:	d1ea      	bne.n	275a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_19200;
    2784:	4b2f      	ldr	r3, [pc, #188]	; (2844 <uart_nrfx_configure+0x130>)
    2786:	e02d      	b.n	27e4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2788:	f647 2512 	movw	r5, #31250	; 0x7a12
    278c:	42ab      	cmp	r3, r5
    278e:	d1e4      	bne.n	275a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_31250;
    2790:	f44f 0300 	mov.w	r3, #8388608	; 0x800000
    2794:	e026      	b.n	27e4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2796:	f5b3 3f61 	cmp.w	r3, #230400	; 0x38400
    279a:	d044      	beq.n	2826 <uart_nrfx_configure+0x112>
    279c:	d811      	bhi.n	27c2 <uart_nrfx_configure+0xae>
    279e:	f5b3 3f96 	cmp.w	r3, #76800	; 0x12c00
    27a2:	d042      	beq.n	282a <uart_nrfx_configure+0x116>
    27a4:	d808      	bhi.n	27b8 <uart_nrfx_configure+0xa4>
    27a6:	f64d 25c0 	movw	r5, #56000	; 0xdac0
    27aa:	42ab      	cmp	r3, r5
    27ac:	d03f      	beq.n	282e <uart_nrfx_configure+0x11a>
    27ae:	f5b3 4f61 	cmp.w	r3, #57600	; 0xe100
    27b2:	d1d2      	bne.n	275a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_57600;
    27b4:	4b24      	ldr	r3, [pc, #144]	; (2848 <uart_nrfx_configure+0x134>)
    27b6:	e015      	b.n	27e4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    27b8:	f5b3 3fe1 	cmp.w	r3, #115200	; 0x1c200
    27bc:	d1cd      	bne.n	275a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_115200;
    27be:	4b23      	ldr	r3, [pc, #140]	; (284c <uart_nrfx_configure+0x138>)
    27c0:	e010      	b.n	27e4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    27c2:	f5b3 2f61 	cmp.w	r3, #921600	; 0xe1000
    27c6:	d035      	beq.n	2834 <uart_nrfx_configure+0x120>
    27c8:	d807      	bhi.n	27da <uart_nrfx_configure+0xc6>
    27ca:	4d21      	ldr	r5, [pc, #132]	; (2850 <uart_nrfx_configure+0x13c>)
    27cc:	42ab      	cmp	r3, r5
    27ce:	d033      	beq.n	2838 <uart_nrfx_configure+0x124>
    27d0:	f5b3 2fe1 	cmp.w	r3, #460800	; 0x70800
    27d4:	d1c1      	bne.n	275a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_460800;
    27d6:	4b1f      	ldr	r3, [pc, #124]	; (2854 <uart_nrfx_configure+0x140>)
    27d8:	e004      	b.n	27e4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    27da:	4d1f      	ldr	r5, [pc, #124]	; (2858 <uart_nrfx_configure+0x144>)
    27dc:	42ab      	cmp	r3, r5
    27de:	d1bc      	bne.n	275a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_1000000;
    27e0:	f04f 5380 	mov.w	r3, #268435456	; 0x10000000
                    | (uint32_t)p_cfg->hwfc;
}

NRF_STATIC_INLINE void nrf_uart_baudrate_set(NRF_UART_Type * p_reg, nrf_uart_baudrate_t baudrate)
{
    p_reg->BAUDRATE = baudrate;
    27e4:	4d1d      	ldr	r5, [pc, #116]	; (285c <uart_nrfx_configure+0x148>)
                    | (uint32_t)p_cfg->hwfc;
    27e6:	4322      	orrs	r2, r4
    p_reg->BAUDRATE = baudrate;
    27e8:	f8c5 3524 	str.w	r3, [r5, #1316]	; 0x524
    p_reg->CONFIG = (uint32_t)p_cfg->parity
    27ec:	f8c5 256c 	str.w	r2, [r5, #1388]	; 0x56c
		return -ENOTSUP;
	}

	nrf_uart_configure(uart0_addr, &uart_cfg);

	get_dev_data(dev)->uart_config = *cfg;
    27f0:	68c3      	ldr	r3, [r0, #12]
    27f2:	c903      	ldmia	r1, {r0, r1}
    27f4:	e883 0003 	stmia.w	r3, {r0, r1}

	return 0;
    27f8:	2000      	movs	r0, #0
}
    27fa:	bd30      	pop	{r4, r5, pc}
		nrf_baudrate = NRF_UART_BAUDRATE_38400;
    27fc:	4b18      	ldr	r3, [pc, #96]	; (2860 <uart_nrfx_configure+0x14c>)
    27fe:	e7f1      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_9600;
    2800:	4b18      	ldr	r3, [pc, #96]	; (2864 <uart_nrfx_configure+0x150>)
    2802:	e7ef      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_1200;
    2804:	f44f 239e 	mov.w	r3, #323584	; 0x4f000
    2808:	e7ec      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = 0x00014000;
    280a:	f44f 33a0 	mov.w	r3, #81920	; 0x14000
    280e:	e7e9      	b.n	27e4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2810:	f44f 331c 	mov.w	r3, #159744	; 0x27000
    2814:	e7e6      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_2400;
    2816:	f44f 231d 	mov.w	r3, #643072	; 0x9d000
    281a:	e7e3      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_28800;
    281c:	4b12      	ldr	r3, [pc, #72]	; (2868 <uart_nrfx_configure+0x154>)
    281e:	e7e1      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_14400;
    2820:	f44f 136c 	mov.w	r3, #3866624	; 0x3b0000
    2824:	e7de      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_230400;
    2826:	4b11      	ldr	r3, [pc, #68]	; (286c <uart_nrfx_configure+0x158>)
    2828:	e7dc      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_76800;
    282a:	4b11      	ldr	r3, [pc, #68]	; (2870 <uart_nrfx_configure+0x15c>)
    282c:	e7da      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_56000;
    282e:	f44f 0365 	mov.w	r3, #15007744	; 0xe50000
    2832:	e7d7      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_921600;
    2834:	4b0f      	ldr	r3, [pc, #60]	; (2874 <uart_nrfx_configure+0x160>)
    2836:	e7d5      	b.n	27e4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_250000;
    2838:	f04f 6380 	mov.w	r3, #67108864	; 0x4000000
    283c:	e7d2      	b.n	27e4 <uart_nrfx_configure+0xd0>
    283e:	bf00      	nop
    2840:	0013b000 	.word	0x0013b000
    2844:	004ea000 	.word	0x004ea000
    2848:	00ebf000 	.word	0x00ebf000
    284c:	01d7e000 	.word	0x01d7e000
    2850:	0003d090 	.word	0x0003d090
    2854:	075f7000 	.word	0x075f7000
    2858:	000f4240 	.word	0x000f4240
    285c:	40002000 	.word	0x40002000
    2860:	009d5000 	.word	0x009d5000
    2864:	00275000 	.word	0x00275000
    2868:	0075f000 	.word	0x0075f000
    286c:	03afb000 	.word	0x03afb000
    2870:	013a9000 	.word	0x013a9000
    2874:	0ebed000 	.word	0x0ebed000

00002878 <uart_nrfx_poll_in>:
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    2878:	4b08      	ldr	r3, [pc, #32]	; (289c <uart_nrfx_poll_in+0x24>)
    287a:	681a      	ldr	r2, [r3, #0]
{
    287c:	b082      	sub	sp, #8
	if (!nrf_uart_event_check(uart0_addr, NRF_UART_EVENT_RXDRDY)) {
    287e:	b152      	cbz	r2, 2896 <uart_nrfx_poll_in+0x1e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    2880:	2000      	movs	r0, #0
    2882:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    2884:	681b      	ldr	r3, [r3, #0]
    2886:	9301      	str	r3, [sp, #4]
    (void)dummy;
    2888:	9b01      	ldr	r3, [sp, #4]
    return p_reg->RXD;
    288a:	4b05      	ldr	r3, [pc, #20]	; (28a0 <uart_nrfx_poll_in+0x28>)
    288c:	f8d3 3518 	ldr.w	r3, [r3, #1304]	; 0x518
    2890:	700b      	strb	r3, [r1, #0]
}
    2892:	b002      	add	sp, #8
    2894:	4770      	bx	lr
		return -1;
    2896:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    289a:	e7fa      	b.n	2892 <uart_nrfx_poll_in+0x1a>
    289c:	40002108 	.word	0x40002108
    28a0:	40002000 	.word	0x40002000

000028a4 <uart_nrfx_poll_out>:
{
    28a4:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    28a6:	460e      	mov	r6, r1
	if (!k_is_in_isr()) {
    28a8:	f004 f970 	bl	6b8c <k_is_in_isr>
    28ac:	4d1b      	ldr	r5, [pc, #108]	; (291c <uart_nrfx_poll_out+0x78>)
    28ae:	bb88      	cbnz	r0, 2914 <uart_nrfx_poll_out+0x70>
    28b0:	2464      	movs	r4, #100	; 0x64
	return __atomic_compare_exchange_n(target, &old_value, new_value,
    28b2:	2701      	movs	r7, #1
    28b4:	f3bf 8f5b 	dmb	ish
    28b8:	e855 3f00 	ldrex	r3, [r5]
    28bc:	2b00      	cmp	r3, #0
    28be:	d103      	bne.n	28c8 <uart_nrfx_poll_out+0x24>
    28c0:	e845 7200 	strex	r2, r7, [r5]
    28c4:	2a00      	cmp	r2, #0
    28c6:	d1f7      	bne.n	28b8 <uart_nrfx_poll_out+0x14>
    28c8:	f3bf 8f5b 	dmb	ish
		while (atomic_cas((atomic_t *) lock,
    28cc:	d007      	beq.n	28de <uart_nrfx_poll_out+0x3a>
	return z_impl_k_sleep(timeout);
    28ce:	2021      	movs	r0, #33	; 0x21
    28d0:	2100      	movs	r1, #0
    28d2:	3c01      	subs	r4, #1
    28d4:	f001 ff18 	bl	4708 <z_impl_k_sleep>
			if (--safety_cnt == 0) {
    28d8:	f014 04ff 	ands.w	r4, r4, #255	; 0xff
    28dc:	d1ea      	bne.n	28b4 <uart_nrfx_poll_out+0x10>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    28de:	4c10      	ldr	r4, [pc, #64]	; (2920 <uart_nrfx_poll_out+0x7c>)
    28e0:	2200      	movs	r2, #0
    28e2:	6022      	str	r2, [r4, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    28e4:	6822      	ldr	r2, [r4, #0]
    28e6:	9201      	str	r2, [sp, #4]
    (void)dummy;
    28e8:	9a01      	ldr	r2, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    28ea:	4a0e      	ldr	r2, [pc, #56]	; (2924 <uart_nrfx_poll_out+0x80>)
    28ec:	2101      	movs	r1, #1
    28ee:	6011      	str	r1, [r2, #0]
    p_reg->TXD = txd;
    28f0:	f8c2 6514 	str.w	r6, [r2, #1300]	; 0x514
    28f4:	f44f 767a 	mov.w	r6, #1000	; 0x3e8
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    28f8:	6823      	ldr	r3, [r4, #0]
	NRFX_WAIT_FOR(event_txdrdy_check(), 1000, 1, res);
    28fa:	b923      	cbnz	r3, 2906 <uart_nrfx_poll_out+0x62>
    28fc:	2001      	movs	r0, #1
    28fe:	f003 fd06 	bl	630e <nrfx_busy_wait>
    2902:	3e01      	subs	r6, #1
    2904:	d1f8      	bne.n	28f8 <uart_nrfx_poll_out+0x54>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    2906:	4b08      	ldr	r3, [pc, #32]	; (2928 <uart_nrfx_poll_out+0x84>)
    2908:	2201      	movs	r2, #1
    290a:	601a      	str	r2, [r3, #0]
	*lock = 0;
    290c:	2300      	movs	r3, #0
    290e:	602b      	str	r3, [r5, #0]
}
    2910:	b003      	add	sp, #12
    2912:	bdf0      	pop	{r4, r5, r6, r7, pc}
		*lock = 1;
    2914:	2301      	movs	r3, #1
    2916:	602b      	str	r3, [r5, #0]
    2918:	e7e1      	b.n	28de <uart_nrfx_poll_out+0x3a>
    291a:	bf00      	nop
    291c:	200005ac 	.word	0x200005ac
    2920:	4000211c 	.word	0x4000211c
    2924:	40002008 	.word	0x40002008
    2928:	4000200c 	.word	0x4000200c

0000292c <uart_nrfx_init>:
 * @param dev UART device struct
 *
 * @return 0 on success
 */
static int uart_nrfx_init(struct device *dev)
{
    292c:	b537      	push	{r0, r1, r2, r4, r5, lr}
    p_reg->OUTSET = set_mask;
    292e:	f04f 43a0 	mov.w	r3, #1342177280	; 0x50000000
    p_reg->ENABLE = UART_ENABLE_ENABLE_Disabled;
    2932:	4c17      	ldr	r4, [pc, #92]	; (2990 <uart_nrfx_init+0x64>)
    2934:	2200      	movs	r2, #0
    2936:	2140      	movs	r1, #64	; 0x40
    2938:	f8c4 2500 	str.w	r2, [r4, #1280]	; 0x500
    p_reg->PSELRXD = pselrxd;
    293c:	2508      	movs	r5, #8
    293e:	f8c3 1508 	str.w	r1, [r3, #1288]	; 0x508
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    2942:	2103      	movs	r1, #3
    2944:	f8c3 1718 	str.w	r1, [r3, #1816]	; 0x718
    2948:	f8c3 2720 	str.w	r2, [r3, #1824]	; 0x720
    294c:	f8c4 5514 	str.w	r5, [r4, #1300]	; 0x514
    p_reg->PSELTXD = pseltxd;
    2950:	2506      	movs	r5, #6
    2952:	f8c4 550c 	str.w	r5, [r4, #1292]	; 0x50c
    p_reg->OUTSET = set_mask;
    2956:	2520      	movs	r5, #32
    2958:	f8c3 5508 	str.w	r5, [r3, #1288]	; 0x508
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    295c:	f8c3 1714 	str.w	r1, [r3, #1812]	; 0x714
    2960:	f8c3 271c 	str.w	r2, [r3, #1820]	; 0x71c
    p_reg->PSELRTS = pselrts;
    2964:	2305      	movs	r3, #5
    2966:	f8c4 3508 	str.w	r3, [r4, #1288]	; 0x508
    p_reg->PSELCTS = pselcts;
    296a:	2307      	movs	r3, #7
	}

	nrf_uart_hwfc_pins_set(uart0_addr, RTS_PIN, CTS_PIN);

	/* Set initial configuration */
	err = uart_nrfx_configure(dev, &get_dev_data(dev)->uart_config);
    296c:	68c1      	ldr	r1, [r0, #12]
    296e:	f8c4 3510 	str.w	r3, [r4, #1296]	; 0x510
    2972:	f7ff fecf 	bl	2714 <uart_nrfx_configure>
	if (err) {
    2976:	b948      	cbnz	r0, 298c <uart_nrfx_init+0x60>
    p_reg->ENABLE = UART_ENABLE_ENABLE_Enabled;
    2978:	2304      	movs	r3, #4
    297a:	f8c4 3500 	str.w	r3, [r4, #1280]	; 0x500
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    297e:	4b05      	ldr	r3, [pc, #20]	; (2994 <uart_nrfx_init+0x68>)
    2980:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    2982:	681b      	ldr	r3, [r3, #0]
    2984:	9301      	str	r3, [sp, #4]
    (void)dummy;
    2986:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    2988:	2301      	movs	r3, #1
    298a:	6023      	str	r3, [r4, #0]
#if HW_FLOW_CONTROL_AVAILABLE
	k_delayed_work_init(&uart0_cb.tx_timeout_work, tx_timeout);
#endif
#endif
	return 0;
}
    298c:	b003      	add	sp, #12
    298e:	bd30      	pop	{r4, r5, pc}
    2990:	40002000 	.word	0x40002000
    2994:	40002108 	.word	0x40002108

00002998 <z_mrsh_uart_err_check>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_err_check(struct device * dev);
uintptr_t z_mrsh_uart_err_check(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2998:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    299a:	4e10      	ldr	r6, [pc, #64]	; (29dc <z_mrsh_uart_err_check+0x44>)
    299c:	9a06      	ldr	r2, [sp, #24]
    299e:	68b3      	ldr	r3, [r6, #8]
    29a0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    29a4:	4604      	mov	r4, r0
	{							 \
		Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, op_)); \
		z_impl_uart_ ## op_(dev); \
	}

UART_SIMPLE(err_check)
    29a6:	f7fd fb99 	bl	dc <z_object_find>
    29aa:	2200      	movs	r2, #0
    29ac:	2126      	movs	r1, #38	; 0x26
    29ae:	f002 fdcf 	bl	5550 <z_object_validate>
    29b2:	4632      	mov	r2, r6
    29b4:	4605      	mov	r5, r0
    29b6:	b130      	cbz	r0, 29c6 <z_mrsh_uart_err_check+0x2e>
    29b8:	f003 fc9f 	bl	62fa <arch_is_user_context>
    29bc:	6893      	ldr	r3, [r2, #8]
    29be:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    29c2:	f003 fb89 	bl	60d8 <arch_syscall_oops>
    29c6:	68a3      	ldr	r3, [r4, #8]
    29c8:	689b      	ldr	r3, [r3, #8]
    29ca:	2b00      	cmp	r3, #0
    29cc:	d0f4      	beq.n	29b8 <z_mrsh_uart_err_check+0x20>
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	if (api->err_check != NULL) {
		return api->err_check(dev);
    29ce:	4620      	mov	r0, r4
    29d0:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_err_check(*(struct device **)&arg0)
;
	_current->syscall_frame = NULL;
    29d2:	68b3      	ldr	r3, [r6, #8]
    29d4:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    29d8:	bd70      	pop	{r4, r5, r6, pc}
    29da:	bf00      	nop
    29dc:	20000eec 	.word	0x20000eec

000029e0 <z_mrsh_uart_poll_in>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_poll_in(struct device * dev, unsigned char * p_char);
uintptr_t z_mrsh_uart_poll_in(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    29e0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    29e2:	4e17      	ldr	r6, [pc, #92]	; (2a40 <z_mrsh_uart_poll_in+0x60>)
    29e4:	9a08      	ldr	r2, [sp, #32]
    29e6:	68b3      	ldr	r3, [r6, #8]
    29e8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    29ec:	460d      	mov	r5, r1
    29ee:	4604      	mov	r4, r0
#include <syscalls/uart_err_check_mrsh.c>

static inline int z_vrfy_uart_poll_in(struct device *dev,
				      unsigned char *p_char)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_in));
    29f0:	f7fd fb74 	bl	dc <z_object_find>
    29f4:	2200      	movs	r2, #0
    29f6:	2126      	movs	r1, #38	; 0x26
    29f8:	f002 fdaa 	bl	5550 <z_object_validate>
    29fc:	4632      	mov	r2, r6
    29fe:	b178      	cbz	r0, 2a20 <z_mrsh_uart_poll_in+0x40>
    2a00:	f003 fc7b 	bl	62fa <arch_is_user_context>
    2a04:	6893      	ldr	r3, [r2, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(p_char, sizeof(unsigned char)));
    2a06:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2a0a:	f003 fb65 	bl	60d8 <arch_syscall_oops>
static inline int z_impl_uart_poll_in(struct device *dev, unsigned char *p_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	return api->poll_in(dev, p_char);
    2a0e:	68a3      	ldr	r3, [r4, #8]
    2a10:	4629      	mov	r1, r5
    2a12:	681b      	ldr	r3, [r3, #0]
    2a14:	4620      	mov	r0, r4
    2a16:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_poll_in(*(struct device **)&arg0, *(unsigned char **)&arg1)
;
	_current->syscall_frame = NULL;
    2a18:	68b3      	ldr	r3, [r6, #8]
    2a1a:	f8c3 7084 	str.w	r7, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2a1e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_in));
    2a20:	68a3      	ldr	r3, [r4, #8]
    2a22:	681b      	ldr	r3, [r3, #0]
    2a24:	2b00      	cmp	r3, #0
    2a26:	d0eb      	beq.n	2a00 <z_mrsh_uart_poll_in+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(p_char, sizeof(unsigned char)));
    2a28:	2201      	movs	r2, #1
    2a2a:	4611      	mov	r1, r2
    2a2c:	4628      	mov	r0, r5
    2a2e:	f003 fb81 	bl	6134 <arch_buffer_validate>
    2a32:	4607      	mov	r7, r0
    2a34:	2800      	cmp	r0, #0
    2a36:	d0ea      	beq.n	2a0e <z_mrsh_uart_poll_in+0x2e>
    2a38:	f003 fc5f 	bl	62fa <arch_is_user_context>
    2a3c:	68b3      	ldr	r3, [r6, #8]
    2a3e:	e7e2      	b.n	2a06 <z_mrsh_uart_poll_in+0x26>
    2a40:	20000eec 	.word	0x20000eec

00002a44 <z_mrsh_uart_poll_out>:
#include <syscalls/uart.h>

extern void z_vrfy_uart_poll_out(struct device * dev, unsigned char out_char);
uintptr_t z_mrsh_uart_poll_out(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2a44:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2a46:	4f11      	ldr	r7, [pc, #68]	; (2a8c <z_mrsh_uart_poll_out+0x48>)
    2a48:	9a08      	ldr	r2, [sp, #32]
    2a4a:	68bb      	ldr	r3, [r7, #8]
    2a4c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_uart_poll_out(*(struct device **)&arg0, *(unsigned char*)&arg1)
    2a50:	b2ce      	uxtb	r6, r1
{
    2a52:	4605      	mov	r5, r0
#include <syscalls/uart_poll_in_mrsh.c>

static inline void z_vrfy_uart_poll_out(struct device *dev,
					unsigned char out_char)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_out));
    2a54:	f7fd fb42 	bl	dc <z_object_find>
    2a58:	2200      	movs	r2, #0
    2a5a:	2126      	movs	r1, #38	; 0x26
    2a5c:	f002 fd78 	bl	5550 <z_object_validate>
    2a60:	463a      	mov	r2, r7
    2a62:	4604      	mov	r4, r0
    2a64:	b130      	cbz	r0, 2a74 <z_mrsh_uart_poll_out+0x30>
    2a66:	f003 fc48 	bl	62fa <arch_is_user_context>
    2a6a:	6893      	ldr	r3, [r2, #8]
    2a6c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2a70:	f003 fb32 	bl	60d8 <arch_syscall_oops>
    2a74:	68ab      	ldr	r3, [r5, #8]
    2a76:	685b      	ldr	r3, [r3, #4]
    2a78:	2b00      	cmp	r3, #0
    2a7a:	d0f4      	beq.n	2a66 <z_mrsh_uart_poll_out+0x22>
						unsigned char out_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	api->poll_out(dev, out_char);
    2a7c:	4628      	mov	r0, r5
    2a7e:	4631      	mov	r1, r6
    2a80:	4798      	blx	r3
;
	_current->syscall_frame = NULL;
    2a82:	68bb      	ldr	r3, [r7, #8]
	return 0;
}
    2a84:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    2a86:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    2a8a:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    2a8c:	20000eec 	.word	0x20000eec

00002a90 <z_mrsh_uart_config_get>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_config_get(struct device * dev, struct uart_config * cfg);
uintptr_t z_mrsh_uart_config_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2a90:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2a92:	4e1a      	ldr	r6, [pc, #104]	; (2afc <z_mrsh_uart_config_get+0x6c>)
    2a94:	9a08      	ldr	r2, [sp, #32]
    2a96:	68b3      	ldr	r3, [r6, #8]
    2a98:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2a9c:	460d      	mov	r5, r1
    2a9e:	4604      	mov	r4, r0
#include <syscalls/uart_poll_out_mrsh.c>

static inline int z_vrfy_uart_config_get(struct device *dev,
		struct uart_config *cfg)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2aa0:	f7fd fb1c 	bl	dc <z_object_find>
    2aa4:	2200      	movs	r2, #0
    2aa6:	2126      	movs	r1, #38	; 0x26
    2aa8:	f002 fd52 	bl	5550 <z_object_validate>
    2aac:	4637      	mov	r7, r6
    2aae:	b1a8      	cbz	r0, 2adc <z_mrsh_uart_config_get+0x4c>
    2ab0:	f003 fc23 	bl	62fa <arch_is_user_context>
    2ab4:	68bb      	ldr	r3, [r7, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(cfg, sizeof(struct uart_config)));
    2ab6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2aba:	f003 fb0d 	bl	60d8 <arch_syscall_oops>
{
	const struct uart_driver_api *api =
				(const struct uart_driver_api *)dev->driver_api;

	if (api->config_get != NULL) {
		return api->config_get(dev, cfg);
    2abe:	4629      	mov	r1, r5
    2ac0:	4620      	mov	r0, r4
    2ac2:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_config_get(*(struct device **)&arg0, *(struct uart_config **)&arg1)
;
	_current->syscall_frame = NULL;
    2ac4:	68bb      	ldr	r3, [r7, #8]
    2ac6:	2200      	movs	r2, #0
    2ac8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2acc:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (api->config_get != NULL) {
    2ace:	68a3      	ldr	r3, [r4, #8]
    2ad0:	691b      	ldr	r3, [r3, #16]
    2ad2:	2b00      	cmp	r3, #0
    2ad4:	d1f3      	bne.n	2abe <z_mrsh_uart_config_get+0x2e>
	}

	return -ENOTSUP;
    2ad6:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2ada:	e7f3      	b.n	2ac4 <z_mrsh_uart_config_get+0x34>
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2adc:	68a3      	ldr	r3, [r4, #8]
    2ade:	691b      	ldr	r3, [r3, #16]
    2ae0:	2b00      	cmp	r3, #0
    2ae2:	d0e5      	beq.n	2ab0 <z_mrsh_uart_config_get+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(cfg, sizeof(struct uart_config)));
    2ae4:	2201      	movs	r2, #1
    2ae6:	2108      	movs	r1, #8
    2ae8:	4628      	mov	r0, r5
    2aea:	f003 fb23 	bl	6134 <arch_buffer_validate>
    2aee:	2800      	cmp	r0, #0
    2af0:	d0ed      	beq.n	2ace <z_mrsh_uart_config_get+0x3e>
    2af2:	f003 fc02 	bl	62fa <arch_is_user_context>
    2af6:	68b3      	ldr	r3, [r6, #8]
    2af8:	e7dd      	b.n	2ab6 <z_mrsh_uart_config_get+0x26>
    2afa:	bf00      	nop
    2afc:	20000eec 	.word	0x20000eec

00002b00 <z_mrsh_uart_configure>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_configure(struct device * dev, const struct uart_config * cfg);
uintptr_t z_mrsh_uart_configure(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2b00:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2b02:	4e1a      	ldr	r6, [pc, #104]	; (2b6c <z_mrsh_uart_configure+0x6c>)
    2b04:	9a08      	ldr	r2, [sp, #32]
    2b06:	68b3      	ldr	r3, [r6, #8]
    2b08:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2b0c:	460d      	mov	r5, r1
    2b0e:	4604      	mov	r4, r0
#include <syscalls/uart_config_get_mrsh.c>

static inline int z_vrfy_uart_configure(struct device *dev,
		const struct uart_config *cfg)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2b10:	f7fd fae4 	bl	dc <z_object_find>
    2b14:	2200      	movs	r2, #0
    2b16:	2126      	movs	r1, #38	; 0x26
    2b18:	f002 fd1a 	bl	5550 <z_object_validate>
    2b1c:	4637      	mov	r7, r6
    2b1e:	4602      	mov	r2, r0
    2b20:	b1a8      	cbz	r0, 2b4e <z_mrsh_uart_configure+0x4e>
    2b22:	f003 fbea 	bl	62fa <arch_is_user_context>
    2b26:	68bb      	ldr	r3, [r7, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_READ(cfg, sizeof(struct uart_config)));
    2b28:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2b2c:	f003 fad4 	bl	60d8 <arch_syscall_oops>
		return api->configure(dev, cfg);
    2b30:	4629      	mov	r1, r5
    2b32:	4620      	mov	r0, r4
    2b34:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_configure(*(struct device **)&arg0, *(const struct uart_config **)&arg1)
;
	_current->syscall_frame = NULL;
    2b36:	68bb      	ldr	r3, [r7, #8]
    2b38:	2200      	movs	r2, #0
    2b3a:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2b3e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (api->configure != NULL) {
    2b40:	68a3      	ldr	r3, [r4, #8]
    2b42:	68db      	ldr	r3, [r3, #12]
    2b44:	2b00      	cmp	r3, #0
    2b46:	d1f3      	bne.n	2b30 <z_mrsh_uart_configure+0x30>
	return -ENOTSUP;
    2b48:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2b4c:	e7f3      	b.n	2b36 <z_mrsh_uart_configure+0x36>
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2b4e:	68a3      	ldr	r3, [r4, #8]
    2b50:	691b      	ldr	r3, [r3, #16]
    2b52:	2b00      	cmp	r3, #0
    2b54:	d0e5      	beq.n	2b22 <z_mrsh_uart_configure+0x22>
	Z_OOPS(Z_SYSCALL_MEMORY_READ(cfg, sizeof(struct uart_config)));
    2b56:	2108      	movs	r1, #8
    2b58:	4628      	mov	r0, r5
    2b5a:	f003 faeb 	bl	6134 <arch_buffer_validate>
    2b5e:	2800      	cmp	r0, #0
    2b60:	d0ee      	beq.n	2b40 <z_mrsh_uart_configure+0x40>
    2b62:	f003 fbca 	bl	62fa <arch_is_user_context>
    2b66:	68b3      	ldr	r3, [r6, #8]
    2b68:	e7de      	b.n	2b28 <z_mrsh_uart_configure+0x28>
    2b6a:	bf00      	nop
    2b6c:	20000eec 	.word	0x20000eec

00002b70 <nrf52_errata_108>:
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1;
            uint32_t var2;

            if (*(uint32_t *)0x10000130ul == 0xFFFFFFFF)
    2b70:	4b0b      	ldr	r3, [pc, #44]	; (2ba0 <nrf52_errata_108+0x30>)
    2b72:	681b      	ldr	r3, [r3, #0]
    2b74:	1c5a      	adds	r2, r3, #1
            {
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2b76:	bf05      	ittet	eq
    2b78:	4b0a      	ldreq	r3, [pc, #40]	; (2ba4 <nrf52_errata_108+0x34>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2b7a:	4a0b      	ldreq	r2, [pc, #44]	; (2ba8 <nrf52_errata_108+0x38>)
            }
            else
            {
                var1 = *(uint32_t *)0x10000130ul;
                var2 = *(uint32_t *)0x10000134ul;
    2b7c:	4a0b      	ldrne	r2, [pc, #44]	; (2bac <nrf52_errata_108+0x3c>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2b7e:	6810      	ldreq	r0, [r2, #0]
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2b80:	bf0a      	itet	eq
    2b82:	781b      	ldrbeq	r3, [r3, #0]
                var2 = *(uint32_t *)0x10000134ul;
    2b84:	6810      	ldrne	r0, [r2, #0]
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2b86:	f3c0 1003 	ubfxeq	r0, r0, #4, #4
            }
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2b8a:	2b06      	cmp	r3, #6
    2b8c:	d105      	bne.n	2b9a <nrf52_errata_108+0x2a>
            {
                switch(var2)
    2b8e:	3803      	subs	r0, #3
    2b90:	2803      	cmp	r0, #3
    2b92:	bf8c      	ite	hi
    2b94:	2000      	movhi	r0, #0
    2b96:	2001      	movls	r0, #1
    2b98:	4770      	bx	lr
                    case 0x06ul:
                        return true;
                }
            }
        #endif
        return false;
    2b9a:	2000      	movs	r0, #0
    #endif
}
    2b9c:	4770      	bx	lr
    2b9e:	bf00      	nop
    2ba0:	10000130 	.word	0x10000130
    2ba4:	f0000fe0 	.word	0xf0000fe0
    2ba8:	f0000fe8 	.word	0xf0000fe8
    2bac:	10000134 	.word	0x10000134

00002bb0 <nrf52_errata_16>:
    #ifndef NRF52_SERIES
        return false;
    #else
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2bb0:	4b07      	ldr	r3, [pc, #28]	; (2bd0 <nrf52_errata_16+0x20>)
    2bb2:	781b      	ldrb	r3, [r3, #0]
            uint32_t var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2bb4:	2b06      	cmp	r3, #6
    2bb6:	d109      	bne.n	2bcc <nrf52_errata_16+0x1c>
            uint32_t var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2bb8:	4b06      	ldr	r3, [pc, #24]	; (2bd4 <nrf52_errata_16+0x24>)
    2bba:	681b      	ldr	r3, [r3, #0]
    2bbc:	f3c3 1303 	ubfx	r3, r3, #4, #4
    2bc0:	3b03      	subs	r3, #3
    2bc2:	2b03      	cmp	r3, #3
    2bc4:	d802      	bhi.n	2bcc <nrf52_errata_16+0x1c>
    2bc6:	4a04      	ldr	r2, [pc, #16]	; (2bd8 <nrf52_errata_16+0x28>)
    2bc8:	5cd0      	ldrb	r0, [r2, r3]
    2bca:	4770      	bx	lr
                    case 0x06ul:
                        return false;
                }
            }
        #endif
        return false;
    2bcc:	2000      	movs	r0, #0
    #endif
}
    2bce:	4770      	bx	lr
    2bd0:	f0000fe0 	.word	0xf0000fe0
    2bd4:	f0000fe8 	.word	0xf0000fe8
    2bd8:	000078d0 	.word	0x000078d0

00002bdc <SystemInit>:
{
    SystemCoreClock = __SYSTEM_CLOCK_64M;
}

void SystemInit(void)
{
    2bdc:	b508      	push	{r3, lr}
        NRF_P0->PIN_CNF[20] = (GPIO_PIN_CNF_DRIVE_H0H1 << GPIO_PIN_CNF_DRIVE_Pos) | (GPIO_PIN_CNF_INPUT_Connect << GPIO_PIN_CNF_INPUT_Pos) | (GPIO_PIN_CNF_DIR_Output << GPIO_PIN_CNF_DIR_Pos);
    #endif
    
    /* Workaround for Errata 12 "COMP: Reference ladder not correctly calibrated" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_12()){
    2bde:	f7ff ffc7 	bl	2b70 <nrf52_errata_108>
    2be2:	b128      	cbz	r0, 2bf0 <SystemInit+0x14>
        *(volatile uint32_t *)0x40013540 = (*(uint32_t *)0x10000324 & 0x00001F00) >> 8;
    2be4:	4b7e      	ldr	r3, [pc, #504]	; (2de0 <SystemInit+0x204>)
    2be6:	4a7f      	ldr	r2, [pc, #508]	; (2de4 <SystemInit+0x208>)
    2be8:	681b      	ldr	r3, [r3, #0]
    2bea:	f3c3 2304 	ubfx	r3, r3, #8, #5
    2bee:	6013      	str	r3, [r2, #0]
    }
    
    /* Workaround for Errata 16 "System: RAM may be corrupt on wakeup from CPU IDLE" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_16()){
    2bf0:	f7ff ffde 	bl	2bb0 <nrf52_errata_16>
    2bf4:	b110      	cbz	r0, 2bfc <SystemInit+0x20>
        *(volatile uint32_t *)0x4007C074 = 3131961357ul;
    2bf6:	4b7c      	ldr	r3, [pc, #496]	; (2de8 <SystemInit+0x20c>)
    2bf8:	4a7c      	ldr	r2, [pc, #496]	; (2dec <SystemInit+0x210>)
    2bfa:	601a      	str	r2, [r3, #0]
    }

    /* Workaround for Errata 31 "CLOCK: Calibration values are not correctly loaded from FICR at reset" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_31()){
    2bfc:	f7ff ffb8 	bl	2b70 <nrf52_errata_108>
    2c00:	b128      	cbz	r0, 2c0e <SystemInit+0x32>
        *(volatile uint32_t *)0x4000053C = ((*(volatile uint32_t *)0x10000244) & 0x0000E000) >> 13;
    2c02:	4b7b      	ldr	r3, [pc, #492]	; (2df0 <SystemInit+0x214>)
    2c04:	4a7b      	ldr	r2, [pc, #492]	; (2df4 <SystemInit+0x218>)
    2c06:	681b      	ldr	r3, [r3, #0]
    2c08:	f3c3 3342 	ubfx	r3, r3, #13, #3
    2c0c:	6013      	str	r3, [r2, #0]
    }

    /* Workaround for Errata 32 "DIF: Debug session automatically enables TracePort pins" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_32()){
    2c0e:	f7ff ffcf 	bl	2bb0 <nrf52_errata_16>
    2c12:	b120      	cbz	r0, 2c1e <SystemInit+0x42>
        CoreDebug->DEMCR &= ~CoreDebug_DEMCR_TRCENA_Msk;
    2c14:	4a78      	ldr	r2, [pc, #480]	; (2df8 <SystemInit+0x21c>)
    2c16:	68d3      	ldr	r3, [r2, #12]
    2c18:	f023 7380 	bic.w	r3, r3, #16777216	; 0x1000000
    2c1c:	60d3      	str	r3, [r2, #12]
    }

    /* Workaround for Errata 36 "CLOCK: Some registers are not reset when expected" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_36()){
    2c1e:	f7ff ffa7 	bl	2b70 <nrf52_errata_108>
    2c22:	b140      	cbz	r0, 2c36 <SystemInit+0x5a>
        NRF_CLOCK->EVENTS_DONE = 0;
    2c24:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    2c28:	2200      	movs	r2, #0
    2c2a:	f8c3 210c 	str.w	r2, [r3, #268]	; 0x10c
        NRF_CLOCK->EVENTS_CTTO = 0;
    2c2e:	f8c3 2110 	str.w	r2, [r3, #272]	; 0x110
        NRF_CLOCK->CTIV = 0;
    2c32:	f8c3 2538 	str.w	r2, [r3, #1336]	; 0x538
    }

    /* Workaround for Errata 37 "RADIO: Encryption engine is slow by default" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_37()){
    2c36:	f7ff ffbb 	bl	2bb0 <nrf52_errata_16>
    2c3a:	b110      	cbz	r0, 2c42 <SystemInit+0x66>
        *(volatile uint32_t *)0x400005A0 = 0x3;
    2c3c:	4b6f      	ldr	r3, [pc, #444]	; (2dfc <SystemInit+0x220>)
    2c3e:	2203      	movs	r2, #3
    2c40:	601a      	str	r2, [r3, #0]
    }

    /* Workaround for Errata 57 "NFCT: NFC Modulation amplitude" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_57()){
    2c42:	f7ff ffb5 	bl	2bb0 <nrf52_errata_16>
    2c46:	b140      	cbz	r0, 2c5a <SystemInit+0x7e>
        *(volatile uint32_t *)0x40005610 = 0x00000005;
    2c48:	4b6d      	ldr	r3, [pc, #436]	; (2e00 <SystemInit+0x224>)
    2c4a:	2205      	movs	r2, #5
    2c4c:	601a      	str	r2, [r3, #0]
        *(volatile uint32_t *)0x40005688 = 0x00000001;
    2c4e:	2201      	movs	r2, #1
    2c50:	679a      	str	r2, [r3, #120]	; 0x78
        *(volatile uint32_t *)0x40005618 = 0x00000000;
    2c52:	2200      	movs	r2, #0
    2c54:	609a      	str	r2, [r3, #8]
        *(volatile uint32_t *)0x40005614 = 0x0000003F;
    2c56:	223f      	movs	r2, #63	; 0x3f
    2c58:	605a      	str	r2, [r3, #4]
         || defined (NRF52833_XXAA) || defined (DEVELOP_IN_NRF52833)\
         || defined (NRF52840_XXAA) || defined (DEVELOP_IN_NRF52840)
            uint32_t var1;
            uint32_t var2;

            if (*(uint32_t *)0x10000130ul == 0xFFFFFFFF)
    2c5a:	4b6a      	ldr	r3, [pc, #424]	; (2e04 <SystemInit+0x228>)
    2c5c:	681a      	ldr	r2, [r3, #0]
    2c5e:	1c51      	adds	r1, r2, #1
            {
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2c60:	bf0b      	itete	eq
    2c62:	4b69      	ldreq	r3, [pc, #420]	; (2e08 <SystemInit+0x22c>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
            }
            else
            {
                var1 = *(uint32_t *)0x10000130ul;
                var2 = *(uint32_t *)0x10000134ul;
    2c64:	4b69      	ldrne	r3, [pc, #420]	; (2e0c <SystemInit+0x230>)
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2c66:	781a      	ldrbeq	r2, [r3, #0]
                var2 = *(uint32_t *)0x10000134ul;
    2c68:	681b      	ldrne	r3, [r3, #0]
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2c6a:	bf02      	ittt	eq
    2c6c:	3308      	addeq	r3, #8
    2c6e:	681b      	ldreq	r3, [r3, #0]
    2c70:	f3c3 1303 	ubfxeq	r3, r3, #4, #4
            }
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2c74:	2a06      	cmp	r2, #6
    2c76:	d14d      	bne.n	2d14 <SystemInit+0x138>
            {
                switch(var2)
    2c78:	3b03      	subs	r3, #3
    2c7a:	2b03      	cmp	r3, #3
    2c7c:	d84a      	bhi.n	2d14 <SystemInit+0x138>
    }

    /* Workaround for Errata 66 "TEMP: Linearity specification not met with default settings" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_66()){
    2c7e:	4a64      	ldr	r2, [pc, #400]	; (2e10 <SystemInit+0x234>)
    2c80:	5cd3      	ldrb	r3, [r2, r3]
    2c82:	2b00      	cmp	r3, #0
    2c84:	d046      	beq.n	2d14 <SystemInit+0x138>
        NRF_TEMP->A0 = NRF_FICR->TEMP.A0;
    2c86:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
    2c8a:	4b62      	ldr	r3, [pc, #392]	; (2e14 <SystemInit+0x238>)
    2c8c:	f8d2 1404 	ldr.w	r1, [r2, #1028]	; 0x404
    2c90:	f8c3 1520 	str.w	r1, [r3, #1312]	; 0x520
        NRF_TEMP->A1 = NRF_FICR->TEMP.A1;
    2c94:	f8d2 1408 	ldr.w	r1, [r2, #1032]	; 0x408
    2c98:	f8c3 1524 	str.w	r1, [r3, #1316]	; 0x524
        NRF_TEMP->A2 = NRF_FICR->TEMP.A2;
    2c9c:	f8d2 140c 	ldr.w	r1, [r2, #1036]	; 0x40c
    2ca0:	f8c3 1528 	str.w	r1, [r3, #1320]	; 0x528
        NRF_TEMP->A3 = NRF_FICR->TEMP.A3;
    2ca4:	f8d2 1410 	ldr.w	r1, [r2, #1040]	; 0x410
    2ca8:	f8c3 152c 	str.w	r1, [r3, #1324]	; 0x52c
        NRF_TEMP->A4 = NRF_FICR->TEMP.A4;
    2cac:	f8d2 1414 	ldr.w	r1, [r2, #1044]	; 0x414
    2cb0:	f8c3 1530 	str.w	r1, [r3, #1328]	; 0x530
        NRF_TEMP->A5 = NRF_FICR->TEMP.A5;
    2cb4:	f8d2 1418 	ldr.w	r1, [r2, #1048]	; 0x418
    2cb8:	f8c3 1534 	str.w	r1, [r3, #1332]	; 0x534
        NRF_TEMP->B0 = NRF_FICR->TEMP.B0;
    2cbc:	f8d2 141c 	ldr.w	r1, [r2, #1052]	; 0x41c
    2cc0:	f8c3 1540 	str.w	r1, [r3, #1344]	; 0x540
        NRF_TEMP->B1 = NRF_FICR->TEMP.B1;
    2cc4:	f8d2 1420 	ldr.w	r1, [r2, #1056]	; 0x420
    2cc8:	f8c3 1544 	str.w	r1, [r3, #1348]	; 0x544
        NRF_TEMP->B2 = NRF_FICR->TEMP.B2;
    2ccc:	f8d2 1424 	ldr.w	r1, [r2, #1060]	; 0x424
    2cd0:	f8c3 1548 	str.w	r1, [r3, #1352]	; 0x548
        NRF_TEMP->B3 = NRF_FICR->TEMP.B3;
    2cd4:	f8d2 1428 	ldr.w	r1, [r2, #1064]	; 0x428
    2cd8:	f8c3 154c 	str.w	r1, [r3, #1356]	; 0x54c
        NRF_TEMP->B4 = NRF_FICR->TEMP.B4;
    2cdc:	f8d2 142c 	ldr.w	r1, [r2, #1068]	; 0x42c
    2ce0:	f8c3 1550 	str.w	r1, [r3, #1360]	; 0x550
        NRF_TEMP->B5 = NRF_FICR->TEMP.B5;
    2ce4:	f8d2 1430 	ldr.w	r1, [r2, #1072]	; 0x430
    2ce8:	f8c3 1554 	str.w	r1, [r3, #1364]	; 0x554
        NRF_TEMP->T0 = NRF_FICR->TEMP.T0;
    2cec:	f8d2 1434 	ldr.w	r1, [r2, #1076]	; 0x434
    2cf0:	f8c3 1560 	str.w	r1, [r3, #1376]	; 0x560
        NRF_TEMP->T1 = NRF_FICR->TEMP.T1;
    2cf4:	f8d2 1438 	ldr.w	r1, [r2, #1080]	; 0x438
    2cf8:	f8c3 1564 	str.w	r1, [r3, #1380]	; 0x564
        NRF_TEMP->T2 = NRF_FICR->TEMP.T2;
    2cfc:	f8d2 143c 	ldr.w	r1, [r2, #1084]	; 0x43c
    2d00:	f8c3 1568 	str.w	r1, [r3, #1384]	; 0x568
        NRF_TEMP->T3 = NRF_FICR->TEMP.T3;
    2d04:	f8d2 1440 	ldr.w	r1, [r2, #1088]	; 0x440
    2d08:	f8c3 156c 	str.w	r1, [r3, #1388]	; 0x56c
        NRF_TEMP->T4 = NRF_FICR->TEMP.T4;
    2d0c:	f8d2 2444 	ldr.w	r2, [r2, #1092]	; 0x444
    2d10:	f8c3 2570 	str.w	r2, [r3, #1392]	; 0x570
    }

    /* Workaround for Errata 108 "RAM: RAM content cannot be trusted upon waking up from System ON Idle or System OFF mode" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_108()){
    2d14:	f7ff ff2c 	bl	2b70 <nrf52_errata_108>
    2d18:	b128      	cbz	r0, 2d26 <SystemInit+0x14a>
        *(volatile uint32_t *)0x40000EE4ul = *(volatile uint32_t *)0x10000258ul & 0x0000004Ful;
    2d1a:	4b3f      	ldr	r3, [pc, #252]	; (2e18 <SystemInit+0x23c>)
    2d1c:	4a3f      	ldr	r2, [pc, #252]	; (2e1c <SystemInit+0x240>)
    2d1e:	681b      	ldr	r3, [r3, #0]
    2d20:	f003 034f 	and.w	r3, r3, #79	; 0x4f
    2d24:	6013      	str	r3, [r2, #0]
    }
    
    /* Workaround for Errata 136 "System: Bits in RESETREAS are set when they should not be" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_136()){
    2d26:	f7ff ff23 	bl	2b70 <nrf52_errata_108>
    2d2a:	b148      	cbz	r0, 2d40 <SystemInit+0x164>
        if (NRF_POWER->RESETREAS & POWER_RESETREAS_RESETPIN_Msk){
    2d2c:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    2d30:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2d34:	07d2      	lsls	r2, r2, #31
            NRF_POWER->RESETREAS =  ~POWER_RESETREAS_RESETPIN_Msk;
    2d36:	bf44      	itt	mi
    2d38:	f06f 0201 	mvnmi.w	r2, #1
    2d3c:	f8c3 2400 	strmi.w	r2, [r3, #1024]	; 0x400
    #ifndef NRF52_SERIES
        return false;
    #else
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1 = *(uint32_t *)0x10000130ul;
    2d40:	4b30      	ldr	r3, [pc, #192]	; (2e04 <SystemInit+0x228>)
            uint32_t var2 = *(uint32_t *)0x10000134ul;
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2d42:	681b      	ldr	r3, [r3, #0]
    2d44:	2b06      	cmp	r3, #6
    2d46:	d10c      	bne.n	2d62 <SystemInit+0x186>
            uint32_t var2 = *(uint32_t *)0x10000134ul;
    2d48:	4b30      	ldr	r3, [pc, #192]	; (2e0c <SystemInit+0x230>)
    2d4a:	681b      	ldr	r3, [r3, #0]
    2d4c:	3b03      	subs	r3, #3
    2d4e:	2b03      	cmp	r3, #3
    2d50:	d807      	bhi.n	2d62 <SystemInit+0x186>
        }
    }
    
    /* Workaround for Errata 182 "RADIO: Fixes for anomalies #102, #106, and #107 do not take effect" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_182()){
    2d52:	4a33      	ldr	r2, [pc, #204]	; (2e20 <SystemInit+0x244>)
    2d54:	5cd3      	ldrb	r3, [r2, r3]
    2d56:	b123      	cbz	r3, 2d62 <SystemInit+0x186>
        *(volatile uint32_t *) 0x4000173C |= (0x1 << 10);
    2d58:	4a32      	ldr	r2, [pc, #200]	; (2e24 <SystemInit+0x248>)
    2d5a:	6813      	ldr	r3, [r2, #0]
    2d5c:	f443 6380 	orr.w	r3, r3, #1024	; 0x400
    2d60:	6013      	str	r3, [r2, #0]

    /* Configure GPIO pads as pPin Reset pin if Pin Reset capabilities desired. If CONFIG_GPIO_AS_PINRESET is not
      defined, pin reset will not be available. One GPIO (see Product Specification to see which one) will then be
      reserved for PinReset and not available as normal GPIO. */
    #if defined (CONFIG_GPIO_AS_PINRESET)
        if (((NRF_UICR->PSELRESET[0] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos)) ||
    2d62:	f04f 2310 	mov.w	r3, #268439552	; 0x10001000
    2d66:	f8d3 2200 	ldr.w	r2, [r3, #512]	; 0x200
    2d6a:	2a00      	cmp	r2, #0
    2d6c:	db03      	blt.n	2d76 <SystemInit+0x19a>
            ((NRF_UICR->PSELRESET[1] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos))){
    2d6e:	f8d3 3204 	ldr.w	r3, [r3, #516]	; 0x204
        if (((NRF_UICR->PSELRESET[0] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos)) ||
    2d72:	2b00      	cmp	r3, #0
    2d74:	da2f      	bge.n	2dd6 <SystemInit+0x1fa>
            NRF_NVMC->CONFIG = NVMC_CONFIG_WEN_Wen << NVMC_CONFIG_WEN_Pos;
    2d76:	4b2c      	ldr	r3, [pc, #176]	; (2e28 <SystemInit+0x24c>)
    2d78:	2201      	movs	r2, #1
    2d7a:	f8c3 2504 	str.w	r2, [r3, #1284]	; 0x504
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2d7e:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2d82:	2a00      	cmp	r2, #0
    2d84:	d0fb      	beq.n	2d7e <SystemInit+0x1a2>
            NRF_UICR->PSELRESET[0] = 21;
    2d86:	f04f 2210 	mov.w	r2, #268439552	; 0x10001000
    2d8a:	2115      	movs	r1, #21
    2d8c:	f8c2 1200 	str.w	r1, [r2, #512]	; 0x200
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2d90:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2d94:	2a00      	cmp	r2, #0
    2d96:	d0fb      	beq.n	2d90 <SystemInit+0x1b4>
            NRF_UICR->PSELRESET[1] = 21;
    2d98:	f04f 2310 	mov.w	r3, #268439552	; 0x10001000
    2d9c:	2215      	movs	r2, #21
    2d9e:	f8c3 2204 	str.w	r2, [r3, #516]	; 0x204
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2da2:	4b21      	ldr	r3, [pc, #132]	; (2e28 <SystemInit+0x24c>)
    2da4:	461a      	mov	r2, r3
    2da6:	f8d3 1400 	ldr.w	r1, [r3, #1024]	; 0x400
    2daa:	2900      	cmp	r1, #0
    2dac:	d0fb      	beq.n	2da6 <SystemInit+0x1ca>
            NRF_NVMC->CONFIG = NVMC_CONFIG_WEN_Ren << NVMC_CONFIG_WEN_Pos;
    2dae:	2100      	movs	r1, #0
    2db0:	f8c3 1504 	str.w	r1, [r3, #1284]	; 0x504
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2db4:	f8d2 3400 	ldr.w	r3, [r2, #1024]	; 0x400
    2db8:	2b00      	cmp	r3, #0
    2dba:	d0fb      	beq.n	2db4 <SystemInit+0x1d8>
  __ASM volatile ("dsb 0xF":::"memory");
    2dbc:	f3bf 8f4f 	dsb	sy
__NO_RETURN __STATIC_INLINE void __NVIC_SystemReset(void)
{
  __DSB();                                                          /* Ensure all outstanding memory accesses included
                                                                       buffered write are completed before reset */
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
                           (SCB->AIRCR & SCB_AIRCR_PRIGROUP_Msk) |
    2dc0:	491a      	ldr	r1, [pc, #104]	; (2e2c <SystemInit+0x250>)
    2dc2:	4b1b      	ldr	r3, [pc, #108]	; (2e30 <SystemInit+0x254>)
    2dc4:	68ca      	ldr	r2, [r1, #12]
    2dc6:	f402 62e0 	and.w	r2, r2, #1792	; 0x700
    2dca:	4313      	orrs	r3, r2
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
    2dcc:	60cb      	str	r3, [r1, #12]
    2dce:	f3bf 8f4f 	dsb	sy
                            SCB_AIRCR_SYSRESETREQ_Msk    );         /* Keep priority group unchanged */
  __DSB();                                                          /* Ensure completion of memory access */

  for(;;)                                                           /* wait until reset */
  {
    __NOP();
    2dd2:	bf00      	nop
  for(;;)                                                           /* wait until reset */
    2dd4:	e7fd      	b.n	2dd2 <SystemInit+0x1f6>
    SystemCoreClock = __SYSTEM_CLOCK_64M;
    2dd6:	4b17      	ldr	r3, [pc, #92]	; (2e34 <SystemInit+0x258>)
    2dd8:	4a17      	ldr	r2, [pc, #92]	; (2e38 <SystemInit+0x25c>)
    2dda:	601a      	str	r2, [r3, #0]
            NVIC_SystemReset();
        }
    #endif

    SystemCoreClockUpdate();
}
    2ddc:	bd08      	pop	{r3, pc}
    2dde:	bf00      	nop
    2de0:	10000324 	.word	0x10000324
    2de4:	40013540 	.word	0x40013540
    2de8:	4007c074 	.word	0x4007c074
    2dec:	baadf00d 	.word	0xbaadf00d
    2df0:	10000244 	.word	0x10000244
    2df4:	4000053c 	.word	0x4000053c
    2df8:	e000edf0 	.word	0xe000edf0
    2dfc:	400005a0 	.word	0x400005a0
    2e00:	40005610 	.word	0x40005610
    2e04:	10000130 	.word	0x10000130
    2e08:	f0000fe0 	.word	0xf0000fe0
    2e0c:	10000134 	.word	0x10000134
    2e10:	000078c8 	.word	0x000078c8
    2e14:	4000c000 	.word	0x4000c000
    2e18:	10000258 	.word	0x10000258
    2e1c:	40000ee4 	.word	0x40000ee4
    2e20:	000078cc 	.word	0x000078cc
    2e24:	4000173c 	.word	0x4000173c
    2e28:	4001e000 	.word	0x4001e000
    2e2c:	e000ed00 	.word	0xe000ed00
    2e30:	05fa0004 	.word	0x05fa0004
    2e34:	20003410 	.word	0x20003410
    2e38:	03d09000 	.word	0x03d09000

00002e3c <z_sys_init_run_level>:
 * off and the next one begins.
 *
 * @param level init level to run.
 */
void z_sys_init_run_level(int32_t level)
{
    2e3c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2e3e:	4b0b      	ldr	r3, [pc, #44]	; (2e6c <z_sys_init_run_level+0x30>)
    2e40:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
    2e44:	3001      	adds	r0, #1
			if (dev) {
				/* Initialization failed. Clear the API struct
				 * so that device_get_binding() will not succeed
				 * for it.
				 */
				dev->driver_api = NULL;
    2e46:	2700      	movs	r7, #0
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2e48:	f853 6020 	ldr.w	r6, [r3, r0, lsl #2]
    2e4c:	42a6      	cmp	r6, r4
    2e4e:	d800      	bhi.n	2e52 <z_sys_init_run_level+0x16>
			}
		}
	}
}
    2e50:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		struct device *dev = entry->dev;
    2e52:	6865      	ldr	r5, [r4, #4]
		if (dev != NULL) {
    2e54:	b115      	cbz	r5, 2e5c <z_sys_init_run_level+0x20>
			z_object_init(dev);
    2e56:	4628      	mov	r0, r5
    2e58:	f004 f870 	bl	6f3c <z_object_init>
		retval = entry->init(dev);
    2e5c:	6823      	ldr	r3, [r4, #0]
    2e5e:	4628      	mov	r0, r5
    2e60:	4798      	blx	r3
		if (retval != 0) {
    2e62:	b108      	cbz	r0, 2e68 <z_sys_init_run_level+0x2c>
			if (dev) {
    2e64:	b105      	cbz	r5, 2e68 <z_sys_init_run_level+0x2c>
				dev->driver_api = NULL;
    2e66:	60af      	str	r7, [r5, #8]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2e68:	3408      	adds	r4, #8
    2e6a:	e7ef      	b.n	2e4c <z_sys_init_run_level+0x10>
    2e6c:	0000734c 	.word	0x0000734c

00002e70 <z_impl_device_get_binding>:
	/* Split the search into two loops: in the common scenario, where
	 * device names are stored in ROM (and are referenced by the user
	 * with CONFIG_* macros), only cheap pointer comparisons will be
	 * performed. Reserve string comparisons for a fallback.
	 */
	for (dev = __device_start; dev != __device_end; dev++) {
    2e70:	4b0f      	ldr	r3, [pc, #60]	; (2eb0 <z_impl_device_get_binding+0x40>)
{
    2e72:	b570      	push	{r4, r5, r6, lr}
	for (dev = __device_start; dev != __device_end; dev++) {
    2e74:	4c0f      	ldr	r4, [pc, #60]	; (2eb4 <z_impl_device_get_binding+0x44>)
{
    2e76:	4605      	mov	r5, r0
    2e78:	461e      	mov	r6, r3
	for (dev = __device_start; dev != __device_end; dev++) {
    2e7a:	429c      	cmp	r4, r3
    2e7c:	d104      	bne.n	2e88 <z_impl_device_get_binding+0x18>
		if (z_device_ready(dev) && (dev->name == name)) {
			return dev;
		}
	}

	for (dev = __device_start; dev != __device_end; dev++) {
    2e7e:	4c0d      	ldr	r4, [pc, #52]	; (2eb4 <z_impl_device_get_binding+0x44>)
    2e80:	42b4      	cmp	r4, r6
    2e82:	d108      	bne.n	2e96 <z_impl_device_get_binding+0x26>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
			return dev;
		}
	}

	return NULL;
    2e84:	2400      	movs	r4, #0
    2e86:	e010      	b.n	2eaa <z_impl_device_get_binding+0x3a>
		if (z_device_ready(dev) && (dev->name == name)) {
    2e88:	68a2      	ldr	r2, [r4, #8]
    2e8a:	b112      	cbz	r2, 2e92 <z_impl_device_get_binding+0x22>
    2e8c:	6822      	ldr	r2, [r4, #0]
    2e8e:	42aa      	cmp	r2, r5
    2e90:	d00b      	beq.n	2eaa <z_impl_device_get_binding+0x3a>
	for (dev = __device_start; dev != __device_end; dev++) {
    2e92:	3410      	adds	r4, #16
    2e94:	e7f1      	b.n	2e7a <z_impl_device_get_binding+0xa>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    2e96:	68a3      	ldr	r3, [r4, #8]
    2e98:	b90b      	cbnz	r3, 2e9e <z_impl_device_get_binding+0x2e>
	for (dev = __device_start; dev != __device_end; dev++) {
    2e9a:	3410      	adds	r4, #16
    2e9c:	e7f0      	b.n	2e80 <z_impl_device_get_binding+0x10>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    2e9e:	6821      	ldr	r1, [r4, #0]
    2ea0:	4628      	mov	r0, r5
    2ea2:	f003 f95d 	bl	6160 <strcmp>
    2ea6:	2800      	cmp	r0, #0
    2ea8:	d1f7      	bne.n	2e9a <z_impl_device_get_binding+0x2a>
}
    2eaa:	4620      	mov	r0, r4
    2eac:	bd70      	pop	{r4, r5, r6, pc}
    2eae:	bf00      	nop
    2eb0:	20003460 	.word	0x20003460
    2eb4:	20003420 	.word	0x20003420

00002eb8 <z_mrsh_device_get_binding>:
#include <syscalls/device.h>

extern struct device * z_vrfy_device_get_binding(const char * name);
uintptr_t z_mrsh_device_get_binding(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2eb8:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    2eba:	4c0b      	ldr	r4, [pc, #44]	; (2ee8 <z_mrsh_device_get_binding+0x30>)
{
    2ebc:	b08c      	sub	sp, #48	; 0x30
	_current->syscall_frame = ssf;
    2ebe:	68a3      	ldr	r3, [r4, #8]
    2ec0:	9a10      	ldr	r2, [sp, #64]	; 0x40
    2ec2:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2ec6:	4601      	mov	r1, r0
#ifdef CONFIG_USERSPACE
static inline struct device *z_vrfy_device_get_binding(const char *name)
{
	char name_copy[Z_DEVICE_MAX_NAME_LEN];

	if (z_user_string_copy(name_copy, (char *)name, sizeof(name_copy))
    2ec8:	2230      	movs	r2, #48	; 0x30
    2eca:	4668      	mov	r0, sp
    2ecc:	f004 f85e 	bl	6f8c <z_user_string_copy>
    2ed0:	b940      	cbnz	r0, 2ee4 <z_mrsh_device_get_binding+0x2c>
	    != 0) {
		return 0;
	}

	return z_impl_device_get_binding(name_copy);
    2ed2:	4668      	mov	r0, sp
    2ed4:	f7ff ffcc 	bl	2e70 <z_impl_device_get_binding>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	struct device * ret = z_vrfy_device_get_binding(*(const char **)&arg0)
;
	_current->syscall_frame = NULL;
    2ed8:	68a3      	ldr	r3, [r4, #8]
    2eda:	2200      	movs	r2, #0
    2edc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2ee0:	b00c      	add	sp, #48	; 0x30
    2ee2:	bd10      	pop	{r4, pc}
		return 0;
    2ee4:	2000      	movs	r0, #0
    2ee6:	e7f7      	b.n	2ed8 <z_mrsh_device_get_binding+0x20>
    2ee8:	20000eec 	.word	0x20000eec

00002eec <z_mrsh_z_errno>:

extern int * z_vrfy_z_errno();
uintptr_t z_mrsh_z_errno(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    2eec:	4b03      	ldr	r3, [pc, #12]	; (2efc <z_mrsh_z_errno+0x10>)
    2eee:	689b      	ldr	r3, [r3, #8]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int * ret = z_vrfy_z_errno()
;
	_current->syscall_frame = NULL;
    2ef0:	2200      	movs	r2, #0
	return (uintptr_t) ret;
}
    2ef2:	6e58      	ldr	r0, [r3, #100]	; 0x64
	_current->syscall_frame = NULL;
    2ef4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
}
    2ef8:	4770      	bx	lr
    2efa:	bf00      	nop
    2efc:	20000eec 	.word	0x20000eec

00002f00 <idle>:
#else
#define IDLE_YIELD_IF_COOP() do { } while (false)
#endif

void idle(void *unused1, void *unused2, void *unused3)
{
    2f00:	b508      	push	{r3, lr}
	_kernel.idle = ticks;
    2f02:	4d0b      	ldr	r5, [pc, #44]	; (2f30 <idle+0x30>)
	__asm__ volatile(
    2f04:	f04f 0220 	mov.w	r2, #32
    2f08:	f3ef 8311 	mrs	r3, BASEPRI
    2f0c:	f382 8811 	msr	BASEPRI, r2
    2f10:	f3bf 8f6f 	isb	sy
	int32_t ticks = z_get_next_timeout_expiry();
    2f14:	f003 fe9a 	bl	6c4c <z_get_next_timeout_expiry>
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    2f18:	2101      	movs	r1, #1
    2f1a:	2802      	cmp	r0, #2
	int32_t ticks = z_get_next_timeout_expiry();
    2f1c:	4604      	mov	r4, r0
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    2f1e:	bfd8      	it	le
    2f20:	4608      	movle	r0, r1
    2f22:	f003 fea3 	bl	6c6c <z_set_timeout_expiry>
	_kernel.idle = ticks;
    2f26:	622c      	str	r4, [r5, #32]
 *
 * @return N/A
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
    2f28:	f7fe fba8 	bl	167c <arch_cpu_idle>
}
    2f2c:	e7ea      	b.n	2f04 <idle+0x4>
    2f2e:	bf00      	nop
    2f30:	20000eec 	.word	0x20000eec

00002f34 <z_bss_zero>:
 *
 * @return N/A
 */
void z_bss_zero(void)
{
	(void)memset(__bss_start, 0, __bss_end - __bss_start);
    2f34:	4802      	ldr	r0, [pc, #8]	; (2f40 <z_bss_zero+0xc>)
    2f36:	4a03      	ldr	r2, [pc, #12]	; (2f44 <z_bss_zero+0x10>)
    2f38:	2100      	movs	r1, #0
    2f3a:	1a12      	subs	r2, r2, r0
    2f3c:	f003 b947 	b.w	61ce <memset>
    2f40:	20000000 	.word	0x20000000
    2f44:	20001348 	.word	0x20001348

00002f48 <z_data_copy>:
 * @return N/A
 */
void z_data_copy(void)
{
	(void)memcpy(&__data_ram_start, &__data_rom_start,
		 __data_ram_end - __data_ram_start);
    2f48:	4809      	ldr	r0, [pc, #36]	; (2f70 <z_data_copy+0x28>)
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    2f4a:	4a0a      	ldr	r2, [pc, #40]	; (2f74 <z_data_copy+0x2c>)
    2f4c:	490a      	ldr	r1, [pc, #40]	; (2f78 <z_data_copy+0x30>)
{
    2f4e:	b508      	push	{r3, lr}
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    2f50:	1a12      	subs	r2, r2, r0
    2f52:	f003 f911 	bl	6178 <memcpy>
#ifdef CONFIG_ARCH_HAS_RAMFUNC_SUPPORT
	(void)memcpy(&_ramfunc_ram_start, &_ramfunc_rom_start,
    2f56:	4a09      	ldr	r2, [pc, #36]	; (2f7c <z_data_copy+0x34>)
    2f58:	4909      	ldr	r1, [pc, #36]	; (2f80 <z_data_copy+0x38>)
    2f5a:	480a      	ldr	r0, [pc, #40]	; (2f84 <z_data_copy+0x3c>)
    2f5c:	f003 f90c 	bl	6178 <memcpy>
		count--;
	}
	__stack_chk_guard = guard_copy;
#else
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
		 _app_smem_end - _app_smem_start);
    2f60:	4809      	ldr	r0, [pc, #36]	; (2f88 <z_data_copy+0x40>)
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
    2f62:	4a0a      	ldr	r2, [pc, #40]	; (2f8c <z_data_copy+0x44>)
    2f64:	490a      	ldr	r1, [pc, #40]	; (2f90 <z_data_copy+0x48>)
#endif /* CONFIG_STACK_CANARIES */
#endif /* CONFIG_USERSPACE */
}
    2f66:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
    2f6a:	1a12      	subs	r2, r2, r0
    2f6c:	f003 b904 	b.w	6178 <memcpy>
    2f70:	20003400 	.word	0x20003400
    2f74:	20004ba4 	.word	0x20004ba4
    2f78:	00007a24 	.word	0x00007a24
    2f7c:	00000000 	.word	0x00000000
    2f80:	00007a24 	.word	0x00007a24
    2f84:	20000000 	.word	0x20000000
    2f88:	20000000 	.word	0x20000000
    2f8c:	20000000 	.word	0x20000000
    2f90:	00007a24 	.word	0x00007a24

00002f94 <bg_thread_main>:
 * init functions, then invokes application's main() routine.
 *
 * @return N/A
 */
static void bg_thread_main(void *unused1, void *unused2, void *unused3)
{
    2f94:	b508      	push	{r3, lr}
	static const unsigned int boot_delay = CONFIG_BOOT_DELAY;
#else
	static const unsigned int boot_delay;
#endif

	z_sys_post_kernel = true;
    2f96:	4b0c      	ldr	r3, [pc, #48]	; (2fc8 <bg_thread_main+0x34>)
    2f98:	2201      	movs	r2, #1

	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    2f9a:	2002      	movs	r0, #2
	z_sys_post_kernel = true;
    2f9c:	701a      	strb	r2, [r3, #0]
	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    2f9e:	f7ff ff4d 	bl	2e3c <z_sys_init_run_level>
		k_busy_wait(CONFIG_BOOT_DELAY * USEC_PER_MSEC);
	}

#if defined(CONFIG_BOOT_BANNER)
#ifdef BUILD_VERSION
	printk("*** Booting Zephyr OS build %s %s ***\n",
    2fa2:	4a0a      	ldr	r2, [pc, #40]	; (2fcc <bg_thread_main+0x38>)
    2fa4:	490a      	ldr	r1, [pc, #40]	; (2fd0 <bg_thread_main+0x3c>)
    2fa6:	480b      	ldr	r0, [pc, #44]	; (2fd4 <bg_thread_main+0x40>)
    2fa8:	f002 fc72 	bl	5890 <printk>
	__do_global_ctors_aux();
	__do_init_array_aux();
#endif

	/* Final init level before app starts */
	z_sys_init_run_level(_SYS_INIT_LEVEL_APPLICATION);
    2fac:	2003      	movs	r0, #3
    2fae:	f7ff ff45 	bl	2e3c <z_sys_init_run_level>

	z_init_static_threads();
    2fb2:	f001 ffd1 	bl	4f58 <z_init_static_threads>
	z_timestamp_main = k_cycle_get_32();
#endif

	extern void main(void);

	main();
    2fb6:	f7fd fb19 	bl	5ec <main>

	/* Mark nonessenrial since main() has no more work to do */
	z_main_thread.base.user_options &= ~K_ESSENTIAL;
    2fba:	4a07      	ldr	r2, [pc, #28]	; (2fd8 <bg_thread_main+0x44>)
    2fbc:	7b13      	ldrb	r3, [r2, #12]
    2fbe:	f023 0301 	bic.w	r3, r3, #1
    2fc2:	7313      	strb	r3, [r2, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
    2fc4:	bd08      	pop	{r3, pc}
    2fc6:	bf00      	nop
    2fc8:	20001346 	.word	0x20001346
    2fcc:	0000791b 	.word	0x0000791b
    2fd0:	000078d4 	.word	0x000078d4
    2fd4:	000078f5 	.word	0x000078f5
    2fd8:	20000320 	.word	0x20000320

00002fdc <z_cstart>:
 * cleared/zeroed.
 *
 * @return Does not return
 */
FUNC_NORETURN void z_cstart(void)
{
    2fdc:	e92d 4880 	stmdb	sp!, {r7, fp, lr}
 *
 * @return N/A
 */
static ALWAYS_INLINE void z_arm_interrupt_stack_setup(void)
{
	uint32_t msp =
    2fe0:	f8df 90ec 	ldr.w	r9, [pc, #236]	; 30d0 <z_cstart+0xf4>
    2fe4:	b0af      	sub	sp, #188	; 0xbc
  __ASM volatile ("MSR msp, %0" : : "r" (topOfMainStack) : );
    2fe6:	f389 8808 	msr	MSP, r9
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    2fea:	4d31      	ldr	r5, [pc, #196]	; (30b0 <z_cstart+0xd4>)
	_kernel.ready_q.cache = &z_main_thread;
    2fec:	4e31      	ldr	r6, [pc, #196]	; (30b4 <z_cstart+0xd8>)
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    2fee:	f8df a0e4 	ldr.w	sl, [pc, #228]	; 30d4 <z_cstart+0xf8>
	z_setup_new_thread(thread, stack,
    2ff2:	4f31      	ldr	r7, [pc, #196]	; (30b8 <z_cstart+0xdc>)
    2ff4:	2400      	movs	r4, #0
    2ff6:	23e0      	movs	r3, #224	; 0xe0
    2ff8:	f885 3022 	strb.w	r3, [r5, #34]	; 0x22
    2ffc:	77ec      	strb	r4, [r5, #31]
    2ffe:	762c      	strb	r4, [r5, #24]
    3000:	766c      	strb	r4, [r5, #25]
    3002:	76ac      	strb	r4, [r5, #26]
#if defined(CONFIG_ARM_SECURE_FIRMWARE)
	NVIC_SetPriority(SecureFault_IRQn, _EXC_FAULT_PRIO);
#endif /* CONFIG_ARM_SECURE_FIRMWARE */

	/* Enable Usage, Mem, & Bus Faults */
	SCB->SHCSR |= SCB_SHCSR_USGFAULTENA_Msk | SCB_SHCSR_MEMFAULTENA_Msk |
    3004:	6a6b      	ldr	r3, [r5, #36]	; 0x24
    3006:	f443 23e0 	orr.w	r3, r3, #458752	; 0x70000
    300a:	626b      	str	r3, [r5, #36]	; 0x24

static ALWAYS_INLINE void arch_kernel_init(void)
{
	z_arm_interrupt_stack_setup();
	z_arm_exc_setup();
	z_arm_fault_init();
    300c:	f7fe fda6 	bl	1b5c <z_arm_fault_init>
	z_arm_cpu_idle_init();
    3010:	f7fe fb2e 	bl	1670 <z_arm_cpu_idle_init>
static ALWAYS_INLINE void z_arm_clear_faults(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* Reset all faults */
	SCB->CFSR = SCB_CFSR_USGFAULTSR_Msk |
    3014:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    3018:	62ab      	str	r3, [r5, #40]	; 0x28
		    SCB_CFSR_MEMFAULTSR_Msk |
		    SCB_CFSR_BUSFAULTSR_Msk;

	/* Clear all Hard Faults - HFSR is write-one-to-clear */
	SCB->HFSR = 0xffffffff;
    301a:	62eb      	str	r3, [r5, #44]	; 0x2c
#endif
#ifdef CONFIG_USERSPACE
	dummy_thread->mem_domain_info.mem_domain = 0;
#endif

	_current_cpu->current = dummy_thread;
    301c:	4d27      	ldr	r5, [pc, #156]	; (30bc <z_cstart+0xe0>)
	dummy_thread->mem_domain_info.mem_domain = 0;
    301e:	9425      	str	r4, [sp, #148]	; 0x94
	dummy_thread->base.user_options = K_ESSENTIAL;
    3020:	f240 1301 	movw	r3, #257	; 0x101
    3024:	f8ad 3024 	strh.w	r3, [sp, #36]	; 0x24
	_current_cpu->current = dummy_thread;
    3028:	ab06      	add	r3, sp, #24
    302a:	60ab      	str	r3, [r5, #8]

	z_dummy_thread_init(&dummy_thread);
#endif

	/* perform basic hardware initialization */
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_1);
    302c:	4620      	mov	r0, r4
	dummy_thread->stack_info.size = 0U;
    302e:	e9cd 4420 	strd	r4, r4, [sp, #128]	; 0x80
    3032:	f7ff ff03 	bl	2e3c <z_sys_init_run_level>
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_2);
    3036:	2001      	movs	r0, #1
    3038:	f7ff ff00 	bl	2e3c <z_sys_init_run_level>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    303c:	f04f 0b01 	mov.w	fp, #1
	z_sched_init();
    3040:	f001 faa8 	bl	4594 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    3044:	4b1e      	ldr	r3, [pc, #120]	; (30c0 <z_cstart+0xe4>)
	_kernel.ready_q.cache = &z_main_thread;
    3046:	626e      	str	r6, [r5, #36]	; 0x24
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    3048:	491e      	ldr	r1, [pc, #120]	; (30c4 <z_cstart+0xe8>)
    304a:	9305      	str	r3, [sp, #20]
    304c:	f44f 6280 	mov.w	r2, #1024	; 0x400
    3050:	4653      	mov	r3, sl
    3052:	e9cd 4b03 	strd	r4, fp, [sp, #12]
    3056:	e9cd 4401 	strd	r4, r4, [sp, #4]
    305a:	9400      	str	r4, [sp, #0]
    305c:	4630      	mov	r0, r6
    305e:	f001 fe7d 	bl	4d5c <z_setup_new_thread>
	sys_trace_thread_resume(thread);
}

static inline void z_mark_thread_as_started(struct k_thread *thread)
{
	thread->base.thread_state &= ~_THREAD_PRESTART;
    3062:	7b73      	ldrb	r3, [r6, #13]
    3064:	4680      	mov	r8, r0
    3066:	f023 0304 	bic.w	r3, r3, #4
	z_ready_thread(&z_main_thread);
    306a:	4630      	mov	r0, r6
    306c:	7373      	strb	r3, [r6, #13]
    306e:	f003 fc44 	bl	68fa <z_ready_thread>
	z_setup_new_thread(thread, stack,
    3072:	230f      	movs	r3, #15
    3074:	e9cd 4302 	strd	r4, r3, [sp, #8]
    3078:	4913      	ldr	r1, [pc, #76]	; (30c8 <z_cstart+0xec>)
    307a:	4b14      	ldr	r3, [pc, #80]	; (30cc <z_cstart+0xf0>)
    307c:	f44f 72a0 	mov.w	r2, #320	; 0x140
    3080:	e9cd b404 	strd	fp, r4, [sp, #16]
    3084:	e9cd 4400 	strd	r4, r4, [sp]
    3088:	4638      	mov	r0, r7
    308a:	f001 fe67 	bl	4d5c <z_setup_new_thread>
    308e:	7b7b      	ldrb	r3, [r7, #13]
		_kernel.cpus[i].idle_thread = &z_idle_threads[i];
    3090:	60ef      	str	r7, [r5, #12]
    3092:	f023 0304 	bic.w	r3, r3, #4
    3096:	737b      	strb	r3, [r7, #13]
 * @return N/A
 */

static inline void sys_dlist_init(sys_dlist_t *list)
{
	list->head = (sys_dnode_t *)list;
    3098:	f105 0318 	add.w	r3, r5, #24
	list->tail = (sys_dnode_t *)list;
    309c:	e9c5 3306 	strd	r3, r3, [r5, #24]
		_kernel.cpus[i].id = i;
    30a0:	752c      	strb	r4, [r5, #20]
		_kernel.cpus[i].irq_stack =
    30a2:	f8c5 9004 	str.w	r9, [r5, #4]
	arch_switch_to_main_thread(&z_main_thread, stack_ptr, bg_thread_main);
    30a6:	4652      	mov	r2, sl
    30a8:	4641      	mov	r1, r8
    30aa:	4630      	mov	r0, r6
    30ac:	f7fe fac6 	bl	163c <arch_switch_to_main_thread>
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
    30b0:	e000ed00 	.word	0xe000ed00
    30b4:	20000320 	.word	0x20000320
    30b8:	20000280 	.word	0x20000280
    30bc:	20000eec 	.word	0x20000eec
    30c0:	0000791c 	.word	0x0000791c
    30c4:	20002800 	.word	0x20002800
    30c8:	20001b30 	.word	0x20001b30
    30cc:	00002f01 	.word	0x00002f01
    30d0:	20002470 	.word	0x20002470
    30d4:	00002f95 	.word	0x00002f95

000030d8 <mbox_message_put>:
 *
 * @return 0 if successful, -ENOMSG if failed immediately, -EAGAIN if timed out
 */
static int mbox_message_put(struct k_mbox *mbox, struct k_mbox_msg *tx_msg,
			     k_timeout_t timeout)
{
    30d8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    30dc:	4699      	mov	r9, r3
	struct k_thread *receiving_thread;
	struct k_mbox_msg *rx_msg;
	k_spinlock_key_t key;

	/* save sender id so it can be used during message matching */
	tx_msg->rx_source_thread = _current;
    30de:	4b37      	ldr	r3, [pc, #220]	; (31bc <mbox_message_put+0xe4>)

	/* finish readying sending thread (actual or dummy) for send */
	sending_thread = tx_msg->_syncing_thread;
    30e0:	f8d1 b024 	ldr.w	fp, [r1, #36]	; 0x24
	tx_msg->rx_source_thread = _current;
    30e4:	689b      	ldr	r3, [r3, #8]
    30e6:	61cb      	str	r3, [r1, #28]
{
    30e8:	b085      	sub	sp, #20
    30ea:	4606      	mov	r6, r0
    30ec:	460f      	mov	r7, r1
    30ee:	4690      	mov	r8, r2
	sending_thread->base.swap_data = tx_msg;
    30f0:	f8cb 1014 	str.w	r1, [fp, #20]

	/* search mailbox's rx queue for a compatible receiver */
	key = k_spin_lock(&mbox->lock);
    30f4:	f100 0310 	add.w	r3, r0, #16
    30f8:	f04f 0220 	mov.w	r2, #32
    30fc:	f3ef 8a11 	mrs	sl, BASEPRI
    3100:	f382 8811 	msr	BASEPRI, r2
    3104:	f3bf 8f6f 	isb	sy
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
    3108:	4602      	mov	r2, r0
    310a:	f852 5f08 	ldr.w	r5, [r2, #8]!
 * @return a pointer to the head element, NULL if list is empty
 */

static inline sys_dnode_t *sys_dlist_peek_head(sys_dlist_t *list)
{
	return sys_dlist_is_empty(list) ? NULL : list->head;
    310e:	4295      	cmp	r5, r2
    3110:	d109      	bne.n	3126 <mbox_message_put+0x4e>

		}
	}

	/* didn't find a matching receiver: don't wait for one */
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    3112:	ea58 0209 	orrs.w	r2, r8, r9
    3116:	d13b      	bne.n	3190 <mbox_message_put+0xb8>
	__asm__ volatile(
    3118:	f38a 8811 	msr	BASEPRI, sl
    311c:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&mbox->lock, key);
		return -ENOMSG;
    3120:	f06f 044f 	mvn.w	r4, #79	; 0x4f
    3124:	e01e      	b.n	3164 <mbox_message_put+0x8c>
    3126:	2d00      	cmp	r5, #0
    3128:	bf38      	it	cc
    312a:	2500      	movcc	r5, #0
	_WAIT_Q_FOR_EACH(&mbox->rx_msg_queue, receiving_thread) {
    312c:	2d00      	cmp	r5, #0
    312e:	d0f0      	beq.n	3112 <mbox_message_put+0x3a>
		if (mbox_message_match(tx_msg, rx_msg) == 0) {
    3130:	6969      	ldr	r1, [r5, #20]
    3132:	9303      	str	r3, [sp, #12]
    3134:	4638      	mov	r0, r7
    3136:	f003 f940 	bl	63ba <mbox_message_match>
    313a:	9b03      	ldr	r3, [sp, #12]
    313c:	4604      	mov	r4, r0
    313e:	bb10      	cbnz	r0, 3186 <mbox_message_put+0xae>
			z_unpend_thread(receiving_thread);
    3140:	4628      	mov	r0, r5
    3142:	f003 fbb3 	bl	68ac <z_unpend_thread>
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
    3146:	f8c5 4090 	str.w	r4, [r5, #144]	; 0x90
			z_ready_thread(receiving_thread);
    314a:	4628      	mov	r0, r5
    314c:	f003 fbd5 	bl	68fa <z_ready_thread>
			if ((sending_thread->base.thread_state & _THREAD_DUMMY)
    3150:	f89b 200d 	ldrb.w	r2, [fp, #13]
    3154:	9b03      	ldr	r3, [sp, #12]
    3156:	f012 0f01 	tst.w	r2, #1
    315a:	d007      	beq.n	316c <mbox_message_put+0x94>
				z_reschedule(&mbox->lock, key);
    315c:	4651      	mov	r1, sl
    315e:	4618      	mov	r0, r3
    3160:	f003 fb83 	bl	686a <z_reschedule>
	}
#endif

	/* synchronous send: sender waits on tx queue for receiver or timeout */
	return z_pend_curr(&mbox->lock, key, &mbox->tx_msg_queue, timeout);
}
    3164:	4620      	mov	r0, r4
    3166:	b005      	add	sp, #20
    3168:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			return z_pend_curr(&mbox->lock, key, NULL, K_FOREVER);
    316c:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    3170:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
    3174:	e9cd 0100 	strd	r0, r1, [sp]
    3178:	4622      	mov	r2, r4
	return z_pend_curr(&mbox->lock, key, &mbox->tx_msg_queue, timeout);
    317a:	4651      	mov	r1, sl
    317c:	4618      	mov	r0, r3
    317e:	f001 f9a1 	bl	44c4 <z_pend_curr>
    3182:	4604      	mov	r4, r0
    3184:	e7ee      	b.n	3164 <mbox_message_put+0x8c>
 */

static inline sys_dnode_t *sys_dlist_peek_next_no_check(sys_dlist_t *list,
							sys_dnode_t *node)
{
	return (node == list->tail) ? NULL : node->next;
    3186:	68f2      	ldr	r2, [r6, #12]
    3188:	4295      	cmp	r5, r2
    318a:	d0c2      	beq.n	3112 <mbox_message_put+0x3a>
    318c:	682d      	ldr	r5, [r5, #0]
    318e:	e7cd      	b.n	312c <mbox_message_put+0x54>
	if ((sending_thread->base.thread_state & _THREAD_DUMMY) != 0U) {
    3190:	f89b 200d 	ldrb.w	r2, [fp, #13]
    3194:	07d2      	lsls	r2, r2, #31
    3196:	d50d      	bpl.n	31b4 <mbox_message_put+0xdc>
		z_pend_thread(sending_thread, &mbox->tx_msg_queue, K_FOREVER);
    3198:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    319c:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    31a0:	4631      	mov	r1, r6
    31a2:	4658      	mov	r0, fp
    31a4:	f003 fc1f 	bl	69e6 <z_pend_thread>
    31a8:	f38a 8811 	msr	BASEPRI, sl
    31ac:	f3bf 8f6f 	isb	sy
		return 0;
    31b0:	2400      	movs	r4, #0
    31b2:	e7d7      	b.n	3164 <mbox_message_put+0x8c>
	return z_pend_curr(&mbox->lock, key, &mbox->tx_msg_queue, timeout);
    31b4:	e9cd 8900 	strd	r8, r9, [sp]
    31b8:	4632      	mov	r2, r6
    31ba:	e7de      	b.n	317a <mbox_message_put+0xa2>
    31bc:	20000eec 	.word	0x20000eec

000031c0 <mbox_message_dispose>:
	if (rx_msg->_syncing_thread == NULL) {
    31c0:	6a43      	ldr	r3, [r0, #36]	; 0x24
{
    31c2:	b510      	push	{r4, lr}
    31c4:	4604      	mov	r4, r0
	if (rx_msg->_syncing_thread == NULL) {
    31c6:	b373      	cbz	r3, 3226 <mbox_message_dispose+0x66>
	if (rx_msg->tx_block.data != NULL) {
    31c8:	6943      	ldr	r3, [r0, #20]
    31ca:	b123      	cbz	r3, 31d6 <mbox_message_dispose+0x16>
		k_mem_pool_free(&rx_msg->tx_block);
    31cc:	3014      	adds	r0, #20
    31ce:	f003 f93d 	bl	644c <k_mem_pool_free>
		rx_msg->tx_block.data = NULL;
    31d2:	2300      	movs	r3, #0
    31d4:	6163      	str	r3, [r4, #20]
	sending_thread = rx_msg->_syncing_thread;
    31d6:	6a61      	ldr	r1, [r4, #36]	; 0x24
	rx_msg->_syncing_thread = NULL;
    31d8:	2300      	movs	r3, #0
	tx_msg = (struct k_mbox_msg *)sending_thread->base.swap_data;
    31da:	694a      	ldr	r2, [r1, #20]
	rx_msg->_syncing_thread = NULL;
    31dc:	6263      	str	r3, [r4, #36]	; 0x24
	tx_msg->size = rx_msg->size;
    31de:	6863      	ldr	r3, [r4, #4]
    31e0:	6053      	str	r3, [r2, #4]
	if ((sending_thread->base.thread_state & _THREAD_DUMMY) != 0U) {
    31e2:	7b4b      	ldrb	r3, [r1, #13]
    31e4:	f013 0001 	ands.w	r0, r3, #1
    31e8:	d009      	beq.n	31fe <mbox_message_dispose+0x3e>
		struct k_sem *async_sem = tx_msg->_async_sem;
    31ea:	6a94      	ldr	r4, [r2, #40]	; 0x28
	return z_impl_k_stack_push(stack, data);
    31ec:	480e      	ldr	r0, [pc, #56]	; (3228 <mbox_message_dispose+0x68>)
    31ee:	f003 fc94 	bl	6b1a <z_impl_k_stack_push>
		if (async_sem != NULL) {
    31f2:	b1c4      	cbz	r4, 3226 <mbox_message_dispose+0x66>
		arch_syscall_invoke1(*(uintptr_t *)&sem, K_SYSCALL_K_SEM_GIVE);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_sem_give(sem);
    31f4:	4620      	mov	r0, r4
}
    31f6:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    31fa:	f001 bbe5 	b.w	49c8 <z_impl_k_sem_give>
	thread->base.thread_state |= _THREAD_PENDING;
}

static inline void z_mark_thread_as_not_pending(struct k_thread *thread)
{
	thread->base.thread_state &= ~_THREAD_PENDING;
    31fe:	f023 0302 	bic.w	r3, r3, #2
    3202:	f8c1 0090 	str.w	r0, [r1, #144]	; 0x90
    3206:	734b      	strb	r3, [r1, #13]
	z_ready_thread(sending_thread);
    3208:	4608      	mov	r0, r1
    320a:	f003 fb76 	bl	68fa <z_ready_thread>
	__asm__ volatile(
    320e:	f04f 0320 	mov.w	r3, #32
    3212:	f3ef 8011 	mrs	r0, BASEPRI
    3216:	f383 8811 	msr	BASEPRI, r3
    321a:	f3bf 8f6f 	isb	sy
}
    321e:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	(void) z_reschedule_irqlock(arch_irq_lock());
    3222:	f003 bb2d 	b.w	6880 <z_reschedule_irqlock>
    3226:	bd10      	pop	{r4, pc}
    3228:	2000349c 	.word	0x2000349c

0000322c <init_mbox_module>:
{
    322c:	b570      	push	{r4, r5, r6, lr}
    322e:	4c0a      	ldr	r4, [pc, #40]	; (3258 <init_mbox_module+0x2c>)
	return z_impl_k_stack_push(stack, data);
    3230:	4e0a      	ldr	r6, [pc, #40]	; (325c <init_mbox_module+0x30>)
	for (i = 0; i < CONFIG_NUM_MBOX_ASYNC_MSGS; i++) {
    3232:	2500      	movs	r5, #0
		z_init_thread_base(&async_msg[i].thread, 0, _THREAD_DUMMY, 0);
    3234:	2300      	movs	r3, #0
    3236:	2201      	movs	r2, #1
    3238:	4619      	mov	r1, r3
    323a:	4620      	mov	r0, r4
    323c:	f003 fcd8 	bl	6bf0 <z_init_thread_base>
    3240:	4621      	mov	r1, r4
    3242:	4630      	mov	r0, r6
	for (i = 0; i < CONFIG_NUM_MBOX_ASYNC_MSGS; i++) {
    3244:	3501      	adds	r5, #1
    3246:	f003 fc68 	bl	6b1a <z_impl_k_stack_push>
    324a:	2d0a      	cmp	r5, #10
    324c:	f104 0468 	add.w	r4, r4, #104	; 0x68
    3250:	d1f0      	bne.n	3234 <init_mbox_module+0x8>
}
    3252:	2000      	movs	r0, #0
    3254:	bd70      	pop	{r4, r5, r6, pc}
    3256:	bf00      	nop
    3258:	20001400 	.word	0x20001400
    325c:	2000349c 	.word	0x2000349c

00003260 <k_mbox_put>:

int k_mbox_put(struct k_mbox *mbox, struct k_mbox_msg *tx_msg,
	       k_timeout_t timeout)
{
    3260:	b410      	push	{r4}
	/* configure things for a synchronous send, then send the message */
	tx_msg->_syncing_thread = _current;
    3262:	4c03      	ldr	r4, [pc, #12]	; (3270 <k_mbox_put+0x10>)
    3264:	68a4      	ldr	r4, [r4, #8]
    3266:	624c      	str	r4, [r1, #36]	; 0x24

	return mbox_message_put(mbox, tx_msg, timeout);
}
    3268:	bc10      	pop	{r4}
	return mbox_message_put(mbox, tx_msg, timeout);
    326a:	f7ff bf35 	b.w	30d8 <mbox_message_put>
    326e:	bf00      	nop
    3270:	20000eec 	.word	0x20000eec

00003274 <k_mbox_get>:
	struct k_mbox_msg *tx_msg;
	k_spinlock_key_t key;
	int result;

	/* save receiver id so it can be used during message matching */
	rx_msg->tx_target_thread = _current;
    3274:	4b2b      	ldr	r3, [pc, #172]	; (3324 <k_mbox_get+0xb0>)
{
    3276:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    327a:	4690      	mov	r8, r2
	rx_msg->tx_target_thread = _current;
    327c:	689a      	ldr	r2, [r3, #8]
    327e:	620a      	str	r2, [r1, #32]
{
    3280:	e9dd 670c 	ldrd	r6, r7, [sp, #48]	; 0x30
    3284:	4681      	mov	r9, r0
    3286:	460d      	mov	r5, r1
    3288:	f04f 0220 	mov.w	r2, #32
    328c:	f3ef 8a11 	mrs	sl, BASEPRI
    3290:	f382 8811 	msr	BASEPRI, r2
    3294:	f3bf 8f6f 	isb	sy
	return list->head == list;
    3298:	6804      	ldr	r4, [r0, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    329a:	42a0      	cmp	r0, r4
    329c:	469b      	mov	fp, r3
    329e:	d109      	bne.n	32b4 <k_mbox_get+0x40>
		}
	}

	/* didn't find a matching sender */

	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    32a0:	ea56 0307 	orrs.w	r3, r6, r7
    32a4:	d12f      	bne.n	3306 <k_mbox_get+0x92>
	__asm__ volatile(
    32a6:	f38a 8811 	msr	BASEPRI, sl
    32aa:	f3bf 8f6f 	isb	sy
		/* don't wait for a matching sender to appear */
		k_spin_unlock(&mbox->lock, key);
		return -ENOMSG;
    32ae:	f06f 004f 	mvn.w	r0, #79	; 0x4f
    32b2:	e018      	b.n	32e6 <k_mbox_get+0x72>
    32b4:	2c00      	cmp	r4, #0
    32b6:	bf38      	it	cc
    32b8:	2400      	movcc	r4, #0
	_WAIT_Q_FOR_EACH(&mbox->tx_msg_queue, sending_thread) {
    32ba:	2c00      	cmp	r4, #0
    32bc:	d0f0      	beq.n	32a0 <k_mbox_get+0x2c>
		if (mbox_message_match(tx_msg, rx_msg) == 0) {
    32be:	6960      	ldr	r0, [r4, #20]
    32c0:	4629      	mov	r1, r5
    32c2:	f003 f87a 	bl	63ba <mbox_message_match>
    32c6:	b9c0      	cbnz	r0, 32fa <k_mbox_get+0x86>
			z_unpend_thread(sending_thread);
    32c8:	4620      	mov	r0, r4
    32ca:	f003 faef 	bl	68ac <z_unpend_thread>
    32ce:	f38a 8811 	msr	BASEPRI, sl
    32d2:	f3bf 8f6f 	isb	sy
	if (buffer != NULL) {
    32d6:	f1b8 0f00 	cmp.w	r8, #0
    32da:	d007      	beq.n	32ec <k_mbox_get+0x78>
		k_mbox_data_get(rx_msg, buffer);
    32dc:	4641      	mov	r1, r8
    32de:	4628      	mov	r0, r5
    32e0:	f003 f8a2 	bl	6428 <k_mbox_data_get>
			return mbox_message_data_check(rx_msg, buffer);
    32e4:	2000      	movs	r0, #0
	if (result == 0) {
		result = mbox_message_data_check(rx_msg, buffer);
	}

	return result;
}
    32e6:	b003      	add	sp, #12
    32e8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	} else if (rx_msg->size == 0) {
    32ec:	686b      	ldr	r3, [r5, #4]
    32ee:	2b00      	cmp	r3, #0
    32f0:	d1f8      	bne.n	32e4 <k_mbox_get+0x70>
		mbox_message_dispose(rx_msg);
    32f2:	4628      	mov	r0, r5
    32f4:	f7ff ff64 	bl	31c0 <mbox_message_dispose>
    32f8:	e7f4      	b.n	32e4 <k_mbox_get+0x70>
	return (node == list->tail) ? NULL : node->next;
    32fa:	f8d9 3004 	ldr.w	r3, [r9, #4]
    32fe:	429c      	cmp	r4, r3
    3300:	d0ce      	beq.n	32a0 <k_mbox_get+0x2c>
    3302:	6824      	ldr	r4, [r4, #0]
    3304:	e7d9      	b.n	32ba <k_mbox_get+0x46>
	_current->base.swap_data = rx_msg;
    3306:	f8db 3008 	ldr.w	r3, [fp, #8]
	result = z_pend_curr(&mbox->lock, key, &mbox->rx_msg_queue, timeout);
    330a:	f109 0208 	add.w	r2, r9, #8
	_current->base.swap_data = rx_msg;
    330e:	615d      	str	r5, [r3, #20]
	result = z_pend_curr(&mbox->lock, key, &mbox->rx_msg_queue, timeout);
    3310:	4651      	mov	r1, sl
    3312:	e9cd 6700 	strd	r6, r7, [sp]
    3316:	f109 0010 	add.w	r0, r9, #16
    331a:	f001 f8d3 	bl	44c4 <z_pend_curr>
	if (result == 0) {
    331e:	2800      	cmp	r0, #0
    3320:	d1e1      	bne.n	32e6 <k_mbox_get+0x72>
    3322:	e7d8      	b.n	32d6 <k_mbox_get+0x62>
    3324:	20000eec 	.word	0x20000eec

00003328 <z_thread_malloc>:
#else
#define _HEAP_MEM_POOL	NULL
#endif

void *z_thread_malloc(size_t size)
{
    3328:	b510      	push	{r4, lr}
    332a:	4604      	mov	r4, r0
	void *ret;
	struct k_mem_pool *pool;

	if (k_is_in_isr()) {
    332c:	f003 fc2e 	bl	6b8c <k_is_in_isr>
    3330:	b950      	cbnz	r0, 3348 <z_thread_malloc+0x20>
		pool = _HEAP_MEM_POOL;
	} else {
		pool = _current->resource_pool;
    3332:	4b07      	ldr	r3, [pc, #28]	; (3350 <z_thread_malloc+0x28>)
    3334:	689b      	ldr	r3, [r3, #8]
    3336:	f8d3 3088 	ldr.w	r3, [r3, #136]	; 0x88
	}

	if (pool) {
    333a:	b13b      	cbz	r3, 334c <z_thread_malloc+0x24>
		ret = k_mem_pool_malloc(pool, size);
    333c:	4621      	mov	r1, r4
    333e:	4618      	mov	r0, r3
	} else {
		ret = NULL;
	}

	return ret;
}
    3340:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		ret = k_mem_pool_malloc(pool, size);
    3344:	f003 b884 	b.w	6450 <k_mem_pool_malloc>
		pool = _HEAP_MEM_POOL;
    3348:	4b02      	ldr	r3, [pc, #8]	; (3354 <z_thread_malloc+0x2c>)
    334a:	e7f7      	b.n	333c <z_thread_malloc+0x14>
}
    334c:	bd10      	pop	{r4, pc}
    334e:	bf00      	nop
    3350:	20000eec 	.word	0x20000eec
    3354:	20003414 	.word	0x20003414

00003358 <z_mrsh_k_mutex_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_init(struct k_mutex * mutex);
uintptr_t z_mrsh_k_mutex_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3358:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    335a:	4d0e      	ldr	r5, [pc, #56]	; (3394 <z_mrsh_k_mutex_init+0x3c>)
    335c:	9a06      	ldr	r2, [sp, #24]
    335e:	68ab      	ldr	r3, [r5, #8]
    3360:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3364:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_init(struct k_mutex *mutex)
{
	Z_OOPS(Z_SYSCALL_OBJ_INIT(mutex, K_OBJ_MUTEX));
    3366:	f7fc feb9 	bl	dc <z_object_find>
    336a:	2201      	movs	r2, #1
    336c:	2103      	movs	r1, #3
    336e:	f002 f8ef 	bl	5550 <z_object_validate>
    3372:	4604      	mov	r4, r0
    3374:	b130      	cbz	r0, 3384 <z_mrsh_k_mutex_init+0x2c>
    3376:	f003 f888 	bl	648a <arch_is_user_context>
    337a:	68ab      	ldr	r3, [r5, #8]
    337c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3380:	f002 feaa 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_mutex_init(mutex);
    3384:	4630      	mov	r0, r6
    3386:	f003 f89a 	bl	64be <z_impl_k_mutex_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_mutex_init(*(struct k_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
    338a:	68ab      	ldr	r3, [r5, #8]
    338c:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3390:	bd70      	pop	{r4, r5, r6, pc}
    3392:	bf00      	nop
    3394:	20000eec 	.word	0x20000eec

00003398 <z_impl_k_mutex_lock>:
	}
	return false;
}

int z_impl_k_mutex_lock(struct k_mutex *mutex, k_timeout_t timeout)
{
    3398:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
    339c:	4604      	mov	r4, r0
    339e:	4616      	mov	r6, r2
    33a0:	461f      	mov	r7, r3
	__asm__ volatile(
    33a2:	f04f 0320 	mov.w	r3, #32
    33a6:	f3ef 8811 	mrs	r8, BASEPRI
    33aa:	f383 8811 	msr	BASEPRI, r3
    33ae:	f3bf 8f6f 	isb	sy
	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");

	sys_trace_void(SYS_TRACE_ID_MUTEX_LOCK);
	key = k_spin_lock(&lock);

	if (likely((mutex->lock_count == 0U) || (mutex->owner == _current))) {
    33b2:	68c3      	ldr	r3, [r0, #12]
    33b4:	4a39      	ldr	r2, [pc, #228]	; (349c <z_impl_k_mutex_lock+0x104>)
    33b6:	b16b      	cbz	r3, 33d4 <z_impl_k_mutex_lock+0x3c>
    33b8:	6880      	ldr	r0, [r0, #8]
    33ba:	6891      	ldr	r1, [r2, #8]
    33bc:	4288      	cmp	r0, r1
    33be:	d01c      	beq.n	33fa <z_impl_k_mutex_lock+0x62>
		sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);

		return 0;
	}

	if (unlikely(K_TIMEOUT_EQ(timeout, K_NO_WAIT))) {
    33c0:	ea56 0307 	orrs.w	r3, r6, r7
    33c4:	d11b      	bne.n	33fe <z_impl_k_mutex_lock+0x66>
	__asm__ volatile(
    33c6:	f388 8811 	msr	BASEPRI, r8
    33ca:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);
		return -EBUSY;
    33ce:	f06f 020f 	mvn.w	r2, #15
    33d2:	e00e      	b.n	33f2 <z_impl_k_mutex_lock+0x5a>
					_current->base.prio :
    33d4:	6891      	ldr	r1, [r2, #8]
    33d6:	f991 100e 	ldrsb.w	r1, [r1, #14]
		mutex->owner_orig_prio = (mutex->lock_count == 0U) ?
    33da:	6121      	str	r1, [r4, #16]
		mutex->lock_count++;
    33dc:	3301      	adds	r3, #1
    33de:	60e3      	str	r3, [r4, #12]
		mutex->owner = _current;
    33e0:	6893      	ldr	r3, [r2, #8]
    33e2:	60a3      	str	r3, [r4, #8]
    33e4:	f003 f851 	bl	648a <arch_is_user_context>
    33e8:	f388 8811 	msr	BASEPRI, r8
    33ec:	f3bf 8f6f 	isb	sy
		return 0;
    33f0:	2200      	movs	r2, #0
		k_spin_unlock(&lock, key);
	}

	sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);
	return -EAGAIN;
}
    33f2:	4610      	mov	r0, r2
    33f4:	b002      	add	sp, #8
    33f6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
					_current->base.prio :
    33fa:	6921      	ldr	r1, [r4, #16]
    33fc:	e7ed      	b.n	33da <z_impl_k_mutex_lock+0x42>
	new_prio = new_prio_for_inheritance(_current->base.prio,
    33fe:	f991 100e 	ldrsb.w	r1, [r1, #14]
    3402:	f990 300e 	ldrsb.w	r3, [r0, #14]
    3406:	4299      	cmp	r1, r3
    3408:	bfa8      	it	ge
    340a:	4619      	movge	r1, r3
    340c:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    3410:	f003 f83b 	bl	648a <arch_is_user_context>
	if (z_is_prio_higher(new_prio, mutex->owner->base.prio)) {
    3414:	68a3      	ldr	r3, [r4, #8]
    3416:	f993 300e 	ldrsb.w	r3, [r3, #14]
    341a:	4299      	cmp	r1, r3
    341c:	da37      	bge.n	348e <z_impl_k_mutex_lock+0xf6>
		resched = adjust_owner_prio(mutex, new_prio);
    341e:	f104 0008 	add.w	r0, r4, #8
    3422:	f003 f83c 	bl	649e <adjust_owner_prio.isra.0>
    3426:	4605      	mov	r5, r0
	int got_mutex = z_pend_curr(&lock, key, &mutex->wait_q, timeout);
    3428:	4622      	mov	r2, r4
    342a:	4641      	mov	r1, r8
    342c:	e9cd 6700 	strd	r6, r7, [sp]
    3430:	481b      	ldr	r0, [pc, #108]	; (34a0 <z_impl_k_mutex_lock+0x108>)
    3432:	f001 f847 	bl	44c4 <z_pend_curr>
    3436:	4602      	mov	r2, r0
    3438:	f003 f827 	bl	648a <arch_is_user_context>
    343c:	f003 f825 	bl	648a <arch_is_user_context>
	if (got_mutex == 0) {
    3440:	2a00      	cmp	r2, #0
    3442:	d0d6      	beq.n	33f2 <z_impl_k_mutex_lock+0x5a>
    3444:	f003 f821 	bl	648a <arch_is_user_context>
	__asm__ volatile(
    3448:	f04f 0320 	mov.w	r3, #32
    344c:	f3ef 8611 	mrs	r6, BASEPRI
    3450:	f383 8811 	msr	BASEPRI, r3
    3454:	f3bf 8f6f 	isb	sy
	return list->head == list;
    3458:	6823      	ldr	r3, [r4, #0]
    345a:	6921      	ldr	r1, [r4, #16]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    345c:	42a3      	cmp	r3, r4
    345e:	d007      	beq.n	3470 <z_impl_k_mutex_lock+0xd8>
		new_prio_for_inheritance(waiter->base.prio, mutex->owner_orig_prio) :
    3460:	b133      	cbz	r3, 3470 <z_impl_k_mutex_lock+0xd8>
    3462:	f993 300e 	ldrsb.w	r3, [r3, #14]
    3466:	4299      	cmp	r1, r3
    3468:	bfa8      	it	ge
    346a:	4619      	movge	r1, r3
    346c:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    3470:	f003 f80b 	bl	648a <arch_is_user_context>
	resched = adjust_owner_prio(mutex, new_prio) || resched;
    3474:	f104 0008 	add.w	r0, r4, #8
    3478:	f003 f811 	bl	649e <adjust_owner_prio.isra.0>
    347c:	b900      	cbnz	r0, 3480 <z_impl_k_mutex_lock+0xe8>
	if (resched) {
    347e:	b145      	cbz	r5, 3492 <z_impl_k_mutex_lock+0xfa>
		z_reschedule(&lock, key);
    3480:	4807      	ldr	r0, [pc, #28]	; (34a0 <z_impl_k_mutex_lock+0x108>)
    3482:	4631      	mov	r1, r6
    3484:	f003 f9f1 	bl	686a <z_reschedule>
	return -EAGAIN;
    3488:	f06f 020a 	mvn.w	r2, #10
    348c:	e7b1      	b.n	33f2 <z_impl_k_mutex_lock+0x5a>
	bool resched = false;
    348e:	2500      	movs	r5, #0
    3490:	e7ca      	b.n	3428 <z_impl_k_mutex_lock+0x90>
	__asm__ volatile(
    3492:	f386 8811 	msr	BASEPRI, r6
    3496:	f3bf 8f6f 	isb	sy
    349a:	e7f5      	b.n	3488 <z_impl_k_mutex_lock+0xf0>
    349c:	20000eec 	.word	0x20000eec
    34a0:	20001347 	.word	0x20001347

000034a4 <z_mrsh_k_mutex_lock>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout);
uintptr_t z_mrsh_k_mutex_lock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    34a4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    34a8:	4d10      	ldr	r5, [pc, #64]	; (34ec <z_mrsh_k_mutex_lock+0x48>)
    34aa:	68ab      	ldr	r3, [r5, #8]
{
    34ac:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    34ae:	9a08      	ldr	r2, [sp, #32]
    34b0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    34b4:	4688      	mov	r8, r1
    34b6:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_lock(struct k_mutex *mutex,
				      k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(mutex, K_OBJ_MUTEX));
    34b8:	f7fc fe10 	bl	dc <z_object_find>
    34bc:	2200      	movs	r2, #0
    34be:	2103      	movs	r1, #3
    34c0:	f002 f846 	bl	5550 <z_object_validate>
    34c4:	4604      	mov	r4, r0
    34c6:	b130      	cbz	r0, 34d6 <z_mrsh_k_mutex_lock+0x32>
    34c8:	f002 ffdf 	bl	648a <arch_is_user_context>
    34cc:	68ab      	ldr	r3, [r5, #8]
    34ce:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    34d2:	f002 fe01 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_mutex_lock(mutex, timeout);
    34d6:	463b      	mov	r3, r7
    34d8:	4642      	mov	r2, r8
    34da:	4630      	mov	r0, r6
    34dc:	f7ff ff5c 	bl	3398 <z_impl_k_mutex_lock>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_mutex_lock(*(struct k_mutex **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    34e0:	68ab      	ldr	r3, [r5, #8]
    34e2:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    34e6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    34ea:	bf00      	nop
    34ec:	20000eec 	.word	0x20000eec

000034f0 <z_impl_k_mutex_unlock>:
}
#include <syscalls/k_mutex_lock_mrsh.c>
#endif

int z_impl_k_mutex_unlock(struct k_mutex *mutex)
{
    34f0:	b538      	push	{r3, r4, r5, lr}
	struct k_thread *new_owner;

	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");

	CHECKIF(mutex->owner == NULL) {
    34f2:	6883      	ldr	r3, [r0, #8]
{
    34f4:	4604      	mov	r4, r0
	CHECKIF(mutex->owner == NULL) {
    34f6:	2b00      	cmp	r3, #0
    34f8:	d03a      	beq.n	3570 <z_impl_k_mutex_unlock+0x80>
		return -EINVAL;
	}
	/*
	 * The current thread does not own the mutex.
	 */
	CHECKIF(mutex->owner != _current) {
    34fa:	4a20      	ldr	r2, [pc, #128]	; (357c <z_impl_k_mutex_unlock+0x8c>)
    34fc:	6892      	ldr	r2, [r2, #8]
    34fe:	4293      	cmp	r3, r2
    3500:	d139      	bne.n	3576 <z_impl_k_mutex_unlock+0x86>
{
#ifdef CONFIG_PREEMPT_ENABLED
	__ASSERT(!arch_is_in_isr(), "");
	__ASSERT(_current->base.sched_locked != 1, "");

	--_current->base.sched_locked;
    3502:	7bda      	ldrb	r2, [r3, #15]
    3504:	3a01      	subs	r2, #1
    3506:	73da      	strb	r2, [r3, #15]
    3508:	f002 ffbf 	bl	648a <arch_is_user_context>

	/*
	 * If we are the owner and count is greater than 1, then decrement
	 * the count and return and keep current thread as the owner.
	 */
	if (mutex->lock_count - 1U != 0U) {
    350c:	68e3      	ldr	r3, [r4, #12]
    350e:	2b01      	cmp	r3, #1
    3510:	d005      	beq.n	351e <z_impl_k_mutex_unlock+0x2e>
		mutex->lock_count--;
    3512:	3b01      	subs	r3, #1
    3514:	60e3      	str	r3, [r4, #12]
		k_spin_unlock(&lock, key);
	}


k_mutex_unlock_return:
	k_sched_unlock();
    3516:	f000 fd87 	bl	4028 <k_sched_unlock>
	sys_trace_end_call(SYS_TRACE_ID_MUTEX_UNLOCK);

	return 0;
    351a:	2000      	movs	r0, #0
}
    351c:	bd38      	pop	{r3, r4, r5, pc}
	__asm__ volatile(
    351e:	f04f 0320 	mov.w	r3, #32
    3522:	f3ef 8511 	mrs	r5, BASEPRI
    3526:	f383 8811 	msr	BASEPRI, r3
    352a:	f3bf 8f6f 	isb	sy
	adjust_owner_prio(mutex, mutex->owner_orig_prio);
    352e:	6921      	ldr	r1, [r4, #16]
    3530:	f104 0008 	add.w	r0, r4, #8
    3534:	f002 ffb3 	bl	649e <adjust_owner_prio.isra.0>
	new_owner = z_unpend_first_thread(&mutex->wait_q);
    3538:	4620      	mov	r0, r4
    353a:	f003 fa56 	bl	69ea <z_unpend_first_thread>
	mutex->owner = new_owner;
    353e:	60a0      	str	r0, [r4, #8]
	new_owner = z_unpend_first_thread(&mutex->wait_q);
    3540:	4602      	mov	r2, r0
    3542:	f002 ffa2 	bl	648a <arch_is_user_context>
	if (new_owner != NULL) {
    3546:	b16a      	cbz	r2, 3564 <z_impl_k_mutex_unlock+0x74>
		mutex->owner_orig_prio = new_owner->base.prio;
    3548:	f992 300e 	ldrsb.w	r3, [r2, #14]
    354c:	6123      	str	r3, [r4, #16]
    354e:	2300      	movs	r3, #0
		z_ready_thread(new_owner);
    3550:	4610      	mov	r0, r2
    3552:	f8c2 3090 	str.w	r3, [r2, #144]	; 0x90
    3556:	f003 f9d0 	bl	68fa <z_ready_thread>
		z_reschedule(&lock, key);
    355a:	4809      	ldr	r0, [pc, #36]	; (3580 <z_impl_k_mutex_unlock+0x90>)
    355c:	4629      	mov	r1, r5
    355e:	f003 f984 	bl	686a <z_reschedule>
    3562:	e7d8      	b.n	3516 <z_impl_k_mutex_unlock+0x26>
		mutex->lock_count = 0U;
    3564:	60e2      	str	r2, [r4, #12]
	__asm__ volatile(
    3566:	f385 8811 	msr	BASEPRI, r5
    356a:	f3bf 8f6f 	isb	sy
    356e:	e7d2      	b.n	3516 <z_impl_k_mutex_unlock+0x26>
		return -EINVAL;
    3570:	f06f 0015 	mvn.w	r0, #21
    3574:	e7d2      	b.n	351c <z_impl_k_mutex_unlock+0x2c>
		return -EPERM;
    3576:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    357a:	e7cf      	b.n	351c <z_impl_k_mutex_unlock+0x2c>
    357c:	20000eec 	.word	0x20000eec
    3580:	20001347 	.word	0x20001347

00003584 <z_mrsh_k_mutex_unlock>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_unlock(struct k_mutex * mutex);
uintptr_t z_mrsh_k_mutex_unlock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3584:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3586:	4d0e      	ldr	r5, [pc, #56]	; (35c0 <z_mrsh_k_mutex_unlock+0x3c>)
    3588:	9a06      	ldr	r2, [sp, #24]
    358a:	68ab      	ldr	r3, [r5, #8]
    358c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3590:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_unlock(struct k_mutex *mutex)
{
	Z_OOPS(Z_SYSCALL_OBJ(mutex, K_OBJ_MUTEX));
    3592:	f7fc fda3 	bl	dc <z_object_find>
    3596:	2200      	movs	r2, #0
    3598:	2103      	movs	r1, #3
    359a:	f001 ffd9 	bl	5550 <z_object_validate>
    359e:	4604      	mov	r4, r0
    35a0:	b130      	cbz	r0, 35b0 <z_mrsh_k_mutex_unlock+0x2c>
    35a2:	f002 ff72 	bl	648a <arch_is_user_context>
    35a6:	68ab      	ldr	r3, [r5, #8]
    35a8:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    35ac:	f002 fd94 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_mutex_unlock(mutex);
    35b0:	4630      	mov	r0, r6
    35b2:	f7ff ff9d 	bl	34f0 <z_impl_k_mutex_unlock>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_mutex_unlock(*(struct k_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
    35b6:	68ab      	ldr	r3, [r5, #8]
    35b8:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    35bc:	bd70      	pop	{r4, r5, r6, pc}
    35be:	bf00      	nop
    35c0:	20000eec 	.word	0x20000eec

000035c4 <pipe_async_finish>:
	k_stack_push(&pipe_async_msgs, (stack_data_t)async);
}

/* Finish an asynchronous operation */
static void pipe_async_finish(struct k_pipe_async *async_desc)
{
    35c4:	b510      	push	{r4, lr}
    35c6:	4604      	mov	r4, r0
	/*
	 * An asynchronous operation is finished with the scheduler locked
	 * to prevent the called routines from scheduling a new thread.
	 */

	k_mem_pool_free(async_desc->desc.block);
    35c8:	6c00      	ldr	r0, [r0, #64]	; 0x40
    35ca:	f002 ff3f 	bl	644c <k_mem_pool_free>

	if (async_desc->desc.sem != NULL) {
    35ce:	6ce0      	ldr	r0, [r4, #76]	; 0x4c
    35d0:	b108      	cbz	r0, 35d6 <pipe_async_finish+0x12>
	z_impl_k_sem_give(sem);
    35d2:	f001 f9f9 	bl	49c8 <z_impl_k_sem_give>
	return z_impl_k_stack_push(stack, data);
    35d6:	4803      	ldr	r0, [pc, #12]	; (35e4 <pipe_async_finish+0x20>)
    35d8:	4621      	mov	r1, r4
		k_sem_give(async_desc->desc.sem);
	}

	pipe_async_free(async_desc);
}
    35da:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    35de:	f003 ba9c 	b.w	6b1a <z_impl_k_stack_push>
    35e2:	bf00      	nop
    35e4:	200034b4 	.word	0x200034b4

000035e8 <init_pipes_module>:

/*
 * Do run-time initialization of pipe object subsystem.
 */
static int init_pipes_module(struct device *dev)
{
    35e8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	 *
	 * Once initialized, the address of each descriptor is added to a stack
	 * that governs access to them.
	 */

	for (int i = 0; i < CONFIG_NUM_PIPE_ASYNC_MSGS; i++) {
    35ec:	2500      	movs	r5, #0
    35ee:	4c0c      	ldr	r4, [pc, #48]	; (3620 <init_pipes_module+0x38>)
    35f0:	4f0c      	ldr	r7, [pc, #48]	; (3624 <init_pipes_module+0x3c>)
		async_msg[i].thread.thread_state = _THREAD_DUMMY;
    35f2:	f04f 0801 	mov.w	r8, #1
	node->next = NULL;
    35f6:	462e      	mov	r6, r5
		async_msg[i].thread.swap_data = &async_msg[i].desc;
    35f8:	f104 0338 	add.w	r3, r4, #56	; 0x38
    35fc:	e9c4 3605 	strd	r3, r6, [r4, #20]
		async_msg[i].thread.thread_state = _THREAD_DUMMY;
    3600:	f884 800d 	strb.w	r8, [r4, #13]
	node->prev = NULL;
    3604:	61e6      	str	r6, [r4, #28]
    3606:	4621      	mov	r1, r4
    3608:	4638      	mov	r0, r7
	for (int i = 0; i < CONFIG_NUM_PIPE_ASYNC_MSGS; i++) {
    360a:	3501      	adds	r5, #1
    360c:	f003 fa85 	bl	6b1a <z_impl_k_stack_push>
    3610:	2d0a      	cmp	r5, #10
    3612:	f104 0450 	add.w	r4, r4, #80	; 0x50
    3616:	d1ef      	bne.n	35f8 <init_pipes_module+0x10>
		SYS_TRACING_OBJ_INIT(k_pipe, pipe);
	}
#endif /* CONFIG_OBJECT_TRACING */

	return 0;
}
    3618:	2000      	movs	r0, #0
    361a:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    361e:	bf00      	nop
    3620:	20001810 	.word	0x20001810
    3624:	200034b4 	.word	0x200034b4

00003628 <z_mrsh_k_pipe_alloc_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_pipe_alloc_init(struct k_pipe * pipe, size_t size);
uintptr_t z_mrsh_k_pipe_alloc_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3628:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    362a:	4d0f      	ldr	r5, [pc, #60]	; (3668 <z_mrsh_k_pipe_alloc_init+0x40>)
    362c:	9a08      	ldr	r2, [sp, #32]
    362e:	68ab      	ldr	r3, [r5, #8]
    3630:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3634:	460f      	mov	r7, r1
    3636:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_pipe_alloc_init(struct k_pipe *pipe, size_t size)
{
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(pipe, K_OBJ_PIPE));
    3638:	f7fc fd50 	bl	dc <z_object_find>
    363c:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    3640:	2104      	movs	r1, #4
    3642:	f001 ff85 	bl	5550 <z_object_validate>
    3646:	4604      	mov	r4, r0
    3648:	b130      	cbz	r0, 3658 <z_mrsh_k_pipe_alloc_init+0x30>
    364a:	f002 ff50 	bl	64ee <arch_is_user_context>
    364e:	68ab      	ldr	r3, [r5, #8]
    3650:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3654:	f002 fd40 	bl	60d8 <arch_syscall_oops>

	return z_impl_k_pipe_alloc_init(pipe, size);
    3658:	4639      	mov	r1, r7
    365a:	4630      	mov	r0, r6
    365c:	f002 fff0 	bl	6640 <z_impl_k_pipe_alloc_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_pipe_alloc_init(*(struct k_pipe **)&arg0, *(size_t*)&arg1)
;
	_current->syscall_frame = NULL;
    3660:	68ab      	ldr	r3, [r5, #8]
    3662:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3666:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3668:	20000eec 	.word	0x20000eec

0000366c <z_pipe_put_internal>:
 */
int z_pipe_put_internal(struct k_pipe *pipe, struct k_pipe_async *async_desc,
			 unsigned char *data, size_t bytes_to_write,
			 size_t *bytes_written, size_t min_xfer,
			 k_timeout_t timeout)
{
    366c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    3670:	b091      	sub	sp, #68	; 0x44
    3672:	461d      	mov	r5, r3

#if (CONFIG_NUM_PIPE_ASYNC_MSGS == 0)
	ARG_UNUSED(async_desc);
#endif

	CHECKIF((min_xfer > bytes_to_write) || bytes_written == NULL) {
    3674:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
    3676:	42ab      	cmp	r3, r5
{
    3678:	4607      	mov	r7, r0
    367a:	460e      	mov	r6, r1
    367c:	4690      	mov	r8, r2
	CHECKIF((min_xfer > bytes_to_write) || bytes_written == NULL) {
    367e:	f200 80d9 	bhi.w	3834 <z_pipe_put_internal+0x1c8>
    3682:	9b1a      	ldr	r3, [sp, #104]	; 0x68
    3684:	2b00      	cmp	r3, #0
    3686:	f000 80d5 	beq.w	3834 <z_pipe_put_internal+0x1c8>
		return -EINVAL;
	}

	k_spinlock_key_t key = k_spin_lock(&pipe->lock);
    368a:	f100 0b14 	add.w	fp, r0, #20
	__asm__ volatile(
    368e:	f04f 0320 	mov.w	r3, #32
    3692:	f3ef 8411 	mrs	r4, BASEPRI
    3696:	f383 8811 	msr	BASEPRI, r3
    369a:	f3bf 8f6f 	isb	sy
	/*
	 * Create a list of "working readers" into which the data will be
	 * directly copied.
	 */

	if (!pipe_xfer_prepare(&xfer_list, &reader, &pipe->wait_q.readers,
    369e:	e9d0 2301 	ldrd	r2, r3, [r0, #4]
    36a2:	e9dd 011c 	ldrd	r0, r1, [sp, #112]	; 0x70
    36a6:	e9cd 0102 	strd	r0, r1, [sp, #8]
    36aa:	991b      	ldr	r1, [sp, #108]	; 0x6c
    36ac:	f10d 0a20 	add.w	sl, sp, #32
    36b0:	e9cd 5100 	strd	r5, r1, [sp]
    36b4:	1ad3      	subs	r3, r2, r3
    36b6:	a907      	add	r1, sp, #28
    36b8:	465a      	mov	r2, fp
    36ba:	4650      	mov	r0, sl
    36bc:	f002 ff60 	bl	6580 <pipe_xfer_prepare>
    36c0:	b950      	cbnz	r0, 36d8 <z_pipe_put_internal+0x6c>
	__asm__ volatile(
    36c2:	f384 8811 	msr	BASEPRI, r4
    36c6:	f3bf 8f6f 	isb	sy
				pipe->size - pipe->bytes_used, bytes_to_write,
				min_xfer, timeout)) {
		k_spin_unlock(&pipe->lock, key);
		*bytes_written = 0;
    36ca:	9b1a      	ldr	r3, [sp, #104]	; 0x68
    36cc:	6018      	str	r0, [r3, #0]
		return -EIO;
    36ce:	f06f 0004 	mvn.w	r0, #4

	*bytes_written = bytes_to_write - pipe_desc.bytes_to_xfer;

	return pipe_return_code(min_xfer, pipe_desc.bytes_to_xfer,
				 bytes_to_write);
}
    36d2:	b011      	add	sp, #68	; 0x44
    36d4:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    36d8:	4b58      	ldr	r3, [pc, #352]	; (383c <z_pipe_put_internal+0x1d0>)
    36da:	689a      	ldr	r2, [r3, #8]
    36dc:	7bd3      	ldrb	r3, [r2, #15]
    36de:	3b01      	subs	r3, #1
    36e0:	73d3      	strb	r3, [r2, #15]
    36e2:	f384 8811 	msr	BASEPRI, r4
    36e6:	f3bf 8f6f 	isb	sy
				  sys_dlist_get(&xfer_list);
    36ea:	4650      	mov	r0, sl
    36ec:	f002 fef1 	bl	64d2 <sys_dlist_get>
	size_t         num_bytes_written = 0;
    36f0:	2400      	movs	r4, #0
				  sys_dlist_get(&xfer_list);
    36f2:	4681      	mov	r9, r0
		thread = (struct k_thread *)sys_dlist_get(&xfer_list);
    36f4:	f8cd a014 	str.w	sl, [sp, #20]
	while (thread != NULL) {
    36f8:	eb08 0204 	add.w	r2, r8, r4
    36fc:	1b2b      	subs	r3, r5, r4
    36fe:	f1b9 0f00 	cmp.w	r9, #0
    3702:	d125      	bne.n	3750 <z_pipe_put_internal+0xe4>
	if (reader != NULL) {
    3704:	9907      	ldr	r1, [sp, #28]
    3706:	b181      	cbz	r1, 372a <z_pipe_put_internal+0xbe>
		desc = (struct k_pipe_desc *)reader->base.swap_data;
    3708:	f8d1 9014 	ldr.w	r9, [r1, #20]
		bytes_copied = pipe_xfer(desc->buffer, desc->bytes_to_xfer,
    370c:	e9d9 0100 	ldrd	r0, r1, [r9]
    3710:	f002 fef7 	bl	6502 <pipe_xfer>
		desc->buffer        += bytes_copied;
    3714:	f8d9 3000 	ldr.w	r3, [r9]
    3718:	4403      	add	r3, r0
    371a:	f8c9 3000 	str.w	r3, [r9]
		desc->bytes_to_xfer -= bytes_copied;
    371e:	f8d9 3004 	ldr.w	r3, [r9, #4]
		num_bytes_written   += bytes_copied;
    3722:	4404      	add	r4, r0
		desc->bytes_to_xfer -= bytes_copied;
    3724:	1a18      	subs	r0, r3, r0
    3726:	f8c9 0004 	str.w	r0, [r9, #4]
		pipe_buffer_put(pipe, data + num_bytes_written,
    372a:	1b2a      	subs	r2, r5, r4
    372c:	eb08 0104 	add.w	r1, r8, r4
    3730:	4638      	mov	r0, r7
    3732:	f002 fef5 	bl	6520 <pipe_buffer_put>
	num_bytes_written +=
    3736:	4404      	add	r4, r0
	if (num_bytes_written == bytes_to_write) {
    3738:	42a5      	cmp	r5, r4
    373a:	d122      	bne.n	3782 <z_pipe_put_internal+0x116>
		*bytes_written = num_bytes_written;
    373c:	9b1a      	ldr	r3, [sp, #104]	; 0x68
    373e:	601d      	str	r5, [r3, #0]
		if (async_desc != NULL) {
    3740:	b116      	cbz	r6, 3748 <z_pipe_put_internal+0xdc>
			pipe_async_finish(async_desc);
    3742:	4630      	mov	r0, r6
    3744:	f7ff ff3e 	bl	35c4 <pipe_async_finish>
		k_sched_unlock();
    3748:	f000 fc6e 	bl	4028 <k_sched_unlock>
		return 0;
    374c:	2000      	movs	r0, #0
    374e:	e7c0      	b.n	36d2 <z_pipe_put_internal+0x66>
		desc = (struct k_pipe_desc *)thread->base.swap_data;
    3750:	f8d9 a014 	ldr.w	sl, [r9, #20]
		bytes_copied = pipe_xfer(desc->buffer, desc->bytes_to_xfer,
    3754:	e9da 0100 	ldrd	r0, r1, [sl]
    3758:	f002 fed3 	bl	6502 <pipe_xfer>
		desc->buffer        += bytes_copied;
    375c:	f8da 3000 	ldr.w	r3, [sl]
    3760:	4403      	add	r3, r0
    3762:	f8ca 3000 	str.w	r3, [sl]
		desc->bytes_to_xfer -= bytes_copied;
    3766:	f8da 3004 	ldr.w	r3, [sl, #4]
		num_bytes_written   += bytes_copied;
    376a:	4404      	add	r4, r0
		desc->bytes_to_xfer -= bytes_copied;
    376c:	1a18      	subs	r0, r3, r0
    376e:	f8ca 0004 	str.w	r0, [sl, #4]
		z_ready_thread(thread);
    3772:	4648      	mov	r0, r9
    3774:	f003 f8c1 	bl	68fa <z_ready_thread>
		thread = (struct k_thread *)sys_dlist_get(&xfer_list);
    3778:	9805      	ldr	r0, [sp, #20]
    377a:	f002 feaa 	bl	64d2 <sys_dlist_get>
    377e:	4681      	mov	r9, r0
    3780:	e7ba      	b.n	36f8 <z_pipe_put_internal+0x8c>
	if (!K_TIMEOUT_EQ(timeout, K_NO_WAIT)
    3782:	e9dd 231c 	ldrd	r2, r3, [sp, #112]	; 0x70
    3786:	4313      	orrs	r3, r2
    3788:	d006      	beq.n	3798 <z_pipe_put_internal+0x12c>
	    && num_bytes_written >= min_xfer
    378a:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
    378c:	42a3      	cmp	r3, r4
    378e:	d803      	bhi.n	3798 <z_pipe_put_internal+0x12c>
	    && min_xfer > 0) {
    3790:	b113      	cbz	r3, 3798 <z_pipe_put_internal+0x12c>
		*bytes_written = num_bytes_written;
    3792:	9b1a      	ldr	r3, [sp, #104]	; 0x68
    3794:	601c      	str	r4, [r3, #0]
		if (async_desc != NULL) {
    3796:	e7d3      	b.n	3740 <z_pipe_put_internal+0xd4>
	if (async_desc != NULL) {
    3798:	eb08 0204 	add.w	r2, r8, r4
    379c:	1b2c      	subs	r4, r5, r4
    379e:	b1e6      	cbz	r6, 37da <z_pipe_put_internal+0x16e>
	__asm__ volatile(
    37a0:	f04f 0320 	mov.w	r3, #32
    37a4:	f3ef 8511 	mrs	r5, BASEPRI
    37a8:	f383 8811 	msr	BASEPRI, r3
    37ac:	f3bf 8f6f 	isb	sy
	__ASSERT(!arch_is_in_isr(), "");
	__ASSERT(_current->base.sched_locked != 0, "");

	compiler_barrier();

	++_current->base.sched_locked;
    37b0:	4b22      	ldr	r3, [pc, #136]	; (383c <z_pipe_put_internal+0x1d0>)
    37b2:	6899      	ldr	r1, [r3, #8]
    37b4:	7bcb      	ldrb	r3, [r1, #15]
    37b6:	3301      	adds	r3, #1
    37b8:	73cb      	strb	r3, [r1, #15]
		z_pend_thread((struct k_thread *) &async_desc->thread,
    37ba:	4630      	mov	r0, r6
		async_desc->desc.bytes_to_xfer =
    37bc:	e9c6 240e 	strd	r2, r4, [r6, #56]	; 0x38
		z_pend_thread((struct k_thread *) &async_desc->thread,
    37c0:	f107 011c 	add.w	r1, r7, #28
    37c4:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    37c8:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    37cc:	f003 f90b 	bl	69e6 <z_pend_thread>
		z_reschedule(&pipe->lock, key2);
    37d0:	4629      	mov	r1, r5
    37d2:	4658      	mov	r0, fp
    37d4:	f003 f849 	bl	686a <z_reschedule>
    37d8:	e7b8      	b.n	374c <z_pipe_put_internal+0xe0>
	pipe_desc.bytes_to_xfer  = bytes_to_write - num_bytes_written;
    37da:	e9cd 240a 	strd	r2, r4, [sp, #40]	; 0x28
	if (!K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    37de:	e9dd 341c 	ldrd	r3, r4, [sp, #112]	; 0x70
    37e2:	4323      	orrs	r3, r4
    37e4:	d023      	beq.n	382e <z_pipe_put_internal+0x1c2>
		_current->base.swap_data = &pipe_desc;
    37e6:	4b15      	ldr	r3, [pc, #84]	; (383c <z_pipe_put_internal+0x1d0>)
    37e8:	689a      	ldr	r2, [r3, #8]
    37ea:	a90a      	add	r1, sp, #40	; 0x28
    37ec:	6151      	str	r1, [r2, #20]
    37ee:	f04f 0220 	mov.w	r2, #32
    37f2:	f3ef 8111 	mrs	r1, BASEPRI
    37f6:	f382 8811 	msr	BASEPRI, r2
    37fa:	f3bf 8f6f 	isb	sy
    37fe:	689a      	ldr	r2, [r3, #8]
    3800:	7bd3      	ldrb	r3, [r2, #15]
    3802:	3301      	adds	r3, #1
    3804:	73d3      	strb	r3, [r2, #15]
		(void)z_pend_curr(&pipe->lock, key2,
    3806:	e9dd 341c 	ldrd	r3, r4, [sp, #112]	; 0x70
    380a:	f107 021c 	add.w	r2, r7, #28
    380e:	e9cd 3400 	strd	r3, r4, [sp]
    3812:	4658      	mov	r0, fp
    3814:	f000 fe56 	bl	44c4 <z_pend_curr>
	*bytes_written = bytes_to_write - pipe_desc.bytes_to_xfer;
    3818:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
    381a:	1aed      	subs	r5, r5, r3
    381c:	9b1a      	ldr	r3, [sp, #104]	; 0x68
    381e:	601d      	str	r5, [r3, #0]
		return 0;
    3820:	9b1b      	ldr	r3, [sp, #108]	; 0x6c
    3822:	429d      	cmp	r5, r3
    3824:	bf34      	ite	cc
    3826:	f06f 000a 	mvncc.w	r0, #10
    382a:	2000      	movcs	r0, #0
    382c:	e751      	b.n	36d2 <z_pipe_put_internal+0x66>
		k_sched_unlock();
    382e:	f000 fbfb 	bl	4028 <k_sched_unlock>
    3832:	e7f1      	b.n	3818 <z_pipe_put_internal+0x1ac>
		return -EINVAL;
    3834:	f06f 0015 	mvn.w	r0, #21
    3838:	e74b      	b.n	36d2 <z_pipe_put_internal+0x66>
    383a:	bf00      	nop
    383c:	20000eec 	.word	0x20000eec

00003840 <z_impl_k_pipe_get>:

int z_impl_k_pipe_get(struct k_pipe *pipe, void *data, size_t bytes_to_read,
		     size_t *bytes_read, size_t min_xfer, k_timeout_t timeout)
{
    3840:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    3844:	b08f      	sub	sp, #60	; 0x3c
    3846:	4699      	mov	r9, r3
	struct k_pipe_desc *desc;
	sys_dlist_t    xfer_list;
	size_t         num_bytes_read = 0;
	size_t         bytes_copied;

	CHECKIF((min_xfer > bytes_to_read) || bytes_read == NULL) {
    3848:	9b18      	ldr	r3, [sp, #96]	; 0x60
    384a:	4293      	cmp	r3, r2
{
    384c:	4605      	mov	r5, r0
    384e:	4688      	mov	r8, r1
    3850:	4616      	mov	r6, r2
	CHECKIF((min_xfer > bytes_to_read) || bytes_read == NULL) {
    3852:	f200 80f8 	bhi.w	3a46 <z_impl_k_pipe_get+0x206>
    3856:	f1b9 0f00 	cmp.w	r9, #0
    385a:	f000 80f4 	beq.w	3a46 <z_impl_k_pipe_get+0x206>
    385e:	f04f 0320 	mov.w	r3, #32
    3862:	f3ef 8411 	mrs	r4, BASEPRI
    3866:	f383 8811 	msr	BASEPRI, r3
    386a:	f3bf 8f6f 	isb	sy

	/*
	 * Create a list of "working readers" into which the data will be
	 * directly copied.
	 */
	if (!pipe_xfer_prepare(&xfer_list, &writer, &pipe->wait_q.writers,
    386e:	e9dd 231a 	ldrd	r2, r3, [sp, #104]	; 0x68
    3872:	e9cd 2302 	strd	r2, r3, [sp, #8]
    3876:	9b18      	ldr	r3, [sp, #96]	; 0x60
    3878:	e9cd 6300 	strd	r6, r3, [sp]
    387c:	f10d 0b18 	add.w	fp, sp, #24
    3880:	6883      	ldr	r3, [r0, #8]
    3882:	f100 021c 	add.w	r2, r0, #28
    3886:	a905      	add	r1, sp, #20
    3888:	4658      	mov	r0, fp
    388a:	f002 fe79 	bl	6580 <pipe_xfer_prepare>
    388e:	b950      	cbnz	r0, 38a6 <z_impl_k_pipe_get+0x66>
	__asm__ volatile(
    3890:	f384 8811 	msr	BASEPRI, r4
    3894:	f3bf 8f6f 	isb	sy
				pipe->bytes_used, bytes_to_read,
				min_xfer, timeout)) {
		k_spin_unlock(&pipe->lock, key);
		*bytes_read = 0;
    3898:	f8c9 0000 	str.w	r0, [r9]
		return -EIO;
    389c:	f06f 0004 	mvn.w	r0, #4

	*bytes_read = bytes_to_read - pipe_desc.bytes_to_xfer;

	return pipe_return_code(min_xfer, pipe_desc.bytes_to_xfer,
				 bytes_to_read);
}
    38a0:	b00f      	add	sp, #60	; 0x3c
    38a2:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	--_current->base.sched_locked;
    38a6:	4b69      	ldr	r3, [pc, #420]	; (3a4c <z_impl_k_pipe_get+0x20c>)
    38a8:	689a      	ldr	r2, [r3, #8]
    38aa:	7bd3      	ldrb	r3, [r2, #15]
    38ac:	3b01      	subs	r3, #1
    38ae:	73d3      	strb	r3, [r2, #15]
    38b0:	f384 8811 	msr	BASEPRI, r4
    38b4:	f3bf 8f6f 	isb	sy
	size_t  num_bytes_read = 0;
    38b8:	2400      	movs	r4, #0
    38ba:	2702      	movs	r7, #2
			pipe->read_index = 0;
    38bc:	46a2      	mov	sl, r4
		run_length = MIN(pipe->bytes_used,
    38be:	68ea      	ldr	r2, [r5, #12]
    38c0:	686b      	ldr	r3, [r5, #4]
    38c2:	68a8      	ldr	r0, [r5, #8]
					  pipe->buffer + pipe->read_index,
    38c4:	6829      	ldr	r1, [r5, #0]
		run_length = MIN(pipe->bytes_used,
    38c6:	1a9b      	subs	r3, r3, r2
		bytes_copied = pipe_xfer(dest + num_bytes_read,
    38c8:	4283      	cmp	r3, r0
    38ca:	bf28      	it	cs
    38cc:	4603      	movcs	r3, r0
    38ce:	440a      	add	r2, r1
    38d0:	eb08 0004 	add.w	r0, r8, r4
    38d4:	1b31      	subs	r1, r6, r4
    38d6:	f002 fe14 	bl	6502 <pipe_xfer>
		pipe->bytes_used -= bytes_copied;
    38da:	68ab      	ldr	r3, [r5, #8]
    38dc:	1a1b      	subs	r3, r3, r0
    38de:	60ab      	str	r3, [r5, #8]
		pipe->read_index += bytes_copied;
    38e0:	68eb      	ldr	r3, [r5, #12]
		num_bytes_read += bytes_copied;
    38e2:	4404      	add	r4, r0
		pipe->read_index += bytes_copied;
    38e4:	4418      	add	r0, r3
		if (pipe->read_index == pipe->size) {
    38e6:	686b      	ldr	r3, [r5, #4]
    38e8:	4298      	cmp	r0, r3
			pipe->read_index = 0;
    38ea:	bf08      	it	eq
    38ec:	4650      	moveq	r0, sl
	for (i = 0; i < 2; i++) {
    38ee:	2f01      	cmp	r7, #1
			pipe->read_index = 0;
    38f0:	60e8      	str	r0, [r5, #12]
	for (i = 0; i < 2; i++) {
    38f2:	d135      	bne.n	3960 <z_impl_k_pipe_get+0x120>
		thread = (struct k_thread *)sys_dlist_get(&xfer_list);
    38f4:	4658      	mov	r0, fp
    38f6:	f002 fdec 	bl	64d2 <sys_dlist_get>
    38fa:	4607      	mov	r7, r0
	while ((thread != NULL) && (num_bytes_read < bytes_to_read)) {
    38fc:	b108      	cbz	r0, 3902 <z_impl_k_pipe_get+0xc2>
    38fe:	42b4      	cmp	r4, r6
    3900:	d330      	bcc.n	3964 <z_impl_k_pipe_get+0x124>
	if ((writer != NULL) && (num_bytes_read < bytes_to_read)) {
    3902:	9b05      	ldr	r3, [sp, #20]
    3904:	b1ab      	cbz	r3, 3932 <z_impl_k_pipe_get+0xf2>
    3906:	42b4      	cmp	r4, r6
    3908:	d213      	bcs.n	3932 <z_impl_k_pipe_get+0xf2>
		desc = (struct k_pipe_desc *)writer->base.swap_data;
    390a:	f8d3 a014 	ldr.w	sl, [r3, #20]
		bytes_copied = pipe_xfer((uint8_t *)data + num_bytes_read,
    390e:	1b31      	subs	r1, r6, r4
    3910:	e9da 2300 	ldrd	r2, r3, [sl]
    3914:	eb08 0004 	add.w	r0, r8, r4
    3918:	f002 fdf3 	bl	6502 <pipe_xfer>
		desc->buffer         += bytes_copied;
    391c:	f8da 3000 	ldr.w	r3, [sl]
    3920:	4403      	add	r3, r0
    3922:	f8ca 3000 	str.w	r3, [sl]
		desc->bytes_to_xfer  -= bytes_copied;
    3926:	f8da 3004 	ldr.w	r3, [sl, #4]
		num_bytes_read       += bytes_copied;
    392a:	4404      	add	r4, r0
		desc->bytes_to_xfer  -= bytes_copied;
    392c:	1a18      	subs	r0, r3, r0
    392e:	f8ca 0004 	str.w	r0, [sl, #4]
	while (thread != NULL) {
    3932:	bb97      	cbnz	r7, 399a <z_impl_k_pipe_get+0x15a>
	if (writer != NULL) {
    3934:	9b05      	ldr	r3, [sp, #20]
    3936:	b15b      	cbz	r3, 3950 <z_impl_k_pipe_get+0x110>
		desc = (struct k_pipe_desc *)writer->base.swap_data;
    3938:	695f      	ldr	r7, [r3, #20]
		bytes_copied = pipe_buffer_put(pipe, desc->buffer,
    393a:	4628      	mov	r0, r5
    393c:	e9d7 1200 	ldrd	r1, r2, [r7]
    3940:	f002 fdee 	bl	6520 <pipe_buffer_put>
		desc->buffer         += bytes_copied;
    3944:	683b      	ldr	r3, [r7, #0]
    3946:	4403      	add	r3, r0
    3948:	603b      	str	r3, [r7, #0]
		desc->bytes_to_xfer  -= bytes_copied;
    394a:	687b      	ldr	r3, [r7, #4]
    394c:	1a18      	subs	r0, r3, r0
    394e:	6078      	str	r0, [r7, #4]
	if (num_bytes_read == bytes_to_read) {
    3950:	42a6      	cmp	r6, r4
    3952:	d13b      	bne.n	39cc <z_impl_k_pipe_get+0x18c>
		k_sched_unlock();
    3954:	f000 fb68 	bl	4028 <k_sched_unlock>
		*bytes_read = num_bytes_read;
    3958:	f8c9 6000 	str.w	r6, [r9]
		return 0;
    395c:	2000      	movs	r0, #0
    395e:	e79f      	b.n	38a0 <z_impl_k_pipe_get+0x60>
    3960:	2701      	movs	r7, #1
    3962:	e7ac      	b.n	38be <z_impl_k_pipe_get+0x7e>
		desc = (struct k_pipe_desc *)thread->base.swap_data;
    3964:	f8d7 a014 	ldr.w	sl, [r7, #20]
		bytes_copied = pipe_xfer((uint8_t *)data + num_bytes_read,
    3968:	1b31      	subs	r1, r6, r4
    396a:	e9da 2300 	ldrd	r2, r3, [sl]
    396e:	eb08 0004 	add.w	r0, r8, r4
    3972:	f002 fdc6 	bl	6502 <pipe_xfer>
		desc->buffer         += bytes_copied;
    3976:	f8da 3000 	ldr.w	r3, [sl]
    397a:	4403      	add	r3, r0
    397c:	f8ca 3000 	str.w	r3, [sl]
		desc->bytes_to_xfer  -= bytes_copied;
    3980:	f8da 3004 	ldr.w	r3, [sl, #4]
		num_bytes_read       += bytes_copied;
    3984:	4404      	add	r4, r0
		if (num_bytes_read == bytes_to_read) {
    3986:	42a6      	cmp	r6, r4
		desc->bytes_to_xfer  -= bytes_copied;
    3988:	eba3 0000 	sub.w	r0, r3, r0
    398c:	f8ca 0004 	str.w	r0, [sl, #4]
		if (num_bytes_read == bytes_to_read) {
    3990:	d0b7      	beq.n	3902 <z_impl_k_pipe_get+0xc2>
		pipe_thread_ready(thread);
    3992:	4638      	mov	r0, r7
    3994:	f002 fe3b 	bl	660e <pipe_thread_ready>
    3998:	e7ac      	b.n	38f4 <z_impl_k_pipe_get+0xb4>
		desc = (struct k_pipe_desc *)thread->base.swap_data;
    399a:	f8d7 a014 	ldr.w	sl, [r7, #20]
		bytes_copied = pipe_buffer_put(pipe, desc->buffer,
    399e:	4628      	mov	r0, r5
    39a0:	e9da 1200 	ldrd	r1, r2, [sl]
    39a4:	f002 fdbc 	bl	6520 <pipe_buffer_put>
		desc->buffer         += bytes_copied;
    39a8:	f8da 3000 	ldr.w	r3, [sl]
    39ac:	4403      	add	r3, r0
    39ae:	f8ca 3000 	str.w	r3, [sl]
		desc->bytes_to_xfer  -= bytes_copied;
    39b2:	f8da 3004 	ldr.w	r3, [sl, #4]
    39b6:	1a18      	subs	r0, r3, r0
    39b8:	f8ca 0004 	str.w	r0, [sl, #4]
		pipe_thread_ready(thread);
    39bc:	4638      	mov	r0, r7
    39be:	f002 fe26 	bl	660e <pipe_thread_ready>
		thread = (struct k_thread *)sys_dlist_get(&xfer_list);
    39c2:	a806      	add	r0, sp, #24
    39c4:	f002 fd85 	bl	64d2 <sys_dlist_get>
    39c8:	4607      	mov	r7, r0
    39ca:	e7b2      	b.n	3932 <z_impl_k_pipe_get+0xf2>
	if (!K_TIMEOUT_EQ(timeout, K_NO_WAIT)
    39cc:	e9dd 231a 	ldrd	r2, r3, [sp, #104]	; 0x68
    39d0:	4313      	orrs	r3, r2
    39d2:	d008      	beq.n	39e6 <z_impl_k_pipe_get+0x1a6>
	    && num_bytes_read >= min_xfer
    39d4:	9b18      	ldr	r3, [sp, #96]	; 0x60
    39d6:	42a3      	cmp	r3, r4
    39d8:	d805      	bhi.n	39e6 <z_impl_k_pipe_get+0x1a6>
	    && min_xfer > 0) {
    39da:	b123      	cbz	r3, 39e6 <z_impl_k_pipe_get+0x1a6>
		k_sched_unlock();
    39dc:	f000 fb24 	bl	4028 <k_sched_unlock>
		*bytes_read = num_bytes_read;
    39e0:	f8c9 4000 	str.w	r4, [r9]
    39e4:	e7ba      	b.n	395c <z_impl_k_pipe_get+0x11c>
	pipe_desc.buffer        = (uint8_t *)data + num_bytes_read;
    39e6:	eb08 0104 	add.w	r1, r8, r4
	pipe_desc.bytes_to_xfer = bytes_to_read - num_bytes_read;
    39ea:	1b34      	subs	r4, r6, r4
    39ec:	9409      	str	r4, [sp, #36]	; 0x24
	if (!K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    39ee:	e9dd 341a 	ldrd	r3, r4, [sp, #104]	; 0x68
    39f2:	4323      	orrs	r3, r4
	pipe_desc.buffer        = (uint8_t *)data + num_bytes_read;
    39f4:	9108      	str	r1, [sp, #32]
	if (!K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    39f6:	d023      	beq.n	3a40 <z_impl_k_pipe_get+0x200>
		_current->base.swap_data = &pipe_desc;
    39f8:	4b14      	ldr	r3, [pc, #80]	; (3a4c <z_impl_k_pipe_get+0x20c>)
    39fa:	689a      	ldr	r2, [r3, #8]
    39fc:	a908      	add	r1, sp, #32
    39fe:	6151      	str	r1, [r2, #20]
	__asm__ volatile(
    3a00:	f04f 0220 	mov.w	r2, #32
    3a04:	f3ef 8111 	mrs	r1, BASEPRI
    3a08:	f382 8811 	msr	BASEPRI, r2
    3a0c:	f3bf 8f6f 	isb	sy
	++_current->base.sched_locked;
    3a10:	689a      	ldr	r2, [r3, #8]
    3a12:	7bd3      	ldrb	r3, [r2, #15]
    3a14:	3301      	adds	r3, #1
    3a16:	73d3      	strb	r3, [r2, #15]
		(void)z_pend_curr(&pipe->lock, key2,
    3a18:	e9dd 341a 	ldrd	r3, r4, [sp, #104]	; 0x68
	k_spinlock_key_t key = k_spin_lock(&pipe->lock);
    3a1c:	f105 0214 	add.w	r2, r5, #20
		(void)z_pend_curr(&pipe->lock, key2,
    3a20:	e9cd 3400 	strd	r3, r4, [sp]
    3a24:	4610      	mov	r0, r2
    3a26:	f000 fd4d 	bl	44c4 <z_pend_curr>
	*bytes_read = bytes_to_read - pipe_desc.bytes_to_xfer;
    3a2a:	9a09      	ldr	r2, [sp, #36]	; 0x24
		return 0;
    3a2c:	9b18      	ldr	r3, [sp, #96]	; 0x60
	*bytes_read = bytes_to_read - pipe_desc.bytes_to_xfer;
    3a2e:	1ab6      	subs	r6, r6, r2
		return 0;
    3a30:	429e      	cmp	r6, r3
	*bytes_read = bytes_to_read - pipe_desc.bytes_to_xfer;
    3a32:	f8c9 6000 	str.w	r6, [r9]
		return 0;
    3a36:	bf34      	ite	cc
    3a38:	f06f 000a 	mvncc.w	r0, #10
    3a3c:	2000      	movcs	r0, #0
    3a3e:	e72f      	b.n	38a0 <z_impl_k_pipe_get+0x60>
		k_sched_unlock();
    3a40:	f000 faf2 	bl	4028 <k_sched_unlock>
    3a44:	e7f1      	b.n	3a2a <z_impl_k_pipe_get+0x1ea>
		return -EINVAL;
    3a46:	f06f 0015 	mvn.w	r0, #21
    3a4a:	e729      	b.n	38a0 <z_impl_k_pipe_get+0x60>
    3a4c:	20000eec 	.word	0x20000eec

00003a50 <z_vrfy_k_pipe_get>:

#ifdef CONFIG_USERSPACE
int z_vrfy_k_pipe_get(struct k_pipe *pipe, void *data, size_t bytes_to_read,
		      size_t *bytes_read, size_t min_xfer, k_timeout_t timeout)
{
    3a50:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    3a54:	e9dd 890a 	ldrd	r8, r9, [sp, #40]	; 0x28
    3a58:	460d      	mov	r5, r1
    3a5a:	4616      	mov	r6, r2
    3a5c:	f8dd a020 	ldr.w	sl, [sp, #32]
    3a60:	4607      	mov	r7, r0
    3a62:	461c      	mov	r4, r3
	Z_OOPS(Z_SYSCALL_OBJ(pipe, K_OBJ_PIPE));
    3a64:	f7fc fb3a 	bl	dc <z_object_find>
    3a68:	2200      	movs	r2, #0
    3a6a:	2104      	movs	r1, #4
    3a6c:	f001 fd70 	bl	5550 <z_object_validate>
    3a70:	b138      	cbz	r0, 3a82 <z_vrfy_k_pipe_get+0x32>
    3a72:	f002 fd3c 	bl	64ee <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(bytes_read, sizeof(*bytes_read)));
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE((void *)data, bytes_to_read));
    3a76:	4b10      	ldr	r3, [pc, #64]	; (3ab8 <z_vrfy_k_pipe_get+0x68>)
    3a78:	689b      	ldr	r3, [r3, #8]
    3a7a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3a7e:	f002 fb2b 	bl	60d8 <arch_syscall_oops>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(bytes_read, sizeof(*bytes_read)));
    3a82:	2201      	movs	r2, #1
    3a84:	2104      	movs	r1, #4
    3a86:	4620      	mov	r0, r4
    3a88:	f002 fb54 	bl	6134 <arch_buffer_validate>
    3a8c:	2800      	cmp	r0, #0
    3a8e:	d1f0      	bne.n	3a72 <z_vrfy_k_pipe_get+0x22>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE((void *)data, bytes_to_read));
    3a90:	2201      	movs	r2, #1
    3a92:	4631      	mov	r1, r6
    3a94:	4628      	mov	r0, r5
    3a96:	f002 fb4d 	bl	6134 <arch_buffer_validate>
    3a9a:	2800      	cmp	r0, #0
    3a9c:	d1e9      	bne.n	3a72 <z_vrfy_k_pipe_get+0x22>

	return z_impl_k_pipe_get((struct k_pipe *)pipe, (void *)data,
    3a9e:	e9cd 890a 	strd	r8, r9, [sp, #40]	; 0x28
    3aa2:	f8cd a020 	str.w	sl, [sp, #32]
    3aa6:	4623      	mov	r3, r4
    3aa8:	4632      	mov	r2, r6
    3aaa:	4629      	mov	r1, r5
    3aac:	4638      	mov	r0, r7
				bytes_to_read, bytes_read, min_xfer,
				timeout);
}
    3aae:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	return z_impl_k_pipe_get((struct k_pipe *)pipe, (void *)data,
    3ab2:	f7ff bec5 	b.w	3840 <z_impl_k_pipe_get>
    3ab6:	bf00      	nop
    3ab8:	20000eec 	.word	0x20000eec

00003abc <z_mrsh_k_pipe_get>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_pipe_get(struct k_pipe * pipe, void * data, size_t bytes_to_read, size_t * bytes_read, size_t min_xfer, k_timeout_t timeout);
uintptr_t z_mrsh_k_pipe_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, void *more, void *ssf)
{
    3abc:	e92d 47ff 	stmdb	sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    3ac0:	4d15      	ldr	r5, [pc, #84]	; (3b18 <z_mrsh_k_pipe_get+0x5c>)
{
    3ac2:	f8dd a034 	ldr.w	sl, [sp, #52]	; 0x34
    3ac6:	4699      	mov	r9, r3
	_current->syscall_frame = ssf;
    3ac8:	68ab      	ldr	r3, [r5, #8]
{
    3aca:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    3acc:	9a0e      	ldr	r2, [sp, #56]	; 0x38
    3ace:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3ad2:	4606      	mov	r6, r0
    3ad4:	460f      	mov	r7, r1
	Z_OOPS(Z_SYSCALL_MEMORY_READ(more, 1 * sizeof(uintptr_t)));
    3ad6:	2200      	movs	r2, #0
    3ad8:	2104      	movs	r1, #4
    3ada:	4650      	mov	r0, sl
    3adc:	f002 fb2a 	bl	6134 <arch_buffer_validate>
    3ae0:	4604      	mov	r4, r0
    3ae2:	b130      	cbz	r0, 3af2 <z_mrsh_k_pipe_get+0x36>
    3ae4:	f002 fd03 	bl	64ee <arch_is_user_context>
    3ae8:	68ab      	ldr	r3, [r5, #8]
    3aea:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3aee:	f002 faf3 	bl	60d8 <arch_syscall_oops>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = (((uintptr_t *)more)[0]);
	parm0.split.hi = (((uintptr_t *)more)[1]);
    3af2:	e9da 2300 	ldrd	r2, r3, [sl]
	int ret = z_vrfy_k_pipe_get(*(struct k_pipe **)&arg0, *(void **)&arg1, *(size_t*)&arg2, *(size_t **)&arg3, *(size_t*)&arg4, parm0.val)
    3af6:	e9cd 2302 	strd	r2, r3, [sp, #8]
    3afa:	9b0c      	ldr	r3, [sp, #48]	; 0x30
    3afc:	9300      	str	r3, [sp, #0]
    3afe:	4642      	mov	r2, r8
    3b00:	464b      	mov	r3, r9
    3b02:	4639      	mov	r1, r7
    3b04:	4630      	mov	r0, r6
    3b06:	f7ff ffa3 	bl	3a50 <z_vrfy_k_pipe_get>
;
	_current->syscall_frame = NULL;
    3b0a:	68ab      	ldr	r3, [r5, #8]
    3b0c:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3b10:	b004      	add	sp, #16
    3b12:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    3b16:	bf00      	nop
    3b18:	20000eec 	.word	0x20000eec

00003b1c <z_vrfy_k_pipe_put>:

#ifdef CONFIG_USERSPACE
int z_vrfy_k_pipe_put(struct k_pipe *pipe, void *data, size_t bytes_to_write,
		     size_t *bytes_written, size_t min_xfer,
		      k_timeout_t timeout)
{
    3b1c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    3b20:	e9dd 670a 	ldrd	r6, r7, [sp, #40]	; 0x28
    3b24:	460d      	mov	r5, r1
    3b26:	4690      	mov	r8, r2
    3b28:	f8dd a020 	ldr.w	sl, [sp, #32]
    3b2c:	4681      	mov	r9, r0
    3b2e:	461c      	mov	r4, r3
	Z_OOPS(Z_SYSCALL_OBJ(pipe, K_OBJ_PIPE));
    3b30:	f7fc fad4 	bl	dc <z_object_find>
    3b34:	2200      	movs	r2, #0
    3b36:	2104      	movs	r1, #4
    3b38:	f001 fd0a 	bl	5550 <z_object_validate>
    3b3c:	b138      	cbz	r0, 3b4e <z_vrfy_k_pipe_put+0x32>
    3b3e:	f002 fcd6 	bl	64ee <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(bytes_written, sizeof(*bytes_written)));
	Z_OOPS(Z_SYSCALL_MEMORY_READ((void *)data, bytes_to_write));
    3b42:	4b10      	ldr	r3, [pc, #64]	; (3b84 <z_vrfy_k_pipe_put+0x68>)
    3b44:	689b      	ldr	r3, [r3, #8]
    3b46:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3b4a:	f002 fac5 	bl	60d8 <arch_syscall_oops>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(bytes_written, sizeof(*bytes_written)));
    3b4e:	2201      	movs	r2, #1
    3b50:	2104      	movs	r1, #4
    3b52:	4620      	mov	r0, r4
    3b54:	f002 faee 	bl	6134 <arch_buffer_validate>
    3b58:	4602      	mov	r2, r0
    3b5a:	2800      	cmp	r0, #0
    3b5c:	d1ef      	bne.n	3b3e <z_vrfy_k_pipe_put+0x22>
	Z_OOPS(Z_SYSCALL_MEMORY_READ((void *)data, bytes_to_write));
    3b5e:	4641      	mov	r1, r8
    3b60:	4628      	mov	r0, r5
    3b62:	f002 fae7 	bl	6134 <arch_buffer_validate>
    3b66:	2800      	cmp	r0, #0
    3b68:	d1e9      	bne.n	3b3e <z_vrfy_k_pipe_put+0x22>

	return z_impl_k_pipe_put((struct k_pipe *)pipe, (void *)data,
    3b6a:	e9cd 670a 	strd	r6, r7, [sp, #40]	; 0x28
    3b6e:	f8cd a020 	str.w	sl, [sp, #32]
    3b72:	4623      	mov	r3, r4
    3b74:	4642      	mov	r2, r8
    3b76:	4629      	mov	r1, r5
    3b78:	4648      	mov	r0, r9
				bytes_to_write, bytes_written, min_xfer,
				timeout);
}
    3b7a:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	return z_impl_k_pipe_put((struct k_pipe *)pipe, (void *)data,
    3b7e:	f002 bd78 	b.w	6672 <z_impl_k_pipe_put>
    3b82:	bf00      	nop
    3b84:	20000eec 	.word	0x20000eec

00003b88 <z_mrsh_k_pipe_put>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_pipe_put(struct k_pipe * pipe, void * data, size_t bytes_to_write, size_t * bytes_written, size_t min_xfer, k_timeout_t timeout);
uintptr_t z_mrsh_k_pipe_put(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, void *more, void *ssf)
{
    3b88:	e92d 47ff 	stmdb	sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    3b8c:	4d15      	ldr	r5, [pc, #84]	; (3be4 <z_mrsh_k_pipe_put+0x5c>)
{
    3b8e:	f8dd a034 	ldr.w	sl, [sp, #52]	; 0x34
    3b92:	4699      	mov	r9, r3
	_current->syscall_frame = ssf;
    3b94:	68ab      	ldr	r3, [r5, #8]
{
    3b96:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    3b98:	9a0e      	ldr	r2, [sp, #56]	; 0x38
    3b9a:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3b9e:	4606      	mov	r6, r0
    3ba0:	460f      	mov	r7, r1
	Z_OOPS(Z_SYSCALL_MEMORY_READ(more, 1 * sizeof(uintptr_t)));
    3ba2:	2200      	movs	r2, #0
    3ba4:	2104      	movs	r1, #4
    3ba6:	4650      	mov	r0, sl
    3ba8:	f002 fac4 	bl	6134 <arch_buffer_validate>
    3bac:	4604      	mov	r4, r0
    3bae:	b130      	cbz	r0, 3bbe <z_mrsh_k_pipe_put+0x36>
    3bb0:	f002 fc9d 	bl	64ee <arch_is_user_context>
    3bb4:	68ab      	ldr	r3, [r5, #8]
    3bb6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3bba:	f002 fa8d 	bl	60d8 <arch_syscall_oops>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = (((uintptr_t *)more)[0]);
	parm0.split.hi = (((uintptr_t *)more)[1]);
    3bbe:	e9da 2300 	ldrd	r2, r3, [sl]
	int ret = z_vrfy_k_pipe_put(*(struct k_pipe **)&arg0, *(void **)&arg1, *(size_t*)&arg2, *(size_t **)&arg3, *(size_t*)&arg4, parm0.val)
    3bc2:	e9cd 2302 	strd	r2, r3, [sp, #8]
    3bc6:	9b0c      	ldr	r3, [sp, #48]	; 0x30
    3bc8:	9300      	str	r3, [sp, #0]
    3bca:	4642      	mov	r2, r8
    3bcc:	464b      	mov	r3, r9
    3bce:	4639      	mov	r1, r7
    3bd0:	4630      	mov	r0, r6
    3bd2:	f7ff ffa3 	bl	3b1c <z_vrfy_k_pipe_put>
;
	_current->syscall_frame = NULL;
    3bd6:	68ab      	ldr	r3, [r5, #8]
    3bd8:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3bdc:	b004      	add	sp, #16
    3bde:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    3be2:	bf00      	nop
    3be4:	20000eec 	.word	0x20000eec

00003be8 <z_vrfy_k_pipe_read_avail>:
	return res;
}

#ifdef CONFIG_USERSPACE
size_t z_vrfy_k_pipe_read_avail(struct k_pipe *pipe)
{
    3be8:	b510      	push	{r4, lr}
    3bea:	4604      	mov	r4, r0
	Z_OOPS(Z_SYSCALL_OBJ(pipe, K_OBJ_PIPE));
    3bec:	f7fc fa76 	bl	dc <z_object_find>
    3bf0:	2200      	movs	r2, #0
    3bf2:	2104      	movs	r1, #4
    3bf4:	f001 fcac 	bl	5550 <z_object_validate>
    3bf8:	b138      	cbz	r0, 3c0a <z_vrfy_k_pipe_read_avail+0x22>
    3bfa:	f002 fc78 	bl	64ee <arch_is_user_context>
    3bfe:	4b05      	ldr	r3, [pc, #20]	; (3c14 <z_vrfy_k_pipe_read_avail+0x2c>)
    3c00:	689b      	ldr	r3, [r3, #8]
    3c02:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3c06:	f002 fa67 	bl	60d8 <arch_syscall_oops>

	return z_impl_k_pipe_read_avail(pipe);
    3c0a:	4620      	mov	r0, r4
}
    3c0c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_impl_k_pipe_read_avail(pipe);
    3c10:	f002 bd39 	b.w	6686 <z_impl_k_pipe_read_avail>
    3c14:	20000eec 	.word	0x20000eec

00003c18 <z_mrsh_k_pipe_read_avail>:
#include <syscalls/kernel.h>

extern size_t z_vrfy_k_pipe_read_avail(struct k_pipe * pipe);
uintptr_t z_mrsh_k_pipe_read_avail(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3c18:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    3c1a:	4c06      	ldr	r4, [pc, #24]	; (3c34 <z_mrsh_k_pipe_read_avail+0x1c>)
    3c1c:	9a04      	ldr	r2, [sp, #16]
    3c1e:	68a3      	ldr	r3, [r4, #8]
    3c20:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg1;	/* unused */
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	size_t ret = z_vrfy_k_pipe_read_avail(*(struct k_pipe **)&arg0)
    3c24:	f7ff ffe0 	bl	3be8 <z_vrfy_k_pipe_read_avail>
;
	_current->syscall_frame = NULL;
    3c28:	68a3      	ldr	r3, [r4, #8]
    3c2a:	2200      	movs	r2, #0
    3c2c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3c30:	bd10      	pop	{r4, pc}
    3c32:	bf00      	nop
    3c34:	20000eec 	.word	0x20000eec

00003c38 <z_vrfy_k_pipe_write_avail>:
	return res;
}

#ifdef CONFIG_USERSPACE
size_t z_vrfy_k_pipe_write_avail(struct k_pipe *pipe)
{
    3c38:	b510      	push	{r4, lr}
    3c3a:	4604      	mov	r4, r0
	Z_OOPS(Z_SYSCALL_OBJ(pipe, K_OBJ_PIPE));
    3c3c:	f7fc fa4e 	bl	dc <z_object_find>
    3c40:	2200      	movs	r2, #0
    3c42:	2104      	movs	r1, #4
    3c44:	f001 fc84 	bl	5550 <z_object_validate>
    3c48:	b138      	cbz	r0, 3c5a <z_vrfy_k_pipe_write_avail+0x22>
    3c4a:	f002 fc50 	bl	64ee <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_OBJ(pipe, K_OBJ_PIPE));
    3c4e:	4b05      	ldr	r3, [pc, #20]	; (3c64 <z_vrfy_k_pipe_write_avail+0x2c>)
    3c50:	689b      	ldr	r3, [r3, #8]
    3c52:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3c56:	f002 fa3f 	bl	60d8 <arch_syscall_oops>

	return z_impl_k_pipe_write_avail(pipe);
    3c5a:	4620      	mov	r0, r4
}
    3c5c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_impl_k_pipe_write_avail(pipe);
    3c60:	f002 bd2d 	b.w	66be <z_impl_k_pipe_write_avail>
    3c64:	20000eec 	.word	0x20000eec

00003c68 <z_mrsh_k_pipe_write_avail>:
#include <syscalls/kernel.h>

extern size_t z_vrfy_k_pipe_write_avail(struct k_pipe * pipe);
uintptr_t z_mrsh_k_pipe_write_avail(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3c68:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    3c6a:	4c06      	ldr	r4, [pc, #24]	; (3c84 <z_mrsh_k_pipe_write_avail+0x1c>)
    3c6c:	9a04      	ldr	r2, [sp, #16]
    3c6e:	68a3      	ldr	r3, [r4, #8]
    3c70:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg1;	/* unused */
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	size_t ret = z_vrfy_k_pipe_write_avail(*(struct k_pipe **)&arg0)
    3c74:	f7ff ffe0 	bl	3c38 <z_vrfy_k_pipe_write_avail>
;
	_current->syscall_frame = NULL;
    3c78:	68a3      	ldr	r3, [r4, #8]
    3c7a:	2200      	movs	r2, #0
    3c7c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3c80:	bd10      	pop	{r4, pc}
    3c82:	bf00      	nop
    3c84:	20000eec 	.word	0x20000eec

00003c88 <z_mrsh_k_queue_init>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_queue_init(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3c88:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3c8a:	4d0f      	ldr	r5, [pc, #60]	; (3cc8 <z_mrsh_k_queue_init+0x40>)
    3c8c:	9a06      	ldr	r2, [sp, #24]
    3c8e:	68ab      	ldr	r3, [r5, #8]
    3c90:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3c94:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_queue_init(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(queue, K_OBJ_QUEUE));
    3c96:	f7fc fa21 	bl	dc <z_object_find>
    3c9a:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    3c9e:	2105      	movs	r1, #5
    3ca0:	f001 fc56 	bl	5550 <z_object_validate>
    3ca4:	4604      	mov	r4, r0
    3ca6:	b130      	cbz	r0, 3cb6 <z_mrsh_k_queue_init+0x2e>
    3ca8:	f002 fd27 	bl	66fa <arch_is_user_context>
    3cac:	68ab      	ldr	r3, [r5, #8]
    3cae:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3cb2:	f002 fa11 	bl	60d8 <arch_syscall_oops>
	z_impl_k_queue_init(queue);
    3cb6:	4630      	mov	r0, r6
    3cb8:	f002 fd92 	bl	67e0 <z_impl_k_queue_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_queue_init(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3cbc:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3cbe:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3cc0:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3cc4:	bd70      	pop	{r4, r5, r6, pc}
    3cc6:	bf00      	nop
    3cc8:	20000eec 	.word	0x20000eec

00003ccc <z_mrsh_k_queue_cancel_wait>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_queue_cancel_wait(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_cancel_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3ccc:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3cce:	4d0e      	ldr	r5, [pc, #56]	; (3d08 <z_mrsh_k_queue_cancel_wait+0x3c>)
    3cd0:	9a06      	ldr	r2, [sp, #24]
    3cd2:	68ab      	ldr	r3, [r5, #8]
    3cd4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3cd8:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_queue_cancel_wait(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3cda:	f7fc f9ff 	bl	dc <z_object_find>
    3cde:	2200      	movs	r2, #0
    3ce0:	2105      	movs	r1, #5
    3ce2:	f001 fc35 	bl	5550 <z_object_validate>
    3ce6:	4604      	mov	r4, r0
    3ce8:	b130      	cbz	r0, 3cf8 <z_mrsh_k_queue_cancel_wait+0x2c>
    3cea:	f002 fd06 	bl	66fa <arch_is_user_context>
    3cee:	68ab      	ldr	r3, [r5, #8]
    3cf0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3cf4:	f002 f9f0 	bl	60d8 <arch_syscall_oops>
	z_impl_k_queue_cancel_wait(queue);
    3cf8:	4630      	mov	r0, r6
    3cfa:	f002 fd7a 	bl	67f2 <z_impl_k_queue_cancel_wait>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_queue_cancel_wait(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3cfe:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3d00:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3d02:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3d06:	bd70      	pop	{r4, r5, r6, pc}
    3d08:	20000eec 	.word	0x20000eec

00003d0c <z_mrsh_k_queue_alloc_append>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_queue_alloc_append(struct k_queue * queue, void * data);
uintptr_t z_mrsh_k_queue_alloc_append(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3d0c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    3d0e:	4d0f      	ldr	r5, [pc, #60]	; (3d4c <z_mrsh_k_queue_alloc_append+0x40>)
    3d10:	9a08      	ldr	r2, [sp, #32]
    3d12:	68ab      	ldr	r3, [r5, #8]
    3d14:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3d18:	460f      	mov	r7, r1
    3d1a:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_queue_alloc_append(struct k_queue *queue,
						void *data)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3d1c:	f7fc f9de 	bl	dc <z_object_find>
    3d20:	2200      	movs	r2, #0
    3d22:	2105      	movs	r1, #5
    3d24:	f001 fc14 	bl	5550 <z_object_validate>
    3d28:	4604      	mov	r4, r0
    3d2a:	b130      	cbz	r0, 3d3a <z_mrsh_k_queue_alloc_append+0x2e>
    3d2c:	f002 fce5 	bl	66fa <arch_is_user_context>
    3d30:	68ab      	ldr	r3, [r5, #8]
    3d32:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3d36:	f002 f9cf 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_queue_alloc_append(queue, data);
    3d3a:	4639      	mov	r1, r7
    3d3c:	4630      	mov	r0, r6
    3d3e:	f002 fd73 	bl	6828 <z_impl_k_queue_alloc_append>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_queue_alloc_append(*(struct k_queue **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    3d42:	68ab      	ldr	r3, [r5, #8]
    3d44:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3d48:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3d4a:	bf00      	nop
    3d4c:	20000eec 	.word	0x20000eec

00003d50 <z_mrsh_k_queue_alloc_prepend>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_queue_alloc_prepend(struct k_queue * queue, void * data);
uintptr_t z_mrsh_k_queue_alloc_prepend(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3d50:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    3d52:	4d0f      	ldr	r5, [pc, #60]	; (3d90 <z_mrsh_k_queue_alloc_prepend+0x40>)
    3d54:	9a08      	ldr	r2, [sp, #32]
    3d56:	68ab      	ldr	r3, [r5, #8]
    3d58:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3d5c:	460f      	mov	r7, r1
    3d5e:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_queue_alloc_prepend(struct k_queue *queue,
						 void *data)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3d60:	f7fc f9bc 	bl	dc <z_object_find>
    3d64:	2200      	movs	r2, #0
    3d66:	2105      	movs	r1, #5
    3d68:	f001 fbf2 	bl	5550 <z_object_validate>
    3d6c:	4604      	mov	r4, r0
    3d6e:	b130      	cbz	r0, 3d7e <z_mrsh_k_queue_alloc_prepend+0x2e>
    3d70:	f002 fcc3 	bl	66fa <arch_is_user_context>
    3d74:	68ab      	ldr	r3, [r5, #8]
    3d76:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3d7a:	f002 f9ad 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_queue_alloc_prepend(queue, data);
    3d7e:	4639      	mov	r1, r7
    3d80:	4630      	mov	r0, r6
    3d82:	f002 fd56 	bl	6832 <z_impl_k_queue_alloc_prepend>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_queue_alloc_prepend(*(struct k_queue **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    3d86:	68ab      	ldr	r3, [r5, #8]
    3d88:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3d8c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3d8e:	bf00      	nop
    3d90:	20000eec 	.word	0x20000eec

00003d94 <z_impl_k_queue_get>:

	return 0;
}

void *z_impl_k_queue_get(struct k_queue *queue, k_timeout_t timeout)
{
    3d94:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    3d96:	4616      	mov	r6, r2
    3d98:	461f      	mov	r7, r3
    3d9a:	f04f 0320 	mov.w	r3, #32
    3d9e:	f3ef 8511 	mrs	r5, BASEPRI
    3da2:	f383 8811 	msr	BASEPRI, r3
    3da6:	f3bf 8f6f 	isb	sy
 *
 * @return a boolean, true if it's empty, false otherwise
 */
static inline bool sys_sflist_is_empty(sys_sflist_t *list);

Z_GENLIST_IS_EMPTY(sflist)
    3daa:	6804      	ldr	r4, [r0, #0]
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
	void *data;

	if (likely(!sys_sflist_is_empty(&queue->data_q))) {
    3dac:	b19c      	cbz	r4, 3dd6 <z_impl_k_queue_get+0x42>
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    3dae:	6823      	ldr	r3, [r4, #0]
 *
 * @return A pointer to the first node of the list
 */
static inline sys_sfnode_t *sys_sflist_get_not_empty(sys_sflist_t *list);

Z_GENLIST_GET_NOT_EMPTY(sflist, sfnode)
    3db0:	6842      	ldr	r2, [r0, #4]
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    3db2:	f023 0303 	bic.w	r3, r3, #3
Z_GENLIST_GET_NOT_EMPTY(sflist, sfnode)
    3db6:	4294      	cmp	r4, r2
	list->head = node;
    3db8:	6003      	str	r3, [r0, #0]
	list->tail = node;
    3dba:	bf08      	it	eq
    3dbc:	6043      	streq	r3, [r0, #4]
		sys_sfnode_t *node;

		node = sys_sflist_get_not_empty(&queue->data_q);
		data = z_queue_node_peek(node, true);
    3dbe:	2101      	movs	r1, #1
    3dc0:	4620      	mov	r0, r4
    3dc2:	f002 fd01 	bl	67c8 <z_queue_node_peek>
    3dc6:	4604      	mov	r4, r0
	__asm__ volatile(
    3dc8:	f385 8811 	msr	BASEPRI, r5
    3dcc:	f3bf 8f6f 	isb	sy
	}

	int ret = z_pend_curr(&queue->lock, key, &queue->wait_q, timeout);

	return (ret != 0) ? NULL : _current->base.swap_data;
}
    3dd0:	4620      	mov	r0, r4
    3dd2:	b003      	add	sp, #12
    3dd4:	bdf0      	pop	{r4, r5, r6, r7, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    3dd6:	ea56 0307 	orrs.w	r3, r6, r7
    3dda:	d0f5      	beq.n	3dc8 <z_impl_k_queue_get+0x34>
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    3ddc:	f100 0208 	add.w	r2, r0, #8
	int ret = z_pend_curr(&queue->lock, key, &queue->wait_q, timeout);
    3de0:	e9cd 6700 	strd	r6, r7, [sp]
    3de4:	4629      	mov	r1, r5
    3de6:	4610      	mov	r0, r2
    3de8:	f000 fb6c 	bl	44c4 <z_pend_curr>
	return (ret != 0) ? NULL : _current->base.swap_data;
    3dec:	2800      	cmp	r0, #0
    3dee:	d1ef      	bne.n	3dd0 <z_impl_k_queue_get+0x3c>
    3df0:	4b01      	ldr	r3, [pc, #4]	; (3df8 <z_impl_k_queue_get+0x64>)
    3df2:	689b      	ldr	r3, [r3, #8]
    3df4:	695c      	ldr	r4, [r3, #20]
    3df6:	e7eb      	b.n	3dd0 <z_impl_k_queue_get+0x3c>
    3df8:	20000eec 	.word	0x20000eec

00003dfc <z_mrsh_k_queue_get>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_get(struct k_queue * queue, k_timeout_t timeout);
uintptr_t z_mrsh_k_queue_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3dfc:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    3e00:	4d10      	ldr	r5, [pc, #64]	; (3e44 <z_mrsh_k_queue_get+0x48>)
    3e02:	68ab      	ldr	r3, [r5, #8]
{
    3e04:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    3e06:	9a08      	ldr	r2, [sp, #32]
    3e08:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3e0c:	4688      	mov	r8, r1
    3e0e:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline void *z_vrfy_k_queue_get(struct k_queue *queue,
				       k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3e10:	f7fc f964 	bl	dc <z_object_find>
    3e14:	2200      	movs	r2, #0
    3e16:	2105      	movs	r1, #5
    3e18:	f001 fb9a 	bl	5550 <z_object_validate>
    3e1c:	4604      	mov	r4, r0
    3e1e:	b130      	cbz	r0, 3e2e <z_mrsh_k_queue_get+0x32>
    3e20:	f002 fc6b 	bl	66fa <arch_is_user_context>
    3e24:	68ab      	ldr	r3, [r5, #8]
    3e26:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3e2a:	f002 f955 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_queue_get(queue, timeout);
    3e2e:	463b      	mov	r3, r7
    3e30:	4642      	mov	r2, r8
    3e32:	4630      	mov	r0, r6
    3e34:	f7ff ffae 	bl	3d94 <z_impl_k_queue_get>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	void * ret = z_vrfy_k_queue_get(*(struct k_queue **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    3e38:	68ab      	ldr	r3, [r5, #8]
    3e3a:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3e3e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    3e42:	bf00      	nop
    3e44:	20000eec 	.word	0x20000eec

00003e48 <z_mrsh_k_queue_is_empty>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_queue_is_empty(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_is_empty(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3e48:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    3e4a:	4c0e      	ldr	r4, [pc, #56]	; (3e84 <z_mrsh_k_queue_is_empty+0x3c>)
    3e4c:	9a06      	ldr	r2, [sp, #24]
    3e4e:	68a3      	ldr	r3, [r4, #8]
    3e50:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3e54:	4605      	mov	r5, r0
}
#include <syscalls/k_queue_get_mrsh.c>

static inline int z_vrfy_k_queue_is_empty(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3e56:	f7fc f941 	bl	dc <z_object_find>
    3e5a:	2200      	movs	r2, #0
    3e5c:	2105      	movs	r1, #5
    3e5e:	f001 fb77 	bl	5550 <z_object_validate>
    3e62:	b130      	cbz	r0, 3e72 <z_mrsh_k_queue_is_empty+0x2a>
    3e64:	f002 fc49 	bl	66fa <arch_is_user_context>
    3e68:	68a3      	ldr	r3, [r4, #8]
    3e6a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3e6e:	f002 f933 	bl	60d8 <arch_syscall_oops>
Z_GENLIST_IS_EMPTY(sflist)
    3e72:	682b      	ldr	r3, [r5, #0]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_queue_is_empty(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3e74:	68a2      	ldr	r2, [r4, #8]
    3e76:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    3e7a:	fab3 f083 	clz	r0, r3
    3e7e:	0940      	lsrs	r0, r0, #5
    3e80:	bd38      	pop	{r3, r4, r5, pc}
    3e82:	bf00      	nop
    3e84:	20000eec 	.word	0x20000eec

00003e88 <z_mrsh_k_queue_peek_head>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_peek_head(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_peek_head(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3e88:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3e8a:	4d0e      	ldr	r5, [pc, #56]	; (3ec4 <z_mrsh_k_queue_peek_head+0x3c>)
    3e8c:	9a06      	ldr	r2, [sp, #24]
    3e8e:	68ab      	ldr	r3, [r5, #8]
    3e90:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3e94:	4606      	mov	r6, r0
}
#include <syscalls/k_queue_is_empty_mrsh.c>

static inline void *z_vrfy_k_queue_peek_head(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3e96:	f7fc f921 	bl	dc <z_object_find>
    3e9a:	2200      	movs	r2, #0
    3e9c:	2105      	movs	r1, #5
    3e9e:	f001 fb57 	bl	5550 <z_object_validate>
    3ea2:	4604      	mov	r4, r0
    3ea4:	b130      	cbz	r0, 3eb4 <z_mrsh_k_queue_peek_head+0x2c>
    3ea6:	f002 fc28 	bl	66fa <arch_is_user_context>
    3eaa:	68ab      	ldr	r3, [r5, #8]
    3eac:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3eb0:	f002 f912 	bl	60d8 <arch_syscall_oops>
	return z_queue_node_peek(sys_sflist_peek_head(&queue->data_q), false);
    3eb4:	4601      	mov	r1, r0
    3eb6:	6830      	ldr	r0, [r6, #0]
    3eb8:	f002 fc86 	bl	67c8 <z_queue_node_peek>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_queue_peek_head(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3ebc:	68ab      	ldr	r3, [r5, #8]
    3ebe:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3ec2:	bd70      	pop	{r4, r5, r6, pc}
    3ec4:	20000eec 	.word	0x20000eec

00003ec8 <z_mrsh_k_queue_peek_tail>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_peek_tail(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_peek_tail(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3ec8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3eca:	4d0e      	ldr	r5, [pc, #56]	; (3f04 <z_mrsh_k_queue_peek_tail+0x3c>)
    3ecc:	9a06      	ldr	r2, [sp, #24]
    3ece:	68ab      	ldr	r3, [r5, #8]
    3ed0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3ed4:	4606      	mov	r6, r0
}
#include <syscalls/k_queue_peek_head_mrsh.c>

static inline void *z_vrfy_k_queue_peek_tail(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3ed6:	f7fc f901 	bl	dc <z_object_find>
    3eda:	2200      	movs	r2, #0
    3edc:	2105      	movs	r1, #5
    3ede:	f001 fb37 	bl	5550 <z_object_validate>
    3ee2:	4604      	mov	r4, r0
    3ee4:	b130      	cbz	r0, 3ef4 <z_mrsh_k_queue_peek_tail+0x2c>
    3ee6:	f002 fc08 	bl	66fa <arch_is_user_context>
    3eea:	68ab      	ldr	r3, [r5, #8]
    3eec:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3ef0:	f002 f8f2 	bl	60d8 <arch_syscall_oops>
	return z_queue_node_peek(sys_sflist_peek_tail(&queue->data_q), false);
    3ef4:	4601      	mov	r1, r0
    3ef6:	6870      	ldr	r0, [r6, #4]
    3ef8:	f002 fc66 	bl	67c8 <z_queue_node_peek>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_queue_peek_tail(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3efc:	68ab      	ldr	r3, [r5, #8]
    3efe:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3f02:	bd70      	pop	{r4, r5, r6, pc}
    3f04:	20000eec 	.word	0x20000eec

00003f08 <z_reset_time_slice>:
 */
static struct k_thread *pending_current;
#endif

void z_reset_time_slice(void)
{
    3f08:	b510      	push	{r4, lr}
	/* Add the elapsed time since the last announced tick to the
	 * slice count, as we'll see those "expired" ticks arrive in a
	 * FUTURE z_time_slice() call.
	 */
	if (slice_time != 0) {
    3f0a:	4c08      	ldr	r4, [pc, #32]	; (3f2c <z_reset_time_slice+0x24>)
    3f0c:	6823      	ldr	r3, [r4, #0]
    3f0e:	b15b      	cbz	r3, 3f28 <z_reset_time_slice+0x20>
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    3f10:	f7fd fa2e 	bl	1370 <z_clock_elapsed>
    3f14:	4603      	mov	r3, r0
    3f16:	6820      	ldr	r0, [r4, #0]
    3f18:	4a05      	ldr	r2, [pc, #20]	; (3f30 <z_reset_time_slice+0x28>)
    3f1a:	4403      	add	r3, r0
		z_set_timeout_expiry(slice_time, false);
	}
}
    3f1c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    3f20:	6113      	str	r3, [r2, #16]
		z_set_timeout_expiry(slice_time, false);
    3f22:	2100      	movs	r1, #0
    3f24:	f002 bea2 	b.w	6c6c <z_set_timeout_expiry>
}
    3f28:	bd10      	pop	{r4, pc}
    3f2a:	bf00      	nop
    3f2c:	20000f24 	.word	0x20000f24
    3f30:	20000eec 	.word	0x20000eec

00003f34 <k_sched_time_slice_set>:

void k_sched_time_slice_set(int32_t slice, int prio)
{
    3f34:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    3f36:	4605      	mov	r5, r0
    3f38:	460c      	mov	r4, r1
	__asm__ volatile(
    3f3a:	f04f 0320 	mov.w	r3, #32
    3f3e:	f3ef 8611 	mrs	r6, BASEPRI
    3f42:	f383 8811 	msr	BASEPRI, r3
    3f46:	f3bf 8f6f 	isb	sy
	LOCKED(&sched_spinlock) {
		_current_cpu->slice_ticks = 0;
    3f4a:	4b0d      	ldr	r3, [pc, #52]	; (3f80 <k_sched_time_slice_set+0x4c>)
    3f4c:	2200      	movs	r2, #0
		} else {
			return t * (to_hz / from_hz);
		}
	} else {
		if (result32) {
			return (uint32_t)((t * to_hz + off) / from_hz);
    3f4e:	f44f 4700 	mov.w	r7, #32768	; 0x8000
    3f52:	f240 30e7 	movw	r0, #999	; 0x3e7
    3f56:	2100      	movs	r1, #0
    3f58:	611a      	str	r2, [r3, #16]
    3f5a:	fbe7 0105 	umlal	r0, r1, r7, r5
    3f5e:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    3f62:	2300      	movs	r3, #0
    3f64:	f7fc f93a 	bl	1dc <__aeabi_uldivmod>
		slice_time = k_ms_to_ticks_ceil32(slice);
    3f68:	4b06      	ldr	r3, [pc, #24]	; (3f84 <k_sched_time_slice_set+0x50>)
    3f6a:	6018      	str	r0, [r3, #0]
		slice_max_prio = prio;
    3f6c:	4b06      	ldr	r3, [pc, #24]	; (3f88 <k_sched_time_slice_set+0x54>)
    3f6e:	601c      	str	r4, [r3, #0]
		z_reset_time_slice();
    3f70:	f7ff ffca 	bl	3f08 <z_reset_time_slice>
	__asm__ volatile(
    3f74:	f386 8811 	msr	BASEPRI, r6
    3f78:	f3bf 8f6f 	isb	sy
	}
}
    3f7c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3f7e:	bf00      	nop
    3f80:	20000eec 	.word	0x20000eec
    3f84:	20000f24 	.word	0x20000f24
    3f88:	20000f20 	.word	0x20000f20

00003f8c <k_sched_lock>:
	__asm__ volatile(
    3f8c:	f04f 0320 	mov.w	r3, #32
    3f90:	f3ef 8111 	mrs	r1, BASEPRI
    3f94:	f383 8811 	msr	BASEPRI, r3
    3f98:	f3bf 8f6f 	isb	sy
	--_current->base.sched_locked;
    3f9c:	4b04      	ldr	r3, [pc, #16]	; (3fb0 <k_sched_lock+0x24>)
    3f9e:	689a      	ldr	r2, [r3, #8]
    3fa0:	7bd3      	ldrb	r3, [r2, #15]
    3fa2:	3b01      	subs	r3, #1
    3fa4:	73d3      	strb	r3, [r2, #15]
	__asm__ volatile(
    3fa6:	f381 8811 	msr	BASEPRI, r1
    3faa:	f3bf 8f6f 	isb	sy
void k_sched_lock(void)
{
	LOCKED(&sched_spinlock) {
		z_sched_lock();
	}
}
    3fae:	4770      	bx	lr
    3fb0:	20000eec 	.word	0x20000eec

00003fb4 <z_priq_dumb_remove>:
}

void z_priq_dumb_remove(sys_dlist_t *pq, struct k_thread *thread)
{
#if defined(CONFIG_SWAP_NONATOMIC) && defined(CONFIG_SCHED_DUMB)
	if (pq == &_kernel.ready_q.runq && thread == _current &&
    3fb4:	4b09      	ldr	r3, [pc, #36]	; (3fdc <z_priq_dumb_remove+0x28>)
    3fb6:	f103 0228 	add.w	r2, r3, #40	; 0x28
    3fba:	4282      	cmp	r2, r0
    3fbc:	d105      	bne.n	3fca <z_priq_dumb_remove+0x16>
    3fbe:	689b      	ldr	r3, [r3, #8]
    3fc0:	428b      	cmp	r3, r1
    3fc2:	d102      	bne.n	3fca <z_priq_dumb_remove+0x16>
    3fc4:	7b4b      	ldrb	r3, [r1, #13]
    3fc6:	06db      	lsls	r3, r3, #27
    3fc8:	d106      	bne.n	3fd8 <z_priq_dumb_remove+0x24>
 * @return N/A
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	node->prev->next = node->next;
    3fca:	e9d1 3200 	ldrd	r3, r2, [r1]
    3fce:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    3fd0:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    3fd2:	2300      	movs	r3, #0
	node->prev = NULL;
    3fd4:	e9c1 3300 	strd	r3, r3, [r1]
#endif

	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));

	sys_dlist_remove(&thread->base.qnode_dlist);
}
    3fd8:	4770      	bx	lr
    3fda:	bf00      	nop
    3fdc:	20000eec 	.word	0x20000eec

00003fe0 <update_cache>:
{
    3fe0:	b570      	push	{r4, r5, r6, lr}
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    3fe2:	4c10      	ldr	r4, [pc, #64]	; (4024 <update_cache+0x44>)
{
    3fe4:	4606      	mov	r6, r0
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    3fe6:	f104 0028 	add.w	r0, r4, #40	; 0x28
    3fea:	f002 fc7c 	bl	68e6 <z_priq_dumb_best>
	if (_current->base.thread_state & _THREAD_ABORTING) {
    3fee:	68a3      	ldr	r3, [r4, #8]
    3ff0:	7b59      	ldrb	r1, [r3, #13]
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    3ff2:	4605      	mov	r5, r0
	if (_current->base.thread_state & _THREAD_ABORTING) {
    3ff4:	0688      	lsls	r0, r1, #26
		_current->base.thread_state |= _THREAD_DEAD;
    3ff6:	bf44      	itt	mi
    3ff8:	f041 0108 	orrmi.w	r1, r1, #8
    3ffc:	7359      	strbmi	r1, [r3, #13]
	return thread ? thread : _current_cpu->idle_thread;
    3ffe:	b905      	cbnz	r5, 4002 <update_cache+0x22>
    4000:	68e5      	ldr	r5, [r4, #12]
	if (preempt_ok != 0) {
    4002:	b94e      	cbnz	r6, 4018 <update_cache+0x38>
	if (z_is_thread_prevented_from_running(_current)) {
    4004:	7b5a      	ldrb	r2, [r3, #13]
    4006:	06d2      	lsls	r2, r2, #27
    4008:	d106      	bne.n	4018 <update_cache+0x38>
	if (IS_ENABLED(CONFIG_SWAP_NONATOMIC)
    400a:	69aa      	ldr	r2, [r5, #24]
    400c:	b922      	cbnz	r2, 4018 <update_cache+0x38>
	if (is_preempt(_current) || is_metairq(thread)) {
    400e:	89da      	ldrh	r2, [r3, #14]
    4010:	2a7f      	cmp	r2, #127	; 0x7f
    4012:	d901      	bls.n	4018 <update_cache+0x38>
		_kernel.ready_q.cache = _current;
    4014:	6263      	str	r3, [r4, #36]	; 0x24
}
    4016:	bd70      	pop	{r4, r5, r6, pc}
		if (thread != _current) {
    4018:	42ab      	cmp	r3, r5
    401a:	d001      	beq.n	4020 <update_cache+0x40>
			z_reset_time_slice();
    401c:	f7ff ff74 	bl	3f08 <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
    4020:	6265      	str	r5, [r4, #36]	; 0x24
}
    4022:	e7f8      	b.n	4016 <update_cache+0x36>
    4024:	20000eec 	.word	0x20000eec

00004028 <k_sched_unlock>:
{
    4028:	b510      	push	{r4, lr}
	__asm__ volatile(
    402a:	f04f 0320 	mov.w	r3, #32
    402e:	f3ef 8411 	mrs	r4, BASEPRI
    4032:	f383 8811 	msr	BASEPRI, r3
    4036:	f3bf 8f6f 	isb	sy
		++_current->base.sched_locked;
    403a:	4b09      	ldr	r3, [pc, #36]	; (4060 <k_sched_unlock+0x38>)
    403c:	689a      	ldr	r2, [r3, #8]
    403e:	7bd3      	ldrb	r3, [r2, #15]
    4040:	3301      	adds	r3, #1
    4042:	73d3      	strb	r3, [r2, #15]
		update_cache(0);
    4044:	2000      	movs	r0, #0
    4046:	f7ff ffcb 	bl	3fe0 <update_cache>
	__asm__ volatile(
    404a:	f384 8811 	msr	BASEPRI, r4
    404e:	f3bf 8f6f 	isb	sy
    4052:	f002 fbf3 	bl	683c <arch_is_user_context>
}
    4056:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule_unlocked();
    405a:	f002 bc1d 	b.w	6898 <z_reschedule_unlocked>
    405e:	bf00      	nop
    4060:	20000eec 	.word	0x20000eec

00004064 <ready_thread>:
{
    4064:	b470      	push	{r4, r5, r6}
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    4066:	7b43      	ldrb	r3, [r0, #13]
    4068:	06db      	lsls	r3, r3, #27
    406a:	d12a      	bne.n	40c2 <ready_thread+0x5e>

int z_abort_timeout(struct _timeout *to);

static inline bool z_is_inactive_timeout(struct _timeout *t)
{
	return !sys_dnode_is_linked(&t->node);
    406c:	6983      	ldr	r3, [r0, #24]
	if (z_is_thread_ready(thread)) {
    406e:	bb43      	cbnz	r3, 40c2 <ready_thread+0x5e>
	return list->head == list;
    4070:	4a15      	ldr	r2, [pc, #84]	; (40c8 <ready_thread+0x64>)
    4072:	4611      	mov	r1, r2
    4074:	f851 4f28 	ldr.w	r4, [r1, #40]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4078:	428c      	cmp	r4, r1
    407a:	bf18      	it	ne
    407c:	4623      	movne	r3, r4
    407e:	2b00      	cmp	r3, #0
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    4080:	6ad4      	ldr	r4, [r2, #44]	; 0x2c
    4082:	bf38      	it	cc
    4084:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    4086:	b1b3      	cbz	r3, 40b6 <ready_thread+0x52>
	if (thread_1->base.prio < thread_2->base.prio) {
    4088:	f990 600e 	ldrsb.w	r6, [r0, #14]
    408c:	f993 500e 	ldrsb.w	r5, [r3, #14]
    4090:	42ae      	cmp	r6, r5
    4092:	db03      	blt.n	409c <ready_thread+0x38>
	return (node == list->tail) ? NULL : node->next;
    4094:	42a3      	cmp	r3, r4
    4096:	d00e      	beq.n	40b6 <ready_thread+0x52>
    4098:	681b      	ldr	r3, [r3, #0]
    409a:	e7f4      	b.n	4086 <ready_thread+0x22>
	node->prev = successor->prev;
    409c:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    409e:	e9c0 3200 	strd	r3, r2, [r0]
	successor->prev->next = node;
    40a2:	6010      	str	r0, [r2, #0]
	successor->prev = node;
    40a4:	6058      	str	r0, [r3, #4]
	thread->base.thread_state |= states;
    40a6:	7b43      	ldrb	r3, [r0, #13]
    40a8:	f063 037f 	orn	r3, r3, #127	; 0x7f
    40ac:	7343      	strb	r3, [r0, #13]
}
    40ae:	bc70      	pop	{r4, r5, r6}
		update_cache(0);
    40b0:	2000      	movs	r0, #0
    40b2:	f7ff bf95 	b.w	3fe0 <update_cache>
	node->prev = list->tail;
    40b6:	e9c0 1400 	strd	r1, r4, [r0]
	list->tail->next = node;
    40ba:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    40bc:	6018      	str	r0, [r3, #0]
	list->tail = node;
    40be:	62d0      	str	r0, [r2, #44]	; 0x2c
}
    40c0:	e7f1      	b.n	40a6 <ready_thread+0x42>
}
    40c2:	bc70      	pop	{r4, r5, r6}
    40c4:	4770      	bx	lr
    40c6:	bf00      	nop
    40c8:	20000eec 	.word	0x20000eec

000040cc <z_sched_start>:
{
    40cc:	b510      	push	{r4, lr}
	__asm__ volatile(
    40ce:	f04f 0220 	mov.w	r2, #32
    40d2:	f3ef 8411 	mrs	r4, BASEPRI
    40d6:	f382 8811 	msr	BASEPRI, r2
    40da:	f3bf 8f6f 	isb	sy
	if (z_has_thread_started(thread)) {
    40de:	7b42      	ldrb	r2, [r0, #13]
    40e0:	0751      	lsls	r1, r2, #29
    40e2:	d404      	bmi.n	40ee <z_sched_start+0x22>
	__asm__ volatile(
    40e4:	f384 8811 	msr	BASEPRI, r4
    40e8:	f3bf 8f6f 	isb	sy
}
    40ec:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_PRESTART;
    40ee:	f022 0204 	bic.w	r2, r2, #4
    40f2:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
    40f4:	f7ff ffb6 	bl	4064 <ready_thread>
	z_reschedule(&sched_spinlock, key);
    40f8:	4621      	mov	r1, r4
    40fa:	4802      	ldr	r0, [pc, #8]	; (4104 <z_sched_start+0x38>)
}
    40fc:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    4100:	f002 bbb3 	b.w	686a <z_reschedule>
    4104:	20001347 	.word	0x20001347

00004108 <z_impl_k_thread_resume>:
{
    4108:	b510      	push	{r4, lr}
	__asm__ volatile(
    410a:	f04f 0220 	mov.w	r2, #32
    410e:	f3ef 8411 	mrs	r4, BASEPRI
    4112:	f382 8811 	msr	BASEPRI, r2
    4116:	f3bf 8f6f 	isb	sy
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    411a:	7b42      	ldrb	r2, [r0, #13]
    411c:	f022 0210 	bic.w	r2, r2, #16
    4120:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
    4122:	f7ff ff9f 	bl	4064 <ready_thread>
	z_reschedule(&sched_spinlock, key);
    4126:	4621      	mov	r1, r4
    4128:	4802      	ldr	r0, [pc, #8]	; (4134 <z_impl_k_thread_resume+0x2c>)
}
    412a:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    412e:	f002 bb9c 	b.w	686a <z_reschedule>
    4132:	bf00      	nop
    4134:	20001347 	.word	0x20001347

00004138 <z_mrsh_k_thread_resume>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_resume(k_tid_t thread);
uintptr_t z_mrsh_k_thread_resume(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4138:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    413a:	4d0e      	ldr	r5, [pc, #56]	; (4174 <z_mrsh_k_thread_resume+0x3c>)
    413c:	9a06      	ldr	r2, [sp, #24]
    413e:	68ab      	ldr	r3, [r5, #8]
    4140:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4144:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    4146:	f7fb ffc9 	bl	dc <z_object_find>
    414a:	2200      	movs	r2, #0
    414c:	2109      	movs	r1, #9
    414e:	f001 f9ff 	bl	5550 <z_object_validate>
    4152:	4604      	mov	r4, r0
    4154:	b130      	cbz	r0, 4164 <z_mrsh_k_thread_resume+0x2c>
    4156:	f002 fb71 	bl	683c <arch_is_user_context>
    415a:	68ab      	ldr	r3, [r5, #8]
    415c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4160:	f001 ffba 	bl	60d8 <arch_syscall_oops>
	z_impl_k_thread_resume(thread);
    4164:	4630      	mov	r0, r6
    4166:	f7ff ffcf 	bl	4108 <z_impl_k_thread_resume>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_resume(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    416a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    416c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    416e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4172:	bd70      	pop	{r4, r5, r6, pc}
    4174:	20000eec 	.word	0x20000eec

00004178 <z_move_thread_to_end_of_prio_q>:
{
    4178:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    417a:	4601      	mov	r1, r0
    417c:	f04f 0320 	mov.w	r3, #32
    4180:	f3ef 8411 	mrs	r4, BASEPRI
    4184:	f383 8811 	msr	BASEPRI, r3
    4188:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    418c:	f990 300d 	ldrsb.w	r3, [r0, #13]
    4190:	2b00      	cmp	r3, #0
    4192:	da02      	bge.n	419a <z_move_thread_to_end_of_prio_q+0x22>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    4194:	4819      	ldr	r0, [pc, #100]	; (41fc <z_move_thread_to_end_of_prio_q+0x84>)
    4196:	f7ff ff0d 	bl	3fb4 <z_priq_dumb_remove>
	return list->head == list;
    419a:	4a19      	ldr	r2, [pc, #100]	; (4200 <z_move_thread_to_end_of_prio_q+0x88>)
    419c:	4610      	mov	r0, r2
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    419e:	6ad5      	ldr	r5, [r2, #44]	; 0x2c
	return list->head == list;
    41a0:	f850 3f28 	ldr.w	r3, [r0, #40]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    41a4:	4283      	cmp	r3, r0
    41a6:	bf08      	it	eq
    41a8:	2300      	moveq	r3, #0
    41aa:	2b00      	cmp	r3, #0
    41ac:	bf38      	it	cc
    41ae:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    41b0:	b1eb      	cbz	r3, 41ee <z_move_thread_to_end_of_prio_q+0x76>
	if (thread_1->base.prio < thread_2->base.prio) {
    41b2:	f991 700e 	ldrsb.w	r7, [r1, #14]
    41b6:	f993 600e 	ldrsb.w	r6, [r3, #14]
    41ba:	42b7      	cmp	r7, r6
    41bc:	db03      	blt.n	41c6 <z_move_thread_to_end_of_prio_q+0x4e>
	return (node == list->tail) ? NULL : node->next;
    41be:	429d      	cmp	r5, r3
    41c0:	d015      	beq.n	41ee <z_move_thread_to_end_of_prio_q+0x76>
    41c2:	681b      	ldr	r3, [r3, #0]
    41c4:	e7f4      	b.n	41b0 <z_move_thread_to_end_of_prio_q+0x38>
	node->prev = successor->prev;
    41c6:	6858      	ldr	r0, [r3, #4]
	node->next = successor;
    41c8:	e9c1 3000 	strd	r3, r0, [r1]
	successor->prev->next = node;
    41cc:	6001      	str	r1, [r0, #0]
	successor->prev = node;
    41ce:	6059      	str	r1, [r3, #4]
	thread->base.thread_state |= states;
    41d0:	7b4b      	ldrb	r3, [r1, #13]
		update_cache(thread == _current);
    41d2:	6890      	ldr	r0, [r2, #8]
    41d4:	f063 037f 	orn	r3, r3, #127	; 0x7f
    41d8:	734b      	strb	r3, [r1, #13]
    41da:	1a43      	subs	r3, r0, r1
    41dc:	4258      	negs	r0, r3
    41de:	4158      	adcs	r0, r3
    41e0:	f7ff fefe 	bl	3fe0 <update_cache>
	__asm__ volatile(
    41e4:	f384 8811 	msr	BASEPRI, r4
    41e8:	f3bf 8f6f 	isb	sy
}
    41ec:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	node->prev = list->tail;
    41ee:	e9c1 0500 	strd	r0, r5, [r1]
	list->tail->next = node;
    41f2:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    41f4:	6019      	str	r1, [r3, #0]
	list->tail = node;
    41f6:	62d1      	str	r1, [r2, #44]	; 0x2c
}
    41f8:	e7ea      	b.n	41d0 <z_move_thread_to_end_of_prio_q+0x58>
    41fa:	bf00      	nop
    41fc:	20000f14 	.word	0x20000f14
    4200:	20000eec 	.word	0x20000eec

00004204 <z_time_slice>:
{
    4204:	b538      	push	{r3, r4, r5, lr}
	if (pending_current == _current) {
    4206:	4a15      	ldr	r2, [pc, #84]	; (425c <z_time_slice+0x58>)
    4208:	4b15      	ldr	r3, [pc, #84]	; (4260 <z_time_slice+0x5c>)
    420a:	6814      	ldr	r4, [r2, #0]
{
    420c:	4601      	mov	r1, r0
	if (pending_current == _current) {
    420e:	6898      	ldr	r0, [r3, #8]
    4210:	42a0      	cmp	r0, r4
    4212:	461c      	mov	r4, r3
    4214:	d103      	bne.n	421e <z_time_slice+0x1a>
}
    4216:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
			z_reset_time_slice();
    421a:	f7ff be75 	b.w	3f08 <z_reset_time_slice>
	pending_current = NULL;
    421e:	2500      	movs	r5, #0
    4220:	6015      	str	r5, [r2, #0]
	if (slice_time && sliceable(_current)) {
    4222:	4a10      	ldr	r2, [pc, #64]	; (4264 <z_time_slice+0x60>)
    4224:	6812      	ldr	r2, [r2, #0]
    4226:	b1b2      	cbz	r2, 4256 <z_time_slice+0x52>
		&& !z_is_thread_timeout_active(thread);
    4228:	89c2      	ldrh	r2, [r0, #14]
    422a:	2a7f      	cmp	r2, #127	; 0x7f
    422c:	d813      	bhi.n	4256 <z_time_slice+0x52>
		&& !z_is_prio_higher(thread->base.prio, slice_max_prio)
    422e:	4a0e      	ldr	r2, [pc, #56]	; (4268 <z_time_slice+0x64>)
    4230:	f990 500e 	ldrsb.w	r5, [r0, #14]
    4234:	6812      	ldr	r2, [r2, #0]
    4236:	4295      	cmp	r5, r2
    4238:	db0d      	blt.n	4256 <z_time_slice+0x52>
		&& !z_is_idle_thread_object(thread)
    423a:	4a0c      	ldr	r2, [pc, #48]	; (426c <z_time_slice+0x68>)
    423c:	4290      	cmp	r0, r2
    423e:	d00a      	beq.n	4256 <z_time_slice+0x52>
		&& !z_is_thread_timeout_active(thread);
    4240:	6982      	ldr	r2, [r0, #24]
    4242:	b942      	cbnz	r2, 4256 <z_time_slice+0x52>
		if (ticks >= _current_cpu->slice_ticks) {
    4244:	691a      	ldr	r2, [r3, #16]
    4246:	428a      	cmp	r2, r1
    4248:	dc02      	bgt.n	4250 <z_time_slice+0x4c>
			z_move_thread_to_end_of_prio_q(_current);
    424a:	f7ff ff95 	bl	4178 <z_move_thread_to_end_of_prio_q>
    424e:	e7e2      	b.n	4216 <z_time_slice+0x12>
			_current_cpu->slice_ticks -= ticks;
    4250:	1a52      	subs	r2, r2, r1
    4252:	611a      	str	r2, [r3, #16]
}
    4254:	bd38      	pop	{r3, r4, r5, pc}
		_current_cpu->slice_ticks = 0;
    4256:	2300      	movs	r3, #0
    4258:	6123      	str	r3, [r4, #16]
    425a:	e7fb      	b.n	4254 <z_time_slice+0x50>
    425c:	20000f1c 	.word	0x20000f1c
    4260:	20000eec 	.word	0x20000eec
    4264:	20000f24 	.word	0x20000f24
    4268:	20000f20 	.word	0x20000f20
    426c:	20000280 	.word	0x20000280

00004270 <z_impl_k_thread_suspend>:
{
    4270:	b570      	push	{r4, r5, r6, lr}
    4272:	4604      	mov	r4, r0
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
    4274:	3018      	adds	r0, #24
    4276:	f002 fcc3 	bl	6c00 <z_abort_timeout>
	__asm__ volatile(
    427a:	f04f 0320 	mov.w	r3, #32
    427e:	f3ef 8611 	mrs	r6, BASEPRI
    4282:	f383 8811 	msr	BASEPRI, r3
    4286:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    428a:	f994 300d 	ldrsb.w	r3, [r4, #13]
    428e:	2b00      	cmp	r3, #0
    4290:	da07      	bge.n	42a2 <z_impl_k_thread_suspend+0x32>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    4292:	480f      	ldr	r0, [pc, #60]	; (42d0 <z_impl_k_thread_suspend+0x60>)
    4294:	4621      	mov	r1, r4
    4296:	f7ff fe8d 	bl	3fb4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    429a:	7b63      	ldrb	r3, [r4, #13]
    429c:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    42a0:	7363      	strb	r3, [r4, #13]
		update_cache(thread == _current);
    42a2:	4d0c      	ldr	r5, [pc, #48]	; (42d4 <z_impl_k_thread_suspend+0x64>)
	thread->base.thread_state |= _THREAD_SUSPENDED;
    42a4:	7b63      	ldrb	r3, [r4, #13]
    42a6:	68a8      	ldr	r0, [r5, #8]
    42a8:	f043 0310 	orr.w	r3, r3, #16
    42ac:	7363      	strb	r3, [r4, #13]
    42ae:	1b03      	subs	r3, r0, r4
    42b0:	4258      	negs	r0, r3
    42b2:	4158      	adcs	r0, r3
    42b4:	f7ff fe94 	bl	3fe0 <update_cache>
	__asm__ volatile(
    42b8:	f386 8811 	msr	BASEPRI, r6
    42bc:	f3bf 8f6f 	isb	sy
	if (thread == _current) {
    42c0:	68ab      	ldr	r3, [r5, #8]
    42c2:	42a3      	cmp	r3, r4
    42c4:	d103      	bne.n	42ce <z_impl_k_thread_suspend+0x5e>
}
    42c6:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule_unlocked();
    42ca:	f002 bae5 	b.w	6898 <z_reschedule_unlocked>
}
    42ce:	bd70      	pop	{r4, r5, r6, pc}
    42d0:	20000f14 	.word	0x20000f14
    42d4:	20000eec 	.word	0x20000eec

000042d8 <z_mrsh_k_thread_suspend>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_suspend(k_tid_t thread);
uintptr_t z_mrsh_k_thread_suspend(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    42d8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    42da:	4d0e      	ldr	r5, [pc, #56]	; (4314 <z_mrsh_k_thread_suspend+0x3c>)
    42dc:	9a06      	ldr	r2, [sp, #24]
    42de:	68ab      	ldr	r3, [r5, #8]
    42e0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    42e4:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    42e6:	f7fb fef9 	bl	dc <z_object_find>
    42ea:	2200      	movs	r2, #0
    42ec:	2109      	movs	r1, #9
    42ee:	f001 f92f 	bl	5550 <z_object_validate>
    42f2:	4604      	mov	r4, r0
    42f4:	b130      	cbz	r0, 4304 <z_mrsh_k_thread_suspend+0x2c>
    42f6:	f002 faa1 	bl	683c <arch_is_user_context>
    42fa:	68ab      	ldr	r3, [r5, #8]
    42fc:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4300:	f001 feea 	bl	60d8 <arch_syscall_oops>
	z_impl_k_thread_suspend(thread);
    4304:	4630      	mov	r0, r6
    4306:	f7ff ffb3 	bl	4270 <z_impl_k_thread_suspend>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_suspend(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    430a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    430c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    430e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4312:	bd70      	pop	{r4, r5, r6, pc}
    4314:	20000eec 	.word	0x20000eec

00004318 <z_thread_single_abort>:
	if (thread->fn_abort != NULL) {
    4318:	6e03      	ldr	r3, [r0, #96]	; 0x60
{
    431a:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    431e:	4604      	mov	r4, r0
	if (thread->fn_abort != NULL) {
    4320:	b103      	cbz	r3, 4324 <z_thread_single_abort+0xc>
		thread->fn_abort();
    4322:	4798      	blx	r3
    4324:	f104 0018 	add.w	r0, r4, #24
    4328:	f002 fc6a 	bl	6c00 <z_abort_timeout>
	__asm__ volatile(
    432c:	f04f 0320 	mov.w	r3, #32
    4330:	f3ef 8611 	mrs	r6, BASEPRI
    4334:	f383 8811 	msr	BASEPRI, r3
    4338:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    433c:	7b63      	ldrb	r3, [r4, #13]
    433e:	06d8      	lsls	r0, r3, #27
    4340:	d12d      	bne.n	439e <z_thread_single_abort+0x86>
		if (z_is_thread_ready(thread)) {
    4342:	69a2      	ldr	r2, [r4, #24]
    4344:	bb5a      	cbnz	r2, 439e <z_thread_single_abort+0x86>
			if (z_is_thread_queued(thread)) {
    4346:	0619      	lsls	r1, r3, #24
    4348:	d507      	bpl.n	435a <z_thread_single_abort+0x42>
				_priq_run_remove(&_kernel.ready_q.runq,
    434a:	4825      	ldr	r0, [pc, #148]	; (43e0 <z_thread_single_abort+0xc8>)
    434c:	4621      	mov	r1, r4
    434e:	f7ff fe31 	bl	3fb4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    4352:	7b63      	ldrb	r3, [r4, #13]
    4354:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    4358:	7363      	strb	r3, [r4, #13]
			update_cache(thread == _current);
    435a:	4b22      	ldr	r3, [pc, #136]	; (43e4 <z_thread_single_abort+0xcc>)
    435c:	6898      	ldr	r0, [r3, #8]
    435e:	1b02      	subs	r2, r0, r4
    4360:	4250      	negs	r0, r2
    4362:	4150      	adcs	r0, r2
    4364:	f7ff fe3c 	bl	3fe0 <update_cache>
		thread->base.thread_state |= mask;
    4368:	7b63      	ldrb	r3, [r4, #13]
		z_object_uninit(thread->stack_obj);
    436a:	f8d4 0080 	ldr.w	r0, [r4, #128]	; 0x80
		thread->base.thread_state |= mask;
    436e:	f043 0308 	orr.w	r3, r3, #8
    4372:	7363      	strb	r3, [r4, #13]
		z_object_uninit(thread->stack_obj);
    4374:	f002 fdeb 	bl	6f4e <z_object_uninit>
		z_object_uninit(thread);
    4378:	4620      	mov	r0, r4
    437a:	f002 fde8 	bl	6f4e <z_object_uninit>
		z_thread_perms_all_clear(thread);
    437e:	4620      	mov	r0, r4
    4380:	f001 f8d8 	bl	5534 <z_thread_perms_all_clear>
	sys_dlist_init(&w->waitq);
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
    4384:	f104 0830 	add.w	r8, r4, #48	; 0x30
			waiter->base.pended_on = NULL;
    4388:	2700      	movs	r7, #0
	return list->head == list;
    438a:	6b25      	ldr	r5, [r4, #48]	; 0x30
	return sys_dlist_is_empty(list) ? NULL : list->head;
    438c:	4545      	cmp	r5, r8
    438e:	d000      	beq.n	4392 <z_thread_single_abort+0x7a>
		while ((waiter = z_waitq_head(&thread->base.join_waiters)) !=
    4390:	b995      	cbnz	r5, 43b8 <z_thread_single_abort+0xa0>
	__asm__ volatile(
    4392:	f386 8811 	msr	BASEPRI, r6
    4396:	f3bf 8f6f 	isb	sy
}
    439a:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			if (z_is_thread_pending(thread)) {
    439e:	079b      	lsls	r3, r3, #30
    43a0:	d5e2      	bpl.n	4368 <z_thread_single_abort+0x50>
				_priq_wait_remove(&pended_on(thread)->waitq,
    43a2:	68a0      	ldr	r0, [r4, #8]
    43a4:	4621      	mov	r1, r4
    43a6:	f7ff fe05 	bl	3fb4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    43aa:	7b63      	ldrb	r3, [r4, #13]
    43ac:	f023 0302 	bic.w	r3, r3, #2
    43b0:	7363      	strb	r3, [r4, #13]
				thread->base.pended_on = NULL;
    43b2:	2300      	movs	r3, #0
    43b4:	60a3      	str	r3, [r4, #8]
    43b6:	e7d7      	b.n	4368 <z_thread_single_abort+0x50>
    43b8:	f105 0018 	add.w	r0, r5, #24
    43bc:	f002 fc20 	bl	6c00 <z_abort_timeout>
			_priq_wait_remove(&pended_on(waiter)->waitq, waiter);
    43c0:	68a8      	ldr	r0, [r5, #8]
    43c2:	4629      	mov	r1, r5
    43c4:	f7ff fdf6 	bl	3fb4 <z_priq_dumb_remove>
    43c8:	7b6b      	ldrb	r3, [r5, #13]
			waiter->base.pended_on = NULL;
    43ca:	60af      	str	r7, [r5, #8]
    43cc:	f023 0302 	bic.w	r3, r3, #2
    43d0:	736b      	strb	r3, [r5, #13]
    43d2:	f8c5 7090 	str.w	r7, [r5, #144]	; 0x90
			ready_thread(waiter);
    43d6:	4628      	mov	r0, r5
    43d8:	f7ff fe44 	bl	4064 <ready_thread>
    43dc:	e7d5      	b.n	438a <z_thread_single_abort+0x72>
    43de:	bf00      	nop
    43e0:	20000f14 	.word	0x20000f14
    43e4:	20000eec 	.word	0x20000eec

000043e8 <unready_thread>:
{
    43e8:	b508      	push	{r3, lr}
	if (z_is_thread_queued(thread)) {
    43ea:	f990 300d 	ldrsb.w	r3, [r0, #13]
    43ee:	2b00      	cmp	r3, #0
{
    43f0:	4601      	mov	r1, r0
	if (z_is_thread_queued(thread)) {
    43f2:	da06      	bge.n	4402 <unready_thread+0x1a>
		_priq_run_remove(&_kernel.ready_q.runq, thread);
    43f4:	4807      	ldr	r0, [pc, #28]	; (4414 <unready_thread+0x2c>)
    43f6:	f7ff fddd 	bl	3fb4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    43fa:	7b4b      	ldrb	r3, [r1, #13]
    43fc:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    4400:	734b      	strb	r3, [r1, #13]
	update_cache(thread == _current);
    4402:	4b05      	ldr	r3, [pc, #20]	; (4418 <unready_thread+0x30>)
    4404:	6898      	ldr	r0, [r3, #8]
    4406:	1a43      	subs	r3, r0, r1
    4408:	4258      	negs	r0, r3
    440a:	4158      	adcs	r0, r3
}
    440c:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	update_cache(thread == _current);
    4410:	f7ff bde6 	b.w	3fe0 <update_cache>
    4414:	20000f14 	.word	0x20000f14
    4418:	20000eec 	.word	0x20000eec

0000441c <z_tick_sleep.part.0>:
	z_impl_k_yield();
}
#include <syscalls/k_yield_mrsh.c>
#endif

static int32_t z_tick_sleep(int32_t ticks)
    441c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    441e:	4605      	mov	r5, r0
#else
	ticks += _TICK_ALIGN;
	timeout = (k_ticks_t) ticks;
#endif

	expected_wakeup_time = ticks + z_tick_get_32();
    4420:	f002 fc3e 	bl	6ca0 <z_tick_get_32>
    4424:	182c      	adds	r4, r5, r0
	__asm__ volatile(
    4426:	f04f 0320 	mov.w	r3, #32
    442a:	f3ef 8711 	mrs	r7, BASEPRI
    442e:	f383 8811 	msr	BASEPRI, r3
    4432:	f3bf 8f6f 	isb	sy
	 */
	struct k_spinlock local_lock = {};
	k_spinlock_key_t key = k_spin_lock(&local_lock);

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    4436:	4e0d      	ldr	r6, [pc, #52]	; (446c <z_tick_sleep.part.0+0x50>)
    4438:	4b0d      	ldr	r3, [pc, #52]	; (4470 <z_tick_sleep.part.0+0x54>)
    443a:	68b0      	ldr	r0, [r6, #8]
    443c:	6018      	str	r0, [r3, #0]
#endif
	z_remove_thread_from_ready_q(_current);
    443e:	f002 fa97 	bl	6970 <z_remove_thread_from_ready_q>
	z_add_thread_timeout(_current, timeout);
    4442:	68b0      	ldr	r0, [r6, #8]
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    4444:	490b      	ldr	r1, [pc, #44]	; (4474 <z_tick_sleep.part.0+0x58>)
    4446:	462a      	mov	r2, r5
    4448:	17eb      	asrs	r3, r5, #31
    444a:	3018      	adds	r0, #24
    444c:	f000 feac 	bl	51a8 <z_add_timeout>
	z_mark_thread_as_suspended(_current);
    4450:	68b2      	ldr	r2, [r6, #8]
	thread->base.thread_state |= _THREAD_SUSPENDED;
    4452:	7b53      	ldrb	r3, [r2, #13]
    4454:	f043 0310 	orr.w	r3, r3, #16
    4458:	7353      	strb	r3, [r2, #13]
	ret = arch_swap(key);
    445a:	4638      	mov	r0, r7
    445c:	f7fc ffd2 	bl	1404 <arch_swap>

	(void)z_swap(&local_lock, key);

	__ASSERT(!z_is_thread_state_set(_current, _THREAD_SUSPENDED), "");

	ticks = expected_wakeup_time - z_tick_get_32();
    4460:	f002 fc1e 	bl	6ca0 <z_tick_get_32>
    4464:	1a20      	subs	r0, r4, r0
		return ticks;
	}
#endif

	return 0;
}
    4466:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    446a:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    446c:	20000eec 	.word	0x20000eec
    4470:	20000f1c 	.word	0x20000f1c
    4474:	0000691b 	.word	0x0000691b

00004478 <pend>:
{
    4478:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    447c:	4606      	mov	r6, r0
    447e:	4614      	mov	r4, r2
    4480:	461d      	mov	r5, r3
    4482:	f04f 0320 	mov.w	r3, #32
    4486:	f3ef 8711 	mrs	r7, BASEPRI
    448a:	f383 8811 	msr	BASEPRI, r3
    448e:	f3bf 8f6f 	isb	sy
		add_to_waitq_locked(thread, wait_q);
    4492:	f002 fa7d 	bl	6990 <add_to_waitq_locked>
	__asm__ volatile(
    4496:	f387 8811 	msr	BASEPRI, r7
    449a:	f3bf 8f6f 	isb	sy
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    449e:	1c6b      	adds	r3, r5, #1
    44a0:	bf08      	it	eq
    44a2:	f1b4 3fff 	cmpeq.w	r4, #4294967295	; 0xffffffff
    44a6:	d008      	beq.n	44ba <pend+0x42>
    44a8:	4622      	mov	r2, r4
    44aa:	462b      	mov	r3, r5
    44ac:	f106 0018 	add.w	r0, r6, #24
    44b0:	4903      	ldr	r1, [pc, #12]	; (44c0 <pend+0x48>)
}
    44b2:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    44b6:	f000 be77 	b.w	51a8 <z_add_timeout>
    44ba:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    44be:	bf00      	nop
    44c0:	0000691b 	.word	0x0000691b

000044c4 <z_pend_curr>:
{
    44c4:	b510      	push	{r4, lr}
	pending_current = _current;
    44c6:	4b07      	ldr	r3, [pc, #28]	; (44e4 <z_pend_curr+0x20>)
    44c8:	6898      	ldr	r0, [r3, #8]
    44ca:	4b07      	ldr	r3, [pc, #28]	; (44e8 <z_pend_curr+0x24>)
{
    44cc:	460c      	mov	r4, r1
	pending_current = _current;
    44ce:	6018      	str	r0, [r3, #0]
{
    44d0:	4611      	mov	r1, r2
	pend(_current, wait_q, timeout);
    44d2:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    44d6:	f7ff ffcf 	bl	4478 <pend>
    44da:	4620      	mov	r0, r4
}
    44dc:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    44e0:	f7fc bf90 	b.w	1404 <arch_swap>
    44e4:	20000eec 	.word	0x20000eec
    44e8:	20000f1c 	.word	0x20000f1c

000044ec <z_set_prio>:
{
    44ec:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    44f0:	4604      	mov	r4, r0
	__asm__ volatile(
    44f2:	f04f 0320 	mov.w	r3, #32
    44f6:	f3ef 8811 	mrs	r8, BASEPRI
    44fa:	f383 8811 	msr	BASEPRI, r3
    44fe:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    4502:	7b43      	ldrb	r3, [r0, #13]
    4504:	06db      	lsls	r3, r3, #27
    4506:	b24e      	sxtb	r6, r1
    4508:	d12e      	bne.n	4568 <z_set_prio+0x7c>
	return !sys_dnode_is_linked(&t->node);
    450a:	6985      	ldr	r5, [r0, #24]
		if (need_sched) {
    450c:	bb65      	cbnz	r5, 4568 <z_set_prio+0x7c>
				_priq_run_remove(&_kernel.ready_q.runq, thread);
    450e:	4f18      	ldr	r7, [pc, #96]	; (4570 <z_set_prio+0x84>)
    4510:	4621      	mov	r1, r4
    4512:	f107 0028 	add.w	r0, r7, #40	; 0x28
    4516:	f7ff fd4d 	bl	3fb4 <z_priq_dumb_remove>
	return list->head == list;
    451a:	6abb      	ldr	r3, [r7, #40]	; 0x28
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    451c:	6afa      	ldr	r2, [r7, #44]	; 0x2c
				thread->base.prio = prio;
    451e:	73a6      	strb	r6, [r4, #14]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4520:	4283      	cmp	r3, r0
    4522:	bf18      	it	ne
    4524:	461d      	movne	r5, r3
    4526:	2d00      	cmp	r5, #0
    4528:	bf38      	it	cc
    452a:	2500      	movcc	r5, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    452c:	b1b5      	cbz	r5, 455c <z_set_prio+0x70>
	if (thread_1->base.prio < thread_2->base.prio) {
    452e:	f995 100e 	ldrsb.w	r1, [r5, #14]
    4532:	42b1      	cmp	r1, r6
    4534:	dc03      	bgt.n	453e <z_set_prio+0x52>
	return (node == list->tail) ? NULL : node->next;
    4536:	42aa      	cmp	r2, r5
    4538:	d010      	beq.n	455c <z_set_prio+0x70>
    453a:	682d      	ldr	r5, [r5, #0]
    453c:	e7f6      	b.n	452c <z_set_prio+0x40>
	node->prev = successor->prev;
    453e:	686a      	ldr	r2, [r5, #4]
	node->next = successor;
    4540:	e9c4 5200 	strd	r5, r2, [r4]
	successor->prev->next = node;
    4544:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    4546:	606c      	str	r4, [r5, #4]
			update_cache(1);
    4548:	2001      	movs	r0, #1
    454a:	f7ff fd49 	bl	3fe0 <update_cache>
    454e:	2001      	movs	r0, #1
	__asm__ volatile(
    4550:	f388 8811 	msr	BASEPRI, r8
    4554:	f3bf 8f6f 	isb	sy
}
    4558:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	node->prev = list->tail;
    455c:	e9c4 0200 	strd	r0, r2, [r4]
	list->tail->next = node;
    4560:	6afb      	ldr	r3, [r7, #44]	; 0x2c
    4562:	601c      	str	r4, [r3, #0]
	list->tail = node;
    4564:	62fc      	str	r4, [r7, #44]	; 0x2c
}
    4566:	e7ef      	b.n	4548 <z_set_prio+0x5c>
			thread->base.prio = prio;
    4568:	73a6      	strb	r6, [r4, #14]
    456a:	2000      	movs	r0, #0
    456c:	e7f0      	b.n	4550 <z_set_prio+0x64>
    456e:	bf00      	nop
    4570:	20000eec 	.word	0x20000eec

00004574 <z_thread_priority_set>:
{
    4574:	b508      	push	{r3, lr}
	bool need_sched = z_set_prio(thread, prio);
    4576:	f7ff ffb9 	bl	44ec <z_set_prio>
	if (need_sched && _current->base.sched_locked == 0) {
    457a:	b138      	cbz	r0, 458c <z_thread_priority_set+0x18>
    457c:	4b04      	ldr	r3, [pc, #16]	; (4590 <z_thread_priority_set+0x1c>)
    457e:	689b      	ldr	r3, [r3, #8]
    4580:	7bdb      	ldrb	r3, [r3, #15]
    4582:	b91b      	cbnz	r3, 458c <z_thread_priority_set+0x18>
}
    4584:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		z_reschedule_unlocked();
    4588:	f002 b986 	b.w	6898 <z_reschedule_unlocked>
}
    458c:	bd08      	pop	{r3, pc}
    458e:	bf00      	nop
    4590:	20000eec 	.word	0x20000eec

00004594 <z_sched_init>:
	list->head = (sys_dnode_t *)list;
    4594:	4b04      	ldr	r3, [pc, #16]	; (45a8 <z_sched_init+0x14>)
	k_sched_time_slice_set(CONFIG_TIMESLICE_SIZE,
    4596:	2100      	movs	r1, #0
    4598:	f103 0228 	add.w	r2, r3, #40	; 0x28
	list->tail = (sys_dnode_t *)list;
    459c:	e9c3 220a 	strd	r2, r2, [r3, #40]	; 0x28
    45a0:	4608      	mov	r0, r1
    45a2:	f7ff bcc7 	b.w	3f34 <k_sched_time_slice_set>
    45a6:	bf00      	nop
    45a8:	20000eec 	.word	0x20000eec

000045ac <z_mrsh_k_thread_priority_get>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_thread_priority_get(k_tid_t thread);
uintptr_t z_mrsh_k_thread_priority_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    45ac:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    45ae:	4c0d      	ldr	r4, [pc, #52]	; (45e4 <z_mrsh_k_thread_priority_get+0x38>)
    45b0:	9a06      	ldr	r2, [sp, #24]
    45b2:	68a3      	ldr	r3, [r4, #8]
    45b4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    45b8:	4605      	mov	r5, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    45ba:	f7fb fd8f 	bl	dc <z_object_find>
    45be:	2200      	movs	r2, #0
    45c0:	2109      	movs	r1, #9
    45c2:	f000 ffc5 	bl	5550 <z_object_validate>
    45c6:	4603      	mov	r3, r0
    45c8:	b130      	cbz	r0, 45d8 <z_mrsh_k_thread_priority_get+0x2c>
    45ca:	f002 f937 	bl	683c <arch_is_user_context>
    45ce:	68a3      	ldr	r3, [r4, #8]
    45d0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    45d4:	f001 fd80 	bl	60d8 <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_thread_priority_get(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    45d8:	68a2      	ldr	r2, [r4, #8]
	return thread->base.prio;
    45da:	f995 000e 	ldrsb.w	r0, [r5, #14]
    45de:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    45e2:	bd38      	pop	{r3, r4, r5, pc}
    45e4:	20000eec 	.word	0x20000eec

000045e8 <z_mrsh_k_thread_priority_set>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_priority_set(k_tid_t thread, int prio);
uintptr_t z_mrsh_k_thread_priority_set(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    45e8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    45ea:	4e17      	ldr	r6, [pc, #92]	; (4648 <z_mrsh_k_thread_priority_set+0x60>)
    45ec:	9a08      	ldr	r2, [sp, #32]
    45ee:	68b3      	ldr	r3, [r6, #8]
    45f0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    45f4:	460c      	mov	r4, r1
    45f6:	4607      	mov	r7, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    45f8:	f7fb fd70 	bl	dc <z_object_find>
    45fc:	2200      	movs	r2, #0
    45fe:	2109      	movs	r1, #9
    4600:	f000 ffa6 	bl	5550 <z_object_validate>
    4604:	4632      	mov	r2, r6
    4606:	4605      	mov	r5, r0
    4608:	b188      	cbz	r0, 462e <z_mrsh_k_thread_priority_set+0x46>
    460a:	f002 f917 	bl	683c <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG((int8_t)prio >= thread->base.prio,
    460e:	68b3      	ldr	r3, [r6, #8]
    4610:	e015      	b.n	463e <z_mrsh_k_thread_priority_set+0x56>
    4612:	f997 200e 	ldrsb.w	r2, [r7, #14]
    4616:	b263      	sxtb	r3, r4
    4618:	429a      	cmp	r2, r3
    461a:	dcf6      	bgt.n	460a <z_mrsh_k_thread_priority_set+0x22>
	z_thread_priority_set(thread, prio);
    461c:	4638      	mov	r0, r7
    461e:	4621      	mov	r1, r4
    4620:	f7ff ffa8 	bl	4574 <z_thread_priority_set>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_priority_set(*(k_tid_t*)&arg0, *(int*)&arg1)
;
	_current->syscall_frame = NULL;
    4624:	68b3      	ldr	r3, [r6, #8]
	return 0;
}
    4626:	4628      	mov	r0, r5
	_current->syscall_frame = NULL;
    4628:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
}
    462c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (!z_is_prio_higher_or_equal(prio,
    462e:	2c0e      	cmp	r4, #14
    4630:	dc02      	bgt.n	4638 <z_mrsh_k_thread_priority_set+0x50>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(_is_valid_prio(prio, NULL),
    4632:	f114 0f10 	cmn.w	r4, #16
    4636:	daec      	bge.n	4612 <z_mrsh_k_thread_priority_set+0x2a>
    4638:	f002 f900 	bl	683c <arch_is_user_context>
    463c:	6893      	ldr	r3, [r2, #8]
    463e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4642:	f001 fd49 	bl	60d8 <arch_syscall_oops>
    4646:	bf00      	nop
    4648:	20000eec 	.word	0x20000eec

0000464c <z_impl_k_yield>:
{
    464c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (!z_is_idle_thread_object(_current)) {
    464e:	4c24      	ldr	r4, [pc, #144]	; (46e0 <z_impl_k_yield+0x94>)
    4650:	4b24      	ldr	r3, [pc, #144]	; (46e4 <z_impl_k_yield+0x98>)
    4652:	68a2      	ldr	r2, [r4, #8]
    4654:	429a      	cmp	r2, r3
    4656:	d030      	beq.n	46ba <z_impl_k_yield+0x6e>
	__asm__ volatile(
    4658:	f04f 0320 	mov.w	r3, #32
    465c:	f3ef 8511 	mrs	r5, BASEPRI
    4660:	f383 8811 	msr	BASEPRI, r3
    4664:	f3bf 8f6f 	isb	sy
				_priq_run_remove(&_kernel.ready_q.runq,
    4668:	68a1      	ldr	r1, [r4, #8]
    466a:	f104 0028 	add.w	r0, r4, #40	; 0x28
    466e:	f7ff fca1 	bl	3fb4 <z_priq_dumb_remove>
	return list->head == list;
    4672:	6aa3      	ldr	r3, [r4, #40]	; 0x28
			_priq_run_add(&_kernel.ready_q.runq, _current);
    4674:	68a2      	ldr	r2, [r4, #8]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    4676:	6ae1      	ldr	r1, [r4, #44]	; 0x2c
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4678:	4283      	cmp	r3, r0
    467a:	bf08      	it	eq
    467c:	2300      	moveq	r3, #0
    467e:	2b00      	cmp	r3, #0
    4680:	bf38      	it	cc
    4682:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    4684:	b32b      	cbz	r3, 46d2 <z_impl_k_yield+0x86>
	if (thread_1->base.prio < thread_2->base.prio) {
    4686:	f992 700e 	ldrsb.w	r7, [r2, #14]
    468a:	f993 600e 	ldrsb.w	r6, [r3, #14]
    468e:	42b7      	cmp	r7, r6
    4690:	db03      	blt.n	469a <z_impl_k_yield+0x4e>
	return (node == list->tail) ? NULL : node->next;
    4692:	428b      	cmp	r3, r1
    4694:	d01d      	beq.n	46d2 <z_impl_k_yield+0x86>
    4696:	681b      	ldr	r3, [r3, #0]
    4698:	e7f4      	b.n	4684 <z_impl_k_yield+0x38>
	node->prev = successor->prev;
    469a:	6859      	ldr	r1, [r3, #4]
	node->next = successor;
    469c:	e9c2 3100 	strd	r3, r1, [r2]
	successor->prev->next = node;
    46a0:	600a      	str	r2, [r1, #0]
	successor->prev = node;
    46a2:	605a      	str	r2, [r3, #4]
	thread->base.thread_state |= states;
    46a4:	7b53      	ldrb	r3, [r2, #13]
    46a6:	f063 037f 	orn	r3, r3, #127	; 0x7f
    46aa:	7353      	strb	r3, [r2, #13]
			update_cache(1);
    46ac:	2001      	movs	r0, #1
    46ae:	f7ff fc97 	bl	3fe0 <update_cache>
	__asm__ volatile(
    46b2:	f385 8811 	msr	BASEPRI, r5
    46b6:	f3bf 8f6f 	isb	sy
	__asm__ volatile(
    46ba:	f04f 0320 	mov.w	r3, #32
    46be:	f3ef 8011 	mrs	r0, BASEPRI
    46c2:	f383 8811 	msr	BASEPRI, r3
    46c6:	f3bf 8f6f 	isb	sy
}
    46ca:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    46ce:	f7fc be99 	b.w	1404 <arch_swap>
	node->prev = list->tail;
    46d2:	e9c2 0100 	strd	r0, r1, [r2]
	list->tail->next = node;
    46d6:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
    46d8:	601a      	str	r2, [r3, #0]
	list->tail = node;
    46da:	62e2      	str	r2, [r4, #44]	; 0x2c
}
    46dc:	e7e2      	b.n	46a4 <z_impl_k_yield+0x58>
    46de:	bf00      	nop
    46e0:	20000eec 	.word	0x20000eec
    46e4:	20000280 	.word	0x20000280

000046e8 <z_mrsh_k_yield>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_yield();
uintptr_t z_mrsh_k_yield(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    46e8:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    46ea:	4c06      	ldr	r4, [pc, #24]	; (4704 <z_mrsh_k_yield+0x1c>)
    46ec:	9a04      	ldr	r2, [sp, #16]
    46ee:	68a3      	ldr	r3, [r4, #8]
    46f0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	z_impl_k_yield();
    46f4:	f7ff ffaa 	bl	464c <z_impl_k_yield>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_yield()
;
	_current->syscall_frame = NULL;
    46f8:	68a3      	ldr	r3, [r4, #8]
    46fa:	2000      	movs	r0, #0
    46fc:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4700:	bd10      	pop	{r4, pc}
    4702:	bf00      	nop
    4704:	20000eec 	.word	0x20000eec

00004708 <z_impl_k_sleep>:

int32_t z_impl_k_sleep(k_timeout_t timeout)
{
    4708:	b5d0      	push	{r4, r6, r7, lr}
    470a:	460f      	mov	r7, r1
	k_ticks_t ticks;

	__ASSERT(!arch_is_in_isr(), "");

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    470c:	3701      	adds	r7, #1
    470e:	bf08      	it	eq
    4710:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    4714:	4606      	mov	r6, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    4716:	d106      	bne.n	4726 <z_impl_k_sleep+0x1e>
		k_thread_suspend(_current);
    4718:	4b0c      	ldr	r3, [pc, #48]	; (474c <z_impl_k_sleep+0x44>)
    471a:	6898      	ldr	r0, [r3, #8]
	z_impl_k_thread_suspend(thread);
    471c:	f7ff fda8 	bl	4270 <z_impl_k_thread_suspend>
    4720:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
	ticks = timeout.ticks;
#endif

	ticks = z_tick_sleep(ticks);
	return k_ticks_to_ms_floor64(ticks);
}
    4724:	bdd0      	pop	{r4, r6, r7, pc}
	ticks = z_tick_sleep(ticks);
    4726:	4604      	mov	r4, r0
    4728:	f002 f888 	bl	683c <arch_is_user_context>
	if (ticks == 0) {
    472c:	b94e      	cbnz	r6, 4742 <z_impl_k_sleep+0x3a>
	z_impl_k_yield();
    472e:	f7ff ff8d 	bl	464c <z_impl_k_yield>
		} else {
			return (t * to_hz + off) / from_hz;
    4732:	f44f 707a 	mov.w	r0, #1000	; 0x3e8
    4736:	fb84 3400 	smull	r3, r4, r4, r0
    473a:	0bd8      	lsrs	r0, r3, #15
    473c:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
	return k_ticks_to_ms_floor64(ticks);
    4740:	e7f0      	b.n	4724 <z_impl_k_sleep+0x1c>
    4742:	4630      	mov	r0, r6
    4744:	f7ff fe6a 	bl	441c <z_tick_sleep.part.0>
    4748:	4604      	mov	r4, r0
    474a:	e7f2      	b.n	4732 <z_impl_k_sleep+0x2a>
    474c:	20000eec 	.word	0x20000eec

00004750 <z_mrsh_k_sleep>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_sleep(k_timeout_t timeout);
uintptr_t z_mrsh_k_sleep(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4750:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    4752:	4c06      	ldr	r4, [pc, #24]	; (476c <z_mrsh_k_sleep+0x1c>)
    4754:	9a04      	ldr	r2, [sp, #16]
    4756:	68a3      	ldr	r3, [r4, #8]
    4758:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_sleep(k_timeout_t timeout)
{
	return z_impl_k_sleep(timeout);
    475c:	f7ff ffd4 	bl	4708 <z_impl_k_sleep>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg0;
	parm0.split.hi = arg1;
	int32_t ret = z_vrfy_k_sleep(parm0.val)
;
	_current->syscall_frame = NULL;
    4760:	68a3      	ldr	r3, [r4, #8]
    4762:	2200      	movs	r2, #0
    4764:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4768:	bd10      	pop	{r4, pc}
    476a:	bf00      	nop
    476c:	20000eec 	.word	0x20000eec

00004770 <z_impl_k_usleep>:
}
#include <syscalls/k_sleep_mrsh.c>
#endif

int32_t z_impl_k_usleep(int us)
{
    4770:	b538      	push	{r3, r4, r5, lr}
    4772:	4c0f      	ldr	r4, [pc, #60]	; (47b0 <z_impl_k_usleep+0x40>)
    4774:	4a0f      	ldr	r2, [pc, #60]	; (47b4 <z_impl_k_usleep+0x44>)
    4776:	f44f 4100 	mov.w	r1, #32768	; 0x8000
    477a:	2500      	movs	r5, #0
    477c:	fbc1 4500 	smlal	r4, r5, r1, r0
    4780:	4620      	mov	r0, r4
    4782:	2300      	movs	r3, #0
    4784:	4629      	mov	r1, r5
    4786:	f7fb fd29 	bl	1dc <__aeabi_uldivmod>
    478a:	4604      	mov	r4, r0
    478c:	f002 f856 	bl	683c <arch_is_user_context>
	if (ticks == 0) {
    4790:	b944      	cbnz	r4, 47a4 <z_impl_k_usleep+0x34>
    4792:	f7ff ff5b 	bl	464c <z_impl_k_yield>
    4796:	4807      	ldr	r0, [pc, #28]	; (47b4 <z_impl_k_usleep+0x44>)
    4798:	fb84 3400 	smull	r3, r4, r4, r0
    479c:	0bd8      	lsrs	r0, r3, #15
	int32_t ticks;

	ticks = k_us_to_ticks_ceil64(us);
	ticks = z_tick_sleep(ticks);
	return k_ticks_to_us_floor64(ticks);
}
    479e:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
    47a2:	bd38      	pop	{r3, r4, r5, pc}
    47a4:	4620      	mov	r0, r4
    47a6:	f7ff fe39 	bl	441c <z_tick_sleep.part.0>
    47aa:	4604      	mov	r4, r0
    47ac:	e7f3      	b.n	4796 <z_impl_k_usleep+0x26>
    47ae:	bf00      	nop
    47b0:	000f423f 	.word	0x000f423f
    47b4:	000f4240 	.word	0x000f4240

000047b8 <z_mrsh_k_usleep>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_usleep(int32_t us);
uintptr_t z_mrsh_k_usleep(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    47b8:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    47ba:	4c06      	ldr	r4, [pc, #24]	; (47d4 <z_mrsh_k_usleep+0x1c>)
    47bc:	9a04      	ldr	r2, [sp, #16]
    47be:	68a3      	ldr	r3, [r4, #8]
    47c0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_usleep(int us)
{
	return z_impl_k_usleep(us);
    47c4:	f7ff ffd4 	bl	4770 <z_impl_k_usleep>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_usleep(*(int32_t*)&arg0)
;
	_current->syscall_frame = NULL;
    47c8:	68a3      	ldr	r3, [r4, #8]
    47ca:	2200      	movs	r2, #0
    47cc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    47d0:	bd10      	pop	{r4, pc}
    47d2:	bf00      	nop
    47d4:	20000eec 	.word	0x20000eec

000047d8 <z_mrsh_k_wakeup>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_wakeup(k_tid_t thread);
uintptr_t z_mrsh_k_wakeup(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    47d8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    47da:	4d0e      	ldr	r5, [pc, #56]	; (4814 <z_mrsh_k_wakeup+0x3c>)
    47dc:	9a06      	ldr	r2, [sp, #24]
    47de:	68ab      	ldr	r3, [r5, #8]
    47e0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    47e4:	4606      	mov	r6, r0
#endif

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_wakeup(k_tid_t thread)
{
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    47e6:	f7fb fc79 	bl	dc <z_object_find>
    47ea:	2200      	movs	r2, #0
    47ec:	2109      	movs	r1, #9
    47ee:	f000 feaf 	bl	5550 <z_object_validate>
    47f2:	4604      	mov	r4, r0
    47f4:	b130      	cbz	r0, 4804 <z_mrsh_k_wakeup+0x2c>
    47f6:	f002 f821 	bl	683c <arch_is_user_context>
    47fa:	68ab      	ldr	r3, [r5, #8]
    47fc:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4800:	f001 fc6a 	bl	60d8 <arch_syscall_oops>
	z_impl_k_wakeup(thread);
    4804:	4630      	mov	r0, r6
    4806:	f002 f92d 	bl	6a64 <z_impl_k_wakeup>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_wakeup(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    480a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    480c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    480e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4812:	bd70      	pop	{r4, r5, r6, pc}
    4814:	20000eec 	.word	0x20000eec

00004818 <z_impl_k_current_get>:

#ifdef CONFIG_SMP
	arch_irq_unlock(k);
#endif
	return ret;
}
    4818:	4b01      	ldr	r3, [pc, #4]	; (4820 <z_impl_k_current_get+0x8>)
    481a:	6898      	ldr	r0, [r3, #8]
    481c:	4770      	bx	lr
    481e:	bf00      	nop
    4820:	20000eec 	.word	0x20000eec

00004824 <z_mrsh_k_current_get>:

extern k_tid_t z_vrfy_k_current_get();
uintptr_t z_mrsh_k_current_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    4824:	4b02      	ldr	r3, [pc, #8]	; (4830 <z_mrsh_k_current_get+0xc>)
    4826:	6898      	ldr	r0, [r3, #8]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_tid_t ret = z_vrfy_k_current_get()
;
	_current->syscall_frame = NULL;
    4828:	2300      	movs	r3, #0
    482a:	f8c0 3084 	str.w	r3, [r0, #132]	; 0x84
	return (uintptr_t) ret;
}
    482e:	4770      	bx	lr
    4830:	20000eec 	.word	0x20000eec

00004834 <z_impl_k_is_preempt_thread>:
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    4834:	f3ef 8305 	mrs	r3, IPSR
#include <syscalls/k_current_get_mrsh.c>
#endif

int z_impl_k_is_preempt_thread(void)
{
	return !arch_is_in_isr() && is_preempt(_current);
    4838:	b93b      	cbnz	r3, 484a <z_impl_k_is_preempt_thread+0x16>
    483a:	4b05      	ldr	r3, [pc, #20]	; (4850 <z_impl_k_is_preempt_thread+0x1c>)
    483c:	689b      	ldr	r3, [r3, #8]
    483e:	89d8      	ldrh	r0, [r3, #14]
    4840:	287f      	cmp	r0, #127	; 0x7f
    4842:	bf8c      	ite	hi
    4844:	2000      	movhi	r0, #0
    4846:	2001      	movls	r0, #1
    4848:	4770      	bx	lr
    484a:	2000      	movs	r0, #0
}
    484c:	4770      	bx	lr
    484e:	bf00      	nop
    4850:	20000eec 	.word	0x20000eec

00004854 <z_mrsh_k_is_preempt_thread>:

extern int z_vrfy_k_is_preempt_thread();
uintptr_t z_mrsh_k_is_preempt_thread(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    4854:	4a06      	ldr	r2, [pc, #24]	; (4870 <z_mrsh_k_is_preempt_thread+0x1c>)
{
    4856:	b508      	push	{r3, lr}
	_current->syscall_frame = ssf;
    4858:	6893      	ldr	r3, [r2, #8]
    485a:	9904      	ldr	r1, [sp, #16]
    485c:	f8c3 1084 	str.w	r1, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_is_preempt_thread(void)
{
	return z_impl_k_is_preempt_thread();
    4860:	f7ff ffe8 	bl	4834 <z_impl_k_is_preempt_thread>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_is_preempt_thread()
;
	_current->syscall_frame = NULL;
    4864:	6893      	ldr	r3, [r2, #8]
    4866:	2200      	movs	r2, #0
    4868:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    486c:	bd08      	pop	{r3, pc}
    486e:	bf00      	nop
    4870:	20000eec 	.word	0x20000eec

00004874 <z_impl_k_thread_join>:
}

#endif /* CONFIG_SCHED_CPU_MASK */

int z_impl_k_thread_join(struct k_thread *thread, k_timeout_t timeout)
{
    4874:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    4876:	4601      	mov	r1, r0
    4878:	4614      	mov	r4, r2
    487a:	461d      	mov	r5, r3
    487c:	f04f 0320 	mov.w	r3, #32
    4880:	f3ef 8611 	mrs	r6, BASEPRI
    4884:	f383 8811 	msr	BASEPRI, r3
    4888:	f3bf 8f6f 	isb	sy
	__ASSERT(((arch_is_in_isr() == false) ||
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	key = k_spin_lock(&sched_spinlock);

	if ((thread->base.pended_on == &_current->base.join_waiters) ||
    488c:	4f18      	ldr	r7, [pc, #96]	; (48f0 <z_impl_k_thread_join+0x7c>)
    488e:	688a      	ldr	r2, [r1, #8]
    4890:	68b8      	ldr	r0, [r7, #8]
    4892:	f100 0330 	add.w	r3, r0, #48	; 0x30
    4896:	429a      	cmp	r2, r3
    4898:	d01d      	beq.n	48d6 <z_impl_k_thread_join+0x62>
    489a:	4288      	cmp	r0, r1
    489c:	d01b      	beq.n	48d6 <z_impl_k_thread_join+0x62>
	    (thread == _current)) {
		ret = -EDEADLK;
		goto out;
	}

	if ((thread->base.thread_state & _THREAD_DEAD) != 0) {
    489e:	7b4b      	ldrb	r3, [r1, #13]
    48a0:	071a      	lsls	r2, r3, #28
    48a2:	d41f      	bmi.n	48e4 <z_impl_k_thread_join+0x70>
		ret = 0;
		goto out;
	}

	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    48a4:	ea54 0305 	orrs.w	r3, r4, r5
    48a8:	d01e      	beq.n	48e8 <z_impl_k_thread_join+0x74>
		ret = -EBUSY;
		goto out;
	}

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    48aa:	4b12      	ldr	r3, [pc, #72]	; (48f4 <z_impl_k_thread_join+0x80>)
#endif
	add_to_waitq_locked(_current, &thread->base.join_waiters);
    48ac:	3130      	adds	r1, #48	; 0x30
	pending_current = _current;
    48ae:	6018      	str	r0, [r3, #0]
	add_to_waitq_locked(_current, &thread->base.join_waiters);
    48b0:	f002 f86e 	bl	6990 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    48b4:	1c6b      	adds	r3, r5, #1
    48b6:	bf08      	it	eq
    48b8:	f1b4 3fff 	cmpeq.w	r4, #4294967295	; 0xffffffff
    48bc:	d006      	beq.n	48cc <z_impl_k_thread_join+0x58>
	add_thread_timeout(_current, timeout);
    48be:	68b8      	ldr	r0, [r7, #8]
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    48c0:	490d      	ldr	r1, [pc, #52]	; (48f8 <z_impl_k_thread_join+0x84>)
    48c2:	4622      	mov	r2, r4
    48c4:	462b      	mov	r3, r5
    48c6:	3018      	adds	r0, #24
    48c8:	f000 fc6e 	bl	51a8 <z_add_timeout>
    48cc:	4630      	mov	r0, r6

	return z_swap(&sched_spinlock, key);
out:
	k_spin_unlock(&sched_spinlock, key);
	return ret;
}
    48ce:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    48d2:	f7fc bd97 	b.w	1404 <arch_swap>
		ret = -EDEADLK;
    48d6:	f06f 0020 	mvn.w	r0, #32
	__asm__ volatile(
    48da:	f386 8811 	msr	BASEPRI, r6
    48de:	f3bf 8f6f 	isb	sy
}
    48e2:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		ret = 0;
    48e4:	2000      	movs	r0, #0
    48e6:	e7f8      	b.n	48da <z_impl_k_thread_join+0x66>
		ret = -EBUSY;
    48e8:	f06f 000f 	mvn.w	r0, #15
    48ec:	e7f5      	b.n	48da <z_impl_k_thread_join+0x66>
    48ee:	bf00      	nop
    48f0:	20000eec 	.word	0x20000eec
    48f4:	20000f1c 	.word	0x20000f1c
    48f8:	0000691b 	.word	0x0000691b

000048fc <z_mrsh_k_thread_join>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_thread_join(struct k_thread * thread, k_timeout_t timeout);
uintptr_t z_mrsh_k_thread_join(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    48fc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    48fe:	4c0b      	ldr	r4, [pc, #44]	; (492c <z_mrsh_k_thread_join+0x30>)
    4900:	68a3      	ldr	r3, [r4, #8]
{
    4902:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
    4904:	9a08      	ldr	r2, [sp, #32]
    4906:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    490a:	4605      	mov	r5, r0
    490c:	460f      	mov	r7, r1
}

static inline int z_vrfy_k_thread_join(struct k_thread *thread,
				       k_timeout_t timeout)
{
	if (thread_obj_validate(thread)) {
    490e:	f001 ff9f 	bl	6850 <thread_obj_validate>
    4912:	b948      	cbnz	r0, 4928 <z_mrsh_k_thread_join+0x2c>
		return 0;
	}

	return z_impl_k_thread_join(thread, timeout);
    4914:	463a      	mov	r2, r7
    4916:	4633      	mov	r3, r6
    4918:	4628      	mov	r0, r5
    491a:	f7ff ffab 	bl	4874 <z_impl_k_thread_join>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_thread_join(*(struct k_thread **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    491e:	68a3      	ldr	r3, [r4, #8]
    4920:	2200      	movs	r2, #0
    4922:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4926:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		return 0;
    4928:	2000      	movs	r0, #0
    492a:	e7f8      	b.n	491e <z_mrsh_k_thread_join+0x22>
    492c:	20000eec 	.word	0x20000eec

00004930 <z_mrsh_k_thread_abort>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_abort(k_tid_t thread);
uintptr_t z_mrsh_k_thread_abort(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4930:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4932:	4d0e      	ldr	r5, [pc, #56]	; (496c <z_mrsh_k_thread_abort+0x3c>)
    4934:	9a06      	ldr	r2, [sp, #24]
    4936:	68ab      	ldr	r3, [r5, #8]
    4938:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    493c:	4604      	mov	r4, r0
}
#include <syscalls/k_thread_join_mrsh.c>

static inline void z_vrfy_k_thread_abort(k_tid_t thread)
{
	if (thread_obj_validate(thread)) {
    493e:	f001 ff87 	bl	6850 <thread_obj_validate>
    4942:	462e      	mov	r6, r5
    4944:	b960      	cbnz	r0, 4960 <z_mrsh_k_thread_abort+0x30>
		return;
	}

	Z_OOPS(Z_SYSCALL_VERIFY_MSG(!(thread->base.user_options & K_ESSENTIAL),
    4946:	7b23      	ldrb	r3, [r4, #12]
    4948:	07db      	lsls	r3, r3, #31
    494a:	d506      	bpl.n	495a <z_mrsh_k_thread_abort+0x2a>
    494c:	f001 ff76 	bl	683c <arch_is_user_context>
    4950:	68ab      	ldr	r3, [r5, #8]
    4952:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4956:	f001 fbbf 	bl	60d8 <arch_syscall_oops>
				    "aborting essential thread %p", thread));

	z_impl_k_thread_abort((struct k_thread *)thread);
    495a:	4620      	mov	r0, r4
    495c:	f7fd f920 	bl	1ba0 <z_impl_k_thread_abort>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_abort(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    4960:	68b3      	ldr	r3, [r6, #8]
    4962:	2000      	movs	r0, #0
    4964:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4968:	bd70      	pop	{r4, r5, r6, pc}
    496a:	bf00      	nop
    496c:	20000eec 	.word	0x20000eec

00004970 <z_vrfy_k_sem_init>:
}

#ifdef CONFIG_USERSPACE
int z_vrfy_k_sem_init(struct k_sem *sem, unsigned int initial_count,
		      unsigned int limit)
{
    4970:	b570      	push	{r4, r5, r6, lr}
    4972:	460d      	mov	r5, r1
    4974:	4616      	mov	r6, r2
    4976:	4604      	mov	r4, r0
	Z_OOPS(Z_SYSCALL_OBJ_INIT(sem, K_OBJ_SEM));
    4978:	f7fb fbb0 	bl	dc <z_object_find>
    497c:	2201      	movs	r2, #1
    497e:	2107      	movs	r1, #7
    4980:	f000 fde6 	bl	5550 <z_object_validate>
    4984:	b138      	cbz	r0, 4996 <z_vrfy_k_sem_init+0x26>
    4986:	f002 f889 	bl	6a9c <arch_is_user_context>
    498a:	4b06      	ldr	r3, [pc, #24]	; (49a4 <z_vrfy_k_sem_init+0x34>)
    498c:	689b      	ldr	r3, [r3, #8]
    498e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4992:	f001 fba1 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_sem_init(sem, initial_count, limit);
    4996:	4632      	mov	r2, r6
    4998:	4629      	mov	r1, r5
    499a:	4620      	mov	r0, r4
}
    499c:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	return z_impl_k_sem_init(sem, initial_count, limit);
    49a0:	f002 b886 	b.w	6ab0 <z_impl_k_sem_init>
    49a4:	20000eec 	.word	0x20000eec

000049a8 <z_mrsh_k_sem_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_sem_init(struct k_sem * sem, unsigned int initial_count, unsigned int limit);
uintptr_t z_mrsh_k_sem_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    49a8:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    49aa:	4c06      	ldr	r4, [pc, #24]	; (49c4 <z_mrsh_k_sem_init+0x1c>)
    49ac:	9d06      	ldr	r5, [sp, #24]
    49ae:	68a3      	ldr	r3, [r4, #8]
    49b0:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_sem_init(*(struct k_sem **)&arg0, *(unsigned int*)&arg1, *(unsigned int*)&arg2)
    49b4:	f7ff ffdc 	bl	4970 <z_vrfy_k_sem_init>
;
	_current->syscall_frame = NULL;
    49b8:	68a3      	ldr	r3, [r4, #8]
    49ba:	2200      	movs	r2, #0
    49bc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    49c0:	bd38      	pop	{r3, r4, r5, pc}
    49c2:	bf00      	nop
    49c4:	20000eec 	.word	0x20000eec

000049c8 <z_impl_k_sem_give>:
	ARG_UNUSED(sem);
#endif
}

void z_impl_k_sem_give(struct k_sem *sem)
{
    49c8:	b538      	push	{r3, r4, r5, lr}
    49ca:	4604      	mov	r4, r0
	__asm__ volatile(
    49cc:	f04f 0320 	mov.w	r3, #32
    49d0:	f3ef 8511 	mrs	r5, BASEPRI
    49d4:	f383 8811 	msr	BASEPRI, r3
    49d8:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&lock);
	struct k_thread *thread = z_unpend_first_thread(&sem->wait_q);
    49dc:	f002 f805 	bl	69ea <z_unpend_first_thread>

	sys_trace_void(SYS_TRACE_ID_SEMA_GIVE);

	if (thread != NULL) {
    49e0:	b150      	cbz	r0, 49f8 <z_impl_k_sem_give+0x30>
    49e2:	2200      	movs	r2, #0
    49e4:	f8c0 2090 	str.w	r2, [r0, #144]	; 0x90
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
    49e8:	f001 ff87 	bl	68fa <z_ready_thread>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
		handle_poll_events(sem);
	}

	sys_trace_end_call(SYS_TRACE_ID_SEMA_GIVE);
	z_reschedule(&lock, key);
    49ec:	4629      	mov	r1, r5
    49ee:	4806      	ldr	r0, [pc, #24]	; (4a08 <z_impl_k_sem_give+0x40>)
}
    49f0:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&lock, key);
    49f4:	f001 bf39 	b.w	686a <z_reschedule>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
    49f8:	e9d4 3202 	ldrd	r3, r2, [r4, #8]
    49fc:	429a      	cmp	r2, r3
    49fe:	bf18      	it	ne
    4a00:	3301      	addne	r3, #1
    4a02:	60a3      	str	r3, [r4, #8]
		handle_poll_events(sem);
    4a04:	e7f2      	b.n	49ec <z_impl_k_sem_give+0x24>
    4a06:	bf00      	nop
    4a08:	20001347 	.word	0x20001347

00004a0c <z_mrsh_k_sem_give>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_sem_give(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_give(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4a0c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4a0e:	4d0e      	ldr	r5, [pc, #56]	; (4a48 <z_mrsh_k_sem_give+0x3c>)
    4a10:	9a06      	ldr	r2, [sp, #24]
    4a12:	68ab      	ldr	r3, [r5, #8]
    4a14:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4a18:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_sem_give(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    4a1a:	f7fb fb5f 	bl	dc <z_object_find>
    4a1e:	2200      	movs	r2, #0
    4a20:	2107      	movs	r1, #7
    4a22:	f000 fd95 	bl	5550 <z_object_validate>
    4a26:	4604      	mov	r4, r0
    4a28:	b130      	cbz	r0, 4a38 <z_mrsh_k_sem_give+0x2c>
    4a2a:	f002 f837 	bl	6a9c <arch_is_user_context>
    4a2e:	68ab      	ldr	r3, [r5, #8]
    4a30:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4a34:	f001 fb50 	bl	60d8 <arch_syscall_oops>
	z_impl_k_sem_give(sem);
    4a38:	4630      	mov	r0, r6
    4a3a:	f7ff ffc5 	bl	49c8 <z_impl_k_sem_give>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_sem_give(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    4a3e:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    4a40:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    4a42:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4a46:	bd70      	pop	{r4, r5, r6, pc}
    4a48:	20000eec 	.word	0x20000eec

00004a4c <z_impl_k_sem_take>:
}
#include <syscalls/k_sem_give_mrsh.c>
#endif

int z_impl_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
    4a4c:	b537      	push	{r0, r1, r2, r4, r5, lr}
    4a4e:	4614      	mov	r4, r2
    4a50:	461d      	mov	r5, r3
    4a52:	f04f 0320 	mov.w	r3, #32
    4a56:	f3ef 8111 	mrs	r1, BASEPRI
    4a5a:	f383 8811 	msr	BASEPRI, r3
    4a5e:	f3bf 8f6f 	isb	sy
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	sys_trace_void(SYS_TRACE_ID_SEMA_TAKE);
	k_spinlock_key_t key = k_spin_lock(&lock);

	if (likely(sem->count > 0U)) {
    4a62:	6883      	ldr	r3, [r0, #8]
    4a64:	b143      	cbz	r3, 4a78 <z_impl_k_sem_take+0x2c>
		sem->count--;
    4a66:	3b01      	subs	r3, #1
    4a68:	6083      	str	r3, [r0, #8]
	__asm__ volatile(
    4a6a:	f381 8811 	msr	BASEPRI, r1
    4a6e:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		ret = 0;
    4a72:	2000      	movs	r0, #0
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);

out:
	sys_trace_end_call(SYS_TRACE_ID_SEMA_TAKE);
	return ret;
}
    4a74:	b003      	add	sp, #12
    4a76:	bd30      	pop	{r4, r5, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    4a78:	ea54 0305 	orrs.w	r3, r4, r5
    4a7c:	d106      	bne.n	4a8c <z_impl_k_sem_take+0x40>
    4a7e:	f381 8811 	msr	BASEPRI, r1
    4a82:	f3bf 8f6f 	isb	sy
		ret = -EBUSY;
    4a86:	f06f 000f 	mvn.w	r0, #15
    4a8a:	e7f3      	b.n	4a74 <z_impl_k_sem_take+0x28>
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);
    4a8c:	4602      	mov	r2, r0
    4a8e:	e9cd 4500 	strd	r4, r5, [sp]
    4a92:	4802      	ldr	r0, [pc, #8]	; (4a9c <z_impl_k_sem_take+0x50>)
    4a94:	f7ff fd16 	bl	44c4 <z_pend_curr>
	return ret;
    4a98:	e7ec      	b.n	4a74 <z_impl_k_sem_take+0x28>
    4a9a:	bf00      	nop
    4a9c:	20001347 	.word	0x20001347

00004aa0 <z_mrsh_k_sem_take>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_sem_take(struct k_sem * sem, k_timeout_t timeout);
uintptr_t z_mrsh_k_sem_take(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4aa0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    4aa4:	4d10      	ldr	r5, [pc, #64]	; (4ae8 <z_mrsh_k_sem_take+0x48>)
    4aa6:	68ab      	ldr	r3, [r5, #8]
{
    4aa8:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    4aaa:	9a08      	ldr	r2, [sp, #32]
    4aac:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4ab0:	4688      	mov	r8, r1
    4ab2:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    4ab4:	f7fb fb12 	bl	dc <z_object_find>
    4ab8:	2200      	movs	r2, #0
    4aba:	2107      	movs	r1, #7
    4abc:	f000 fd48 	bl	5550 <z_object_validate>
    4ac0:	4604      	mov	r4, r0
    4ac2:	b130      	cbz	r0, 4ad2 <z_mrsh_k_sem_take+0x32>
    4ac4:	f001 ffea 	bl	6a9c <arch_is_user_context>
    4ac8:	68ab      	ldr	r3, [r5, #8]
    4aca:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4ace:	f001 fb03 	bl	60d8 <arch_syscall_oops>
	return z_impl_k_sem_take((struct k_sem *)sem, timeout);
    4ad2:	463b      	mov	r3, r7
    4ad4:	4642      	mov	r2, r8
    4ad6:	4630      	mov	r0, r6
    4ad8:	f7ff ffb8 	bl	4a4c <z_impl_k_sem_take>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_sem_take(*(struct k_sem **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    4adc:	68ab      	ldr	r3, [r5, #8]
    4ade:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4ae2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    4ae6:	bf00      	nop
    4ae8:	20000eec 	.word	0x20000eec

00004aec <z_mrsh_k_sem_reset>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_sem_reset(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_reset(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4aec:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    4aee:	4c0c      	ldr	r4, [pc, #48]	; (4b20 <z_mrsh_k_sem_reset+0x34>)
    4af0:	9a06      	ldr	r2, [sp, #24]
    4af2:	68a3      	ldr	r3, [r4, #8]
    4af4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4af8:	4605      	mov	r5, r0
}
#include <syscalls/k_sem_take_mrsh.c>

static inline void z_vrfy_k_sem_reset(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    4afa:	f7fb faef 	bl	dc <z_object_find>
    4afe:	2200      	movs	r2, #0
    4b00:	2107      	movs	r1, #7
    4b02:	f000 fd25 	bl	5550 <z_object_validate>
    4b06:	b130      	cbz	r0, 4b16 <z_mrsh_k_sem_reset+0x2a>
    4b08:	f001 ffc8 	bl	6a9c <arch_is_user_context>
    4b0c:	68a3      	ldr	r3, [r4, #8]
    4b0e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4b12:	f001 fae1 	bl	60d8 <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_sem_reset(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    4b16:	68a2      	ldr	r2, [r4, #8]
	sem->count = 0U;
    4b18:	60a8      	str	r0, [r5, #8]
    4b1a:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    4b1e:	bd38      	pop	{r3, r4, r5, pc}
    4b20:	20000eec 	.word	0x20000eec

00004b24 <z_mrsh_k_sem_count_get>:
#include <syscalls/kernel.h>

extern unsigned int z_vrfy_k_sem_count_get(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_count_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4b24:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    4b26:	4c0d      	ldr	r4, [pc, #52]	; (4b5c <z_mrsh_k_sem_count_get+0x38>)
    4b28:	9a06      	ldr	r2, [sp, #24]
    4b2a:	68a3      	ldr	r3, [r4, #8]
    4b2c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4b30:	4605      	mov	r5, r0
}
#include <syscalls/k_sem_reset_mrsh.c>

static inline unsigned int z_vrfy_k_sem_count_get(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    4b32:	f7fb fad3 	bl	dc <z_object_find>
    4b36:	2200      	movs	r2, #0
    4b38:	2107      	movs	r1, #7
    4b3a:	f000 fd09 	bl	5550 <z_object_validate>
    4b3e:	4603      	mov	r3, r0
    4b40:	b130      	cbz	r0, 4b50 <z_mrsh_k_sem_count_get+0x2c>
    4b42:	f001 ffab 	bl	6a9c <arch_is_user_context>
    4b46:	68a3      	ldr	r3, [r4, #8]
    4b48:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4b4c:	f001 fac4 	bl	60d8 <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	unsigned int ret = z_vrfy_k_sem_count_get(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    4b50:	68a2      	ldr	r2, [r4, #8]
	return z_impl_k_sem_count_get(sem);
    4b52:	68a8      	ldr	r0, [r5, #8]
    4b54:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    4b58:	bd38      	pop	{r3, r4, r5, pc}
    4b5a:	bf00      	nop
    4b5c:	20000eec 	.word	0x20000eec

00004b60 <z_mrsh_k_stack_alloc_init>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_stack_alloc_init(struct k_stack * stack, uint32_t num_entries);
uintptr_t z_mrsh_k_stack_alloc_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4b60:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    4b62:	4c10      	ldr	r4, [pc, #64]	; (4ba4 <z_mrsh_k_stack_alloc_init+0x44>)
    4b64:	9a08      	ldr	r2, [sp, #32]
    4b66:	68a3      	ldr	r3, [r4, #8]
    4b68:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4b6c:	460d      	mov	r5, r1
    4b6e:	4607      	mov	r7, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_stack_alloc_init(struct k_stack *stack,
					      uint32_t num_entries)
{
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(stack, K_OBJ_STACK));
    4b70:	f7fb fab4 	bl	dc <z_object_find>
    4b74:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    4b78:	2108      	movs	r1, #8
    4b7a:	f000 fce9 	bl	5550 <z_object_validate>
    4b7e:	4606      	mov	r6, r0
    4b80:	b130      	cbz	r0, 4b90 <z_mrsh_k_stack_alloc_init+0x30>
    4b82:	f001 ffa4 	bl	6ace <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY(num_entries > 0));
    4b86:	68a3      	ldr	r3, [r4, #8]
    4b88:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4b8c:	f001 faa4 	bl	60d8 <arch_syscall_oops>
    4b90:	2d00      	cmp	r5, #0
    4b92:	d0f6      	beq.n	4b82 <z_mrsh_k_stack_alloc_init+0x22>
	return z_impl_k_stack_alloc_init(stack, num_entries);
    4b94:	4629      	mov	r1, r5
    4b96:	4638      	mov	r0, r7
    4b98:	f001 ffac 	bl	6af4 <z_impl_k_stack_alloc_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_stack_alloc_init(*(struct k_stack **)&arg0, *(uint32_t*)&arg1)
;
	_current->syscall_frame = NULL;
    4b9c:	68a3      	ldr	r3, [r4, #8]
    4b9e:	f8c3 6084 	str.w	r6, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4ba2:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    4ba4:	20000eec 	.word	0x20000eec

00004ba8 <z_mrsh_k_stack_push>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_stack_push(struct k_stack * stack, stack_data_t data);
uintptr_t z_mrsh_k_stack_push(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4ba8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    4baa:	4d0f      	ldr	r5, [pc, #60]	; (4be8 <z_mrsh_k_stack_push+0x40>)
    4bac:	9a08      	ldr	r2, [sp, #32]
    4bae:	68ab      	ldr	r3, [r5, #8]
    4bb0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4bb4:	460f      	mov	r7, r1
    4bb6:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_stack_push(struct k_stack *stack, stack_data_t data)
{
	Z_OOPS(Z_SYSCALL_OBJ(stack, K_OBJ_STACK));
    4bb8:	f7fb fa90 	bl	dc <z_object_find>
    4bbc:	2200      	movs	r2, #0
    4bbe:	2108      	movs	r1, #8
    4bc0:	f000 fcc6 	bl	5550 <z_object_validate>
    4bc4:	4604      	mov	r4, r0
    4bc6:	b130      	cbz	r0, 4bd6 <z_mrsh_k_stack_push+0x2e>
    4bc8:	f001 ff81 	bl	6ace <arch_is_user_context>
    4bcc:	68ab      	ldr	r3, [r5, #8]
    4bce:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4bd2:	f001 fa81 	bl	60d8 <arch_syscall_oops>

	return z_impl_k_stack_push(stack, data);
    4bd6:	4639      	mov	r1, r7
    4bd8:	4630      	mov	r0, r6
    4bda:	f001 ff9e 	bl	6b1a <z_impl_k_stack_push>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_stack_push(*(struct k_stack **)&arg0, *(stack_data_t*)&arg1)
;
	_current->syscall_frame = NULL;
    4bde:	68ab      	ldr	r3, [r5, #8]
    4be0:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4be4:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    4be6:	bf00      	nop
    4be8:	20000eec 	.word	0x20000eec

00004bec <z_impl_k_stack_pop>:
#include <syscalls/k_stack_push_mrsh.c>
#endif

int z_impl_k_stack_pop(struct k_stack *stack, stack_data_t *data,
		       k_timeout_t timeout)
{
    4bec:	b5d3      	push	{r0, r1, r4, r6, r7, lr}
    4bee:	460c      	mov	r4, r1
    4bf0:	4616      	mov	r6, r2
    4bf2:	461f      	mov	r7, r3
	__asm__ volatile(
    4bf4:	f04f 0320 	mov.w	r3, #32
    4bf8:	f3ef 8111 	mrs	r1, BASEPRI
    4bfc:	f383 8811 	msr	BASEPRI, r3
    4c00:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&stack->lock);

	if (likely(stack->next > stack->base)) {
    4c04:	e9d0 2302 	ldrd	r2, r3, [r0, #8]
    4c08:	4293      	cmp	r3, r2
    4c0a:	d90a      	bls.n	4c22 <z_impl_k_stack_pop+0x36>
		stack->next--;
    4c0c:	1f1a      	subs	r2, r3, #4
		*data = *(stack->next);
    4c0e:	f853 3c04 	ldr.w	r3, [r3, #-4]
		stack->next--;
    4c12:	60c2      	str	r2, [r0, #12]
		*data = *(stack->next);
    4c14:	6023      	str	r3, [r4, #0]
	__asm__ volatile(
    4c16:	f381 8811 	msr	BASEPRI, r1
    4c1a:	f3bf 8f6f 	isb	sy
	if (result == -EAGAIN) {
		return -EAGAIN;
	}

	*data = (stack_data_t)_current->base.swap_data;
	return 0;
    4c1e:	2000      	movs	r0, #0
    4c20:	e008      	b.n	4c34 <z_impl_k_stack_pop+0x48>
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    4c22:	ea56 0307 	orrs.w	r3, r6, r7
    4c26:	d107      	bne.n	4c38 <z_impl_k_stack_pop+0x4c>
    4c28:	f381 8811 	msr	BASEPRI, r1
    4c2c:	f3bf 8f6f 	isb	sy
		return -EBUSY;
    4c30:	f06f 000f 	mvn.w	r0, #15
}
    4c34:	b002      	add	sp, #8
    4c36:	bdd0      	pop	{r4, r6, r7, pc}
	result = z_pend_curr(&stack->lock, key, &stack->wait_q, timeout);
    4c38:	4602      	mov	r2, r0
    4c3a:	e9cd 6700 	strd	r6, r7, [sp]
    4c3e:	3008      	adds	r0, #8
    4c40:	f7ff fc40 	bl	44c4 <z_pend_curr>
	if (result == -EAGAIN) {
    4c44:	f110 0f0b 	cmn.w	r0, #11
    4c48:	d0f4      	beq.n	4c34 <z_impl_k_stack_pop+0x48>
	*data = (stack_data_t)_current->base.swap_data;
    4c4a:	4b02      	ldr	r3, [pc, #8]	; (4c54 <z_impl_k_stack_pop+0x68>)
    4c4c:	689b      	ldr	r3, [r3, #8]
    4c4e:	695b      	ldr	r3, [r3, #20]
    4c50:	6023      	str	r3, [r4, #0]
    4c52:	e7e4      	b.n	4c1e <z_impl_k_stack_pop+0x32>
    4c54:	20000eec 	.word	0x20000eec

00004c58 <z_mrsh_k_stack_pop>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_stack_pop(struct k_stack * stack, stack_data_t * data, k_timeout_t timeout);
uintptr_t z_mrsh_k_stack_pop(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4c58:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	_current->syscall_frame = ssf;
    4c5c:	4c14      	ldr	r4, [pc, #80]	; (4cb0 <z_mrsh_k_stack_pop+0x58>)
{
    4c5e:	4699      	mov	r9, r3
	_current->syscall_frame = ssf;
    4c60:	68a3      	ldr	r3, [r4, #8]
{
    4c62:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    4c64:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    4c66:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4c6a:	460e      	mov	r6, r1
    4c6c:	4607      	mov	r7, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_stack_pop(struct k_stack *stack,
				     stack_data_t *data, k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(stack, K_OBJ_STACK));
    4c6e:	f7fb fa35 	bl	dc <z_object_find>
    4c72:	2200      	movs	r2, #0
    4c74:	2108      	movs	r1, #8
    4c76:	f000 fc6b 	bl	5550 <z_object_validate>
    4c7a:	b130      	cbz	r0, 4c8a <z_mrsh_k_stack_pop+0x32>
    4c7c:	f001 ff27 	bl	6ace <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(data, sizeof(stack_data_t)));
    4c80:	68a3      	ldr	r3, [r4, #8]
    4c82:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4c86:	f001 fa27 	bl	60d8 <arch_syscall_oops>
    4c8a:	2201      	movs	r2, #1
    4c8c:	2104      	movs	r1, #4
    4c8e:	4630      	mov	r0, r6
    4c90:	f001 fa50 	bl	6134 <arch_buffer_validate>
    4c94:	4605      	mov	r5, r0
    4c96:	2800      	cmp	r0, #0
    4c98:	d1f0      	bne.n	4c7c <z_mrsh_k_stack_pop+0x24>
	return z_impl_k_stack_pop(stack, data, timeout);
    4c9a:	464b      	mov	r3, r9
    4c9c:	4642      	mov	r2, r8
    4c9e:	4631      	mov	r1, r6
    4ca0:	4638      	mov	r0, r7
    4ca2:	f7ff ffa3 	bl	4bec <z_impl_k_stack_pop>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_stack_pop(*(struct k_stack **)&arg0, *(stack_data_t **)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    4ca6:	68a3      	ldr	r3, [r4, #8]
    4ca8:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4cac:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
    4cb0:	20000eec 	.word	0x20000eec

00004cb4 <schedule_new_thread>:
#endif
#endif

#ifdef CONFIG_MULTITHREADING
static void schedule_new_thread(struct k_thread *thread, k_timeout_t delay)
{
    4cb4:	b4d0      	push	{r4, r6, r7}
    4cb6:	4616      	mov	r6, r2
    4cb8:	461f      	mov	r7, r3
#ifdef CONFIG_SYS_CLOCK_EXISTS
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
    4cba:	ea56 0107 	orrs.w	r1, r6, r7
    4cbe:	d102      	bne.n	4cc6 <schedule_new_thread+0x12>
	}
#else
	ARG_UNUSED(delay);
	k_thread_start(thread);
#endif
}
    4cc0:	bcd0      	pop	{r4, r6, r7}
	z_sched_start(thread);
    4cc2:	f7ff ba03 	b.w	40cc <z_sched_start>
}
    4cc6:	bcd0      	pop	{r4, r6, r7}
    4cc8:	4901      	ldr	r1, [pc, #4]	; (4cd0 <schedule_new_thread+0x1c>)
    4cca:	3018      	adds	r0, #24
    4ccc:	f000 ba6c 	b.w	51a8 <z_add_timeout>
    4cd0:	0000691b 	.word	0x0000691b

00004cd4 <z_mrsh_k_busy_wait>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_busy_wait(uint32_t usec_to_wait);
uintptr_t z_mrsh_k_busy_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4cd4:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    4cd6:	4c06      	ldr	r4, [pc, #24]	; (4cf0 <z_mrsh_k_busy_wait+0x1c>)
    4cd8:	9a04      	ldr	r2, [sp, #16]
    4cda:	68a3      	ldr	r3, [r4, #8]
    4cdc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	arch_busy_wait(usec_to_wait);
    4ce0:	f7fd f9a2 	bl	2028 <arch_busy_wait>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_busy_wait(*(uint32_t*)&arg0)
;
	_current->syscall_frame = NULL;
    4ce4:	68a3      	ldr	r3, [r4, #8]
    4ce6:	2000      	movs	r0, #0
    4ce8:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4cec:	bd10      	pop	{r4, pc}
    4cee:	bf00      	nop
    4cf0:	20000eec 	.word	0x20000eec

00004cf4 <z_mrsh_k_thread_name_set>:

extern int z_vrfy_k_thread_name_set(k_tid_t thread_id, const char * value);
uintptr_t z_mrsh_k_thread_name_set(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    4cf4:	4b03      	ldr	r3, [pc, #12]	; (4d04 <z_mrsh_k_thread_name_set+0x10>)
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_thread_name_set(*(k_tid_t*)&arg0, *(const char **)&arg1)
;
	_current->syscall_frame = NULL;
    4cf6:	689b      	ldr	r3, [r3, #8]
    4cf8:	2200      	movs	r2, #0
    4cfa:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4cfe:	f06f 0046 	mvn.w	r0, #70	; 0x46
    4d02:	4770      	bx	lr
    4d04:	20000eec 	.word	0x20000eec

00004d08 <z_mrsh_k_thread_name_copy>:
    4d08:	4b03      	ldr	r3, [pc, #12]	; (4d18 <z_mrsh_k_thread_name_copy+0x10>)
    4d0a:	689b      	ldr	r3, [r3, #8]
    4d0c:	2200      	movs	r2, #0
    4d0e:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
    4d12:	f06f 0046 	mvn.w	r0, #70	; 0x46
    4d16:	4770      	bx	lr
    4d18:	20000eec 	.word	0x20000eec

00004d1c <z_mrsh_k_thread_start>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_start(k_tid_t thread);
uintptr_t z_mrsh_k_thread_start(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4d1c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4d1e:	4d0e      	ldr	r5, [pc, #56]	; (4d58 <z_mrsh_k_thread_start+0x3c>)
    4d20:	9a06      	ldr	r2, [sp, #24]
    4d22:	68ab      	ldr	r3, [r5, #8]
    4d24:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4d28:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    4d2a:	f7fb f9d7 	bl	dc <z_object_find>
    4d2e:	2200      	movs	r2, #0
    4d30:	2109      	movs	r1, #9
    4d32:	f000 fc0d 	bl	5550 <z_object_validate>
    4d36:	4604      	mov	r4, r0
    4d38:	b130      	cbz	r0, 4d48 <z_mrsh_k_thread_start+0x2c>
    4d3a:	f001 ff1d 	bl	6b78 <arch_is_user_context>
    4d3e:	68ab      	ldr	r3, [r5, #8]
    4d40:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4d44:	f001 f9c8 	bl	60d8 <arch_syscall_oops>
	z_sched_start(thread);
    4d48:	4630      	mov	r0, r6
    4d4a:	f7ff f9bf 	bl	40cc <z_sched_start>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_start(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    4d4e:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    4d50:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    4d52:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4d56:	bd70      	pop	{r4, r5, r6, pc}
    4d58:	20000eec 	.word	0x20000eec

00004d5c <z_setup_new_thread>:
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
    4d5c:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    4d60:	b085      	sub	sp, #20
    4d62:	4604      	mov	r4, r0
    4d64:	460e      	mov	r6, r1
    4d66:	4617      	mov	r7, r2
    4d68:	4699      	mov	r9, r3
		 "user thread %p with kernel-only stack %p",
		 new_thread, stack);
	z_object_init(new_thread);
	z_object_init(stack);
	new_thread->stack_obj = stack;
	new_thread->mem_domain_info.mem_domain = NULL;
    4d6a:	2500      	movs	r5, #0
{
    4d6c:	f8dd 8040 	ldr.w	r8, [sp, #64]	; 0x40
	z_object_init(new_thread);
    4d70:	f002 f8e4 	bl	6f3c <z_object_init>
	z_object_init(stack);
    4d74:	4630      	mov	r0, r6
    4d76:	f002 f8e1 	bl	6f3c <z_object_init>
	new_thread->stack_obj = stack;
    4d7a:	f8c4 6080 	str.w	r6, [r4, #128]	; 0x80
	new_thread->mem_domain_info.mem_domain = NULL;
    4d7e:	67e5      	str	r5, [r4, #124]	; 0x7c
	new_thread->syscall_frame = NULL;
    4d80:	f8c4 5084 	str.w	r5, [r4, #132]	; 0x84
	z_impl_k_object_access_grant(object, thread);
    4d84:	4620      	mov	r0, r4
    4d86:	4621      	mov	r1, r4
    4d88:	f002 f8cd 	bl	6f26 <z_impl_k_object_access_grant>
	sys_dlist_init(&w->waitq);
    4d8c:	f104 0330 	add.w	r3, r4, #48	; 0x30
	list->tail = (sys_dnode_t *)list;
    4d90:	e9c4 330c 	strd	r3, r3, [r4, #48]	; 0x30
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */

	thread_base->user_options = (uint8_t)options;
	thread_base->thread_state = (uint8_t)initial_state;
    4d94:	2304      	movs	r3, #4
    4d96:	7363      	strb	r3, [r4, #13]

	thread_base->prio = priority;
    4d98:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
	thread_base->user_options = (uint8_t)options;
    4d9a:	f884 800c 	strb.w	r8, [r4, #12]
	node->prev = NULL;
    4d9e:	e9c4 5506 	strd	r5, r5, [r4, #24]
	thread_base->prio = priority;
    4da2:	73a3      	strb	r3, [r4, #14]

	thread_base->sched_locked = 0U;
    4da4:	73e5      	strb	r5, [r4, #15]
	if (z_stack_is_user_capable(stack)) {
    4da6:	4630      	mov	r0, r6
    4da8:	f001 fefb 	bl	6ba2 <z_stack_is_user_capable>
    4dac:	b358      	cbz	r0, 4e06 <z_setup_new_thread+0xaa>
		stack_obj_size = Z_THREAD_STACK_SIZE_ADJUST(stack_size);
    4dae:	fab7 f387 	clz	r3, r7
    4db2:	f04f 4500 	mov.w	r5, #2147483648	; 0x80000000
    4db6:	40dd      	lsrs	r5, r3
    4db8:	42af      	cmp	r7, r5
    4dba:	d903      	bls.n	4dc4 <z_setup_new_thread+0x68>
    4dbc:	f1c3 0320 	rsb	r3, r3, #32
    4dc0:	2501      	movs	r5, #1
    4dc2:	409d      	lsls	r5, r3
    4dc4:	f001 fed8 	bl	6b78 <arch_is_user_context>
	new_thread->stack_info.delta = delta;
    4dc8:	2304      	movs	r3, #4
    4dca:	6723      	str	r3, [r4, #112]	; 0x70
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4dcc:	9b0e      	ldr	r3, [sp, #56]	; 0x38
    4dce:	9302      	str	r3, [sp, #8]
		(struct _thread_userspace_local_data *)(stack_ptr - delta);
    4dd0:	1f2f      	subs	r7, r5, #4
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4dd2:	9b0d      	ldr	r3, [sp, #52]	; 0x34
    4dd4:	9301      	str	r3, [sp, #4]
		(struct _thread_userspace_local_data *)(stack_ptr - delta);
    4dd6:	4437      	add	r7, r6
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4dd8:	9b0c      	ldr	r3, [sp, #48]	; 0x30
	new_thread->stack_info.size = stack_buf_size;
    4dda:	66e5      	str	r5, [r4, #108]	; 0x6c
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4ddc:	9300      	str	r3, [sp, #0]
	new_thread->stack_info.start = (uintptr_t)stack_buf_start;
    4dde:	e9c4 7619 	strd	r7, r6, [r4, #100]	; 0x64
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4de2:	464b      	mov	r3, r9
	if (!_current) {
    4de4:	4d12      	ldr	r5, [pc, #72]	; (4e30 <z_setup_new_thread+0xd4>)
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4de6:	463a      	mov	r2, r7
    4de8:	4631      	mov	r1, r6
    4dea:	4620      	mov	r0, r4
    4dec:	f7fc fbda 	bl	15a4 <arch_new_thread>
	new_thread->init_data = NULL;
    4df0:	2300      	movs	r3, #0
	new_thread->fn_abort = NULL;
    4df2:	e9c4 3317 	strd	r3, r3, [r4, #92]	; 0x5c
	if (!_current) {
    4df6:	68ab      	ldr	r3, [r5, #8]
    4df8:	b94b      	cbnz	r3, 4e0e <z_setup_new_thread+0xb2>
}
    4dfa:	4638      	mov	r0, r7
	new_thread->resource_pool = _current->resource_pool;
    4dfc:	f8c4 3088 	str.w	r3, [r4, #136]	; 0x88
}
    4e00:	b005      	add	sp, #20
    4e02:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
    4e06:	1cfd      	adds	r5, r7, #3
    4e08:	f025 0503 	bic.w	r5, r5, #3
		stack_buf_size = stack_obj_size - K_KERNEL_STACK_RESERVED;
    4e0c:	e7da      	b.n	4dc4 <z_setup_new_thread+0x68>
	if (_current->mem_domain_info.mem_domain != NULL) {
    4e0e:	6fd8      	ldr	r0, [r3, #124]	; 0x7c
    4e10:	b110      	cbz	r0, 4e18 <z_setup_new_thread+0xbc>
		k_mem_domain_add_thread(_current->mem_domain_info.mem_domain,
    4e12:	4621      	mov	r1, r4
    4e14:	f001 ffdb 	bl	6dce <k_mem_domain_add_thread>
	if ((options & K_INHERIT_PERMS) != 0U) {
    4e18:	f018 0f08 	tst.w	r8, #8
    4e1c:	d003      	beq.n	4e26 <z_setup_new_thread+0xca>
		z_thread_perms_inherit(_current, new_thread);
    4e1e:	68a8      	ldr	r0, [r5, #8]
    4e20:	4621      	mov	r1, r4
    4e22:	f000 fb6d 	bl	5500 <z_thread_perms_inherit>
	new_thread->resource_pool = _current->resource_pool;
    4e26:	68ab      	ldr	r3, [r5, #8]
    4e28:	f8d3 3088 	ldr.w	r3, [r3, #136]	; 0x88
    4e2c:	e7e5      	b.n	4dfa <z_setup_new_thread+0x9e>
    4e2e:	bf00      	nop
    4e30:	20000eec 	.word	0x20000eec

00004e34 <z_vrfy_k_thread_create>:
{
    4e34:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    4e38:	b087      	sub	sp, #28
    4e3a:	460e      	mov	r6, r1
    4e3c:	4617      	mov	r7, r2
    4e3e:	4699      	mov	r9, r3
    4e40:	e9dd a813 	ldrd	sl, r8, [sp, #76]	; 0x4c
    4e44:	4605      	mov	r5, r0
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(new_thread, K_OBJ_THREAD));
    4e46:	f7fb f949 	bl	dc <z_object_find>
    4e4a:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    4e4e:	2109      	movs	r1, #9
    4e50:	f000 fb7e 	bl	5550 <z_object_validate>
    4e54:	4c23      	ldr	r4, [pc, #140]	; (4ee4 <z_vrfy_k_thread_create+0xb0>)
    4e56:	b130      	cbz	r0, 4e66 <z_vrfy_k_thread_create+0x32>
    4e58:	f001 fe8e 	bl	6b78 <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY(z_is_prio_lower_or_equal(prio,
    4e5c:	68a3      	ldr	r3, [r4, #8]
    4e5e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4e62:	f001 f939 	bl	60d8 <arch_syscall_oops>
	stack_object = z_object_find(stack);
    4e66:	4630      	mov	r0, r6
    4e68:	f7fb f938 	bl	dc <z_object_find>
    4e6c:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    4e70:	210b      	movs	r1, #11
    4e72:	4683      	mov	fp, r0
    4e74:	f000 fb6c 	bl	5550 <z_object_validate>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(z_obj_validation_check(stack_object, stack,
    4e78:	2800      	cmp	r0, #0
    4e7a:	d1ed      	bne.n	4e58 <z_vrfy_k_thread_create+0x24>
	stack_obj_size = stack_object->data.stack_data->size;
    4e7c:	f8db 3008 	ldr.w	r3, [fp, #8]
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(total_size <= stack_obj_size,
    4e80:	681b      	ldr	r3, [r3, #0]
    4e82:	42bb      	cmp	r3, r7
    4e84:	d3e8      	bcc.n	4e58 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(options & K_USER));
    4e86:	f018 0f04 	tst.w	r8, #4
    4e8a:	d0e5      	beq.n	4e58 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(!(options & K_ESSENTIAL)));
    4e8c:	f018 0301 	ands.w	r3, r8, #1
    4e90:	d1e2      	bne.n	4e58 <z_vrfy_k_thread_create+0x24>
	if (!z_is_prio_higher_or_equal(prio,
    4e92:	f10a 0210 	add.w	r2, sl, #16
    4e96:	2a1e      	cmp	r2, #30
    4e98:	d8de      	bhi.n	4e58 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(z_is_prio_lower_or_equal(prio,
    4e9a:	68a2      	ldr	r2, [r4, #8]
    4e9c:	f992 200e 	ldrsb.w	r2, [r2, #14]
    4ea0:	4592      	cmp	sl, r2
    4ea2:	dbd9      	blt.n	4e58 <z_vrfy_k_thread_create+0x24>
	z_setup_new_thread(new_thread, stack, stack_size,
    4ea4:	e9cd 8304 	strd	r8, r3, [sp, #16]
    4ea8:	9b12      	ldr	r3, [sp, #72]	; 0x48
    4eaa:	9302      	str	r3, [sp, #8]
    4eac:	9b11      	ldr	r3, [sp, #68]	; 0x44
    4eae:	9301      	str	r3, [sp, #4]
    4eb0:	9b10      	ldr	r3, [sp, #64]	; 0x40
    4eb2:	9300      	str	r3, [sp, #0]
    4eb4:	f8cd a00c 	str.w	sl, [sp, #12]
    4eb8:	464b      	mov	r3, r9
    4eba:	463a      	mov	r2, r7
    4ebc:	4631      	mov	r1, r6
    4ebe:	4628      	mov	r0, r5
    4ec0:	f7ff ff4c 	bl	4d5c <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
    4ec4:	e9dd 3416 	ldrd	r3, r4, [sp, #88]	; 0x58
    4ec8:	3401      	adds	r4, #1
    4eca:	bf08      	it	eq
    4ecc:	f1b3 3fff 	cmpeq.w	r3, #4294967295	; 0xffffffff
    4ed0:	d004      	beq.n	4edc <z_vrfy_k_thread_create+0xa8>
		schedule_new_thread(new_thread, delay);
    4ed2:	e9dd 2316 	ldrd	r2, r3, [sp, #88]	; 0x58
    4ed6:	4628      	mov	r0, r5
    4ed8:	f7ff feec 	bl	4cb4 <schedule_new_thread>
}
    4edc:	4628      	mov	r0, r5
    4ede:	b007      	add	sp, #28
    4ee0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    4ee4:	20000eec 	.word	0x20000eec

00004ee8 <z_mrsh_k_thread_create>:
#include <syscalls/kernel.h>

extern k_tid_t z_vrfy_k_thread_create(struct k_thread * new_thread, k_thread_stack_t * stack, size_t stack_size, k_thread_entry_t entry, void * p1, void * p2, void * p3, int prio, uint32_t options, k_timeout_t delay);
uintptr_t z_mrsh_k_thread_create(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, void *more, void *ssf)
{
    4ee8:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    4eec:	4e19      	ldr	r6, [pc, #100]	; (4f54 <z_mrsh_k_thread_create+0x6c>)
{
    4eee:	b088      	sub	sp, #32
    4ef0:	469a      	mov	sl, r3
    4ef2:	9c11      	ldr	r4, [sp, #68]	; 0x44
	_current->syscall_frame = ssf;
    4ef4:	68b3      	ldr	r3, [r6, #8]
{
    4ef6:	4691      	mov	r9, r2
	_current->syscall_frame = ssf;
    4ef8:	9a12      	ldr	r2, [sp, #72]	; 0x48
    4efa:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4efe:	4607      	mov	r7, r0
    4f00:	4688      	mov	r8, r1
	Z_OOPS(Z_SYSCALL_MEMORY_READ(more, 5 * sizeof(uintptr_t)));
    4f02:	2200      	movs	r2, #0
    4f04:	2114      	movs	r1, #20
    4f06:	4620      	mov	r0, r4
    4f08:	f001 f914 	bl	6134 <arch_buffer_validate>
    4f0c:	4605      	mov	r5, r0
    4f0e:	b130      	cbz	r0, 4f1e <z_mrsh_k_thread_create+0x36>
    4f10:	f001 fe32 	bl	6b78 <arch_is_user_context>
    4f14:	68b3      	ldr	r3, [r6, #8]
    4f16:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4f1a:	f001 f8dd 	bl	60d8 <arch_syscall_oops>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = (((uintptr_t *)more)[4]);
	parm0.split.hi = (((uintptr_t *)more)[5]);
    4f1e:	e9d4 2304 	ldrd	r2, r3, [r4, #16]
	k_tid_t ret = z_vrfy_k_thread_create(*(struct k_thread **)&arg0, *(k_thread_stack_t **)&arg1, *(size_t*)&arg2, *(k_thread_entry_t*)&arg3, *(void **)&arg4, *(void **)&(((uintptr_t *)more)[0]), *(void **)&(((uintptr_t *)more)[1]), *(int*)&(((uintptr_t *)more)[2]), *(uint32_t*)&(((uintptr_t *)more)[3]), parm0.val)
    4f22:	e9cd 2306 	strd	r2, r3, [sp, #24]
    4f26:	68e3      	ldr	r3, [r4, #12]
    4f28:	9304      	str	r3, [sp, #16]
    4f2a:	68a3      	ldr	r3, [r4, #8]
    4f2c:	9303      	str	r3, [sp, #12]
    4f2e:	6863      	ldr	r3, [r4, #4]
    4f30:	9302      	str	r3, [sp, #8]
    4f32:	6823      	ldr	r3, [r4, #0]
    4f34:	9301      	str	r3, [sp, #4]
    4f36:	9b10      	ldr	r3, [sp, #64]	; 0x40
    4f38:	9300      	str	r3, [sp, #0]
    4f3a:	464a      	mov	r2, r9
    4f3c:	4653      	mov	r3, sl
    4f3e:	4641      	mov	r1, r8
    4f40:	4638      	mov	r0, r7
    4f42:	f7ff ff77 	bl	4e34 <z_vrfy_k_thread_create>
;
	_current->syscall_frame = NULL;
    4f46:	68b3      	ldr	r3, [r6, #8]
    4f48:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4f4c:	b008      	add	sp, #32
    4f4e:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    4f52:	bf00      	nop
    4f54:	20000eec 	.word	0x20000eec

00004f58 <z_init_static_threads>:
{
    4f58:	e92d 4bf0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, fp, lr}
	_FOREACH_STATIC_THREAD(thread_data) {
    4f5c:	4f2e      	ldr	r7, [pc, #184]	; (5018 <z_init_static_threads+0xc0>)
    4f5e:	4e2f      	ldr	r6, [pc, #188]	; (501c <z_init_static_threads+0xc4>)
{
    4f60:	b086      	sub	sp, #24
    4f62:	463d      	mov	r5, r7
	_FOREACH_STATIC_THREAD(thread_data) {
    4f64:	42be      	cmp	r6, r7
    4f66:	f106 0430 	add.w	r4, r6, #48	; 0x30
    4f6a:	d312      	bcc.n	4f92 <z_init_static_threads+0x3a>
	Z_STRUCT_SECTION_FOREACH(z_object_assignment, pos) {
    4f6c:	4c2c      	ldr	r4, [pc, #176]	; (5020 <z_init_static_threads+0xc8>)
    4f6e:	4f2d      	ldr	r7, [pc, #180]	; (5024 <z_init_static_threads+0xcc>)
    4f70:	42bc      	cmp	r4, r7
    4f72:	d335      	bcc.n	4fe0 <z_init_static_threads+0x88>
	k_sched_lock();
    4f74:	f7ff f80a 	bl	3f8c <k_sched_lock>
	_FOREACH_STATIC_THREAD(thread_data) {
    4f78:	4c28      	ldr	r4, [pc, #160]	; (501c <z_init_static_threads+0xc4>)
    4f7a:	f44f 4800 	mov.w	r8, #32768	; 0x8000
    4f7e:	f240 36e7 	movw	r6, #999	; 0x3e7
    4f82:	2700      	movs	r7, #0
    4f84:	42ac      	cmp	r4, r5
    4f86:	d32d      	bcc.n	4fe4 <z_init_static_threads+0x8c>
}
    4f88:	b006      	add	sp, #24
    4f8a:	e8bd 4bf0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, fp, lr}
	k_sched_unlock();
    4f8e:	f7ff b84b 	b.w	4028 <k_sched_unlock>
		z_setup_new_thread(
    4f92:	f854 3c04 	ldr.w	r3, [r4, #-4]
    4f96:	9305      	str	r3, [sp, #20]
    4f98:	f854 3c10 	ldr.w	r3, [r4, #-16]
    4f9c:	9304      	str	r3, [sp, #16]
    4f9e:	f854 3c14 	ldr.w	r3, [r4, #-20]
    4fa2:	9303      	str	r3, [sp, #12]
    4fa4:	f854 3c18 	ldr.w	r3, [r4, #-24]
    4fa8:	9302      	str	r3, [sp, #8]
    4faa:	f854 3c1c 	ldr.w	r3, [r4, #-28]
    4fae:	9301      	str	r3, [sp, #4]
    4fb0:	f854 3c20 	ldr.w	r3, [r4, #-32]
    4fb4:	9300      	str	r3, [sp, #0]
    4fb6:	e954 230a 	ldrd	r2, r3, [r4, #-40]	; 0x28
    4fba:	e954 010c 	ldrd	r0, r1, [r4, #-48]	; 0x30
    4fbe:	f7ff fecd 	bl	4d5c <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
    4fc2:	f854 3c30 	ldr.w	r3, [r4, #-48]
    4fc6:	65de      	str	r6, [r3, #92]	; 0x5c
    4fc8:	4626      	mov	r6, r4
    4fca:	e7cb      	b.n	4f64 <z_init_static_threads+0xc>
			k_object_access_grant(pos->objects[i],
    4fcc:	6821      	ldr	r1, [r4, #0]
    4fce:	f001 ffaa 	bl	6f26 <z_impl_k_object_access_grant>
		for (int i = 0; pos->objects[i] != NULL; i++) {
    4fd2:	6863      	ldr	r3, [r4, #4]
    4fd4:	5998      	ldr	r0, [r3, r6]
    4fd6:	3604      	adds	r6, #4
    4fd8:	2800      	cmp	r0, #0
    4fda:	d1f7      	bne.n	4fcc <z_init_static_threads+0x74>
	Z_STRUCT_SECTION_FOREACH(z_object_assignment, pos) {
    4fdc:	3408      	adds	r4, #8
    4fde:	e7c7      	b.n	4f70 <z_init_static_threads+0x18>
    4fe0:	2600      	movs	r6, #0
    4fe2:	e7f6      	b.n	4fd2 <z_init_static_threads+0x7a>
		if (thread_data->init_delay != K_TICKS_FOREVER) {
    4fe4:	6a61      	ldr	r1, [r4, #36]	; 0x24
    4fe6:	1c4b      	adds	r3, r1, #1
    4fe8:	d013      	beq.n	5012 <z_init_static_threads+0xba>
					    K_MSEC(thread_data->init_delay));
    4fea:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    4fee:	46b3      	mov	fp, r6
    4ff0:	46bc      	mov	ip, r7
    4ff2:	fbc8 bc01 	smlal	fp, ip, r8, r1
    4ff6:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    4ffa:	2300      	movs	r3, #0
    4ffc:	4658      	mov	r0, fp
    4ffe:	4661      	mov	r1, ip
    5000:	f7fb f8ec 	bl	1dc <__aeabi_uldivmod>
			schedule_new_thread(thread_data->init_thread,
    5004:	f8d4 9000 	ldr.w	r9, [r4]
    5008:	4602      	mov	r2, r0
    500a:	460b      	mov	r3, r1
    500c:	4648      	mov	r0, r9
    500e:	f7ff fe51 	bl	4cb4 <schedule_new_thread>
	_FOREACH_STATIC_THREAD(thread_data) {
    5012:	3430      	adds	r4, #48	; 0x30
    5014:	e7b6      	b.n	4f84 <z_init_static_threads+0x2c>
    5016:	bf00      	nop
    5018:	20003460 	.word	0x20003460
    501c:	20003460 	.word	0x20003460
    5020:	000072b0 	.word	0x000072b0
    5024:	000072b0 	.word	0x000072b0

00005028 <z_mrsh_k_float_disable>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_float_disable(struct k_thread * thread);
uintptr_t z_mrsh_k_float_disable(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5028:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    502a:	4c0c      	ldr	r4, [pc, #48]	; (505c <z_mrsh_k_float_disable+0x34>)
    502c:	9a04      	ldr	r2, [sp, #16]
    502e:	68a3      	ldr	r3, [r4, #8]
    5030:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_float_disable(struct k_thread *thread)
{
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    5034:	f7fb f852 	bl	dc <z_object_find>
    5038:	2200      	movs	r2, #0
    503a:	2109      	movs	r1, #9
    503c:	f000 fa88 	bl	5550 <z_object_validate>
    5040:	b130      	cbz	r0, 5050 <z_mrsh_k_float_disable+0x28>
    5042:	f001 fd99 	bl	6b78 <arch_is_user_context>
    5046:	68a3      	ldr	r3, [r4, #8]
    5048:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    504c:	f001 f844 	bl	60d8 <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_float_disable(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    5050:	68a3      	ldr	r3, [r4, #8]
    5052:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    5056:	f06f 0046 	mvn.w	r0, #70	; 0x46
    505a:	bd10      	pop	{r4, pc}
    505c:	20000eec 	.word	0x20000eec

00005060 <z_mrsh_k_thread_timeout_remaining_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_thread_timeout_remaining_ticks(struct k_thread * t);
uintptr_t z_mrsh_k_thread_timeout_remaining_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5060:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    5062:	4d0e      	ldr	r5, [pc, #56]	; (509c <z_mrsh_k_thread_timeout_remaining_ticks+0x3c>)
    5064:	9a06      	ldr	r2, [sp, #24]
    5066:	68ab      	ldr	r3, [r5, #8]
    5068:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    506c:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline k_ticks_t z_vrfy_k_thread_timeout_remaining_ticks(
						    struct k_thread *t)
{
	Z_OOPS(Z_SYSCALL_OBJ(t, K_OBJ_THREAD));
    506e:	f7fb f835 	bl	dc <z_object_find>
    5072:	2200      	movs	r2, #0
    5074:	2109      	movs	r1, #9
    5076:	f000 fa6b 	bl	5550 <z_object_validate>
    507a:	4604      	mov	r4, r0
    507c:	b130      	cbz	r0, 508c <z_mrsh_k_thread_timeout_remaining_ticks+0x2c>
    507e:	f001 fd7b 	bl	6b78 <arch_is_user_context>
    5082:	68ab      	ldr	r3, [r5, #8]
    5084:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5088:	f001 f826 	bl	60d8 <arch_syscall_oops>
	return z_timeout_remaining(&t->base.timeout);
    508c:	f106 0018 	add.w	r0, r6, #24
    5090:	f001 fdcc 	bl	6c2c <z_timeout_remaining>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_thread_timeout_remaining_ticks(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    5094:	68ab      	ldr	r3, [r5, #8]
    5096:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    509a:	bd70      	pop	{r4, r5, r6, pc}
    509c:	20000eec 	.word	0x20000eec

000050a0 <z_mrsh_k_thread_timeout_expires_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_thread_timeout_expires_ticks(struct k_thread * t);
uintptr_t z_mrsh_k_thread_timeout_expires_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    50a0:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    50a2:	4d0e      	ldr	r5, [pc, #56]	; (50dc <z_mrsh_k_thread_timeout_expires_ticks+0x3c>)
    50a4:	9a06      	ldr	r2, [sp, #24]
    50a6:	68ab      	ldr	r3, [r5, #8]
    50a8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    50ac:	4606      	mov	r6, r0
#include <syscalls/k_thread_timeout_remaining_ticks_mrsh.c>

static inline k_ticks_t z_vrfy_k_thread_timeout_expires_ticks(
						  struct k_thread *t)
{
	Z_OOPS(Z_SYSCALL_OBJ(t, K_OBJ_THREAD));
    50ae:	f7fb f815 	bl	dc <z_object_find>
    50b2:	2200      	movs	r2, #0
    50b4:	2109      	movs	r1, #9
    50b6:	f000 fa4b 	bl	5550 <z_object_validate>
    50ba:	4604      	mov	r4, r0
    50bc:	b130      	cbz	r0, 50cc <z_mrsh_k_thread_timeout_expires_ticks+0x2c>
    50be:	f001 fd5b 	bl	6b78 <arch_is_user_context>
    50c2:	68ab      	ldr	r3, [r5, #8]
    50c4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    50c8:	f001 f806 	bl	60d8 <arch_syscall_oops>
	return z_timeout_expires(&t->base.timeout);
    50cc:	f106 0018 	add.w	r0, r6, #24
    50d0:	f000 f8f2 	bl	52b8 <z_timeout_expires>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_thread_timeout_expires_ticks(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    50d4:	68ab      	ldr	r3, [r5, #8]
    50d6:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    50da:	bd70      	pop	{r4, r5, r6, pc}
    50dc:	20000eec 	.word	0x20000eec

000050e0 <elapsed>:
	sys_dlist_remove(&t->node);
}

static int32_t elapsed(void)
{
	return announce_remaining == 0 ? z_clock_elapsed() : 0;
    50e0:	4b03      	ldr	r3, [pc, #12]	; (50f0 <elapsed+0x10>)
    50e2:	681b      	ldr	r3, [r3, #0]
    50e4:	b90b      	cbnz	r3, 50ea <elapsed+0xa>
    50e6:	f7fc b943 	b.w	1370 <z_clock_elapsed>
}
    50ea:	2000      	movs	r0, #0
    50ec:	4770      	bx	lr
    50ee:	bf00      	nop
    50f0:	20000f28 	.word	0x20000f28

000050f4 <remove_timeout>:
{
    50f4:	b530      	push	{r4, r5, lr}
    50f6:	6803      	ldr	r3, [r0, #0]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    50f8:	b168      	cbz	r0, 5116 <remove_timeout+0x22>
    50fa:	4a0a      	ldr	r2, [pc, #40]	; (5124 <remove_timeout+0x30>)
	return (node == list->tail) ? NULL : node->next;
    50fc:	6852      	ldr	r2, [r2, #4]
    50fe:	4290      	cmp	r0, r2
    5100:	d009      	beq.n	5116 <remove_timeout+0x22>
	if (next(t) != NULL) {
    5102:	b143      	cbz	r3, 5116 <remove_timeout+0x22>
		next(t)->dticks += t->dticks;
    5104:	e9d3 2104 	ldrd	r2, r1, [r3, #16]
    5108:	e9d0 4504 	ldrd	r4, r5, [r0, #16]
    510c:	1912      	adds	r2, r2, r4
    510e:	eb45 0101 	adc.w	r1, r5, r1
    5112:	e9c3 2104 	strd	r2, r1, [r3, #16]
	node->prev->next = node->next;
    5116:	6842      	ldr	r2, [r0, #4]
    5118:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    511a:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    511c:	2300      	movs	r3, #0
	node->prev = NULL;
    511e:	e9c0 3300 	strd	r3, r3, [r0]
}
    5122:	bd30      	pop	{r4, r5, pc}
    5124:	20003418 	.word	0x20003418

00005128 <next_timeout>:
	return list->head == list;
    5128:	4b0a      	ldr	r3, [pc, #40]	; (5154 <next_timeout+0x2c>)

static int32_t next_timeout(void)
{
    512a:	b510      	push	{r4, lr}
    512c:	681c      	ldr	r4, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    512e:	429c      	cmp	r4, r3
    5130:	bf08      	it	eq
    5132:	2400      	moveq	r4, #0
	struct _timeout *to = first();
	int32_t ticks_elapsed = elapsed();
    5134:	f7ff ffd4 	bl	50e0 <elapsed>
	int32_t ret = to == NULL ? MAX_WAIT : MAX(0, to->dticks - ticks_elapsed);
    5138:	b144      	cbz	r4, 514c <next_timeout+0x24>
    513a:	6923      	ldr	r3, [r4, #16]
    513c:	1a18      	subs	r0, r3, r0

#ifdef CONFIG_TIMESLICING
	if (_current_cpu->slice_ticks && _current_cpu->slice_ticks < ret) {
    513e:	4b06      	ldr	r3, [pc, #24]	; (5158 <next_timeout+0x30>)
    5140:	691b      	ldr	r3, [r3, #16]
    5142:	b113      	cbz	r3, 514a <next_timeout+0x22>
    5144:	4298      	cmp	r0, r3
    5146:	bfa8      	it	ge
    5148:	4618      	movge	r0, r3
		ret = _current_cpu->slice_ticks;
	}
#endif
	return ret;
}
    514a:	bd10      	pop	{r4, pc}
	int32_t ret = to == NULL ? MAX_WAIT : MAX(0, to->dticks - ticks_elapsed);
    514c:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
    5150:	e7f5      	b.n	513e <next_timeout+0x16>
    5152:	bf00      	nop
    5154:	20003418 	.word	0x20003418
    5158:	20000eec 	.word	0x20000eec

0000515c <timeout_rem>:
/* must be locked */
static k_ticks_t timeout_rem(struct _timeout *timeout)
{
	k_ticks_t ticks = 0;

	if (z_is_inactive_timeout(timeout)) {
    515c:	6803      	ldr	r3, [r0, #0]
{
    515e:	b570      	push	{r4, r5, r6, lr}
	if (z_is_inactive_timeout(timeout)) {
    5160:	b1eb      	cbz	r3, 519e <timeout_rem+0x42>
	return list->head == list;
    5162:	4a10      	ldr	r2, [pc, #64]	; (51a4 <timeout_rem+0x48>)
    5164:	6813      	ldr	r3, [r2, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    5166:	4293      	cmp	r3, r2
    5168:	d016      	beq.n	5198 <timeout_rem+0x3c>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    516a:	6851      	ldr	r1, [r2, #4]
    516c:	2400      	movs	r4, #0
    516e:	2500      	movs	r5, #0
		return 0;
	}

	for (struct _timeout *t = first(); t != NULL; t = next(t)) {
    5170:	b93b      	cbnz	r3, 5182 <timeout_rem+0x26>
		if (timeout == t) {
			break;
		}
	}

	return ticks - elapsed();
    5172:	f7ff ffb5 	bl	50e0 <elapsed>
    5176:	1a24      	subs	r4, r4, r0
    5178:	eb65 75e0 	sbc.w	r5, r5, r0, asr #31
}
    517c:	4620      	mov	r0, r4
    517e:	4629      	mov	r1, r5
    5180:	bd70      	pop	{r4, r5, r6, pc}
		ticks += t->dticks;
    5182:	e9d3 2604 	ldrd	r2, r6, [r3, #16]
    5186:	18a4      	adds	r4, r4, r2
    5188:	eb46 0505 	adc.w	r5, r6, r5
		if (timeout == t) {
    518c:	4283      	cmp	r3, r0
    518e:	d0f0      	beq.n	5172 <timeout_rem+0x16>
	return (node == list->tail) ? NULL : node->next;
    5190:	428b      	cmp	r3, r1
    5192:	d0ee      	beq.n	5172 <timeout_rem+0x16>
    5194:	681b      	ldr	r3, [r3, #0]
    5196:	e7eb      	b.n	5170 <timeout_rem+0x14>
    5198:	2400      	movs	r4, #0
    519a:	2500      	movs	r5, #0
    519c:	e7e9      	b.n	5172 <timeout_rem+0x16>
		return 0;
    519e:	2400      	movs	r4, #0
    51a0:	2500      	movs	r5, #0
    51a2:	e7eb      	b.n	517c <timeout_rem+0x20>
    51a4:	20003418 	.word	0x20003418

000051a8 <z_add_timeout>:
{
    51a8:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    51ac:	9101      	str	r1, [sp, #4]
    51ae:	4619      	mov	r1, r3
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    51b0:	1c4b      	adds	r3, r1, #1
    51b2:	bf08      	it	eq
    51b4:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
{
    51b8:	4682      	mov	sl, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    51ba:	d06c      	beq.n	5296 <z_add_timeout+0xee>
	k_ticks_t ticks = timeout.ticks + 1;
    51bc:	1c54      	adds	r4, r2, #1
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    51be:	f06f 0301 	mvn.w	r3, #1
	k_ticks_t ticks = timeout.ticks + 1;
    51c2:	f141 0500 	adc.w	r5, r1, #0
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    51c6:	f04f 3bff 	mov.w	fp, #4294967295	; 0xffffffff
    51ca:	ebb3 0804 	subs.w	r8, r3, r4
    51ce:	eb6b 0905 	sbc.w	r9, fp, r5
    51d2:	f1b8 0f00 	cmp.w	r8, #0
    51d6:	f179 0300 	sbcs.w	r3, r9, #0
    51da:	db0f      	blt.n	51fc <z_add_timeout+0x54>
		ticks = Z_TICK_ABS(ticks) - (curr_tick + elapsed());
    51dc:	f7ff ff80 	bl	50e0 <elapsed>
    51e0:	4a33      	ldr	r2, [pc, #204]	; (52b0 <z_add_timeout+0x108>)
    51e2:	e9d2 1c00 	ldrd	r1, ip, [r2]
    51e6:	f06f 0301 	mvn.w	r3, #1
    51ea:	1a5b      	subs	r3, r3, r1
    51ec:	eb6b 020c 	sbc.w	r2, fp, ip
    51f0:	1b1e      	subs	r6, r3, r4
    51f2:	eb62 0705 	sbc.w	r7, r2, r5
    51f6:	1a34      	subs	r4, r6, r0
    51f8:	eb67 75e0 	sbc.w	r5, r7, r0, asr #31
	to->fn = fn;
    51fc:	9b01      	ldr	r3, [sp, #4]
    51fe:	f8ca 3008 	str.w	r3, [sl, #8]
	__asm__ volatile(
    5202:	f04f 0320 	mov.w	r3, #32
    5206:	f3ef 8611 	mrs	r6, BASEPRI
    520a:	f383 8811 	msr	BASEPRI, r3
    520e:	f3bf 8f6f 	isb	sy
		to->dticks = ticks + elapsed();
    5212:	f7ff ff65 	bl	50e0 <elapsed>
	ticks = MAX(1, ticks);
    5216:	2c01      	cmp	r4, #1
    5218:	f175 0300 	sbcs.w	r3, r5, #0
	return list->head == list;
    521c:	4b25      	ldr	r3, [pc, #148]	; (52b4 <z_add_timeout+0x10c>)
    521e:	bfb8      	it	lt
    5220:	2401      	movlt	r4, #1
    5222:	681a      	ldr	r2, [r3, #0]
    5224:	bfb8      	it	lt
    5226:	2500      	movlt	r5, #0
		to->dticks = ticks + elapsed();
    5228:	1824      	adds	r4, r4, r0
    522a:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    522e:	429a      	cmp	r2, r3
    5230:	e9ca 4504 	strd	r4, r5, [sl, #16]
    5234:	d001      	beq.n	523a <z_add_timeout+0x92>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    5236:	685f      	ldr	r7, [r3, #4]
		for (t = first(); t != NULL; t = next(t)) {
    5238:	b952      	cbnz	r2, 5250 <z_add_timeout+0xa8>
	node->prev = list->tail;
    523a:	685a      	ldr	r2, [r3, #4]
    523c:	f8ca 2004 	str.w	r2, [sl, #4]
	list->tail->next = node;
    5240:	685a      	ldr	r2, [r3, #4]
	node->next = list;
    5242:	f8ca 3000 	str.w	r3, [sl]
	list->tail->next = node;
    5246:	f8c2 a000 	str.w	sl, [r2]
	list->tail = node;
    524a:	f8c3 a004 	str.w	sl, [r3, #4]
}
    524e:	e014      	b.n	527a <z_add_timeout+0xd2>
			if (t->dticks > to->dticks) {
    5250:	e9d2 8904 	ldrd	r8, r9, [r2, #16]
    5254:	e9da 4504 	ldrd	r4, r5, [sl, #16]
    5258:	454d      	cmp	r5, r9
    525a:	bf08      	it	eq
    525c:	4544      	cmpeq	r4, r8
    525e:	d21d      	bcs.n	529c <z_add_timeout+0xf4>
				t->dticks -= to->dticks;
    5260:	ebb8 0004 	subs.w	r0, r8, r4
    5264:	eb69 0105 	sbc.w	r1, r9, r5
    5268:	e9c2 0104 	strd	r0, r1, [r2, #16]
	node->prev = successor->prev;
    526c:	6851      	ldr	r1, [r2, #4]
	node->next = successor;
    526e:	e9ca 2100 	strd	r2, r1, [sl]
	successor->prev->next = node;
    5272:	f8c1 a000 	str.w	sl, [r1]
	successor->prev = node;
    5276:	f8c2 a004 	str.w	sl, [r2, #4]
	return list->head == list;
    527a:	681a      	ldr	r2, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    527c:	429a      	cmp	r2, r3
    527e:	d006      	beq.n	528e <z_add_timeout+0xe6>
		if (to == first()) {
    5280:	4592      	cmp	sl, r2
    5282:	d104      	bne.n	528e <z_add_timeout+0xe6>
			z_clock_set_timeout(next_timeout(), false);
    5284:	f7ff ff50 	bl	5128 <next_timeout>
    5288:	2100      	movs	r1, #0
    528a:	f7fc f805 	bl	1298 <z_clock_set_timeout>
	__asm__ volatile(
    528e:	f386 8811 	msr	BASEPRI, r6
    5292:	f3bf 8f6f 	isb	sy
}
    5296:	b003      	add	sp, #12
    5298:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			to->dticks -= t->dticks;
    529c:	ebb4 0008 	subs.w	r0, r4, r8
    52a0:	eb65 0109 	sbc.w	r1, r5, r9
	return (node == list->tail) ? NULL : node->next;
    52a4:	42ba      	cmp	r2, r7
    52a6:	e9ca 0104 	strd	r0, r1, [sl, #16]
    52aa:	d0c6      	beq.n	523a <z_add_timeout+0x92>
    52ac:	6812      	ldr	r2, [r2, #0]
    52ae:	e7c3      	b.n	5238 <z_add_timeout+0x90>
    52b0:	200003c0 	.word	0x200003c0
    52b4:	20003418 	.word	0x20003418

000052b8 <z_timeout_expires>:

	return ticks;
}

k_ticks_t z_timeout_expires(struct _timeout *timeout)
{
    52b8:	b510      	push	{r4, lr}
	__asm__ volatile(
    52ba:	f04f 0320 	mov.w	r3, #32
    52be:	f3ef 8411 	mrs	r4, BASEPRI
    52c2:	f383 8811 	msr	BASEPRI, r3
    52c6:	f3bf 8f6f 	isb	sy
	k_ticks_t ticks = 0;

	LOCKED(&timeout_lock) {
		ticks = curr_tick + timeout_rem(timeout);
    52ca:	f7ff ff47 	bl	515c <timeout_rem>
    52ce:	4a05      	ldr	r2, [pc, #20]	; (52e4 <z_timeout_expires+0x2c>)
    52d0:	e9d2 3200 	ldrd	r3, r2, [r2]
    52d4:	18c0      	adds	r0, r0, r3
    52d6:	eb42 0101 	adc.w	r1, r2, r1
	__asm__ volatile(
    52da:	f384 8811 	msr	BASEPRI, r4
    52de:	f3bf 8f6f 	isb	sy
	}

	return ticks;
}
    52e2:	bd10      	pop	{r4, pc}
    52e4:	200003c0 	.word	0x200003c0

000052e8 <z_clock_announce>:
		}
	}
}

void z_clock_announce(int32_t ticks)
{
    52e8:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    52ec:	4606      	mov	r6, r0
#ifdef CONFIG_TIMESLICING
	z_time_slice(ticks);
    52ee:	f7fe ff89 	bl	4204 <z_time_slice>
	__asm__ volatile(
    52f2:	f04f 0320 	mov.w	r3, #32
    52f6:	f3ef 8411 	mrs	r4, BASEPRI
    52fa:	f383 8811 	msr	BASEPRI, r3
    52fe:	f3bf 8f6f 	isb	sy
#endif

	k_spinlock_key_t key = k_spin_lock(&timeout_lock);

	announce_remaining = ticks;
    5302:	4d2d      	ldr	r5, [pc, #180]	; (53b8 <z_clock_announce+0xd0>)
    5304:	f8df a0b4 	ldr.w	sl, [pc, #180]	; 53bc <z_clock_announce+0xd4>
	return list->head == list;
    5308:	f8df b0b4 	ldr.w	fp, [pc, #180]	; 53c0 <z_clock_announce+0xd8>
    530c:	602e      	str	r6, [r5, #0]

	while (first() != NULL && first()->dticks <= announce_remaining) {
    530e:	4651      	mov	r1, sl
    5310:	f8d5 c000 	ldr.w	ip, [r5]
    5314:	f8db 0000 	ldr.w	r0, [fp]
    5318:	4662      	mov	r2, ip
    531a:	17d3      	asrs	r3, r2, #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    531c:	4558      	cmp	r0, fp
    531e:	e9cd 2300 	strd	r2, r3, [sp]
    5322:	e9da 8900 	ldrd	r8, r9, [sl]
    5326:	d00e      	beq.n	5346 <z_clock_announce+0x5e>
    5328:	b168      	cbz	r0, 5346 <z_clock_announce+0x5e>
    532a:	e9d0 6704 	ldrd	r6, r7, [r0, #16]
    532e:	42bb      	cmp	r3, r7
    5330:	bf08      	it	eq
    5332:	45b4      	cmpeq	ip, r6
    5334:	d21e      	bcs.n	5374 <z_clock_announce+0x8c>
		t->fn(t);
		key = k_spin_lock(&timeout_lock);
	}

	if (first() != NULL) {
		first()->dticks -= announce_remaining;
    5336:	9b00      	ldr	r3, [sp, #0]
    5338:	ebb6 0c03 	subs.w	ip, r6, r3
    533c:	9b01      	ldr	r3, [sp, #4]
    533e:	eb67 0603 	sbc.w	r6, r7, r3
    5342:	e9c0 c604 	strd	ip, r6, [r0, #16]
	}

	curr_tick += announce_remaining;
    5346:	9b00      	ldr	r3, [sp, #0]
    5348:	eb13 0208 	adds.w	r2, r3, r8
    534c:	9b01      	ldr	r3, [sp, #4]
	announce_remaining = 0;
    534e:	f04f 0600 	mov.w	r6, #0
	curr_tick += announce_remaining;
    5352:	eb43 0309 	adc.w	r3, r3, r9
    5356:	e9c1 2300 	strd	r2, r3, [r1]
	announce_remaining = 0;
    535a:	602e      	str	r6, [r5, #0]

	z_clock_set_timeout(next_timeout(), false);
    535c:	f7ff fee4 	bl	5128 <next_timeout>
    5360:	4631      	mov	r1, r6
    5362:	f7fb ff99 	bl	1298 <z_clock_set_timeout>
	__asm__ volatile(
    5366:	f384 8811 	msr	BASEPRI, r4
    536a:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&timeout_lock, key);
}
    536e:	b003      	add	sp, #12
    5370:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		curr_tick += dt;
    5374:	eb18 0806 	adds.w	r8, r8, r6
		t->dticks = 0;
    5378:	f04f 0200 	mov.w	r2, #0
    537c:	f04f 0300 	mov.w	r3, #0
		curr_tick += dt;
    5380:	eb49 79e6 	adc.w	r9, r9, r6, asr #31
		t->dticks = 0;
    5384:	e9c0 2304 	strd	r2, r3, [r0, #16]
		announce_remaining -= dt;
    5388:	ebac 0606 	sub.w	r6, ip, r6
		curr_tick += dt;
    538c:	e9ca 8900 	strd	r8, r9, [sl]
		announce_remaining -= dt;
    5390:	602e      	str	r6, [r5, #0]
		remove_timeout(t);
    5392:	f7ff feaf 	bl	50f4 <remove_timeout>
    5396:	f384 8811 	msr	BASEPRI, r4
    539a:	f3bf 8f6f 	isb	sy
		t->fn(t);
    539e:	6883      	ldr	r3, [r0, #8]
    53a0:	4798      	blx	r3
	__asm__ volatile(
    53a2:	f04f 0320 	mov.w	r3, #32
    53a6:	f3ef 8411 	mrs	r4, BASEPRI
    53aa:	f383 8811 	msr	BASEPRI, r3
    53ae:	f3bf 8f6f 	isb	sy

	/* Note that we need to use the underlying arch-specific lock
	 * implementation.  The "irq_lock()" API in SMP context is
	 * actually a wrapper for a global spinlock!
	 */
	k.key = arch_irq_lock();
    53b2:	4902      	ldr	r1, [pc, #8]	; (53bc <z_clock_announce+0xd4>)
#endif

#ifdef CONFIG_SPIN_VALIDATE
	z_spin_lock_set_owner(l);
#endif
	return k;
    53b4:	e7ac      	b.n	5310 <z_clock_announce+0x28>
    53b6:	bf00      	nop
    53b8:	20000f28 	.word	0x20000f28
    53bc:	200003c0 	.word	0x200003c0
    53c0:	20003418 	.word	0x20003418

000053c4 <z_tick_get>:

int64_t z_tick_get(void)
{
    53c4:	b510      	push	{r4, lr}
    53c6:	f04f 0320 	mov.w	r3, #32
    53ca:	f3ef 8411 	mrs	r4, BASEPRI
    53ce:	f383 8811 	msr	BASEPRI, r3
    53d2:	f3bf 8f6f 	isb	sy
	uint64_t t = 0U;

	LOCKED(&timeout_lock) {
		t = curr_tick + z_clock_elapsed();
    53d6:	f7fb ffcb 	bl	1370 <z_clock_elapsed>
    53da:	4b06      	ldr	r3, [pc, #24]	; (53f4 <z_tick_get+0x30>)
    53dc:	e9d3 2300 	ldrd	r2, r3, [r3]
    53e0:	1812      	adds	r2, r2, r0
    53e2:	f143 0300 	adc.w	r3, r3, #0
	__asm__ volatile(
    53e6:	f384 8811 	msr	BASEPRI, r4
    53ea:	f3bf 8f6f 	isb	sy
	}
	return t;
}
    53ee:	4610      	mov	r0, r2
    53f0:	4619      	mov	r1, r3
    53f2:	bd10      	pop	{r4, pc}
    53f4:	200003c0 	.word	0x200003c0

000053f8 <z_mrsh_k_uptime_ticks>:
#include <syscalls/kernel.h>

extern int64_t z_vrfy_k_uptime_ticks();
uintptr_t z_mrsh_k_uptime_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    53f8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    53fa:	4d10      	ldr	r5, [pc, #64]	; (543c <z_mrsh_k_uptime_ticks+0x44>)
    53fc:	9a08      	ldr	r2, [sp, #32]
    53fe:	68ab      	ldr	r3, [r5, #8]
    5400:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    5404:	4604      	mov	r4, r0
#endif
}

int64_t z_impl_k_uptime_ticks(void)
{
	return z_tick_get();
    5406:	f7ff ffdd 	bl	53c4 <z_tick_get>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int64_t ret = z_vrfy_k_uptime_ticks()
;
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(((uint64_t *)arg0), 8));
    540a:	2201      	movs	r2, #1
    540c:	4607      	mov	r7, r0
    540e:	460e      	mov	r6, r1
    5410:	4620      	mov	r0, r4
    5412:	2108      	movs	r1, #8
    5414:	f000 fe8e 	bl	6134 <arch_buffer_validate>
    5418:	462a      	mov	r2, r5
    541a:	b148      	cbz	r0, 5430 <z_mrsh_k_uptime_ticks+0x38>
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    541c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5420:	b90b      	cbnz	r3, 5426 <z_mrsh_k_uptime_ticks+0x2e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5422:	f3ef 8314 	mrs	r3, CONTROL
    5426:	6893      	ldr	r3, [r2, #8]
    5428:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    542c:	f000 fe54 	bl	60d8 <arch_syscall_oops>
	*((uint64_t *)arg0) = ret;
	_current->syscall_frame = NULL;
    5430:	68aa      	ldr	r2, [r5, #8]
	*((uint64_t *)arg0) = ret;
    5432:	e9c4 7600 	strd	r7, r6, [r4]
	_current->syscall_frame = NULL;
    5436:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    543a:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    543c:	20000eec 	.word	0x20000eec

00005440 <z_mrsh_k_futex_wake>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_futex_wake(struct k_futex * futex, bool wake_all);
uintptr_t z_mrsh_k_futex_wake(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5440:	b573      	push	{r0, r1, r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    5442:	4c0e      	ldr	r4, [pc, #56]	; (547c <z_mrsh_k_futex_wake+0x3c>)
    5444:	9a08      	ldr	r2, [sp, #32]
    5446:	68a3      	ldr	r3, [r4, #8]
{
    5448:	9101      	str	r1, [sp, #4]
	_current->syscall_frame = ssf;
    544a:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_futex_wake(*(struct k_futex **)&arg0, *(bool*)&arg1)
    544e:	b2ce      	uxtb	r6, r1
	return woken;
}

static inline int z_vrfy_k_futex_wake(struct k_futex *futex, bool wake_all)
{
	if (Z_SYSCALL_MEMORY_WRITE(futex, sizeof(struct k_futex)) != 0) {
    5450:	2201      	movs	r2, #1
    5452:	2104      	movs	r1, #4
{
    5454:	4605      	mov	r5, r0
    5456:	f000 fe6d 	bl	6134 <arch_buffer_validate>
    545a:	b148      	cbz	r0, 5470 <z_mrsh_k_futex_wake+0x30>
    545c:	f001 fc4d 	bl	6cfa <arch_is_user_context>
		return -EACCES;
    5460:	f06f 000c 	mvn.w	r0, #12
;
	_current->syscall_frame = NULL;
    5464:	68a3      	ldr	r3, [r4, #8]
    5466:	2200      	movs	r2, #0
    5468:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    546c:	b002      	add	sp, #8
    546e:	bd70      	pop	{r4, r5, r6, pc}
	}

	return z_impl_k_futex_wake(futex, wake_all);
    5470:	4631      	mov	r1, r6
    5472:	4628      	mov	r0, r5
    5474:	f001 fc4b 	bl	6d0e <z_impl_k_futex_wake>
    5478:	e7f4      	b.n	5464 <z_mrsh_k_futex_wake+0x24>
    547a:	bf00      	nop
    547c:	20000eec 	.word	0x20000eec

00005480 <z_mrsh_k_futex_wait>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_futex_wait(struct k_futex * futex, int expected, k_timeout_t timeout);
uintptr_t z_mrsh_k_futex_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5480:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    5484:	4c0f      	ldr	r4, [pc, #60]	; (54c4 <z_mrsh_k_futex_wait+0x44>)
{
    5486:	461f      	mov	r7, r3
	_current->syscall_frame = ssf;
    5488:	68a3      	ldr	r3, [r4, #8]
{
    548a:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    548c:	9a08      	ldr	r2, [sp, #32]
    548e:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    5492:	460e      	mov	r6, r1
}

static inline int z_vrfy_k_futex_wait(struct k_futex *futex, int expected,
				      k_timeout_t timeout)
{
	if (Z_SYSCALL_MEMORY_WRITE(futex, sizeof(struct k_futex)) != 0) {
    5494:	2201      	movs	r2, #1
    5496:	2104      	movs	r1, #4
    5498:	4605      	mov	r5, r0
    549a:	f000 fe4b 	bl	6134 <arch_buffer_validate>
    549e:	b148      	cbz	r0, 54b4 <z_mrsh_k_futex_wait+0x34>
    54a0:	f001 fc2b 	bl	6cfa <arch_is_user_context>
		return -EACCES;
    54a4:	f06f 000c 	mvn.w	r0, #12
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_futex_wait(*(struct k_futex **)&arg0, *(int*)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    54a8:	68a3      	ldr	r3, [r4, #8]
    54aa:	2200      	movs	r2, #0
    54ac:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    54b0:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	}

	return z_impl_k_futex_wait(futex, expected, timeout);
    54b4:	4642      	mov	r2, r8
    54b6:	463b      	mov	r3, r7
    54b8:	4631      	mov	r1, r6
    54ba:	4628      	mov	r0, r5
    54bc:	f001 fc54 	bl	6d68 <z_impl_k_futex_wait>
    54c0:	e7f2      	b.n	54a8 <z_mrsh_k_futex_wait+0x28>
    54c2:	bf00      	nop
    54c4:	20000eec 	.word	0x20000eec

000054c8 <init_mem_domain_module>:
	thread->mem_domain_info.mem_domain = NULL;
	k_spin_unlock(&lock, key);
}

static int init_mem_domain_module(struct device *arg)
{
    54c8:	b508      	push	{r3, lr}
	ARG_UNUSED(arg);

	max_partitions = arch_mem_domain_max_partitions_get();
    54ca:	f000 fe2e 	bl	612a <arch_mem_domain_max_partitions_get>
    54ce:	4b02      	ldr	r3, [pc, #8]	; (54d8 <init_mem_domain_module+0x10>)
    54d0:	7018      	strb	r0, [r3, #0]
	 * out of bounds error.
	 */
	__ASSERT(max_partitions <= CONFIG_MAX_DOMAIN_PARTITIONS, "");

	return 0;
}
    54d2:	2000      	movs	r0, #0
    54d4:	bd08      	pop	{r3, pc}
    54d6:	bf00      	nop
    54d8:	20001347 	.word	0x20001347

000054dc <app_shmem_bss_zero>:

extern char __app_shmem_regions_start[];
extern char __app_shmem_regions_end[];

static int app_shmem_bss_zero(struct device *unused)
{
    54dc:	b538      	push	{r3, r4, r5, lr}
	struct z_app_region *region, *end;

	ARG_UNUSED(unused);

	end = (struct z_app_region *)&__app_shmem_regions_end;
	region = (struct z_app_region *)&__app_shmem_regions_start;
    54de:	4c06      	ldr	r4, [pc, #24]	; (54f8 <app_shmem_bss_zero+0x1c>)

	for ( ; region < end; region++) {
    54e0:	4d06      	ldr	r5, [pc, #24]	; (54fc <app_shmem_bss_zero+0x20>)
    54e2:	42ac      	cmp	r4, r5
    54e4:	d301      	bcc.n	54ea <app_shmem_bss_zero+0xe>
		(void)memset(region->bss_start, 0, region->bss_size);
	}

	return 0;
}
    54e6:	2000      	movs	r0, #0
    54e8:	bd38      	pop	{r3, r4, r5, pc}
		(void)memset(region->bss_start, 0, region->bss_size);
    54ea:	6862      	ldr	r2, [r4, #4]
    54ec:	f854 0b08 	ldr.w	r0, [r4], #8
    54f0:	2100      	movs	r1, #0
    54f2:	f000 fe6c 	bl	61ce <memset>
	for ( ; region < end; region++) {
    54f6:	e7f4      	b.n	54e2 <app_shmem_bss_zero+0x6>
    54f8:	000072b0 	.word	0x000072b0
    54fc:	000072b0 	.word	0x000072b0

00005500 <z_thread_perms_inherit>:
{
    5500:	b530      	push	{r4, r5, lr}
    5502:	b085      	sub	sp, #20
    5504:	460d      	mov	r5, r1
    5506:	4604      	mov	r4, r0
		thread_index_get(parent),
    5508:	f001 fcc4 	bl	6e94 <thread_index_get>
	struct perm_ctx ctx = {
    550c:	9001      	str	r0, [sp, #4]
		thread_index_get(child),
    550e:	4628      	mov	r0, r5
    5510:	f001 fcc0 	bl	6e94 <thread_index_get>
	if ((ctx.parent_id != -1) && (ctx.child_id != -1)) {
    5514:	9b01      	ldr	r3, [sp, #4]
    5516:	3301      	adds	r3, #1
	struct perm_ctx ctx = {
    5518:	e9cd 0402 	strd	r0, r4, [sp, #8]
	if ((ctx.parent_id != -1) && (ctx.child_id != -1)) {
    551c:	d005      	beq.n	552a <z_thread_perms_inherit+0x2a>
    551e:	3001      	adds	r0, #1
    5520:	d003      	beq.n	552a <z_thread_perms_inherit+0x2a>
		z_object_wordlist_foreach(wordlist_cb, &ctx);
    5522:	4803      	ldr	r0, [pc, #12]	; (5530 <z_thread_perms_inherit+0x30>)
    5524:	a901      	add	r1, sp, #4
    5526:	f7fa fdf3 	bl	110 <z_object_gperf_wordlist_foreach>
}
    552a:	b005      	add	sp, #20
    552c:	bd30      	pop	{r4, r5, pc}
    552e:	bf00      	nop
    5530:	00006e59 	.word	0x00006e59

00005534 <z_thread_perms_all_clear>:
{
    5534:	b508      	push	{r3, lr}
	uintptr_t index = thread_index_get(thread);
    5536:	f001 fcad 	bl	6e94 <thread_index_get>
	if (index != -1) {
    553a:	1c43      	adds	r3, r0, #1
	uintptr_t index = thread_index_get(thread);
    553c:	4601      	mov	r1, r0
	if (index != -1) {
    553e:	d004      	beq.n	554a <z_thread_perms_all_clear+0x16>
}
    5540:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		z_object_wordlist_foreach(clear_perms_cb, (void *)index);
    5544:	4801      	ldr	r0, [pc, #4]	; (554c <z_thread_perms_all_clear+0x18>)
    5546:	f7fa bde3 	b.w	110 <z_object_gperf_wordlist_foreach>
}
    554a:	bd08      	pop	{r3, pc}
    554c:	00006e91 	.word	0x00006e91

00005550 <z_object_validate>:
{
    5550:	b538      	push	{r3, r4, r5, lr}
    5552:	4615      	mov	r5, r2
	if (unlikely((ko == NULL) ||
    5554:	4604      	mov	r4, r0
    5556:	b368      	cbz	r0, 55b4 <z_object_validate+0x64>
    5558:	b111      	cbz	r1, 5560 <z_object_validate+0x10>
    555a:	7983      	ldrb	r3, [r0, #6]
    555c:	428b      	cmp	r3, r1
    555e:	d129      	bne.n	55b4 <z_object_validate+0x64>
	if ((ko->flags & K_OBJ_FLAG_PUBLIC) != 0U) {
    5560:	79e3      	ldrb	r3, [r4, #7]
    5562:	079a      	lsls	r2, r3, #30
    5564:	d50a      	bpl.n	557c <z_object_validate+0x2c>
	if (likely(init == _OBJ_INIT_TRUE)) {
    5566:	2d00      	cmp	r5, #0
    5568:	d01c      	beq.n	55a4 <z_object_validate+0x54>
	} else if (init < _OBJ_INIT_TRUE) { /* _OBJ_INIT_FALSE case */
    556a:	da26      	bge.n	55ba <z_object_validate+0x6a>
		if (unlikely((ko->flags & K_OBJ_FLAG_INITIALIZED) != 0U)) {
    556c:	79e3      	ldrb	r3, [r4, #7]
			return -EADDRINUSE;
    556e:	f013 0f01 	tst.w	r3, #1
    5572:	bf0c      	ite	eq
    5574:	2000      	moveq	r0, #0
    5576:	f06f 002f 	mvnne.w	r0, #47	; 0x2f
    557a:	e01a      	b.n	55b2 <z_object_validate+0x62>
	index = thread_index_get(_current);
    557c:	4b10      	ldr	r3, [pc, #64]	; (55c0 <z_object_validate+0x70>)
    557e:	6898      	ldr	r0, [r3, #8]
    5580:	f001 fc88 	bl	6e94 <thread_index_get>
	if (index != -1) {
    5584:	1c43      	adds	r3, r0, #1
    5586:	d014      	beq.n	55b2 <z_object_validate+0x62>
}

static ALWAYS_INLINE
	int sys_bitfield_test_bit(mem_addr_t addr, unsigned int bit)
{
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    5588:	0942      	lsrs	r2, r0, #5
		return sys_bitfield_test_bit((mem_addr_t)&ko->perms, index);
    558a:	1d23      	adds	r3, r4, #4
    558c:	f000 001f 	and.w	r0, r0, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    5590:	f853 2022 	ldr.w	r2, [r3, r2, lsl #2]
	return temp & (1 << bit);
    5594:	2301      	movs	r3, #1
    5596:	fa03 f000 	lsl.w	r0, r3, r0
	if (unlikely(thread_perms_test(ko) == 0)) {
    559a:	4210      	tst	r0, r2
    559c:	d1e3      	bne.n	5566 <z_object_validate+0x16>
		return -EPERM;
    559e:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    55a2:	e006      	b.n	55b2 <z_object_validate+0x62>
		if (unlikely((ko->flags & K_OBJ_FLAG_INITIALIZED) == 0U)) {
    55a4:	79e3      	ldrb	r3, [r4, #7]
			return -EINVAL;
    55a6:	f013 0f01 	tst.w	r3, #1
    55aa:	bf14      	ite	ne
    55ac:	2000      	movne	r0, #0
    55ae:	f06f 0015 	mvneq.w	r0, #21
}
    55b2:	bd38      	pop	{r3, r4, r5, pc}
		return -EBADF;
    55b4:	f06f 0008 	mvn.w	r0, #8
    55b8:	e7fb      	b.n	55b2 <z_object_validate+0x62>
	return 0;
    55ba:	2000      	movs	r0, #0
    55bc:	e7f9      	b.n	55b2 <z_object_validate+0x62>
    55be:	bf00      	nop
    55c0:	20000eec 	.word	0x20000eec

000055c4 <statics_init>:
	z_waitq_init(&h->wait_q);
	sys_heap_init(&h->heap, mem, bytes);
}

static int statics_init(struct device *unused)
{
    55c4:	b538      	push	{r3, r4, r5, lr}
	ARG_UNUSED(unused);
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    55c6:	4c06      	ldr	r4, [pc, #24]	; (55e0 <statics_init+0x1c>)
    55c8:	4d06      	ldr	r5, [pc, #24]	; (55e4 <statics_init+0x20>)
    55ca:	42ac      	cmp	r4, r5
    55cc:	d301      	bcc.n	55d2 <statics_init+0xe>
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
	}
	return 0;
}
    55ce:	2000      	movs	r0, #0
    55d0:	bd38      	pop	{r3, r4, r5, pc}
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
    55d2:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
    55d6:	4620      	mov	r0, r4
    55d8:	f001 fcf8 	bl	6fcc <k_heap_init>
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    55dc:	3414      	adds	r4, #20
    55de:	e7f4      	b.n	55ca <statics_init+0x6>
    55e0:	20003460 	.word	0x20003460
    55e4:	20003474 	.word	0x20003474

000055e8 <z_mrsh_k_object_access_grant>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_object_access_grant(void * object, struct k_thread * thread);
uintptr_t z_mrsh_k_object_access_grant(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    55e8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    55ea:	4d12      	ldr	r5, [pc, #72]	; (5634 <z_mrsh_k_object_access_grant+0x4c>)
    55ec:	9a08      	ldr	r2, [sp, #32]
    55ee:	68ab      	ldr	r3, [r5, #8]
{
    55f0:	4607      	mov	r7, r0
	_current->syscall_frame = ssf;
    55f2:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
static inline void z_vrfy_k_object_access_grant(void *object,
						struct k_thread *thread)
{
	struct z_object *ko;

	Z_OOPS(Z_SYSCALL_OBJ_INIT(thread, K_OBJ_THREAD));
    55f6:	4608      	mov	r0, r1
{
    55f8:	460e      	mov	r6, r1
    55fa:	f7fa fd6f 	bl	dc <z_object_find>
    55fe:	2201      	movs	r2, #1
    5600:	2109      	movs	r1, #9
    5602:	f7ff ffa5 	bl	5550 <z_object_validate>
    5606:	4604      	mov	r4, r0
    5608:	b130      	cbz	r0, 5618 <z_mrsh_k_object_access_grant+0x30>
    560a:	f001 fd64 	bl	70d6 <arch_is_user_context>
	ko = validate_any_object(object);
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    560e:	68ab      	ldr	r3, [r5, #8]
    5610:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5614:	f000 fd60 	bl	60d8 <arch_syscall_oops>
	ko = validate_any_object(object);
    5618:	4638      	mov	r0, r7
    561a:	f001 fd66 	bl	70ea <validate_any_object>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    561e:	2800      	cmp	r0, #0
    5620:	d0f3      	beq.n	560a <z_mrsh_k_object_access_grant+0x22>
				    object));
	z_thread_perms_set(ko, thread);
    5622:	4631      	mov	r1, r6
    5624:	f001 fc51 	bl	6eca <z_thread_perms_set>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_object_access_grant(*(void **)&arg0, *(struct k_thread **)&arg1)
;
	_current->syscall_frame = NULL;
    5628:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    562a:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    562c:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    5630:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    5632:	bf00      	nop
    5634:	20000eec 	.word	0x20000eec

00005638 <z_mrsh_k_object_release>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_object_release(void * object);
uintptr_t z_mrsh_k_object_release(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    5638:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    563a:	4c0b      	ldr	r4, [pc, #44]	; (5668 <z_mrsh_k_object_release+0x30>)
    563c:	9a04      	ldr	r2, [sp, #16]
    563e:	68a3      	ldr	r3, [r4, #8]
    5640:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

static inline void z_vrfy_k_object_release(void *object)
{
	struct z_object *ko;

	ko = validate_any_object((void *)object);
    5644:	f001 fd51 	bl	70ea <validate_any_object>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    5648:	b930      	cbnz	r0, 5658 <z_mrsh_k_object_release+0x20>
    564a:	f001 fd44 	bl	70d6 <arch_is_user_context>
    564e:	68a3      	ldr	r3, [r4, #8]
    5650:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    5654:	f000 fd40 	bl	60d8 <arch_syscall_oops>
				    (void *)object));
	z_thread_perms_clear(ko, _current);
    5658:	68a1      	ldr	r1, [r4, #8]
    565a:	f001 fc4a 	bl	6ef2 <z_thread_perms_clear>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_object_release(*(void **)&arg0)
;
	_current->syscall_frame = NULL;
    565e:	68a3      	ldr	r3, [r4, #8]
    5660:	2000      	movs	r0, #0
    5662:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    5666:	bd10      	pop	{r4, pc}
    5668:	20000eec 	.word	0x20000eec

0000566c <z_mrsh_k_object_alloc>:

extern void * z_vrfy_k_object_alloc(enum k_objects otype);
uintptr_t z_mrsh_k_object_alloc(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    566c:	4b02      	ldr	r3, [pc, #8]	; (5678 <z_mrsh_k_object_alloc+0xc>)
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_object_alloc(*(enum k_objects*)&arg0)
;
	_current->syscall_frame = NULL;
    566e:	689b      	ldr	r3, [r3, #8]
    5670:	2000      	movs	r0, #0
    5672:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    5676:	4770      	bx	lr
    5678:	20000eec 	.word	0x20000eec

0000567c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    567c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5680:	b923      	cbnz	r3, 568c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5682:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5686:	f000 0001 	and.w	r0, r0, #1
    568a:	4770      	bx	lr
		return false;
    568c:	2000      	movs	r0, #0
}
    568e:	4770      	bx	lr

00005690 <k_sleep>:
{
    5690:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    5694:	4602      	mov	r2, r0
	ret = arch_is_user_context();
    5696:	f7ff fff1 	bl	567c <arch_is_user_context>
	if (z_syscall_trap()) {
    569a:	b120      	cbz	r0, 56a6 <k_sleep+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    569c:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    569e:	2688      	movs	r6, #136	; 0x88
	__asm__ volatile("svc %[svid]\n"
    56a0:	df03      	svc	3
}
    56a2:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    56a6:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_k_sleep(timeout);
    56aa:	4610      	mov	r0, r2
    56ac:	f7ff b82c 	b.w	4708 <z_impl_k_sleep>

000056b0 <k_thread_suspend>:
{
    56b0:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    56b4:	4602      	mov	r2, r0
    56b6:	f7ff ffe1 	bl	567c <arch_is_user_context>
	if (z_syscall_trap()) {
    56ba:	b120      	cbz	r0, 56c6 <k_thread_suspend+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    56bc:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    56be:	269a      	movs	r6, #154	; 0x9a
	__asm__ volatile("svc %[svid]\n"
    56c0:	df03      	svc	3
}
    56c2:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    56c6:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_thread_suspend(thread);
    56ca:	4610      	mov	r0, r2
    56cc:	f7fe bdd0 	b.w	4270 <z_impl_k_thread_suspend>

000056d0 <gpio_pin_configure.constprop.0>:
static inline int gpio_pin_configure(struct device *port, gpio_pin_t pin,
    56d0:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
	struct gpio_driver_data *data =
    56d4:	68c7      	ldr	r7, [r0, #12]
	ret = gpio_config(port, pin, flags);
    56d6:	f88d 1007 	strb.w	r1, [sp, #7]
static inline int gpio_pin_configure(struct device *port, gpio_pin_t pin,
    56da:	4604      	mov	r4, r0
    56dc:	460d      	mov	r5, r1
    56de:	f7ff ffcd 	bl	567c <arch_is_user_context>

extern int z_impl_gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
static inline int gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    56e2:	b180      	cbz	r0, 5706 <gpio_pin_configure.constprop.0+0x36>
	register uint32_t ret __asm__("r0") = arg1;
    56e4:	4620      	mov	r0, r4
	register uint32_t r1 __asm__("r1") = arg2;
    56e6:	f8dd 1007 	ldr.w	r1, [sp, #7]
	register uint32_t r2 __asm__("r2") = arg3;
    56ea:	f240 6201 	movw	r2, #1537	; 0x601
	register uint32_t r6 __asm__("r6") = call_id;
    56ee:	2644      	movs	r6, #68	; 0x44
	__asm__ volatile("svc %[svid]\n"
    56f0:	df03      	svc	3
	if (ret != 0) {
    56f2:	b928      	cbnz	r0, 5700 <gpio_pin_configure.constprop.0+0x30>
		data->invert |= (gpio_port_pins_t)BIT(pin);
    56f4:	2301      	movs	r3, #1
    56f6:	fa03 f505 	lsl.w	r5, r3, r5
    56fa:	683b      	ldr	r3, [r7, #0]
    56fc:	432b      	orrs	r3, r5
    56fe:	603b      	str	r3, [r7, #0]
}
    5700:	b002      	add	sp, #8
    5702:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return api->pin_configure(port, pin, flags);
    5706:	68a3      	ldr	r3, [r4, #8]
    5708:	f89d 1007 	ldrb.w	r1, [sp, #7]
    570c:	681b      	ldr	r3, [r3, #0]
    570e:	f240 6201 	movw	r2, #1537	; 0x601
    5712:	4620      	mov	r0, r4
    5714:	4798      	blx	r3
		return (int) arch_syscall_invoke3(*(uintptr_t *)&port, *(uintptr_t *)&pin, *(uintptr_t *)&flags, K_SYSCALL_GPIO_CONFIG);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_config(port, pin, flags);
    5716:	e7ec      	b.n	56f2 <gpio_pin_configure.constprop.0+0x22>

00005718 <k_thread_create.constprop.0>:
static inline k_tid_t k_thread_create(struct k_thread * new_thread, k_thread_stack_t * stack, size_t stack_size, k_thread_entry_t entry, void * p1, void * p2, void * p3, int prio, uint32_t options, k_timeout_t delay)
    5718:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    571c:	b08e      	sub	sp, #56	; 0x38
    571e:	4616      	mov	r6, r2
    5720:	4605      	mov	r5, r0
    5722:	e9dd 7214 	ldrd	r7, r2, [sp, #80]	; 0x50
    5726:	f7ff ffa9 	bl	567c <arch_is_user_context>
	if (z_syscall_trap()) {
    572a:	b188      	cbz	r0, 5750 <k_thread_create.constprop.0+0x38>
		uintptr_t more[] = {
    572c:	2400      	movs	r4, #0
    572e:	2305      	movs	r3, #5
    5730:	e9cd 340a 	strd	r3, r4, [sp, #40]	; 0x28
    5734:	e9cd 720c 	strd	r7, r2, [sp, #48]	; 0x30
	register uint32_t ret __asm__("r0") = arg1;
    5738:	4628      	mov	r0, r5
	register uint32_t r3 __asm__("r3") = arg4;
    573a:	4633      	mov	r3, r6
    573c:	e9cd 4408 	strd	r4, r4, [sp, #32]
	register uint32_t r2 __asm__("r2") = arg3;
    5740:	f44f 7200 	mov.w	r2, #512	; 0x200
	register uint32_t r5 __asm__("r5") = arg6;
    5744:	ad08      	add	r5, sp, #32
	register uint32_t r6 __asm__("r6") = call_id;
    5746:	268e      	movs	r6, #142	; 0x8e
	__asm__ volatile("svc %[svid]\n"
    5748:	df03      	svc	3
}
    574a:	b00e      	add	sp, #56	; 0x38
    574c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
    5750:	2305      	movs	r3, #5
    5752:	e9cd 0302 	strd	r0, r3, [sp, #8]
    5756:	e9cd 7206 	strd	r7, r2, [sp, #24]
    575a:	e9cd 0000 	strd	r0, r0, [sp]
    575e:	9004      	str	r0, [sp, #16]
    5760:	4633      	mov	r3, r6
    5762:	f44f 7200 	mov.w	r2, #512	; 0x200
    5766:	4628      	mov	r0, r5
    5768:	f001 fa22 	bl	6bb0 <z_impl_k_thread_create>
    576c:	e7ed      	b.n	574a <k_thread_create.constprop.0+0x32>

0000576e <k_thread_name_set>:
{
    576e:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    5772:	4602      	mov	r2, r0
    5774:	f7ff ff82 	bl	567c <arch_is_user_context>
	if (z_syscall_trap()) {
    5778:	b120      	cbz	r0, 5784 <k_thread_name_set+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    577a:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    577c:	2694      	movs	r6, #148	; 0x94
	__asm__ volatile("svc %[svid]\n"
    577e:	df03      	svc	3
}
    5780:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    5784:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_k_thread_name_set(thread_id, value);
    5788:	4610      	mov	r0, r2
    578a:	f001 ba07 	b.w	6b9c <z_impl_k_thread_name_set>

0000578e <gpio_port_set_bits_raw>:
}


extern int z_impl_gpio_port_set_bits_raw(struct device * port, gpio_port_pins_t pins);
static inline int gpio_port_set_bits_raw(struct device * port, gpio_port_pins_t pins)
{
    578e:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    5792:	4602      	mov	r2, r0
    5794:	f7ff ff72 	bl	567c <arch_is_user_context>
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    5798:	b120      	cbz	r0, 57a4 <gpio_port_set_bits_raw+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    579a:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    579c:	2649      	movs	r6, #73	; 0x49
	__asm__ volatile("svc %[svid]\n"
    579e:	df03      	svc	3
		return (int) arch_syscall_invoke2(*(uintptr_t *)&port, *(uintptr_t *)&pins, K_SYSCALL_GPIO_PORT_SET_BITS_RAW);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_port_set_bits_raw(port, pins);
}
    57a0:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return api->port_set_bits_raw(port, pins);
    57a4:	6893      	ldr	r3, [r2, #8]
    57a6:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
    57aa:	68db      	ldr	r3, [r3, #12]
    57ac:	4610      	mov	r0, r2
    57ae:	4718      	bx	r3

000057b0 <gpio_port_clear_bits_raw>:


extern int z_impl_gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins);
static inline int gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins)
{
    57b0:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    57b4:	4602      	mov	r2, r0
    57b6:	f7ff ff61 	bl	567c <arch_is_user_context>
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    57ba:	b120      	cbz	r0, 57c6 <gpio_port_clear_bits_raw+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    57bc:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    57be:	2647      	movs	r6, #71	; 0x47
	__asm__ volatile("svc %[svid]\n"
    57c0:	df03      	svc	3
		return (int) arch_syscall_invoke2(*(uintptr_t *)&port, *(uintptr_t *)&pins, K_SYSCALL_GPIO_PORT_CLEAR_BITS_RAW);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_port_clear_bits_raw(port, pins);
}
    57c2:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return api->port_clear_bits_raw(port, pins);
    57c6:	6893      	ldr	r3, [r2, #8]
    57c8:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
    57cc:	691b      	ldr	r3, [r3, #16]
    57ce:	4610      	mov	r0, r2
    57d0:	4718      	bx	r3

000057d2 <k_busy_wait>:
{
    57d2:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    57d6:	4602      	mov	r2, r0
    57d8:	f7ff ff50 	bl	567c <arch_is_user_context>
	if (z_syscall_trap()) {
    57dc:	b120      	cbz	r0, 57e8 <k_busy_wait+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    57de:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    57e0:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    57e2:	df03      	svc	3
}
    57e4:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    57e8:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_busy_wait(usec_to_wait);
    57ec:	4610      	mov	r0, r2
    57ee:	f001 b9d3 	b.w	6b98 <z_impl_k_busy_wait>

000057f2 <sys_notify_validate>:

int sys_notify_validate(struct sys_notify *notify)
{
	int rv = 0;

	if (notify == NULL) {
    57f2:	4603      	mov	r3, r0
    57f4:	b158      	cbz	r0, 580e <sys_notify_validate+0x1c>
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    57f6:	6842      	ldr	r2, [r0, #4]
	return method & SYS_NOTIFY_METHOD_MASK;
    57f8:	f002 0203 	and.w	r2, r2, #3
		return -EINVAL;
	}

	/* Validate configuration based on mode */
	switch (sys_notify_get_method(notify)) {
    57fc:	2a01      	cmp	r2, #1
    57fe:	d003      	beq.n	5808 <sys_notify_validate+0x16>
    5800:	2a03      	cmp	r2, #3
    5802:	d104      	bne.n	580e <sys_notify_validate+0x1c>
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		if (notify->method.callback == NULL) {
    5804:	6802      	ldr	r2, [r0, #0]
    5806:	b112      	cbz	r2, 580e <sys_notify_validate+0x1c>
		break;
	}

	/* Clear the result here instead of in all callers. */
	if (rv == 0) {
		notify->result = 0;
    5808:	2000      	movs	r0, #0
    580a:	6098      	str	r0, [r3, #8]
    580c:	4770      	bx	lr
		return -EINVAL;
    580e:	f06f 0015 	mvn.w	r0, #21
	}

	return rv;
}
    5812:	4770      	bx	lr

00005814 <sys_notify_finalize>:
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    5814:	6842      	ldr	r2, [r0, #4]
	uint32_t method = sys_notify_get_method(notify);

	/* Store the result and capture secondary notification
	 * information.
	 */
	notify->result = res;
    5816:	6081      	str	r1, [r0, #8]
	return method & SYS_NOTIFY_METHOD_MASK;
    5818:	f002 0203 	and.w	r2, r2, #3
	switch (method) {
    581c:	2a03      	cmp	r2, #3
    581e:	f04f 0200 	mov.w	r2, #0
{
    5822:	4603      	mov	r3, r0
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		rv = notify->method.callback;
    5824:	bf0c      	ite	eq
    5826:	6800      	ldreq	r0, [r0, #0]
	sys_notify_generic_callback rv = 0;
    5828:	4610      	movne	r0, r2
	/* Mark completion by clearing the flags field to the
	 * completed state, releasing any spin-waiters, then complete
	 * secondary notification.
	 */
	compiler_barrier();
	notify->flags = SYS_NOTIFY_METHOD_COMPLETED;
    582a:	605a      	str	r2, [r3, #4]
	if (IS_ENABLED(CONFIG_POLL) && (sig != NULL)) {
		k_poll_signal_raise(sig, res);
	}

	return rv;
}
    582c:	4770      	bx	lr

0000582e <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    582e:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5832:	b923      	cbnz	r3, 583e <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5834:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5838:	f000 0001 	and.w	r0, r0, #1
    583c:	4770      	bx	lr
		return false;
    583e:	2000      	movs	r0, #0
}
    5840:	4770      	bx	lr

00005842 <arch_printk_char_out>:
}
    5842:	2000      	movs	r0, #0
    5844:	4770      	bx	lr

00005846 <buf_flush>:
{
    5846:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	k_str_out(ctx->buf, ctx->buf_count);
    584a:	6841      	ldr	r1, [r0, #4]
{
    584c:	4604      	mov	r4, r0
	k_str_out(ctx->buf, ctx->buf_count);
    584e:	f100 0208 	add.w	r2, r0, #8
    5852:	f7ff ffec 	bl	582e <arch_is_user_context>

extern void z_impl_k_str_out(char * c, size_t n);
static inline void k_str_out(char * c, size_t n)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    5856:	b130      	cbz	r0, 5866 <buf_flush+0x20>
	register uint32_t ret __asm__("r0") = arg1;
    5858:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    585a:	268c      	movs	r6, #140	; 0x8c
	__asm__ volatile("svc %[svid]\n"
    585c:	df03      	svc	3
	ctx->buf_count = 0U;
    585e:	2300      	movs	r3, #0
    5860:	6063      	str	r3, [r4, #4]
}
    5862:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
		arch_syscall_invoke2(*(uintptr_t *)&c, *(uintptr_t *)&n, K_SYSCALL_K_STR_OUT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_str_out(c, n);
    5866:	4610      	mov	r0, r2
    5868:	f7fb f93c 	bl	ae4 <z_impl_k_str_out>
    586c:	e7f7      	b.n	585e <buf_flush+0x18>

0000586e <buf_char_out>:
	ctx->count++;
    586e:	680b      	ldr	r3, [r1, #0]
    5870:	3301      	adds	r3, #1
    5872:	600b      	str	r3, [r1, #0]
	ctx->buf[ctx->buf_count++] = c;
    5874:	684b      	ldr	r3, [r1, #4]
    5876:	1c5a      	adds	r2, r3, #1
    5878:	440b      	add	r3, r1
{
    587a:	b510      	push	{r4, lr}
	if (ctx->buf_count == CONFIG_PRINTK_BUFFER_SIZE) {
    587c:	2a20      	cmp	r2, #32
{
    587e:	4604      	mov	r4, r0
	ctx->buf[ctx->buf_count++] = c;
    5880:	604a      	str	r2, [r1, #4]
{
    5882:	4608      	mov	r0, r1
	ctx->buf[ctx->buf_count++] = c;
    5884:	721c      	strb	r4, [r3, #8]
	if (ctx->buf_count == CONFIG_PRINTK_BUFFER_SIZE) {
    5886:	d101      	bne.n	588c <buf_char_out+0x1e>
		buf_flush(ctx);
    5888:	f7ff ffdd 	bl	5846 <buf_flush>
}
    588c:	4620      	mov	r0, r4
    588e:	bd10      	pop	{r4, pc}

00005890 <printk>:
 * @param fmt formatted string to output
 *
 * @return N/A
 */
void printk(const char *fmt, ...)
{
    5890:	b40f      	push	{r0, r1, r2, r3}
    5892:	b507      	push	{r0, r1, r2, lr}
    5894:	a904      	add	r1, sp, #16
    5896:	f851 0b04 	ldr.w	r0, [r1], #4
	va_list ap;

	va_start(ap, fmt);
    589a:	9101      	str	r1, [sp, #4]

	if (IS_ENABLED(CONFIG_LOG_PRINTK)) {
		log_printk(fmt, ap);
	} else {
		vprintk(fmt, ap);
    589c:	f7fb f930 	bl	b00 <vprintk>
	}
	va_end(ap);
}
    58a0:	b003      	add	sp, #12
    58a2:	f85d eb04 	ldr.w	lr, [sp], #4
    58a6:	b004      	add	sp, #16
    58a8:	4770      	bx	lr

000058aa <process_recheck>:
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    58aa:	8b03      	ldrh	r3, [r0, #24]
	if ((state == ONOFF_STATE_OFF)
    58ac:	f013 0307 	ands.w	r3, r3, #7
    58b0:	d105      	bne.n	58be <process_recheck+0x14>
	    && !sys_slist_is_empty(&mgr->clients)) {
    58b2:	6803      	ldr	r3, [r0, #0]
    58b4:	2b00      	cmp	r3, #0
		evt = EVT_START;
    58b6:	bf0c      	ite	eq
    58b8:	2000      	moveq	r0, #0
    58ba:	2003      	movne	r0, #3
    58bc:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ON)
    58be:	2b02      	cmp	r3, #2
    58c0:	d105      	bne.n	58ce <process_recheck+0x24>
		   && (mgr->refs == 0)) {
    58c2:	8b43      	ldrh	r3, [r0, #26]
    58c4:	2b00      	cmp	r3, #0
		evt = EVT_STOP;
    58c6:	bf14      	ite	ne
    58c8:	2000      	movne	r0, #0
    58ca:	2004      	moveq	r0, #4
    58cc:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ERROR)
    58ce:	2b01      	cmp	r3, #1
    58d0:	d105      	bne.n	58de <process_recheck+0x34>
		   && !sys_slist_is_empty(&mgr->clients)) {
    58d2:	6803      	ldr	r3, [r0, #0]
    58d4:	2b00      	cmp	r3, #0
		evt = EVT_RESET;
    58d6:	bf0c      	ite	eq
    58d8:	2000      	moveq	r0, #0
    58da:	2005      	movne	r0, #5
    58dc:	4770      	bx	lr
	int evt = EVT_NOP;
    58de:	2000      	movs	r0, #0
}
    58e0:	4770      	bx	lr

000058e2 <validate_args>:
{
    58e2:	b510      	push	{r4, lr}
    58e4:	460c      	mov	r4, r1
	if ((mgr == NULL) || (cli == NULL)) {
    58e6:	b140      	cbz	r0, 58fa <validate_args+0x18>
    58e8:	b139      	cbz	r1, 58fa <validate_args+0x18>
	int rv = sys_notify_validate(&cli->notify);
    58ea:	1d08      	adds	r0, r1, #4
    58ec:	f7ff ff81 	bl	57f2 <sys_notify_validate>
	if ((rv == 0)
    58f0:	b928      	cbnz	r0, 58fe <validate_args+0x1c>
	    && ((cli->notify.flags
    58f2:	68a3      	ldr	r3, [r4, #8]
    58f4:	f033 0303 	bics.w	r3, r3, #3
    58f8:	d001      	beq.n	58fe <validate_args+0x1c>
		rv = -EINVAL;
    58fa:	f06f 0015 	mvn.w	r0, #21
}
    58fe:	bd10      	pop	{r4, pc}

00005900 <transition_complete>:
{
    5900:	b410      	push	{r4}
	__asm__ volatile(
    5902:	f04f 0420 	mov.w	r4, #32
    5906:	f3ef 8211 	mrs	r2, BASEPRI
    590a:	f384 8811 	msr	BASEPRI, r4
    590e:	f3bf 8f6f 	isb	sy
	mgr->last_res = res;
    5912:	6141      	str	r1, [r0, #20]
}
    5914:	bc10      	pop	{r4}
	process_event(mgr, EVT_COMPLETE, key);
    5916:	2101      	movs	r1, #1
    5918:	f7fb b938 	b.w	b8c <process_event>

0000591c <onoff_manager_init>:
{
    591c:	b538      	push	{r3, r4, r5, lr}
    591e:	460c      	mov	r4, r1
	if ((mgr == NULL)
    5920:	4605      	mov	r5, r0
    5922:	b158      	cbz	r0, 593c <onoff_manager_init+0x20>
	    || (transitions == NULL)
    5924:	b151      	cbz	r1, 593c <onoff_manager_init+0x20>
	    || (transitions->start == NULL)
    5926:	680b      	ldr	r3, [r1, #0]
    5928:	b143      	cbz	r3, 593c <onoff_manager_init+0x20>
	    || (transitions->stop == NULL)) {
    592a:	684b      	ldr	r3, [r1, #4]
    592c:	b133      	cbz	r3, 593c <onoff_manager_init+0x20>
	*mgr = (struct onoff_manager)ONOFF_MANAGER_INITIALIZER(transitions);
    592e:	221c      	movs	r2, #28
    5930:	2100      	movs	r1, #0
    5932:	f000 fc4c 	bl	61ce <memset>
    5936:	612c      	str	r4, [r5, #16]
	return 0;
    5938:	2000      	movs	r0, #0
}
    593a:	bd38      	pop	{r3, r4, r5, pc}
		return -EINVAL;
    593c:	f06f 0015 	mvn.w	r0, #21
    5940:	e7fb      	b.n	593a <onoff_manager_init+0x1e>

00005942 <onoff_request>:

int onoff_request(struct onoff_manager *mgr,
		  struct onoff_client *cli)
{
    5942:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5946:	4604      	mov	r4, r0
    5948:	460d      	mov	r5, r1
	bool add_client = false;        /* add client to pending list */
	bool start = false;             /* trigger a start transition */
	bool notify = false;            /* do client notification */
	int rv = validate_args(mgr, cli);
    594a:	f7ff ffca 	bl	58e2 <validate_args>

	if (rv < 0) {
    594e:	1e06      	subs	r6, r0, #0
    5950:	db36      	blt.n	59c0 <onoff_request+0x7e>
    5952:	f04f 0320 	mov.w	r3, #32
    5956:	f3ef 8211 	mrs	r2, BASEPRI
    595a:	f383 8811 	msr	BASEPRI, r3
    595e:	f3bf 8f6f 	isb	sy

	k_spinlock_key_t key = k_spin_lock(&mgr->lock);
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;

	/* Reject if this would overflow the reference count. */
	if (mgr->refs == SERVICE_REFS_MAX) {
    5962:	8b63      	ldrh	r3, [r4, #26]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    5964:	8b21      	ldrh	r1, [r4, #24]
	if (mgr->refs == SERVICE_REFS_MAX) {
    5966:	f64f 70ff 	movw	r0, #65535	; 0xffff
    596a:	4283      	cmp	r3, r0
    596c:	f001 0707 	and.w	r7, r1, #7
    5970:	d034      	beq.n	59dc <onoff_request+0x9a>
		rv = -EAGAIN;
		goto out;
	}

	rv = state;
	if (state == ONOFF_STATE_ON) {
    5972:	2f02      	cmp	r7, #2
    5974:	d114      	bne.n	59a0 <onoff_request+0x5e>
		/* Increment reference count, notify in exit */
		notify = true;
		mgr->refs += 1U;
    5976:	3301      	adds	r3, #1
    5978:	8363      	strh	r3, [r4, #26]
	rv = state;
    597a:	463e      	mov	r6, r7
		notify = true;
    597c:	2301      	movs	r3, #1
	__asm__ volatile(
    597e:	f382 8811 	msr	BASEPRI, r2
    5982:	f3bf 8f6f 	isb	sy
	if (start) {
		process_event(mgr, EVT_RECHECK, key);
	} else {
		k_spin_unlock(&mgr->lock, key);

		if (notify) {
    5986:	b1db      	cbz	r3, 59c0 <onoff_request+0x7e>
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
    5988:	2100      	movs	r1, #0
    598a:	1d28      	adds	r0, r5, #4
    598c:	f7ff ff42 	bl	5814 <sys_notify_finalize>
	if (cb) {
    5990:	4680      	mov	r8, r0
    5992:	b1a8      	cbz	r0, 59c0 <onoff_request+0x7e>
		cb(mgr, cli, state, res);
    5994:	2300      	movs	r3, #0
    5996:	463a      	mov	r2, r7
    5998:	4629      	mov	r1, r5
    599a:	4620      	mov	r0, r4
    599c:	47c0      	blx	r8
    599e:	e00f      	b.n	59c0 <onoff_request+0x7e>
	} else if ((state == ONOFF_STATE_OFF)
    59a0:	078b      	lsls	r3, r1, #30
    59a2:	d001      	beq.n	59a8 <onoff_request+0x66>
		   || (state == ONOFF_STATE_TO_ON)) {
    59a4:	2f06      	cmp	r7, #6
    59a6:	d10e      	bne.n	59c6 <onoff_request+0x84>
	parent->next = child;
    59a8:	2300      	movs	r3, #0
    59aa:	602b      	str	r3, [r5, #0]
Z_GENLIST_APPEND(slist, snode)
    59ac:	6863      	ldr	r3, [r4, #4]
    59ae:	b993      	cbnz	r3, 59d6 <onoff_request+0x94>
	list->head = node;
    59b0:	e9c4 5500 	strd	r5, r5, [r4]
	if (start) {
    59b4:	463e      	mov	r6, r7
    59b6:	b967      	cbnz	r7, 59d2 <onoff_request+0x90>
		process_event(mgr, EVT_RECHECK, key);
    59b8:	2102      	movs	r1, #2
    59ba:	4620      	mov	r0, r4
    59bc:	f7fb f8e6 	bl	b8c <process_event>
			notify_one(mgr, cli, state, 0);
		}
	}

	return rv;
}
    59c0:	4630      	mov	r0, r6
    59c2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		rv = -EIO;
    59c6:	2f05      	cmp	r7, #5
    59c8:	bf0c      	ite	eq
    59ca:	f06f 0622 	mvneq.w	r6, #34	; 0x22
    59ce:	f06f 0604 	mvnne.w	r6, #4
    59d2:	2300      	movs	r3, #0
    59d4:	e7d3      	b.n	597e <onoff_request+0x3c>
	parent->next = child;
    59d6:	601d      	str	r5, [r3, #0]
	list->tail = node;
    59d8:	6065      	str	r5, [r4, #4]
}
    59da:	e7eb      	b.n	59b4 <onoff_request+0x72>
		rv = -EAGAIN;
    59dc:	f06f 060a 	mvn.w	r6, #10
    59e0:	e7f7      	b.n	59d2 <onoff_request+0x90>

000059e2 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
    59e2:	4604      	mov	r4, r0
    59e4:	b508      	push	{r3, lr}
    59e6:	4608      	mov	r0, r1
    59e8:	4611      	mov	r1, r2
	entry(p1, p2, p3);
    59ea:	461a      	mov	r2, r3
    59ec:	47a0      	blx	r4
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    59ee:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    59f2:	b973      	cbnz	r3, 5a12 <z_thread_entry+0x30>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    59f4:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    59f8:	07da      	lsls	r2, r3, #31
    59fa:	d50a      	bpl.n	5a12 <z_thread_entry+0x30>
	register uint32_t r6 __asm__("r6") = call_id;
    59fc:	265e      	movs	r6, #94	; 0x5e
	__asm__ volatile("svc %[svid]\n"
    59fe:	df03      	svc	3
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5a00:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5a04:	b943      	cbnz	r3, 5a18 <z_thread_entry+0x36>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5a06:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    5a0a:	07db      	lsls	r3, r3, #31
    5a0c:	d504      	bpl.n	5a18 <z_thread_entry+0x36>
	register uint32_t r6 __asm__("r6") = call_id;
    5a0e:	268d      	movs	r6, #141	; 0x8d
	__asm__ volatile("svc %[svid]\n"
    5a10:	df03      	svc	3
	return z_impl_k_current_get();
    5a12:	f7fe ff01 	bl	4818 <z_impl_k_current_get>
    5a16:	e7f3      	b.n	5a00 <z_thread_entry+0x1e>
	z_impl_k_thread_abort(thread);
    5a18:	f7fc f8c2 	bl	1ba0 <z_impl_k_thread_abort>
    5a1c:	e7f9      	b.n	5a12 <z_thread_entry+0x30>

00005a1e <chunk_field>:
				 enum chunk_fields f)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    5a1e:	6883      	ldr	r3, [r0, #8]
	void *cmem = &buf[c];
    5a20:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    5a24:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
		return ((uint32_t *)cmem)[f];
    5a28:	bf2c      	ite	cs
    5a2a:	f851 0022 	ldrcs.w	r0, [r1, r2, lsl #2]
	} else {
		return ((uint16_t *)cmem)[f];
    5a2e:	f831 0012 	ldrhcc.w	r0, [r1, r2, lsl #1]
	}
}
    5a32:	4770      	bx	lr

00005a34 <chunk_set>:
			     enum chunk_fields f, chunkid_t val)
{
	CHECK(c <= h->len);

	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];
    5a34:	eb00 01c1 	add.w	r1, r0, r1, lsl #3

	if (big_heap(h)) {
    5a38:	6880      	ldr	r0, [r0, #8]
    5a3a:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
		CHECK(val == (uint32_t)val);
		((uint32_t *)cmem)[f] = val;
    5a3e:	bf2c      	ite	cs
    5a40:	f841 3022 	strcs.w	r3, [r1, r2, lsl #2]
	} else {
		CHECK(val == (uint16_t)val);
		((uint16_t *)cmem)[f] = val;
    5a44:	f821 3012 	strhcc.w	r3, [r1, r2, lsl #1]
	}
}
    5a48:	4770      	bx	lr

00005a4a <chunk_size>:
{
	return chunk_field(h, c, SIZE_AND_USED) & 1;
}

static inline size_t chunk_size(struct z_heap *h, chunkid_t c)
{
    5a4a:	b508      	push	{r3, lr}
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
    5a4c:	2201      	movs	r2, #1
    5a4e:	f7ff ffe6 	bl	5a1e <chunk_field>
}
    5a52:	0840      	lsrs	r0, r0, #1
    5a54:	bd08      	pop	{r3, pc}

00005a56 <set_chunk_used>:
static inline void set_chunk_used(struct z_heap *h, chunkid_t c, bool used)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    5a56:	6883      	ldr	r3, [r0, #8]
    5a58:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
	void *cmem = &buf[c];
    5a5c:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    5a60:	d308      	bcc.n	5a74 <set_chunk_used+0x1e>
		if (used) {
    5a62:	684b      	ldr	r3, [r1, #4]
    5a64:	b11a      	cbz	r2, 5a6e <set_chunk_used+0x18>
			((uint32_t *)cmem)[SIZE_AND_USED] |= 1;
    5a66:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint32_t *)cmem)[SIZE_AND_USED] &= ~1;
    5a6a:	604b      	str	r3, [r1, #4]
    5a6c:	4770      	bx	lr
    5a6e:	f023 0301 	bic.w	r3, r3, #1
    5a72:	e7fa      	b.n	5a6a <set_chunk_used+0x14>
		}
	} else {
		if (used) {
    5a74:	884b      	ldrh	r3, [r1, #2]
    5a76:	b11a      	cbz	r2, 5a80 <set_chunk_used+0x2a>
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1;
    5a78:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    5a7c:	804b      	strh	r3, [r1, #2]
		}
	}
}
    5a7e:	4770      	bx	lr
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    5a80:	f023 0301 	bic.w	r3, r3, #1
    5a84:	e7fa      	b.n	5a7c <set_chunk_used+0x26>

00005a86 <set_chunk_size>:
 * when its size is modified, and potential set_chunk_used() is always
 * invoked after set_chunk_size().
 */
static inline void set_chunk_size(struct z_heap *h, chunkid_t c, size_t size)
{
	chunk_set(h, c, SIZE_AND_USED, size << 1);
    5a86:	0053      	lsls	r3, r2, #1
    5a88:	2201      	movs	r2, #1
    5a8a:	f7ff bfd3 	b.w	5a34 <chunk_set>

00005a8e <bucket_idx>:
	return big_heap(h) && chunk_size(h, c) == 1;
}

static inline size_t chunk_header_bytes(struct z_heap *h)
{
	return big_heap(h) ? 8 : 4;
    5a8e:	6880      	ldr	r0, [r0, #8]
	return bytes_to_chunksz(h, 1);
}

static inline int bucket_idx(struct z_heap *h, size_t sz)
{
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    5a90:	3101      	adds	r1, #1
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    5a92:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
    5a96:	bf2c      	ite	cs
    5a98:	2002      	movcs	r0, #2
    5a9a:	2001      	movcc	r0, #1
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    5a9c:	1a08      	subs	r0, r1, r0
	return 31 - __builtin_clz(usable_sz);
    5a9e:	fab0 f080 	clz	r0, r0
}
    5aa2:	f1c0 001f 	rsb	r0, r0, #31
    5aa6:	4770      	bx	lr

00005aa8 <merge_chunks>:
	set_left_chunk_size(h, right_chunk(h, rc), rsz);
}

/* Does not modify free list */
static void merge_chunks(struct z_heap *h, chunkid_t lc, chunkid_t rc)
{
    5aa8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5aac:	4616      	mov	r6, r2
    5aae:	4604      	mov	r4, r0
    5ab0:	460f      	mov	r7, r1
	size_t newsz = chunk_size(h, lc) + chunk_size(h, rc);
    5ab2:	f7ff ffca 	bl	5a4a <chunk_size>
    5ab6:	4631      	mov	r1, r6
    5ab8:	4605      	mov	r5, r0
    5aba:	4620      	mov	r0, r4
    5abc:	f7ff ffc5 	bl	5a4a <chunk_size>
    5ac0:	4405      	add	r5, r0

	set_chunk_size(h, lc, newsz);
    5ac2:	462a      	mov	r2, r5
    5ac4:	4639      	mov	r1, r7
    5ac6:	4620      	mov	r0, r4
    5ac8:	f7ff ffdd 	bl	5a86 <set_chunk_size>
	return c + chunk_size(h, c);
    5acc:	4631      	mov	r1, r6
    5ace:	4620      	mov	r0, r4
    5ad0:	f7ff ffbb 	bl	5a4a <chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5ad4:	462b      	mov	r3, r5
    5ad6:	1831      	adds	r1, r6, r0
    5ad8:	2200      	movs	r2, #0
    5ada:	4620      	mov	r0, r4
	set_left_chunk_size(h, right_chunk(h, rc), newsz);
}
    5adc:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5ae0:	f7ff bfa8 	b.w	5a34 <chunk_set>

00005ae4 <split_chunks>:
{
    5ae4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5ae8:	4614      	mov	r4, r2
    5aea:	4605      	mov	r5, r0
    5aec:	460e      	mov	r6, r1
	size_t sz0 = chunk_size(h, lc);
    5aee:	f7ff ffac 	bl	5a4a <chunk_size>
	size_t lsz = rc - lc;
    5af2:	eba4 0806 	sub.w	r8, r4, r6
	size_t rsz = sz0 - lsz;
    5af6:	1b37      	subs	r7, r6, r4
    5af8:	4407      	add	r7, r0
	set_chunk_size(h, lc, lsz);
    5afa:	4642      	mov	r2, r8
    5afc:	4631      	mov	r1, r6
    5afe:	4628      	mov	r0, r5
    5b00:	f7ff ffc1 	bl	5a86 <set_chunk_size>
	set_chunk_size(h, rc, rsz);
    5b04:	463a      	mov	r2, r7
    5b06:	4621      	mov	r1, r4
    5b08:	4628      	mov	r0, r5
    5b0a:	f7ff ffbc 	bl	5a86 <set_chunk_size>
    5b0e:	4643      	mov	r3, r8
    5b10:	2200      	movs	r2, #0
    5b12:	4621      	mov	r1, r4
    5b14:	4628      	mov	r0, r5
    5b16:	f7ff ff8d 	bl	5a34 <chunk_set>
	return c + chunk_size(h, c);
    5b1a:	4621      	mov	r1, r4
    5b1c:	4628      	mov	r0, r5
    5b1e:	f7ff ff94 	bl	5a4a <chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5b22:	463b      	mov	r3, r7
    5b24:	1821      	adds	r1, r4, r0
    5b26:	2200      	movs	r2, #0
    5b28:	4628      	mov	r0, r5
}
    5b2a:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5b2e:	f7ff bf81 	b.w	5a34 <chunk_set>

00005b32 <free_list_remove_bidx>:
{
    5b32:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5b36:	4617      	mov	r7, r2
	return chunk_field(h, c, FREE_NEXT);
    5b38:	2203      	movs	r2, #3
    5b3a:	460e      	mov	r6, r1
    5b3c:	4604      	mov	r4, r0
    5b3e:	f7ff ff6e 	bl	5a1e <chunk_field>
	if (next_free_chunk(h, c) == c) {
    5b42:	4286      	cmp	r6, r0
    5b44:	4605      	mov	r5, r0
    5b46:	f107 0804 	add.w	r8, r7, #4
    5b4a:	d10b      	bne.n	5b64 <free_list_remove_bidx+0x32>
		h->avail_buckets &= ~(1 << bidx);
    5b4c:	2301      	movs	r3, #1
    5b4e:	fa03 f707 	lsl.w	r7, r3, r7
    5b52:	68e3      	ldr	r3, [r4, #12]
    5b54:	ea23 0307 	bic.w	r3, r3, r7
    5b58:	60e3      	str	r3, [r4, #12]
		b->next = 0;
    5b5a:	2300      	movs	r3, #0
    5b5c:	f844 3028 	str.w	r3, [r4, r8, lsl #2]
}
    5b60:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return chunk_field(h, c, FREE_PREV);
    5b64:	4631      	mov	r1, r6
    5b66:	2202      	movs	r2, #2
    5b68:	4620      	mov	r0, r4
    5b6a:	f7ff ff58 	bl	5a1e <chunk_field>
	chunk_set(h, c, FREE_NEXT, next);
    5b6e:	462b      	mov	r3, r5
	return chunk_field(h, c, FREE_PREV);
    5b70:	4606      	mov	r6, r0
	chunk_set(h, c, FREE_NEXT, next);
    5b72:	4601      	mov	r1, r0
		b->next = second;
    5b74:	f844 5028 	str.w	r5, [r4, r8, lsl #2]
    5b78:	4620      	mov	r0, r4
    5b7a:	2203      	movs	r2, #3
    5b7c:	f7ff ff5a 	bl	5a34 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    5b80:	4633      	mov	r3, r6
    5b82:	4629      	mov	r1, r5
    5b84:	4620      	mov	r0, r4
    5b86:	2202      	movs	r2, #2
}
    5b88:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5b8c:	f7ff bf52 	b.w	5a34 <chunk_set>

00005b90 <free_list_remove>:
{
    5b90:	b538      	push	{r3, r4, r5, lr}
    5b92:	4604      	mov	r4, r0
    5b94:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    5b96:	f7ff ff58 	bl	5a4a <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    5b9a:	68a3      	ldr	r3, [r4, #8]
    5b9c:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5ba0:	4601      	mov	r1, r0
    5ba2:	d301      	bcc.n	5ba8 <free_list_remove+0x18>
	if (!solo_free_header(h, c)) {
    5ba4:	2801      	cmp	r0, #1
    5ba6:	d009      	beq.n	5bbc <free_list_remove+0x2c>
		int bidx = bucket_idx(h, chunk_size(h, c));
    5ba8:	4620      	mov	r0, r4
    5baa:	f7ff ff70 	bl	5a8e <bucket_idx>
		free_list_remove_bidx(h, c, bidx);
    5bae:	4629      	mov	r1, r5
		int bidx = bucket_idx(h, chunk_size(h, c));
    5bb0:	4602      	mov	r2, r0
		free_list_remove_bidx(h, c, bidx);
    5bb2:	4620      	mov	r0, r4
}
    5bb4:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		free_list_remove_bidx(h, c, bidx);
    5bb8:	f7ff bfbb 	b.w	5b32 <free_list_remove_bidx>
}
    5bbc:	bd38      	pop	{r3, r4, r5, pc}

00005bbe <alloc_chunk>:
	set_chunk_used(h, c, false);
	free_chunk(h, c);
}

static chunkid_t alloc_chunk(struct z_heap *h, size_t sz)
{
    5bbe:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    5bc2:	4604      	mov	r4, r0
    5bc4:	4688      	mov	r8, r1
	int bi = bucket_idx(h, sz);
    5bc6:	f7ff ff62 	bl	5a8e <bucket_idx>
	struct z_heap_bucket *b = &h->buckets[bi];

	if (bi > bucket_idx(h, h->len)) {
    5bca:	68a1      	ldr	r1, [r4, #8]
	int bi = bucket_idx(h, sz);
    5bcc:	4605      	mov	r5, r0
	if (bi > bucket_idx(h, h->len)) {
    5bce:	4620      	mov	r0, r4
    5bd0:	f7ff ff5d 	bl	5a8e <bucket_idx>
    5bd4:	42a8      	cmp	r0, r5
    5bd6:	da03      	bge.n	5be0 <alloc_chunk+0x22>
		return 0;
    5bd8:	2600      	movs	r6, #0
		CHECK(chunk_size(h, c) >= sz);
		return c;
	}

	return 0;
}
    5bda:	4630      	mov	r0, r6
    5bdc:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	if (b->next) {
    5be0:	eb04 0a85 	add.w	sl, r4, r5, lsl #2
    5be4:	f8da 9010 	ldr.w	r9, [sl, #16]
    5be8:	f1b9 0f00 	cmp.w	r9, #0
    5bec:	d019      	beq.n	5c22 <alloc_chunk+0x64>
    5bee:	2703      	movs	r7, #3
			chunkid_t c = b->next;
    5bf0:	f8da 6010 	ldr.w	r6, [sl, #16]
			if (chunk_size(h, c) >= sz) {
    5bf4:	4620      	mov	r0, r4
    5bf6:	4631      	mov	r1, r6
    5bf8:	f7ff ff27 	bl	5a4a <chunk_size>
    5bfc:	4540      	cmp	r0, r8
    5bfe:	d305      	bcc.n	5c0c <alloc_chunk+0x4e>
				free_list_remove_bidx(h, c, bi);
    5c00:	462a      	mov	r2, r5
		free_list_remove_bidx(h, c, minbucket);
    5c02:	4631      	mov	r1, r6
    5c04:	4620      	mov	r0, r4
    5c06:	f7ff ff94 	bl	5b32 <free_list_remove_bidx>
		return c;
    5c0a:	e7e6      	b.n	5bda <alloc_chunk+0x1c>
	return chunk_field(h, c, FREE_NEXT);
    5c0c:	2203      	movs	r2, #3
    5c0e:	4631      	mov	r1, r6
    5c10:	4620      	mov	r0, r4
    5c12:	f7ff ff04 	bl	5a1e <chunk_field>
		} while (--i && b->next != first);
    5c16:	3f01      	subs	r7, #1
			b->next = next_free_chunk(h, c);
    5c18:	f8ca 0010 	str.w	r0, [sl, #16]
		} while (--i && b->next != first);
    5c1c:	d001      	beq.n	5c22 <alloc_chunk+0x64>
    5c1e:	4581      	cmp	r9, r0
    5c20:	d1e6      	bne.n	5bf0 <alloc_chunk+0x32>
	size_t bmask = h->avail_buckets & ~((1 << (bi + 1)) - 1);
    5c22:	68e3      	ldr	r3, [r4, #12]
    5c24:	3501      	adds	r5, #1
    5c26:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    5c2a:	40aa      	lsls	r2, r5
	if ((bmask & h->avail_buckets) != 0) {
    5c2c:	401a      	ands	r2, r3
    5c2e:	d0d3      	beq.n	5bd8 <alloc_chunk+0x1a>
		int minbucket = __builtin_ctz(bmask & h->avail_buckets);
    5c30:	fa92 f2a2 	rbit	r2, r2
    5c34:	fab2 f282 	clz	r2, r2
		chunkid_t c = h->buckets[minbucket].next;
    5c38:	1d13      	adds	r3, r2, #4
    5c3a:	f854 6023 	ldr.w	r6, [r4, r3, lsl #2]
    5c3e:	e7e0      	b.n	5c02 <alloc_chunk+0x44>

00005c40 <free_list_add>:
{
    5c40:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5c44:	4604      	mov	r4, r0
    5c46:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    5c48:	f7ff feff 	bl	5a4a <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    5c4c:	68a3      	ldr	r3, [r4, #8]
    5c4e:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5c52:	4601      	mov	r1, r0
    5c54:	d301      	bcc.n	5c5a <free_list_add+0x1a>
	if (!solo_free_header(h, c)) {
    5c56:	2801      	cmp	r0, #1
    5c58:	d035      	beq.n	5cc6 <free_list_add+0x86>
		int bidx = bucket_idx(h, chunk_size(h, c));
    5c5a:	4620      	mov	r0, r4
    5c5c:	f7ff ff17 	bl	5a8e <bucket_idx>
	if (b->next == 0) {
    5c60:	eb04 0280 	add.w	r2, r4, r0, lsl #2
    5c64:	6916      	ldr	r6, [r2, #16]
    5c66:	b99e      	cbnz	r6, 5c90 <free_list_add+0x50>
		h->avail_buckets |= (1 << bidx);
    5c68:	2301      	movs	r3, #1
    5c6a:	fa03 f000 	lsl.w	r0, r3, r0
    5c6e:	68e3      	ldr	r3, [r4, #12]
    5c70:	4303      	orrs	r3, r0
    5c72:	60e3      	str	r3, [r4, #12]
	chunk_set(h, c, FREE_PREV, prev);
    5c74:	4629      	mov	r1, r5
		b->next = c;
    5c76:	6115      	str	r5, [r2, #16]
    5c78:	462b      	mov	r3, r5
    5c7a:	2202      	movs	r2, #2
    5c7c:	4620      	mov	r0, r4
    5c7e:	f7ff fed9 	bl	5a34 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    5c82:	2203      	movs	r2, #3
    5c84:	4629      	mov	r1, r5
	chunk_set(h, c, FREE_PREV, prev);
    5c86:	4620      	mov	r0, r4
}
    5c88:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5c8c:	f7ff bed2 	b.w	5a34 <chunk_set>
	return chunk_field(h, c, FREE_PREV);
    5c90:	2202      	movs	r2, #2
    5c92:	4631      	mov	r1, r6
    5c94:	4620      	mov	r0, r4
    5c96:	f7ff fec2 	bl	5a1e <chunk_field>
	chunk_set(h, c, FREE_PREV, prev);
    5c9a:	2202      	movs	r2, #2
    5c9c:	4603      	mov	r3, r0
	return chunk_field(h, c, FREE_PREV);
    5c9e:	4607      	mov	r7, r0
	chunk_set(h, c, FREE_PREV, prev);
    5ca0:	4629      	mov	r1, r5
    5ca2:	4620      	mov	r0, r4
    5ca4:	f7ff fec6 	bl	5a34 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    5ca8:	4633      	mov	r3, r6
    5caa:	2203      	movs	r2, #3
    5cac:	4629      	mov	r1, r5
    5cae:	4620      	mov	r0, r4
    5cb0:	f7ff fec0 	bl	5a34 <chunk_set>
    5cb4:	2203      	movs	r2, #3
    5cb6:	4639      	mov	r1, r7
    5cb8:	462b      	mov	r3, r5
    5cba:	4620      	mov	r0, r4
    5cbc:	f7ff feba 	bl	5a34 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    5cc0:	2202      	movs	r2, #2
    5cc2:	4631      	mov	r1, r6
    5cc4:	e7df      	b.n	5c86 <free_list_add+0x46>
    5cc6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

00005cca <sys_heap_free>:
{
    5cca:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (mem == NULL) {
    5ccc:	2900      	cmp	r1, #0
    5cce:	d050      	beq.n	5d72 <sys_heap_free+0xa8>
	struct z_heap *h = heap->heap;
    5cd0:	6805      	ldr	r5, [r0, #0]
	return big_heap(h) ? 8 : 4;
    5cd2:	68ab      	ldr	r3, [r5, #8]
    5cd4:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5cd8:	bf2c      	ite	cs
    5cda:	2408      	movcs	r4, #8
    5cdc:	2404      	movcc	r4, #4
	return (mem - chunk_header_bytes(h) - base) / CHUNK_UNIT;
    5cde:	1b0c      	subs	r4, r1, r4
    5ce0:	1b64      	subs	r4, r4, r5
    5ce2:	bf48      	it	mi
    5ce4:	3407      	addmi	r4, #7
    5ce6:	10e4      	asrs	r4, r4, #3
	set_chunk_used(h, c, false);
    5ce8:	2200      	movs	r2, #0
    5cea:	4621      	mov	r1, r4
    5cec:	4628      	mov	r0, r5
    5cee:	f7ff feb2 	bl	5a56 <set_chunk_used>
	return c + chunk_size(h, c);
    5cf2:	4621      	mov	r1, r4
    5cf4:	f7ff fea9 	bl	5a4a <chunk_size>
    5cf8:	1826      	adds	r6, r4, r0
	return chunk_field(h, c, SIZE_AND_USED) & 1;
    5cfa:	2201      	movs	r2, #1
    5cfc:	4631      	mov	r1, r6
    5cfe:	4628      	mov	r0, r5
    5d00:	f7ff fe8d 	bl	5a1e <chunk_field>
	if (!chunk_used(h, right_chunk(h, c))) {
    5d04:	07c3      	lsls	r3, r0, #31
    5d06:	d40c      	bmi.n	5d22 <sys_heap_free+0x58>
		free_list_remove(h, right_chunk(h, c));
    5d08:	4631      	mov	r1, r6
    5d0a:	4628      	mov	r0, r5
    5d0c:	f7ff ff40 	bl	5b90 <free_list_remove>
	return c + chunk_size(h, c);
    5d10:	4621      	mov	r1, r4
    5d12:	4628      	mov	r0, r5
    5d14:	f7ff fe99 	bl	5a4a <chunk_size>
		merge_chunks(h, c, right_chunk(h, c));
    5d18:	4621      	mov	r1, r4
    5d1a:	1822      	adds	r2, r4, r0
    5d1c:	4628      	mov	r0, r5
    5d1e:	f7ff fec3 	bl	5aa8 <merge_chunks>
	return c - chunk_field(h, c, LEFT_SIZE);
    5d22:	2200      	movs	r2, #0
    5d24:	4621      	mov	r1, r4
    5d26:	4628      	mov	r0, r5
    5d28:	f7ff fe79 	bl	5a1e <chunk_field>
    5d2c:	1a27      	subs	r7, r4, r0
	return chunk_field(h, c, SIZE_AND_USED) & 1;
    5d2e:	2201      	movs	r2, #1
    5d30:	4639      	mov	r1, r7
    5d32:	4628      	mov	r0, r5
    5d34:	f7ff fe73 	bl	5a1e <chunk_field>
	if (!chunk_used(h, left_chunk(h, c))) {
    5d38:	f010 0601 	ands.w	r6, r0, #1
    5d3c:	d113      	bne.n	5d66 <sys_heap_free+0x9c>
		free_list_remove(h, left_chunk(h, c));
    5d3e:	4639      	mov	r1, r7
    5d40:	4628      	mov	r0, r5
    5d42:	f7ff ff25 	bl	5b90 <free_list_remove>
	return c - chunk_field(h, c, LEFT_SIZE);
    5d46:	4621      	mov	r1, r4
    5d48:	4632      	mov	r2, r6
    5d4a:	4628      	mov	r0, r5
    5d4c:	f7ff fe67 	bl	5a1e <chunk_field>
		merge_chunks(h, left_chunk(h, c), c);
    5d50:	4622      	mov	r2, r4
    5d52:	1a21      	subs	r1, r4, r0
    5d54:	4628      	mov	r0, r5
    5d56:	f7ff fea7 	bl	5aa8 <merge_chunks>
    5d5a:	4621      	mov	r1, r4
    5d5c:	4632      	mov	r2, r6
    5d5e:	4628      	mov	r0, r5
    5d60:	f7ff fe5d 	bl	5a1e <chunk_field>
    5d64:	1a24      	subs	r4, r4, r0
	free_list_add(h, c);
    5d66:	4621      	mov	r1, r4
    5d68:	4628      	mov	r0, r5
}
    5d6a:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, c);
    5d6e:	f7ff bf67 	b.w	5c40 <free_list_add>
}
    5d72:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

00005d74 <sys_heap_alloc>:

void *sys_heap_alloc(struct sys_heap *heap, size_t bytes)
{
    5d74:	b570      	push	{r4, r5, r6, lr}
	if (bytes == 0) {
    5d76:	b909      	cbnz	r1, 5d7c <sys_heap_alloc+0x8>
		return NULL;
    5d78:	2000      	movs	r0, #0
		free_list_add(h, c + chunk_sz);
	}

	set_chunk_used(h, c, true);
	return chunk_mem(h, c);
}
    5d7a:	bd70      	pop	{r4, r5, r6, pc}
	struct z_heap *h = heap->heap;
    5d7c:	6805      	ldr	r5, [r0, #0]
	return big_heap(h) ? 8 : 4;
    5d7e:	68ab      	ldr	r3, [r5, #8]
    5d80:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5d84:	bf2c      	ite	cs
    5d86:	2208      	movcs	r2, #8
    5d88:	2204      	movcc	r2, #4
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    5d8a:	1dcc      	adds	r4, r1, #7
    5d8c:	4414      	add	r4, r2
    5d8e:	08e4      	lsrs	r4, r4, #3
	chunkid_t c = alloc_chunk(h, chunk_sz);
    5d90:	4621      	mov	r1, r4
    5d92:	4628      	mov	r0, r5
    5d94:	f7ff ff13 	bl	5bbe <alloc_chunk>
	if (c == 0) {
    5d98:	4606      	mov	r6, r0
    5d9a:	2800      	cmp	r0, #0
    5d9c:	d0ec      	beq.n	5d78 <sys_heap_alloc+0x4>
	if (chunk_size(h, c) > chunk_sz) {
    5d9e:	4601      	mov	r1, r0
    5da0:	4628      	mov	r0, r5
    5da2:	f7ff fe52 	bl	5a4a <chunk_size>
    5da6:	42a0      	cmp	r0, r4
    5da8:	d909      	bls.n	5dbe <sys_heap_alloc+0x4a>
		split_chunks(h, c, c + chunk_sz);
    5daa:	4434      	add	r4, r6
    5dac:	4631      	mov	r1, r6
    5dae:	4628      	mov	r0, r5
    5db0:	4622      	mov	r2, r4
    5db2:	f7ff fe97 	bl	5ae4 <split_chunks>
		free_list_add(h, c + chunk_sz);
    5db6:	4621      	mov	r1, r4
    5db8:	4628      	mov	r0, r5
    5dba:	f7ff ff41 	bl	5c40 <free_list_add>
	set_chunk_used(h, c, true);
    5dbe:	4628      	mov	r0, r5
    5dc0:	2201      	movs	r2, #1
    5dc2:	4631      	mov	r1, r6
    5dc4:	f7ff fe47 	bl	5a56 <set_chunk_used>
	return big_heap(h) ? 8 : 4;
    5dc8:	68ab      	ldr	r3, [r5, #8]
    5dca:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5dce:	bf2c      	ite	cs
    5dd0:	2008      	movcs	r0, #8
    5dd2:	2004      	movcc	r0, #4
	uint8_t *ret = ((uint8_t *)&buf[c]) + chunk_header_bytes(h);
    5dd4:	eb00 00c6 	add.w	r0, r0, r6, lsl #3
    5dd8:	4428      	add	r0, r5
	return chunk_mem(h, c);
    5dda:	e7ce      	b.n	5d7a <sys_heap_alloc+0x6>

00005ddc <sys_heap_init>:
	return big_heap_bytes(size) ? 8 : 4;
    5ddc:	f5b2 2f80 	cmp.w	r2, #262144	; 0x40000
	set_chunk_used(h, c, true);
	return mem;
}

void sys_heap_init(struct sys_heap *heap, void *mem, size_t bytes)
{
    5de0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    5de2:	bf2c      	ite	cs
    5de4:	2508      	movcs	r5, #8
    5de6:	2504      	movcc	r5, #4
	/* Must fit in a 32 bit count of HUNK_UNIT */
	__ASSERT(bytes / CHUNK_UNIT <= 0xffffffffU, "heap size is too big");

	/* Reserve the final marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
    5de8:	1b55      	subs	r5, r2, r5

	/* Round the start up, the end down */
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    5dea:	1dcc      	adds	r4, r1, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    5dec:	440d      	add	r5, r1
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    5dee:	f024 0407 	bic.w	r4, r4, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    5df2:	f025 0507 	bic.w	r5, r5, #7
	CHECK(end > addr);
	__ASSERT(buf_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->chunk0_hdr_area = 0;
    5df6:	2200      	movs	r2, #0
    5df8:	2300      	movs	r3, #0
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    5dfa:	1b2d      	subs	r5, r5, r4
	heap->heap = h;
    5dfc:	6004      	str	r4, [r0, #0]
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    5dfe:	08ed      	lsrs	r5, r5, #3
	h->chunk0_hdr_area = 0;
    5e00:	e9c4 2300 	strd	r2, r3, [r4]
	h->len = buf_sz;
	h->avail_buckets = 0;
    5e04:	2300      	movs	r3, #0

	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5e06:	4629      	mov	r1, r5
	h->len = buf_sz;
    5e08:	60a5      	str	r5, [r4, #8]
	h->avail_buckets = 0;
    5e0a:	60e3      	str	r3, [r4, #12]
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5e0c:	4620      	mov	r0, r4
    5e0e:	f7ff fe3e 	bl	5a8e <bucket_idx>
	size_t chunk0_size = chunksz(sizeof(struct z_heap) +
    5e12:	0086      	lsls	r6, r0, #2
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    5e14:	361b      	adds	r6, #27
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5e16:	1c41      	adds	r1, r0, #1
    5e18:	08f6      	lsrs	r6, r6, #3
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) < buf_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
    5e1a:	f104 0210 	add.w	r2, r4, #16
		h->buckets[i].next = 0;
    5e1e:	4618      	mov	r0, r3
	for (int i = 0; i < nb_buckets; i++) {
    5e20:	428b      	cmp	r3, r1
    5e22:	db29      	blt.n	5e78 <sys_heap_init+0x9c>
	}

	/* chunk containing our struct z_heap */
	set_chunk_size(h, 0, chunk0_size);
    5e24:	4632      	mov	r2, r6
    5e26:	4620      	mov	r0, r4
    5e28:	2100      	movs	r1, #0
    5e2a:	f7ff fe2c 	bl	5a86 <set_chunk_size>
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    5e2e:	1baf      	subs	r7, r5, r6
	set_chunk_used(h, 0, true);
    5e30:	4620      	mov	r0, r4
    5e32:	2201      	movs	r2, #1
    5e34:	2100      	movs	r1, #0
    5e36:	f7ff fe0e 	bl	5a56 <set_chunk_used>
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    5e3a:	463a      	mov	r2, r7
    5e3c:	4631      	mov	r1, r6
    5e3e:	f7ff fe22 	bl	5a86 <set_chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5e42:	4633      	mov	r3, r6
    5e44:	4631      	mov	r1, r6
    5e46:	4620      	mov	r0, r4
    5e48:	2200      	movs	r2, #0
    5e4a:	f7ff fdf3 	bl	5a34 <chunk_set>
	set_left_chunk_size(h, chunk0_size, chunk0_size);

	/* the end marker chunk */
	set_chunk_size(h, buf_sz, 0);
    5e4e:	4629      	mov	r1, r5
    5e50:	4620      	mov	r0, r4
    5e52:	2200      	movs	r2, #0
    5e54:	f7ff fe17 	bl	5a86 <set_chunk_size>
    5e58:	463b      	mov	r3, r7
    5e5a:	4629      	mov	r1, r5
    5e5c:	4620      	mov	r0, r4
    5e5e:	2200      	movs	r2, #0
    5e60:	f7ff fde8 	bl	5a34 <chunk_set>
	set_left_chunk_size(h, buf_sz, buf_sz - chunk0_size);
	set_chunk_used(h, buf_sz, true);
    5e64:	4629      	mov	r1, r5
    5e66:	4620      	mov	r0, r4
    5e68:	2201      	movs	r2, #1
    5e6a:	f7ff fdf4 	bl	5a56 <set_chunk_used>

	free_list_add(h, chunk0_size);
    5e6e:	4631      	mov	r1, r6
}
    5e70:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, chunk0_size);
    5e74:	f7ff bee4 	b.w	5c40 <free_list_add>
		h->buckets[i].next = 0;
    5e78:	f842 0b04 	str.w	r0, [r2], #4
	for (int i = 0; i < nb_buckets; i++) {
    5e7c:	3301      	adds	r3, #1
    5e7e:	e7cf      	b.n	5e20 <sys_heap_init+0x44>

00005e80 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5e80:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5e84:	b923      	cbnz	r3, 5e90 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5e86:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5e8a:	f000 0001 	and.w	r0, r0, #1
    5e8e:	4770      	bx	lr
		return false;
    5e90:	2000      	movs	r0, #0
}
    5e92:	4770      	bx	lr

00005e94 <z_impl_z_sys_mutex_kernel_lock>:
{
    5e94:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5e98:	4615      	mov	r5, r2
    5e9a:	461c      	mov	r4, r3
	obj = z_object_find(mutex);
    5e9c:	f7fa f91e 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_SYS_MUTEX) {
    5ea0:	b1a8      	cbz	r0, 5ece <z_impl_z_sys_mutex_kernel_lock+0x3a>
    5ea2:	7983      	ldrb	r3, [r0, #6]
    5ea4:	2b0e      	cmp	r3, #14
    5ea6:	d112      	bne.n	5ece <z_impl_z_sys_mutex_kernel_lock+0x3a>
	return obj->data.mutex;
    5ea8:	6881      	ldr	r1, [r0, #8]
	if (kernel_mutex == NULL) {
    5eaa:	b181      	cbz	r1, 5ece <z_impl_z_sys_mutex_kernel_lock+0x3a>
    5eac:	f7ff ffe8 	bl	5e80 <arch_is_user_context>
	if (z_syscall_trap()) {
    5eb0:	b130      	cbz	r0, 5ec0 <z_impl_z_sys_mutex_kernel_lock+0x2c>
	register uint32_t ret __asm__("r0") = arg1;
    5eb2:	4608      	mov	r0, r1
	register uint32_t r2 __asm__("r2") = arg3;
    5eb4:	4622      	mov	r2, r4
	register uint32_t r1 __asm__("r1") = arg2;
    5eb6:	4629      	mov	r1, r5
	register uint32_t r6 __asm__("r6") = call_id;
    5eb8:	266c      	movs	r6, #108	; 0x6c
	__asm__ volatile("svc %[svid]\n"
    5eba:	df03      	svc	3
}
    5ebc:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return z_impl_k_mutex_lock(mutex, timeout);
    5ec0:	462a      	mov	r2, r5
    5ec2:	4623      	mov	r3, r4
    5ec4:	4608      	mov	r0, r1
    5ec6:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5eca:	f7fd ba65 	b.w	3398 <z_impl_k_mutex_lock>
		return -EINVAL;
    5ece:	f06f 0015 	mvn.w	r0, #21
    5ed2:	e7f3      	b.n	5ebc <z_impl_z_sys_mutex_kernel_lock+0x28>

00005ed4 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_DISASSEMBLY, 1);
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_PRINT_MEMORY_USAGE, 1);
GEN_ABSOLUTE_SYM(CONFIG_BUILD_OUTPUT_BIN, 1);
GEN_ABSOLUTE_SYM(CONFIG_COMPAT_INCLUDES, 1);

GEN_ABS_SYM_END
    5ed4:	4770      	bx	lr

00005ed6 <uart_poll_out>:
}


extern void z_impl_uart_poll_out(struct device * dev, unsigned char out_char);
static inline void uart_poll_out(struct device * dev, unsigned char out_char)
{
    5ed6:	e92d 4147 	stmdb	sp!, {r0, r1, r2, r6, r8, lr}
    5eda:	4603      	mov	r3, r0
    5edc:	f88d 1007 	strb.w	r1, [sp, #7]
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5ee0:	f3ef 8205 	mrs	r2, IPSR
	if (value) {
    5ee4:	b952      	cbnz	r2, 5efc <uart_poll_out+0x26>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5ee6:	f3ef 8214 	mrs	r2, CONTROL
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    5eea:	07d2      	lsls	r2, r2, #31
    5eec:	d506      	bpl.n	5efc <uart_poll_out+0x26>
	register uint32_t r1 __asm__("r1") = arg2;
    5eee:	f8dd 1007 	ldr.w	r1, [sp, #7]
	register uint32_t r6 __asm__("r6") = call_id;
    5ef2:	26e5      	movs	r6, #229	; 0xe5
	__asm__ volatile("svc %[svid]\n"
    5ef4:	df03      	svc	3
		return;
	}
#endif
	compiler_barrier();
	z_impl_uart_poll_out(dev, out_char);
}
    5ef6:	b003      	add	sp, #12
    5ef8:	e8bd 8140 	ldmia.w	sp!, {r6, r8, pc}
	api->poll_out(dev, out_char);
    5efc:	689a      	ldr	r2, [r3, #8]
    5efe:	f89d 1007 	ldrb.w	r1, [sp, #7]
    5f02:	6852      	ldr	r2, [r2, #4]
    5f04:	4618      	mov	r0, r3
    5f06:	4790      	blx	r2
}
    5f08:	e7f5      	b.n	5ef6 <uart_poll_out+0x20>

00005f0a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5f0a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5f0e:	b923      	cbnz	r3, 5f1a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5f10:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5f14:	f000 0001 	and.w	r0, r0, #1
    5f18:	4770      	bx	lr
		return false;
    5f1a:	2000      	movs	r0, #0
}
    5f1c:	4770      	bx	lr

00005f1e <get_status>:
	return GET_STATUS(get_sub_data(dev, type)->flags);
    5f1e:	68c2      	ldr	r2, [r0, #12]
    5f20:	b2cb      	uxtb	r3, r1
    5f22:	210c      	movs	r1, #12
    5f24:	fb03 2101 	mla	r1, r3, r1, r2
    5f28:	6c08      	ldr	r0, [r1, #64]	; 0x40
}
    5f2a:	f000 0007 	and.w	r0, r0, #7
    5f2e:	4770      	bx	lr

00005f30 <set_off_state>:
	__asm__ volatile(
    5f30:	f04f 0320 	mov.w	r3, #32
    5f34:	f3ef 8211 	mrs	r2, BASEPRI
    5f38:	f383 8811 	msr	BASEPRI, r3
    5f3c:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    5f40:	6803      	ldr	r3, [r0, #0]
	if ((current_ctx != 0) && (current_ctx != ctx)) {
    5f42:	f013 03c0 	ands.w	r3, r3, #192	; 0xc0
    5f46:	d001      	beq.n	5f4c <set_off_state+0x1c>
    5f48:	428b      	cmp	r3, r1
    5f4a:	d107      	bne.n	5f5c <set_off_state+0x2c>
		*flags = CLOCK_CONTROL_STATUS_OFF;
    5f4c:	2301      	movs	r3, #1
    5f4e:	6003      	str	r3, [r0, #0]
	int err = 0;
    5f50:	2000      	movs	r0, #0
	__asm__ volatile(
    5f52:	f382 8811 	msr	BASEPRI, r2
    5f56:	f3bf 8f6f 	isb	sy
}
    5f5a:	4770      	bx	lr
		err = -EPERM;
    5f5c:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    5f60:	e7f7      	b.n	5f52 <set_off_state+0x22>

00005f62 <set_starting_state>:
{
    5f62:	b510      	push	{r4, lr}
	__asm__ volatile(
    5f64:	f04f 0320 	mov.w	r3, #32
    5f68:	f3ef 8211 	mrs	r2, BASEPRI
    5f6c:	f383 8811 	msr	BASEPRI, r3
    5f70:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    5f74:	6803      	ldr	r3, [r0, #0]
	if ((*flags & (STATUS_MASK)) == CLOCK_CONTROL_STATUS_OFF) {
    5f76:	f003 0407 	and.w	r4, r3, #7
    5f7a:	2c01      	cmp	r4, #1
    5f7c:	d106      	bne.n	5f8c <set_starting_state+0x2a>
		*flags = CLOCK_CONTROL_STATUS_STARTING | ctx;
    5f7e:	6001      	str	r1, [r0, #0]
	int err = 0;
    5f80:	2000      	movs	r0, #0
	__asm__ volatile(
    5f82:	f382 8811 	msr	BASEPRI, r2
    5f86:	f3bf 8f6f 	isb	sy
}
    5f8a:	bd10      	pop	{r4, pc}
	uint32_t current_ctx = GET_CTX(*flags);
    5f8c:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
	} else if (current_ctx != ctx) {
    5f90:	428b      	cmp	r3, r1
		err = -EBUSY;
    5f92:	bf14      	ite	ne
    5f94:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
    5f98:	f06f 000f 	mvneq.w	r0, #15
    5f9c:	e7f1      	b.n	5f82 <set_starting_state+0x20>

00005f9e <set_on_state>:
	__asm__ volatile(
    5f9e:	f04f 0320 	mov.w	r3, #32
    5fa2:	f3ef 8211 	mrs	r2, BASEPRI
    5fa6:	f383 8811 	msr	BASEPRI, r3
    5faa:	f3bf 8f6f 	isb	sy
	*flags = CLOCK_CONTROL_STATUS_ON | GET_CTX(*flags);
    5fae:	6803      	ldr	r3, [r0, #0]
    5fb0:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
    5fb4:	f043 0302 	orr.w	r3, r3, #2
    5fb8:	6003      	str	r3, [r0, #0]
	__asm__ volatile(
    5fba:	f382 8811 	msr	BASEPRI, r2
    5fbe:	f3bf 8f6f 	isb	sy
}
    5fc2:	4770      	bx	lr

00005fc4 <onoff_started_callback>:
	return &data->mgr[type];
    5fc4:	68c0      	ldr	r0, [r0, #12]
{
    5fc6:	b410      	push	{r4}
	return &data->mgr[type];
    5fc8:	b2cb      	uxtb	r3, r1
	notify(mgr, 0);
    5fca:	241c      	movs	r4, #28
    5fcc:	fb03 0004 	mla	r0, r3, r4, r0
    5fd0:	2100      	movs	r1, #0
}
    5fd2:	bc10      	pop	{r4}
	notify(mgr, 0);
    5fd4:	4710      	bx	r2

00005fd6 <blocking_start_callback>:
{
    5fd6:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    5fda:	f7ff ff96 	bl	5f0a <arch_is_user_context>
	if (z_syscall_trap()) {
    5fde:	b120      	cbz	r0, 5fea <blocking_start_callback+0x14>
	register uint32_t ret __asm__("r0") = arg1;
    5fe0:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    5fe2:	2684      	movs	r6, #132	; 0x84
	__asm__ volatile("svc %[svid]\n"
    5fe4:	df03      	svc	3
}
    5fe6:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    5fea:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_sem_give(sem);
    5fee:	4610      	mov	r0, r2
    5ff0:	f7fe bcea 	b.w	49c8 <z_impl_k_sem_give>

00005ff4 <lfclk_spinwait>:
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    5ff4:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    5ff8:	f8d2 3418 	ldr.w	r3, [r2, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    5ffc:	f8d2 1418 	ldr.w	r1, [r2, #1048]	; 0x418
    6000:	03c9      	lsls	r1, r1, #15
    6002:	d5f9      	bpl.n	5ff8 <lfclk_spinwait+0x4>
                                        >> CLOCK_LFCLKSTAT_SRC_Pos);
    6004:	f003 0303 	and.w	r3, r3, #3
	while (!(nrf_clock_is_running(NRF_CLOCK, d, (void *)&type)
    6008:	4298      	cmp	r0, r3
    600a:	d1f5      	bne.n	5ff8 <lfclk_spinwait+0x4>
}
    600c:	4770      	bx	lr

0000600e <api_stop>:
{
    600e:	b538      	push	{r3, r4, r5, lr}
    6010:	b2cc      	uxtb	r4, r1
	err = set_off_state(&subdata->flags, ctx);
    6012:	230c      	movs	r3, #12
{
    6014:	4605      	mov	r5, r0
	err = set_off_state(&subdata->flags, ctx);
    6016:	4363      	muls	r3, r4
    6018:	68c0      	ldr	r0, [r0, #12]
    601a:	3340      	adds	r3, #64	; 0x40
    601c:	2180      	movs	r1, #128	; 0x80
    601e:	4418      	add	r0, r3
    6020:	f7ff ff86 	bl	5f30 <set_off_state>
	if (err < 0) {
    6024:	2800      	cmp	r0, #0
    6026:	db05      	blt.n	6034 <api_stop+0x26>
	get_sub_config(dev, type)->stop();
    6028:	6869      	ldr	r1, [r5, #4]
    602a:	eb01 04c4 	add.w	r4, r1, r4, lsl #3
    602e:	6863      	ldr	r3, [r4, #4]
    6030:	4798      	blx	r3
	return 0;
    6032:	2000      	movs	r0, #0
}
    6034:	bd38      	pop	{r3, r4, r5, pc}

00006036 <api_start>:
{
    6036:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    603a:	b2cd      	uxtb	r5, r1
	err = set_starting_state(&subdata->flags, ctx);
    603c:	f04f 080c 	mov.w	r8, #12
	struct nrf_clock_control_sub_data *subdata = get_sub_data(dev, type);
    6040:	68c4      	ldr	r4, [r0, #12]
	err = set_starting_state(&subdata->flags, ctx);
    6042:	fb08 f805 	mul.w	r8, r8, r5
{
    6046:	4606      	mov	r6, r0
	err = set_starting_state(&subdata->flags, ctx);
    6048:	f108 0040 	add.w	r0, r8, #64	; 0x40
    604c:	2180      	movs	r1, #128	; 0x80
    604e:	4420      	add	r0, r4
{
    6050:	4617      	mov	r7, r2
	err = set_starting_state(&subdata->flags, ctx);
    6052:	f7ff ff86 	bl	5f62 <set_starting_state>
	if (err < 0) {
    6056:	2800      	cmp	r0, #0
    6058:	db09      	blt.n	606e <api_start+0x38>
	subdata->cb = data->cb;
    605a:	4444      	add	r4, r8
    605c:	687b      	ldr	r3, [r7, #4]
    605e:	63a3      	str	r3, [r4, #56]	; 0x38
	subdata->user_data = data->user_data;
    6060:	68bb      	ldr	r3, [r7, #8]
    6062:	63e3      	str	r3, [r4, #60]	; 0x3c
	 get_sub_config(dev, type)->start();
    6064:	6873      	ldr	r3, [r6, #4]
    6066:	f853 3035 	ldr.w	r3, [r3, r5, lsl #3]
    606a:	4798      	blx	r3
	return 0;
    606c:	2000      	movs	r0, #0
}
    606e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

00006072 <z_clock_isr>:
/* Weak-linked noop defaults for optional driver interfaces: */

void __weak z_clock_isr(void *arg)
{
	__ASSERT_NO_MSG(false);
}
    6072:	4770      	bx	lr

00006074 <z_clock_idle_exit>:
{
}

void __weak z_clock_idle_exit(void)
{
}
    6074:	4770      	bx	lr

00006076 <SEGGER_RTT_Init>:
*    Initializes the RTT Control Block.
*    Should be used in RAM targets, at start of the application.
*
*/
void SEGGER_RTT_Init (void) {
  _DoInit();
    6076:	f7fb b995 	b.w	13a4 <_DoInit>

0000607a <rtt_init>:
 */

K_MUTEX_DEFINE(rtt_term_mutex);

static int rtt_init(struct device *unused)
{
    607a:	b508      	push	{r3, lr}
	ARG_UNUSED(unused);

	SEGGER_RTT_Init();
    607c:	f7ff fffb 	bl	6076 <SEGGER_RTT_Init>

	return 0;
}
    6080:	2000      	movs	r0, #0
    6082:	bd08      	pop	{r3, pc}

00006084 <z_irq_spurious>:
 */
void z_irq_spurious(void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
    6084:	2100      	movs	r1, #0
    6086:	2001      	movs	r0, #1
    6088:	f000 b80a 	b.w	60a0 <z_arm_fatal_error>

0000608c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    608c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6090:	b923      	cbnz	r3, 609c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6092:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6096:	f000 0001 	and.w	r0, r0, #1
    609a:	4770      	bx	lr
		return false;
    609c:	2000      	movs	r0, #0
}
    609e:	4770      	bx	lr

000060a0 <z_arm_fatal_error>:
	LOG_ERR("Faulting instruction address (r15/pc): 0x%08x",
		esf->basic.pc);
}

void z_arm_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    60a0:	b508      	push	{r3, lr}
    60a2:	4602      	mov	r2, r0

	if (esf != NULL) {
    60a4:	b139      	cbz	r1, 60b6 <z_arm_fatal_error+0x16>
	return arch_is_user_context();
    60a6:	f7ff fff1 	bl	608c <arch_is_user_context>
    60aa:	f7ff ffef 	bl	608c <arch_is_user_context>
    60ae:	f7ff ffed 	bl	608c <arch_is_user_context>
    60b2:	f7ff ffeb 	bl	608c <arch_is_user_context>
		esf_dump(esf);
	}
	z_fatal_error(reason, esf);
}
    60b6:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_fatal_error(reason, esf);
    60ba:	4610      	mov	r0, r2
    60bc:	f000 b955 	b.w	636a <z_fatal_error>

000060c0 <z_do_kernel_oops>:
 *   fault handler will executed insted of the SVC.
 *
 * @param esf exception frame
 */
void z_do_kernel_oops(const z_arch_esf_t *esf)
{
    60c0:	4601      	mov	r1, r0
	/* Stacked R0 holds the exception reason. */
	unsigned int reason = esf->basic.r0;
    60c2:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    60c4:	f3ef 8314 	mrs	r3, CONTROL

#if defined(CONFIG_USERSPACE)
	if ((__get_CONTROL() & CONTROL_nPRIV_Msk) == CONTROL_nPRIV_Msk) {
    60c8:	07db      	lsls	r3, r3, #31
    60ca:	d503      	bpl.n	60d4 <z_do_kernel_oops+0x14>
		 * Exception triggered from nPRIV mode.
		 *
		 * User mode is only allowed to induce oopses and stack check
		 * failures via software-triggered system fatal exceptions.
		 */
		if (!((esf->basic.r0 == K_ERR_KERNEL_OOPS) ||
    60cc:	1e83      	subs	r3, r0, #2
			(esf->basic.r0 == K_ERR_STACK_CHK_FAIL))) {

			reason = K_ERR_KERNEL_OOPS;
    60ce:	2b02      	cmp	r3, #2
    60d0:	bf28      	it	cs
    60d2:	2003      	movcs	r0, #3
		}
	}

#endif /* CONFIG_USERSPACE */
	z_arm_fatal_error(reason, esf);
    60d4:	f7ff bfe4 	b.w	60a0 <z_arm_fatal_error>

000060d8 <arch_syscall_oops>:
}

FUNC_NORETURN void arch_syscall_oops(void *ssf_ptr)
{
    60d8:	b500      	push	{lr}
    60da:	4604      	mov	r4, r0
    60dc:	b089      	sub	sp, #36	; 0x24
	uint32_t *ssf_contents = ssf_ptr;
	z_arch_esf_t oops_esf = { 0 };
    60de:	2100      	movs	r1, #0
    60e0:	2220      	movs	r2, #32
    60e2:	4668      	mov	r0, sp
    60e4:	f000 f873 	bl	61ce <memset>

	/* TODO: Copy the rest of the register set out of ssf_ptr */
	oops_esf.basic.pc = ssf_contents[3];
    60e8:	68e3      	ldr	r3, [r4, #12]
    60ea:	9306      	str	r3, [sp, #24]

	z_arm_fatal_error(K_ERR_KERNEL_OOPS, &oops_esf);
    60ec:	4669      	mov	r1, sp
    60ee:	2003      	movs	r0, #3
    60f0:	f7ff ffd6 	bl	60a0 <z_arm_fatal_error>

000060f4 <z_arm_nmi>:
 *
 * @return N/A
 */

void z_arm_nmi(void)
{
    60f4:	b508      	push	{r3, lr}
	handler();
    60f6:	f7fb facf 	bl	1698 <z_SysNmiOnReset>
	z_arm_int_exit();
}
    60fa:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
    60fe:	f7fb bd35 	b.w	1b6c <z_arm_exc_exit>

00006102 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6102:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6106:	b923      	cbnz	r3, 6112 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6108:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    610c:	f000 0001 	and.w	r0, r0, #1
    6110:	4770      	bx	lr
		return false;
    6112:	2000      	movs	r0, #0
}
    6114:	4770      	bx	lr

00006116 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6116:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    611a:	b923      	cbnz	r3, 6126 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    611c:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6120:	f000 0001 	and.w	r0, r0, #1
    6124:	4770      	bx	lr
		return false;
    6126:	2000      	movs	r0, #0
}
    6128:	4770      	bx	lr

0000612a <arch_mem_domain_max_partitions_get>:
{
    612a:	b508      	push	{r3, lr}
	int available_regions = arm_core_mpu_get_max_available_dyn_regions();
    612c:	f7fb fe4e 	bl	1dcc <arm_core_mpu_get_max_available_dyn_regions>
}
    6130:	3801      	subs	r0, #1
    6132:	bd08      	pop	{r3, pc}

00006134 <arch_buffer_validate>:
	arch_mem_domain_destroy(thread->mem_domain_info.mem_domain);
}

int arch_buffer_validate(void *addr, size_t size, int write)
{
	return arm_core_mpu_buffer_validate(addr, size, write);
    6134:	f7fb be52 	b.w	1ddc <arm_core_mpu_buffer_validate>

00006138 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6138:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    613c:	b923      	cbnz	r3, 6148 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    613e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6142:	f000 0001 	and.w	r0, r0, #1
    6146:	4770      	bx	lr
		return false;
    6148:	2000      	movs	r0, #0
}
    614a:	4770      	bx	lr

0000614c <strcpy>:

char *strcpy(char *_MLIBC_RESTRICT d, const char *_MLIBC_RESTRICT s)
{
	char *dest = d;

	while (*s != '\0') {
    614c:	3901      	subs	r1, #1
    614e:	4603      	mov	r3, r0
    6150:	f811 2f01 	ldrb.w	r2, [r1, #1]!
    6154:	b90a      	cbnz	r2, 615a <strcpy+0xe>
		*d = *s;
		d++;
		s++;
	}

	*d = '\0';
    6156:	701a      	strb	r2, [r3, #0]

	return dest;
}
    6158:	4770      	bx	lr
		*d = *s;
    615a:	f803 2b01 	strb.w	r2, [r3], #1
		s++;
    615e:	e7f7      	b.n	6150 <strcpy+0x4>

00006160 <strcmp>:
 * @return negative # if <s1> < <s2>, 0 if <s1> == <s2>, else positive #
 */

int strcmp(const char *s1, const char *s2)
{
	while ((*s1 == *s2) && (*s1 != '\0')) {
    6160:	1e43      	subs	r3, r0, #1
    6162:	3901      	subs	r1, #1
    6164:	f813 2f01 	ldrb.w	r2, [r3, #1]!
    6168:	f811 0f01 	ldrb.w	r0, [r1, #1]!
    616c:	4282      	cmp	r2, r0
    616e:	d101      	bne.n	6174 <strcmp+0x14>
    6170:	2a00      	cmp	r2, #0
    6172:	d1f7      	bne.n	6164 <strcmp+0x4>
		s1++;
		s2++;
	}

	return *s1 - *s2;
}
    6174:	1a10      	subs	r0, r2, r0
    6176:	4770      	bx	lr

00006178 <memcpy>:
 *
 * @return pointer to start of destination buffer
 */

void *memcpy(void *_MLIBC_RESTRICT d, const void *_MLIBC_RESTRICT s, size_t n)
{
    6178:	b5f0      	push	{r4, r5, r6, r7, lr}

	unsigned char *d_byte = (unsigned char *)d;
	const unsigned char *s_byte = (const unsigned char *)s;
	const uintptr_t mask = sizeof(mem_word_t) - 1;

	if ((((uintptr_t)d ^ (uintptr_t)s_byte) & mask) == 0) {
    617a:	ea81 0400 	eor.w	r4, r1, r0
    617e:	07a5      	lsls	r5, r4, #30
    6180:	4603      	mov	r3, r0
    6182:	d00b      	beq.n	619c <memcpy+0x24>
    6184:	3b01      	subs	r3, #1
    6186:	440a      	add	r2, r1
		s_byte = (unsigned char *)s_word;
	}

	/* do byte-sized copying until finished */

	while (n > 0) {
    6188:	4291      	cmp	r1, r2
    618a:	d11b      	bne.n	61c4 <memcpy+0x4c>
		*(d_byte++) = *(s_byte++);
		n--;
	}

	return d;
}
    618c:	bdf0      	pop	{r4, r5, r6, r7, pc}
			if (n == 0) {
    618e:	2a00      	cmp	r2, #0
    6190:	d0fc      	beq.n	618c <memcpy+0x14>
			*(d_byte++) = *(s_byte++);
    6192:	f811 4b01 	ldrb.w	r4, [r1], #1
    6196:	f803 4b01 	strb.w	r4, [r3], #1
			n--;
    619a:	3a01      	subs	r2, #1
		while (((uintptr_t)d_byte) & mask) {
    619c:	079c      	lsls	r4, r3, #30
    619e:	d1f6      	bne.n	618e <memcpy+0x16>
    61a0:	f022 0403 	bic.w	r4, r2, #3
    61a4:	1f1d      	subs	r5, r3, #4
    61a6:	0896      	lsrs	r6, r2, #2
    61a8:	190f      	adds	r7, r1, r4
		while (n >= sizeof(mem_word_t)) {
    61aa:	42b9      	cmp	r1, r7
    61ac:	d105      	bne.n	61ba <memcpy+0x42>
    61ae:	f06f 0503 	mvn.w	r5, #3
    61b2:	fb05 2206 	mla	r2, r5, r6, r2
    61b6:	4423      	add	r3, r4
    61b8:	e7e4      	b.n	6184 <memcpy+0xc>
			*(d_word++) = *(s_word++);
    61ba:	f851 cb04 	ldr.w	ip, [r1], #4
    61be:	f845 cf04 	str.w	ip, [r5, #4]!
			n -= sizeof(mem_word_t);
    61c2:	e7f2      	b.n	61aa <memcpy+0x32>
		*(d_byte++) = *(s_byte++);
    61c4:	f811 4b01 	ldrb.w	r4, [r1], #1
    61c8:	f803 4f01 	strb.w	r4, [r3, #1]!
		n--;
    61cc:	e7dc      	b.n	6188 <memcpy+0x10>

000061ce <memset>:
 *
 * @return pointer to start of buffer
 */

void *memset(void *buf, int c, size_t n)
{
    61ce:	b570      	push	{r4, r5, r6, lr}
	/* do byte-sized initialization until word-aligned or finished */

	unsigned char *d_byte = (unsigned char *)buf;
	unsigned char c_byte = (unsigned char)c;
    61d0:	b2c9      	uxtb	r1, r1
	unsigned char *d_byte = (unsigned char *)buf;
    61d2:	4603      	mov	r3, r0

	while (((uintptr_t)d_byte) & (sizeof(mem_word_t) - 1)) {
    61d4:	079c      	lsls	r4, r3, #30
    61d6:	d111      	bne.n	61fc <memset+0x2e>
	/* do word-sized initialization as long as possible */

	mem_word_t *d_word = (mem_word_t *)d_byte;
	mem_word_t c_word = (mem_word_t)c_byte;

	c_word |= c_word << 8;
    61d8:	ea41 2401 	orr.w	r4, r1, r1, lsl #8
	c_word |= c_word << 16;
    61dc:	f022 0603 	bic.w	r6, r2, #3
    61e0:	ea44 4504 	orr.w	r5, r4, r4, lsl #16
#if Z_MEM_WORD_T_WIDTH > 32
	c_word |= c_word << 32;
#endif

	while (n >= sizeof(mem_word_t)) {
    61e4:	441e      	add	r6, r3
    61e6:	0894      	lsrs	r4, r2, #2
    61e8:	42b3      	cmp	r3, r6
    61ea:	d10d      	bne.n	6208 <memset+0x3a>
    61ec:	f06f 0503 	mvn.w	r5, #3
    61f0:	fb05 2204 	mla	r2, r5, r4, r2
    61f4:	441a      	add	r2, r3

	/* do byte-sized initialization until finished */

	d_byte = (unsigned char *)d_word;

	while (n > 0) {
    61f6:	4293      	cmp	r3, r2
    61f8:	d109      	bne.n	620e <memset+0x40>
		*(d_byte++) = c_byte;
		n--;
	}

	return buf;
}
    61fa:	bd70      	pop	{r4, r5, r6, pc}
		if (n == 0) {
    61fc:	2a00      	cmp	r2, #0
    61fe:	d0fc      	beq.n	61fa <memset+0x2c>
		*(d_byte++) = c_byte;
    6200:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    6204:	3a01      	subs	r2, #1
    6206:	e7e5      	b.n	61d4 <memset+0x6>
		*(d_word++) = c_word;
    6208:	f843 5b04 	str.w	r5, [r3], #4
		n -= sizeof(mem_word_t);
    620c:	e7ec      	b.n	61e8 <memset+0x1a>
		*(d_byte++) = c_byte;
    620e:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    6212:	e7f0      	b.n	61f6 <memset+0x28>

00006214 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6214:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6218:	b923      	cbnz	r3, 6224 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    621a:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    621e:	f000 0001 	and.w	r0, r0, #1
    6222:	4770      	bx	lr
		return false;
    6224:	2000      	movs	r0, #0
}
    6226:	4770      	bx	lr

00006228 <_stdout_hook_default>:
}
    6228:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    622c:	4770      	bx	lr

0000622e <z_platform_init>:

void z_platform_init(void)
{
	SystemInit();
    622e:	f7fc bcd5 	b.w	2bdc <SystemInit>

00006232 <gpio_nrfx_port_get_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    6232:	6843      	ldr	r3, [r0, #4]
    6234:	685b      	ldr	r3, [r3, #4]
    return p_reg->IN;
    6236:	f8d3 3510 	ldr.w	r3, [r3, #1296]	; 0x510
	*value = nrf_gpio_port_in_read(reg);
    623a:	600b      	str	r3, [r1, #0]
}
    623c:	2000      	movs	r0, #0
    623e:	4770      	bx	lr

00006240 <gpio_nrfx_port_set_masked_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    6240:	6843      	ldr	r3, [r0, #4]
    6242:	685b      	ldr	r3, [r3, #4]
    return p_reg->OUT;
    6244:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
	nrf_gpio_port_out_write(reg, value_tmp | (mask & value));
    6248:	4042      	eors	r2, r0
    624a:	400a      	ands	r2, r1
    624c:	4042      	eors	r2, r0
    p_reg->OUT = value;
    624e:	f8c3 2504 	str.w	r2, [r3, #1284]	; 0x504
}
    6252:	2000      	movs	r0, #0
    6254:	4770      	bx	lr

00006256 <gpio_nrfx_port_set_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    6256:	6843      	ldr	r3, [r0, #4]
    6258:	685b      	ldr	r3, [r3, #4]
}
    625a:	2000      	movs	r0, #0
    p_reg->OUTSET = set_mask;
    625c:	f8c3 1508 	str.w	r1, [r3, #1288]	; 0x508
    6260:	4770      	bx	lr

00006262 <gpio_nrfx_port_clear_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    6262:	6843      	ldr	r3, [r0, #4]
    6264:	685b      	ldr	r3, [r3, #4]
}
    6266:	2000      	movs	r0, #0
    p_reg->OUTCLR = clr_mask;
    6268:	f8c3 150c 	str.w	r1, [r3, #1292]	; 0x50c
    626c:	4770      	bx	lr

0000626e <gpio_nrfx_port_toggle_bits>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    626e:	6843      	ldr	r3, [r0, #4]
    6270:	685a      	ldr	r2, [r3, #4]
    return p_reg->OUT;
    6272:	f8d2 3504 	ldr.w	r3, [r2, #1284]	; 0x504
	nrf_gpio_port_out_write(reg, value ^ mask);
    6276:	404b      	eors	r3, r1
    p_reg->OUT = value;
    6278:	f8c2 3504 	str.w	r3, [r2, #1284]	; 0x504
}
    627c:	2000      	movs	r0, #0
    627e:	4770      	bx	lr

00006280 <gpio_nrfx_manage_callback>:
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    6280:	68c3      	ldr	r3, [r0, #12]
Z_GENLIST_IS_EMPTY(slist)
    6282:	6858      	ldr	r0, [r3, #4]
{
    6284:	b530      	push	{r4, r5, lr}
	if (!sys_slist_is_empty(callbacks)) {
    6286:	b158      	cbz	r0, 62a0 <gpio_nrfx_manage_callback+0x20>
 * @return true if node was removed
 */
static inline bool sys_slist_find_and_remove(sys_slist_t *list,
					     sys_snode_t *node);

Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    6288:	2400      	movs	r4, #0
    628a:	4281      	cmp	r1, r0
    628c:	d113      	bne.n	62b6 <gpio_nrfx_manage_callback+0x36>
Z_GENLIST_REMOVE(slist, snode)
    628e:	6808      	ldr	r0, [r1, #0]
    6290:	b95c      	cbnz	r4, 62aa <gpio_nrfx_manage_callback+0x2a>
    6292:	689c      	ldr	r4, [r3, #8]
	list->head = node;
    6294:	6058      	str	r0, [r3, #4]
Z_GENLIST_REMOVE(slist, snode)
    6296:	42a1      	cmp	r1, r4
    6298:	d100      	bne.n	629c <gpio_nrfx_manage_callback+0x1c>
	list->tail = node;
    629a:	6098      	str	r0, [r3, #8]
	parent->next = child;
    629c:	2000      	movs	r0, #0
    629e:	6008      	str	r0, [r1, #0]
	if (set) {
    62a0:	b972      	cbnz	r2, 62c0 <gpio_nrfx_manage_callback+0x40>
	return 0;
    62a2:	2000      	movs	r0, #0
}
    62a4:	bd30      	pop	{r4, r5, pc}
    62a6:	4628      	mov	r0, r5
    62a8:	e7ef      	b.n	628a <gpio_nrfx_manage_callback+0xa>
    62aa:	6020      	str	r0, [r4, #0]
Z_GENLIST_REMOVE(slist, snode)
    62ac:	6898      	ldr	r0, [r3, #8]
    62ae:	4281      	cmp	r1, r0
	list->tail = node;
    62b0:	bf08      	it	eq
    62b2:	609c      	streq	r4, [r3, #8]
}
    62b4:	e7f2      	b.n	629c <gpio_nrfx_manage_callback+0x1c>
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    62b6:	6805      	ldr	r5, [r0, #0]
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    62b8:	4604      	mov	r4, r0
    62ba:	2d00      	cmp	r5, #0
    62bc:	d1f3      	bne.n	62a6 <gpio_nrfx_manage_callback+0x26>
			if (!set) {
    62be:	b13a      	cbz	r2, 62d0 <gpio_nrfx_manage_callback+0x50>
Z_GENLIST_PREPEND(slist, snode)
    62c0:	685a      	ldr	r2, [r3, #4]
	parent->next = child;
    62c2:	600a      	str	r2, [r1, #0]
Z_GENLIST_PREPEND(slist, snode)
    62c4:	6898      	ldr	r0, [r3, #8]
	list->head = node;
    62c6:	6059      	str	r1, [r3, #4]
Z_GENLIST_PREPEND(slist, snode)
    62c8:	2800      	cmp	r0, #0
    62ca:	d1ea      	bne.n	62a2 <gpio_nrfx_manage_callback+0x22>
	list->tail = node;
    62cc:	6099      	str	r1, [r3, #8]
}
    62ce:	e7e9      	b.n	62a4 <gpio_nrfx_manage_callback+0x24>
				return -EINVAL;
    62d0:	f06f 0015 	mvn.w	r0, #21
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    62d4:	e7e6      	b.n	62a4 <gpio_nrfx_manage_callback+0x24>

000062d6 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    62d6:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    62da:	b923      	cbnz	r3, 62e6 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    62dc:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    62e0:	f000 0001 	and.w	r0, r0, #1
    62e4:	4770      	bx	lr
		return false;
    62e6:	2000      	movs	r0, #0
}
    62e8:	4770      	bx	lr

000062ea <uart_nrfx_config_get>:
	*cfg = get_dev_data(dev)->uart_config;
    62ea:	68c2      	ldr	r2, [r0, #12]
{
    62ec:	460b      	mov	r3, r1
	*cfg = get_dev_data(dev)->uart_config;
    62ee:	e892 0003 	ldmia.w	r2, {r0, r1}
    62f2:	e883 0003 	stmia.w	r3, {r0, r1}
}
    62f6:	2000      	movs	r0, #0
    62f8:	4770      	bx	lr

000062fa <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    62fa:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    62fe:	b923      	cbnz	r3, 630a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6300:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6304:	f000 0001 	and.w	r0, r0, #1
    6308:	4770      	bx	lr
		return false;
    630a:	2000      	movs	r0, #0
}
    630c:	4770      	bx	lr

0000630e <nrfx_busy_wait>:
{
	((nrfx_irq_handler_t)irq_handler)();
}

void nrfx_busy_wait(uint32_t usec_to_wait)
{
    630e:	e92d 0140 	stmdb	sp!, {r6, r8}
    6312:	4603      	mov	r3, r0
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6314:	f3ef 8205 	mrs	r2, IPSR
	if (value) {
    6318:	b942      	cbnz	r2, 632c <nrfx_busy_wait+0x1e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    631a:	f3ef 8214 	mrs	r2, CONTROL
	if (z_syscall_trap()) {
    631e:	07d2      	lsls	r2, r2, #31
    6320:	d504      	bpl.n	632c <nrfx_busy_wait+0x1e>
	register uint32_t r6 __asm__("r6") = call_id;
    6322:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    6324:	df03      	svc	3
	k_busy_wait(usec_to_wait);
}
    6326:	e8bd 0140 	ldmia.w	sp!, {r6, r8}
    632a:	4770      	bx	lr
    632c:	e8bd 0140 	ldmia.w	sp!, {r6, r8}
	z_impl_k_busy_wait(usec_to_wait);
    6330:	4618      	mov	r0, r3
    6332:	f000 bc31 	b.w	6b98 <z_impl_k_busy_wait>

00006336 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6336:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    633a:	b923      	cbnz	r3, 6346 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    633c:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6340:	f000 0001 	and.w	r0, r0, #1
    6344:	4770      	bx	lr
		return false;
    6346:	2000      	movs	r0, #0
}
    6348:	4770      	bx	lr

0000634a <arch_system_halt>:
	__asm__ volatile(
    634a:	f04f 0220 	mov.w	r2, #32
    634e:	f3ef 8311 	mrs	r3, BASEPRI
    6352:	f382 8811 	msr	BASEPRI, r2
    6356:	f3bf 8f6f 	isb	sy
	/* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 */

	(void)arch_irq_lock();
	for (;;) {
    635a:	e7fe      	b.n	635a <arch_system_halt+0x10>

0000635c <k_sys_fatal_error_handler>:
/* LCOV_EXCL_STOP */

/* LCOV_EXCL_START */
__weak void k_sys_fatal_error_handler(unsigned int reason,
				      const z_arch_esf_t *esf)
{
    635c:	b508      	push	{r3, lr}
    635e:	4602      	mov	r2, r0
    6360:	f7ff ffe9 	bl	6336 <arch_is_user_context>
	ARG_UNUSED(esf);

	LOG_PANIC();
	LOG_ERR("Halting system");
	arch_system_halt(reason);
    6364:	4610      	mov	r0, r2
    6366:	f7ff fff0 	bl	634a <arch_system_halt>

0000636a <z_fatal_error>:
	return 0;
#endif
}

void z_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    636a:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    636c:	4606      	mov	r6, r0
    636e:	460c      	mov	r4, r1
    6370:	f04f 0320 	mov.w	r3, #32
    6374:	f3ef 8711 	mrs	r7, BASEPRI
    6378:	f383 8811 	msr	BASEPRI, r3
    637c:	f3bf 8f6f 	isb	sy
	return z_impl_k_current_get();
    6380:	f7fe fa4a 	bl	4818 <z_impl_k_current_get>
    6384:	4605      	mov	r5, r0
    6386:	f7ff ffd6 	bl	6336 <arch_is_user_context>
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
    638a:	b12c      	cbz	r4, 6398 <z_fatal_error+0x2e>
	return (esf->basic.xpsr & IPSR_ISR_Msk) ? (true) : (false);
    638c:	69e3      	ldr	r3, [r4, #28]
    638e:	f3c3 0308 	ubfx	r3, r3, #0, #9
    6392:	b10b      	cbz	r3, 6398 <z_fatal_error+0x2e>
    6394:	f7ff ffcf 	bl	6336 <arch_is_user_context>
    6398:	f7ff ffcd 	bl	6336 <arch_is_user_context>
#endif

	LOG_ERR("Current thread: %p (%s)", thread,
		log_strdup(thread_name_get(thread)));

	k_sys_fatal_error_handler(reason, esf);
    639c:	4621      	mov	r1, r4
    639e:	4630      	mov	r0, r6
    63a0:	f7ff ffdc 	bl	635c <k_sys_fatal_error_handler>
	__asm__ volatile(
    63a4:	f387 8811 	msr	BASEPRI, r7
    63a8:	f3bf 8f6f 	isb	sy
	z_impl_k_thread_abort(thread);
    63ac:	4628      	mov	r0, r5
#endif /*CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION */
	}

	arch_irq_unlock(key);
	k_thread_abort(thread);
}
    63ae:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    63b2:	f7fb bbf5 	b.w	1ba0 <z_impl_k_thread_abort>

000063b6 <z_sys_power_save_idle_exit>:
	z_clock_idle_exit();
    63b6:	f7ff be5d 	b.w	6074 <z_clock_idle_exit>

000063ba <mbox_message_match>:
{
    63ba:	460b      	mov	r3, r1
	if (((tx_msg->tx_target_thread == (k_tid_t)K_ANY) ||
    63bc:	6a01      	ldr	r1, [r0, #32]
{
    63be:	b530      	push	{r4, r5, lr}
    63c0:	4602      	mov	r2, r0
	if (((tx_msg->tx_target_thread == (k_tid_t)K_ANY) ||
    63c2:	b111      	cbz	r1, 63ca <mbox_message_match+0x10>
    63c4:	6a18      	ldr	r0, [r3, #32]
    63c6:	4281      	cmp	r1, r0
    63c8:	d124      	bne.n	6414 <mbox_message_match+0x5a>
	    ((rx_msg->rx_source_thread == (k_tid_t)K_ANY) ||
    63ca:	69d8      	ldr	r0, [r3, #28]
    63cc:	69d1      	ldr	r1, [r2, #28]
	     (tx_msg->tx_target_thread == rx_msg->tx_target_thread)) &&
    63ce:	b108      	cbz	r0, 63d4 <mbox_message_match+0x1a>
	    ((rx_msg->rx_source_thread == (k_tid_t)K_ANY) ||
    63d0:	4288      	cmp	r0, r1
    63d2:	d11f      	bne.n	6414 <mbox_message_match+0x5a>
		rx_msg->rx_source_thread = tx_msg->rx_source_thread;
    63d4:	61d9      	str	r1, [r3, #28]
		tx_msg->tx_target_thread = rx_msg->tx_target_thread;
    63d6:	6a19      	ldr	r1, [r3, #32]
		rx_msg->info = tx_msg->info;
    63d8:	6890      	ldr	r0, [r2, #8]
		tx_msg->tx_target_thread = rx_msg->tx_target_thread;
    63da:	6211      	str	r1, [r2, #32]
		temp_info = rx_msg->info;
    63dc:	6899      	ldr	r1, [r3, #8]
		rx_msg->info = tx_msg->info;
    63de:	6098      	str	r0, [r3, #8]
		if (rx_msg->size > tx_msg->size) {
    63e0:	6858      	ldr	r0, [r3, #4]
		tx_msg->info = temp_info;
    63e2:	6091      	str	r1, [r2, #8]
		if (rx_msg->size > tx_msg->size) {
    63e4:	6851      	ldr	r1, [r2, #4]
		rx_msg->tx_data = tx_msg->tx_data;
    63e6:	68d5      	ldr	r5, [r2, #12]
    63e8:	60dd      	str	r5, [r3, #12]
		if (rx_msg->size > tx_msg->size) {
    63ea:	4288      	cmp	r0, r1
			rx_msg->size = tx_msg->size;
    63ec:	bf88      	it	hi
    63ee:	6059      	strhi	r1, [r3, #4]
		rx_msg->tx_block = tx_msg->tx_block;
    63f0:	e9d2 0105 	ldrd	r0, r1, [r2, #20]
    63f4:	f103 0414 	add.w	r4, r3, #20
    63f8:	e884 0003 	stmia.w	r4, {r0, r1}
		if (rx_msg->tx_data != NULL) {
    63fc:	b12d      	cbz	r5, 640a <mbox_message_match+0x50>
			rx_msg->tx_block.data = NULL;
    63fe:	2100      	movs	r1, #0
    6400:	6159      	str	r1, [r3, #20]
		rx_msg->_syncing_thread = tx_msg->_syncing_thread;
    6402:	6a52      	ldr	r2, [r2, #36]	; 0x24
    6404:	625a      	str	r2, [r3, #36]	; 0x24
		return 0;
    6406:	2000      	movs	r0, #0
}
    6408:	bd30      	pop	{r4, r5, pc}
		} else if (rx_msg->tx_block.data != NULL) {
    640a:	6959      	ldr	r1, [r3, #20]
    640c:	2900      	cmp	r1, #0
    640e:	d0f8      	beq.n	6402 <mbox_message_match+0x48>
			rx_msg->tx_data = rx_msg->tx_block.data;
    6410:	60d9      	str	r1, [r3, #12]
    6412:	e7f6      	b.n	6402 <mbox_message_match+0x48>
	return -1;
    6414:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    6418:	e7f6      	b.n	6408 <mbox_message_match+0x4e>

0000641a <k_mbox_init>:
    641a:	f100 0308 	add.w	r3, r0, #8
	list->tail = (sys_dnode_t *)list;
    641e:	e9c0 0000 	strd	r0, r0, [r0]
    6422:	e9c0 3302 	strd	r3, r3, [r0, #8]
}
    6426:	4770      	bx	lr

00006428 <k_mbox_data_get>:
{
    6428:	b510      	push	{r4, lr}
	if (buffer == NULL) {
    642a:	460b      	mov	r3, r1
{
    642c:	4604      	mov	r4, r0
	if (buffer == NULL) {
    642e:	b921      	cbnz	r1, 643a <k_mbox_data_get+0x12>
		rx_msg->size = 0;
    6430:	6041      	str	r1, [r0, #4]
}
    6432:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	mbox_message_dispose(rx_msg);
    6436:	f7fc bec3 	b.w	31c0 <mbox_message_dispose>
	if ((rx_msg->tx_data != NULL) && (rx_msg->size > 0)) {
    643a:	68c1      	ldr	r1, [r0, #12]
    643c:	b121      	cbz	r1, 6448 <k_mbox_data_get+0x20>
    643e:	6842      	ldr	r2, [r0, #4]
    6440:	b112      	cbz	r2, 6448 <k_mbox_data_get+0x20>
		(void)memcpy(buffer, rx_msg->tx_data, rx_msg->size);
    6442:	4618      	mov	r0, r3
    6444:	f7ff fe98 	bl	6178 <memcpy>
	mbox_message_dispose(rx_msg);
    6448:	4620      	mov	r0, r4
    644a:	e7f2      	b.n	6432 <k_mbox_data_get+0xa>

0000644c <k_mem_pool_free>:
	k_mem_pool_free_id(&block->id);
    644c:	f000 be3f 	b.w	70ce <k_mem_pool_free_id>

00006450 <k_mem_pool_malloc>:
{
    6450:	b5df      	push	{r0, r1, r2, r3, r4, r6, r7, lr}
	return __builtin_add_overflow(a, b, result);
    6452:	2408      	movs	r4, #8
    6454:	190a      	adds	r2, r1, r4
    6456:	d208      	bcs.n	646a <k_mem_pool_malloc+0x1a>
	if (k_mem_pool_alloc(pool, &block, size, K_NO_WAIT) != 0) {
    6458:	2600      	movs	r6, #0
    645a:	2700      	movs	r7, #0
    645c:	e9cd 6700 	strd	r6, r7, [sp]
    6460:	eb0d 0104 	add.w	r1, sp, r4
    6464:	f000 fe1a 	bl	709c <k_mem_pool_alloc>
    6468:	b110      	cbz	r0, 6470 <k_mem_pool_malloc+0x20>
		return NULL;
    646a:	2000      	movs	r0, #0
}
    646c:	b004      	add	sp, #16
    646e:	bdd0      	pop	{r4, r6, r7, pc}
	(void)memcpy(block.data, &block.id, sizeof(struct k_mem_block_id));
    6470:	9802      	ldr	r0, [sp, #8]
    6472:	4622      	mov	r2, r4
    6474:	a902      	add	r1, sp, #8
    6476:	f7ff fe7f 	bl	6178 <memcpy>
	return (char *)block.data + WB_UP(sizeof(struct k_mem_block_id));
    647a:	9802      	ldr	r0, [sp, #8]
    647c:	3008      	adds	r0, #8
    647e:	e7f5      	b.n	646c <k_mem_pool_malloc+0x1c>

00006480 <k_free>:
	if (ptr != NULL) {
    6480:	b110      	cbz	r0, 6488 <k_free+0x8>
		k_mem_pool_free_id(ptr);
    6482:	3808      	subs	r0, #8
    6484:	f000 be23 	b.w	70ce <k_mem_pool_free_id>
}
    6488:	4770      	bx	lr

0000648a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    648a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    648e:	b923      	cbnz	r3, 649a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6490:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6494:	f000 0001 	and.w	r0, r0, #1
    6498:	4770      	bx	lr
		return false;
    649a:	2000      	movs	r0, #0
}
    649c:	4770      	bx	lr

0000649e <adjust_owner_prio.isra.0>:
static bool adjust_owner_prio(struct k_mutex *mutex, int32_t new_prio)
    649e:	b508      	push	{r3, lr}
	if (mutex->owner->base.prio != new_prio) {
    64a0:	6803      	ldr	r3, [r0, #0]
    64a2:	f993 300e 	ldrsb.w	r3, [r3, #14]
    64a6:	428b      	cmp	r3, r1
static bool adjust_owner_prio(struct k_mutex *mutex, int32_t new_prio)
    64a8:	4602      	mov	r2, r0
	if (mutex->owner->base.prio != new_prio) {
    64aa:	d006      	beq.n	64ba <adjust_owner_prio.isra.0+0x1c>
    64ac:	f7ff ffed 	bl	648a <arch_is_user_context>
}
    64b0:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		return z_set_prio(mutex->owner, new_prio);
    64b4:	6810      	ldr	r0, [r2, #0]
    64b6:	f7fe b819 	b.w	44ec <z_set_prio>
}
    64ba:	2000      	movs	r0, #0
    64bc:	bd08      	pop	{r3, pc}

000064be <z_impl_k_mutex_init>:
{
    64be:	b510      	push	{r4, lr}
	mutex->owner = NULL;
    64c0:	2400      	movs	r4, #0
	mutex->lock_count = 0U;
    64c2:	e9c0 4402 	strd	r4, r4, [r0, #8]
    64c6:	e9c0 0000 	strd	r0, r0, [r0]
	z_object_init(mutex);
    64ca:	f000 fd37 	bl	6f3c <z_object_init>
}
    64ce:	4620      	mov	r0, r4
    64d0:	bd10      	pop	{r4, pc}

000064d2 <sys_dlist_get>:
 *
 * @return the first node in the list, NULL if list is empty
 */

static inline sys_dnode_t *sys_dlist_get(sys_dlist_t *list)
{
    64d2:	4603      	mov	r3, r0
	return list->head == list;
    64d4:	6800      	ldr	r0, [r0, #0]
	sys_dnode_t *node = NULL;

	if (!sys_dlist_is_empty(list)) {
    64d6:	4283      	cmp	r3, r0
	node->prev->next = node->next;
    64d8:	bf1f      	itttt	ne
    64da:	e9d0 3200 	ldrdne	r3, r2, [r0]
    64de:	6013      	strne	r3, [r2, #0]
	node->next->prev = node->prev;
    64e0:	605a      	strne	r2, [r3, #4]
	node->next = NULL;
    64e2:	2300      	movne	r3, #0
	node->prev = NULL;
    64e4:	bf14      	ite	ne
    64e6:	e9c0 3300 	strdne	r3, r3, [r0]
	sys_dnode_t *node = NULL;
    64ea:	2000      	moveq	r0, #0
		node = list->head;
		sys_dlist_remove(node);
	}

	return node;
}
    64ec:	4770      	bx	lr

000064ee <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    64ee:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    64f2:	b923      	cbnz	r3, 64fe <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    64f4:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    64f8:	f000 0001 	and.w	r0, r0, #1
    64fc:	4770      	bx	lr
		return false;
    64fe:	2000      	movs	r0, #0
}
    6500:	4770      	bx	lr

00006502 <pipe_xfer>:
	size_t num_bytes = MIN(dest_size, src_size);
    6502:	428b      	cmp	r3, r1
    6504:	bf28      	it	cs
    6506:	460b      	movcs	r3, r1
{
    6508:	b510      	push	{r4, lr}
    650a:	4604      	mov	r4, r0
	size_t num_bytes = MIN(dest_size, src_size);
    650c:	4618      	mov	r0, r3
	const unsigned char *end = src + num_bytes;
    650e:	18d3      	adds	r3, r2, r3
	while (src != end) {
    6510:	429a      	cmp	r2, r3
    6512:	d100      	bne.n	6516 <pipe_xfer+0x14>
}
    6514:	bd10      	pop	{r4, pc}
		*dest = *src;
    6516:	f812 1b01 	ldrb.w	r1, [r2], #1
    651a:	f804 1b01 	strb.w	r1, [r4], #1
		src++;
    651e:	e7f7      	b.n	6510 <pipe_xfer+0xe>

00006520 <pipe_buffer_put>:
{
    6520:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	size_t  num_bytes_written = 0;
    6524:	2500      	movs	r5, #0
{
    6526:	4604      	mov	r4, r0
    6528:	460e      	mov	r6, r1
    652a:	4617      	mov	r7, r2
    652c:	f04f 0802 	mov.w	r8, #2
			pipe->write_index = 0;
    6530:	46a9      	mov	r9, r5
		run_length = MIN(pipe->size - pipe->bytes_used,
    6532:	6861      	ldr	r1, [r4, #4]
    6534:	f8d4 c010 	ldr.w	ip, [r4, #16]
    6538:	68a3      	ldr	r3, [r4, #8]
		bytes_copied = pipe_xfer(pipe->buffer + pipe->write_index,
    653a:	6820      	ldr	r0, [r4, #0]
		run_length = MIN(pipe->size - pipe->bytes_used,
    653c:	eba1 0e03 	sub.w	lr, r1, r3
    6540:	eba1 010c 	sub.w	r1, r1, ip
		bytes_copied = pipe_xfer(pipe->buffer + pipe->write_index,
    6544:	4571      	cmp	r1, lr
    6546:	eba7 0305 	sub.w	r3, r7, r5
    654a:	eb06 0205 	add.w	r2, r6, r5
    654e:	bf28      	it	cs
    6550:	4671      	movcs	r1, lr
    6552:	4460      	add	r0, ip
    6554:	f7ff ffd5 	bl	6502 <pipe_xfer>
		pipe->bytes_used += bytes_copied;
    6558:	68a3      	ldr	r3, [r4, #8]
    655a:	4403      	add	r3, r0
    655c:	60a3      	str	r3, [r4, #8]
		pipe->write_index += bytes_copied;
    655e:	6923      	ldr	r3, [r4, #16]
		num_bytes_written += bytes_copied;
    6560:	4405      	add	r5, r0
		pipe->write_index += bytes_copied;
    6562:	4418      	add	r0, r3
		if (pipe->write_index == pipe->size) {
    6564:	6863      	ldr	r3, [r4, #4]
    6566:	4298      	cmp	r0, r3
			pipe->write_index = 0;
    6568:	bf08      	it	eq
    656a:	4648      	moveq	r0, r9
	for (i = 0; i < 2; i++) {
    656c:	f1b8 0f01 	cmp.w	r8, #1
			pipe->write_index = 0;
    6570:	6120      	str	r0, [r4, #16]
	for (i = 0; i < 2; i++) {
    6572:	d102      	bne.n	657a <pipe_buffer_put+0x5a>
}
    6574:	4628      	mov	r0, r5
    6576:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
    657a:	f04f 0801 	mov.w	r8, #1
    657e:	e7d8      	b.n	6532 <pipe_buffer_put+0x12>

00006580 <pipe_xfer_prepare>:
{
    6580:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    6584:	4605      	mov	r5, r0
    6586:	4688      	mov	r8, r1
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    6588:	e9dd 010a 	ldrd	r0, r1, [sp, #40]	; 0x28
{
    658c:	4616      	mov	r6, r2
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    658e:	ea50 0201 	orrs.w	r2, r0, r1
{
    6592:	9f08      	ldr	r7, [sp, #32]
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    6594:	d10b      	bne.n	65ae <pipe_xfer_prepare+0x2e>
	return list->head == list;
    6596:	6834      	ldr	r4, [r6, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    6598:	42a6      	cmp	r6, r4
    659a:	d023      	beq.n	65e4 <pipe_xfer_prepare+0x64>
    659c:	2c00      	cmp	r4, #0
    659e:	bf38      	it	cc
    65a0:	2400      	movcc	r4, #0
    65a2:	2200      	movs	r2, #0
		_WAIT_Q_FOR_EACH(wait_q, thread) {
    65a4:	b984      	cbnz	r4, 65c8 <pipe_xfer_prepare+0x48>
		if (num_bytes + pipe_space < min_xfer) {
    65a6:	441a      	add	r2, r3
    65a8:	9b09      	ldr	r3, [sp, #36]	; 0x24
    65aa:	429a      	cmp	r2, r3
    65ac:	d32d      	bcc.n	660a <pipe_xfer_prepare+0x8a>
	list->tail = (sys_dnode_t *)list;
    65ae:	e9c5 5500 	strd	r5, r5, [r5]
	num_bytes = 0;
    65b2:	f04f 0900 	mov.w	r9, #0
	return list->head == list;
    65b6:	6834      	ldr	r4, [r6, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    65b8:	42a6      	cmp	r6, r4
    65ba:	d024      	beq.n	6606 <pipe_xfer_prepare+0x86>
	while ((thread = z_waitq_head(wait_q)) != NULL) {
    65bc:	b9a4      	cbnz	r4, 65e8 <pipe_xfer_prepare+0x68>
	*waiter = (num_bytes > bytes_to_xfer) ? thread : NULL;
    65be:	f8c8 4000 	str.w	r4, [r8]
    65c2:	2001      	movs	r0, #1
}
    65c4:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
			num_bytes += desc->bytes_to_xfer;
    65c8:	6961      	ldr	r1, [r4, #20]
    65ca:	6849      	ldr	r1, [r1, #4]
    65cc:	440a      	add	r2, r1
			if (num_bytes >= bytes_to_xfer) {
    65ce:	42ba      	cmp	r2, r7
    65d0:	d2e9      	bcs.n	65a6 <pipe_xfer_prepare+0x26>
	return (node == list->tail) ? NULL : node->next;
    65d2:	6871      	ldr	r1, [r6, #4]
    65d4:	428c      	cmp	r4, r1
    65d6:	bf14      	ite	ne
    65d8:	6824      	ldrne	r4, [r4, #0]
    65da:	2400      	moveq	r4, #0
    65dc:	2c00      	cmp	r4, #0
    65de:	bf38      	it	cc
    65e0:	2400      	movcc	r4, #0
    65e2:	e7df      	b.n	65a4 <pipe_xfer_prepare+0x24>
    65e4:	2200      	movs	r2, #0
    65e6:	e7de      	b.n	65a6 <pipe_xfer_prepare+0x26>
		num_bytes += desc->bytes_to_xfer;
    65e8:	6963      	ldr	r3, [r4, #20]
    65ea:	685b      	ldr	r3, [r3, #4]
    65ec:	4499      	add	r9, r3
		if (num_bytes > bytes_to_xfer) {
    65ee:	454f      	cmp	r7, r9
    65f0:	d3e5      	bcc.n	65be <pipe_xfer_prepare+0x3e>
		z_unpend_thread(thread);
    65f2:	4620      	mov	r0, r4
    65f4:	f000 f95a 	bl	68ac <z_unpend_thread>
	node->prev = list->tail;
    65f8:	686b      	ldr	r3, [r5, #4]
    65fa:	6063      	str	r3, [r4, #4]
	list->tail->next = node;
    65fc:	686b      	ldr	r3, [r5, #4]
	node->next = list;
    65fe:	6025      	str	r5, [r4, #0]
	list->tail->next = node;
    6600:	601c      	str	r4, [r3, #0]
	list->tail = node;
    6602:	606c      	str	r4, [r5, #4]
}
    6604:	e7d7      	b.n	65b6 <pipe_xfer_prepare+0x36>
    6606:	2400      	movs	r4, #0
    6608:	e7d9      	b.n	65be <pipe_xfer_prepare+0x3e>
			return false;
    660a:	2000      	movs	r0, #0
    660c:	e7da      	b.n	65c4 <pipe_xfer_prepare+0x44>

0000660e <pipe_thread_ready>:
	if ((thread->base.thread_state & _THREAD_DUMMY) != 0U) {
    660e:	7b43      	ldrb	r3, [r0, #13]
    6610:	07db      	lsls	r3, r3, #31
    6612:	d501      	bpl.n	6618 <pipe_thread_ready+0xa>
		pipe_async_finish((struct k_pipe_async *)thread);
    6614:	f7fc bfd6 	b.w	35c4 <pipe_async_finish>
	z_ready_thread(thread);
    6618:	f000 b96f 	b.w	68fa <z_ready_thread>

0000661c <k_pipe_init>:
	pipe->size = size;
    661c:	e9c0 1200 	strd	r1, r2, [r0]
    6620:	f100 011c 	add.w	r1, r0, #28
	pipe->bytes_used = 0;
    6624:	2200      	movs	r2, #0
	list->tail = (sys_dnode_t *)list;
    6626:	e9c0 1107 	strd	r1, r1, [r0, #28]
    662a:	f100 0114 	add.w	r1, r0, #20
	pipe->read_index = 0;
    662e:	e9c0 2202 	strd	r2, r2, [r0, #8]
    6632:	e9c0 1105 	strd	r1, r1, [r0, #20]
	pipe->write_index = 0;
    6636:	6102      	str	r2, [r0, #16]
	pipe->flags = 0;
    6638:	f880 2024 	strb.w	r2, [r0, #36]	; 0x24
	z_object_init(pipe);
    663c:	f000 bc7e 	b.w	6f3c <z_object_init>

00006640 <z_impl_k_pipe_alloc_init>:
{
    6640:	b538      	push	{r3, r4, r5, lr}
    6642:	4605      	mov	r5, r0
	if (size != 0) {
    6644:	460c      	mov	r4, r1
    6646:	b169      	cbz	r1, 6664 <z_impl_k_pipe_alloc_init+0x24>
		buffer = z_thread_malloc(size);
    6648:	4608      	mov	r0, r1
    664a:	f7fc fe6d 	bl	3328 <z_thread_malloc>
		if (buffer != NULL) {
    664e:	4601      	mov	r1, r0
    6650:	b160      	cbz	r0, 666c <z_impl_k_pipe_alloc_init+0x2c>
			k_pipe_init(pipe, buffer, size);
    6652:	4622      	mov	r2, r4
    6654:	4628      	mov	r0, r5
    6656:	f7ff ffe1 	bl	661c <k_pipe_init>
			pipe->flags = K_PIPE_FLAG_ALLOC;
    665a:	2301      	movs	r3, #1
    665c:	f885 3024 	strb.w	r3, [r5, #36]	; 0x24
			ret = 0;
    6660:	2000      	movs	r0, #0
}
    6662:	bd38      	pop	{r3, r4, r5, pc}
		k_pipe_init(pipe, NULL, 0);
    6664:	460a      	mov	r2, r1
    6666:	f7ff ffd9 	bl	661c <k_pipe_init>
		ret = 0;
    666a:	e7f9      	b.n	6660 <z_impl_k_pipe_alloc_init+0x20>
			ret = -ENOMEM;
    666c:	f06f 000b 	mvn.w	r0, #11
	return ret;
    6670:	e7f7      	b.n	6662 <z_impl_k_pipe_alloc_init+0x22>

00006672 <z_impl_k_pipe_put>:
{
    6672:	b410      	push	{r4}
	return z_pipe_put_internal(pipe, NULL, data,
    6674:	9c01      	ldr	r4, [sp, #4]
    6676:	e9cd 3401 	strd	r3, r4, [sp, #4]
    667a:	4613      	mov	r3, r2
}
    667c:	bc10      	pop	{r4}
	return z_pipe_put_internal(pipe, NULL, data,
    667e:	460a      	mov	r2, r1
    6680:	2100      	movs	r1, #0
    6682:	f7fc bff3 	b.w	366c <z_pipe_put_internal>

00006686 <z_impl_k_pipe_read_avail>:
{
    6686:	4602      	mov	r2, r0
	if (pipe->buffer == NULL || pipe->size == 0) {
    6688:	6800      	ldr	r0, [r0, #0]
    668a:	b190      	cbz	r0, 66b2 <z_impl_k_pipe_read_avail+0x2c>
    668c:	6850      	ldr	r0, [r2, #4]
    668e:	b180      	cbz	r0, 66b2 <z_impl_k_pipe_read_avail+0x2c>
	__asm__ volatile(
    6690:	f04f 0320 	mov.w	r3, #32
    6694:	f3ef 8111 	mrs	r1, BASEPRI
    6698:	f383 8811 	msr	BASEPRI, r3
    669c:	f3bf 8f6f 	isb	sy
	if (pipe->read_index == pipe->write_index) {
    66a0:	e9d2 3003 	ldrd	r3, r0, [r2, #12]
    66a4:	4283      	cmp	r3, r0
    66a6:	d105      	bne.n	66b4 <z_impl_k_pipe_read_avail+0x2e>
		res = pipe->bytes_used;
    66a8:	6890      	ldr	r0, [r2, #8]
	__asm__ volatile(
    66aa:	f381 8811 	msr	BASEPRI, r1
    66ae:	f3bf 8f6f 	isb	sy
}
    66b2:	4770      	bx	lr
		res = pipe->size - (pipe->read_index - pipe->write_index);
    66b4:	bf24      	itt	cs
    66b6:	6852      	ldrcs	r2, [r2, #4]
    66b8:	1880      	addcs	r0, r0, r2
    66ba:	1ac0      	subs	r0, r0, r3
    66bc:	e7f5      	b.n	66aa <z_impl_k_pipe_read_avail+0x24>

000066be <z_impl_k_pipe_write_avail>:
{
    66be:	4602      	mov	r2, r0
	if (pipe->buffer == NULL || pipe->size == 0) {
    66c0:	6800      	ldr	r0, [r0, #0]
    66c2:	b1a0      	cbz	r0, 66ee <z_impl_k_pipe_write_avail+0x30>
    66c4:	6850      	ldr	r0, [r2, #4]
    66c6:	b190      	cbz	r0, 66ee <z_impl_k_pipe_write_avail+0x30>
	__asm__ volatile(
    66c8:	f04f 0320 	mov.w	r3, #32
    66cc:	f3ef 8111 	mrs	r1, BASEPRI
    66d0:	f383 8811 	msr	BASEPRI, r3
    66d4:	f3bf 8f6f 	isb	sy
	if (pipe->write_index == pipe->read_index) {
    66d8:	e9d2 0303 	ldrd	r0, r3, [r2, #12]
    66dc:	4283      	cmp	r3, r0
    66de:	d107      	bne.n	66f0 <z_impl_k_pipe_write_avail+0x32>
		res = pipe->size - pipe->bytes_used;
    66e0:	e9d2 3001 	ldrd	r3, r0, [r2, #4]
    66e4:	1a18      	subs	r0, r3, r0
	__asm__ volatile(
    66e6:	f381 8811 	msr	BASEPRI, r1
    66ea:	f3bf 8f6f 	isb	sy
}
    66ee:	4770      	bx	lr
		res = pipe->size - (pipe->write_index - pipe->read_index);
    66f0:	bf24      	itt	cs
    66f2:	6852      	ldrcs	r2, [r2, #4]
    66f4:	1880      	addcs	r0, r0, r2
    66f6:	1ac0      	subs	r0, r0, r3
    66f8:	e7f5      	b.n	66e6 <z_impl_k_pipe_write_avail+0x28>

000066fa <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    66fa:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    66fe:	b923      	cbnz	r3, 670a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6700:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6704:	f000 0001 	and.w	r0, r0, #1
    6708:	4770      	bx	lr
		return false;
    670a:	2000      	movs	r0, #0
}
    670c:	4770      	bx	lr

0000670e <queue_insert>:
{
    670e:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    6712:	4604      	mov	r4, r0
    6714:	460d      	mov	r5, r1
    6716:	4690      	mov	r8, r2
    6718:	4699      	mov	r9, r3
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    671a:	f100 0708 	add.w	r7, r0, #8
	__asm__ volatile(
    671e:	f04f 0320 	mov.w	r3, #32
    6722:	f3ef 8611 	mrs	r6, BASEPRI
    6726:	f383 8811 	msr	BASEPRI, r3
    672a:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&queue->wait_q);
    672e:	4638      	mov	r0, r7
    6730:	f000 f95b 	bl	69ea <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    6734:	b160      	cbz	r0, 6750 <queue_insert+0x42>
    6736:	2400      	movs	r4, #0
    6738:	f8c0 4090 	str.w	r4, [r0, #144]	; 0x90
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
    673c:	f8c0 8014 	str.w	r8, [r0, #20]
	z_ready_thread(thread);
    6740:	f000 f8db 	bl	68fa <z_ready_thread>
	z_reschedule(&queue->lock, key);
    6744:	4638      	mov	r0, r7
    6746:	4631      	mov	r1, r6
    6748:	f000 f88f 	bl	686a <z_reschedule>
	return 0;
    674c:	2000      	movs	r0, #0
    674e:	e00c      	b.n	676a <queue_insert+0x5c>
	if (alloc) {
    6750:	f1b9 0f00 	cmp.w	r9, #0
    6754:	d01c      	beq.n	6790 <queue_insert+0x82>
		anode = z_thread_malloc(sizeof(*anode));
    6756:	2008      	movs	r0, #8
    6758:	f7fc fde6 	bl	3328 <z_thread_malloc>
		if (anode == NULL) {
    675c:	b938      	cbnz	r0, 676e <queue_insert+0x60>
	__asm__ volatile(
    675e:	f386 8811 	msr	BASEPRI, r6
    6762:	f3bf 8f6f 	isb	sy
			return -ENOMEM;
    6766:	f06f 000b 	mvn.w	r0, #11
}
    676a:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
	node->next_and_flags = flags;
    676e:	2301      	movs	r3, #1
		anode->data = data;
    6770:	f8c0 8004 	str.w	r8, [r0, #4]
    6774:	6003      	str	r3, [r0, #0]
Z_GENLIST_INSERT(sflist, sfnode)
    6776:	6803      	ldr	r3, [r0, #0]
    6778:	f003 0203 	and.w	r2, r3, #3
    677c:	b965      	cbnz	r5, 6798 <queue_insert+0x8a>
	parent->next_and_flags = cur_flags | (unative_t)child;
    677e:	6823      	ldr	r3, [r4, #0]
    6780:	4313      	orrs	r3, r2
    6782:	6003      	str	r3, [r0, #0]
Z_GENLIST_PREPEND(sflist, sfnode)
    6784:	6863      	ldr	r3, [r4, #4]
	list->head = node;
    6786:	6020      	str	r0, [r4, #0]
Z_GENLIST_PREPEND(sflist, sfnode)
    6788:	2b00      	cmp	r3, #0
    678a:	d1db      	bne.n	6744 <queue_insert+0x36>
	list->tail = node;
    678c:	6060      	str	r0, [r4, #4]
}
    678e:	e7d9      	b.n	6744 <queue_insert+0x36>
	node->next_and_flags = flags;
    6790:	f8c8 9000 	str.w	r9, [r8]
}
    6794:	4640      	mov	r0, r8
    6796:	e7ee      	b.n	6776 <queue_insert+0x68>
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    6798:	682b      	ldr	r3, [r5, #0]
Z_GENLIST_INSERT(sflist, sfnode)
    679a:	f033 0303 	bics.w	r3, r3, #3
    679e:	d10b      	bne.n	67b8 <queue_insert+0xaa>
	parent->next_and_flags = cur_flags | (unative_t)child;
    67a0:	6002      	str	r2, [r0, #0]
Z_GENLIST_APPEND(sflist, sfnode)
    67a2:	6862      	ldr	r2, [r4, #4]
    67a4:	b912      	cbnz	r2, 67ac <queue_insert+0x9e>
	list->head = node;
    67a6:	e9c4 0000 	strd	r0, r0, [r4]
}
    67aa:	e7cb      	b.n	6744 <queue_insert+0x36>
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    67ac:	6813      	ldr	r3, [r2, #0]
	parent->next_and_flags = cur_flags | (unative_t)child;
    67ae:	f003 0303 	and.w	r3, r3, #3
    67b2:	4303      	orrs	r3, r0
    67b4:	6013      	str	r3, [r2, #0]
    67b6:	e7e9      	b.n	678c <queue_insert+0x7e>
    67b8:	4313      	orrs	r3, r2
    67ba:	6003      	str	r3, [r0, #0]
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    67bc:	682b      	ldr	r3, [r5, #0]
	parent->next_and_flags = cur_flags | (unative_t)child;
    67be:	f003 0303 	and.w	r3, r3, #3
    67c2:	4318      	orrs	r0, r3
    67c4:	6028      	str	r0, [r5, #0]
}
    67c6:	e7bd      	b.n	6744 <queue_insert+0x36>

000067c8 <z_queue_node_peek>:
{
    67c8:	b510      	push	{r4, lr}
	if ((node != NULL) && (sys_sfnode_flags_get(node) != (uint8_t)0)) {
    67ca:	4604      	mov	r4, r0
    67cc:	b130      	cbz	r0, 67dc <z_queue_node_peek+0x14>
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    67ce:	6802      	ldr	r2, [r0, #0]
    67d0:	0793      	lsls	r3, r2, #30
    67d2:	d003      	beq.n	67dc <z_queue_node_peek+0x14>
		ret = anode->data;
    67d4:	6844      	ldr	r4, [r0, #4]
		if (needs_free) {
    67d6:	b109      	cbz	r1, 67dc <z_queue_node_peek+0x14>
			k_free(anode);
    67d8:	f7ff fe52 	bl	6480 <k_free>
}
    67dc:	4620      	mov	r0, r4
    67de:	bd10      	pop	{r4, pc}

000067e0 <z_impl_k_queue_init>:
	list->head = NULL;
    67e0:	2200      	movs	r2, #0
	list->tail = NULL;
    67e2:	e9c0 2200 	strd	r2, r2, [r0]
    67e6:	f100 0208 	add.w	r2, r0, #8
    67ea:	e9c0 2202 	strd	r2, r2, [r0, #8]
	z_object_init(queue);
    67ee:	f000 bba5 	b.w	6f3c <z_object_init>

000067f2 <z_impl_k_queue_cancel_wait>:
{
    67f2:	b538      	push	{r3, r4, r5, lr}
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    67f4:	f100 0408 	add.w	r4, r0, #8
	__asm__ volatile(
    67f8:	f04f 0320 	mov.w	r3, #32
    67fc:	f3ef 8511 	mrs	r5, BASEPRI
    6800:	f383 8811 	msr	BASEPRI, r3
    6804:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&queue->wait_q);
    6808:	4620      	mov	r0, r4
    680a:	f000 f8ee 	bl	69ea <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    680e:	b128      	cbz	r0, 681c <z_impl_k_queue_cancel_wait+0x2a>
    6810:	2200      	movs	r2, #0
    6812:	f8c0 2090 	str.w	r2, [r0, #144]	; 0x90
    6816:	6142      	str	r2, [r0, #20]
	z_ready_thread(thread);
    6818:	f000 f86f 	bl	68fa <z_ready_thread>
	z_reschedule(&queue->lock, key);
    681c:	4629      	mov	r1, r5
    681e:	4620      	mov	r0, r4
}
    6820:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&queue->lock, key);
    6824:	f000 b821 	b.w	686a <z_reschedule>

00006828 <z_impl_k_queue_alloc_append>:
{
    6828:	460a      	mov	r2, r1
	return queue_insert(queue, sys_sflist_peek_tail(&queue->data_q), data,
    682a:	2301      	movs	r3, #1
    682c:	6841      	ldr	r1, [r0, #4]
    682e:	f7ff bf6e 	b.w	670e <queue_insert>

00006832 <z_impl_k_queue_alloc_prepend>:
{
    6832:	460a      	mov	r2, r1
	return queue_insert(queue, NULL, data, true);
    6834:	2301      	movs	r3, #1
    6836:	2100      	movs	r1, #0
    6838:	f7ff bf69 	b.w	670e <queue_insert>

0000683c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    683c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6840:	b923      	cbnz	r3, 684c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6842:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6846:	f000 0001 	and.w	r0, r0, #1
    684a:	4770      	bx	lr
		return false;
    684c:	2000      	movs	r0, #0
}
    684e:	4770      	bx	lr

00006850 <thread_obj_validate>:
{
    6850:	b508      	push	{r3, lr}
	struct z_object *ko = z_object_find(thread);
    6852:	f7f9 fc43 	bl	dc <z_object_find>
	int ret = z_object_validate(ko, K_OBJ_THREAD, _OBJ_INIT_TRUE);
    6856:	2200      	movs	r2, #0
    6858:	2109      	movs	r1, #9
    685a:	f7fe fe79 	bl	5550 <z_object_validate>
}
    685e:	f110 0f16 	cmn.w	r0, #22
    6862:	bf14      	ite	ne
    6864:	2000      	movne	r0, #0
    6866:	2001      	moveq	r0, #1
    6868:	bd08      	pop	{r3, pc}

0000686a <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    686a:	b921      	cbnz	r1, 6876 <z_reschedule+0xc>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    686c:	f3ef 8005 	mrs	r0, IPSR
    6870:	b908      	cbnz	r0, 6876 <z_reschedule+0xc>
    6872:	f7fa bdc7 	b.w	1404 <arch_swap>
	__asm__ volatile(
    6876:	f381 8811 	msr	BASEPRI, r1
    687a:	f3bf 8f6f 	isb	sy
}
    687e:	4770      	bx	lr

00006880 <z_reschedule_irqlock>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    6880:	4603      	mov	r3, r0
    6882:	b920      	cbnz	r0, 688e <z_reschedule_irqlock+0xe>
    6884:	f3ef 8205 	mrs	r2, IPSR
    6888:	b90a      	cbnz	r2, 688e <z_reschedule_irqlock+0xe>
    688a:	f7fa bdbb 	b.w	1404 <arch_swap>
    688e:	f383 8811 	msr	BASEPRI, r3
    6892:	f3bf 8f6f 	isb	sy
}
    6896:	4770      	bx	lr

00006898 <z_reschedule_unlocked>:
	__asm__ volatile(
    6898:	f04f 0320 	mov.w	r3, #32
    689c:	f3ef 8011 	mrs	r0, BASEPRI
    68a0:	f383 8811 	msr	BASEPRI, r3
    68a4:	f3bf 8f6f 	isb	sy
	(void) z_reschedule_irqlock(arch_irq_lock());
    68a8:	f7ff bfea 	b.w	6880 <z_reschedule_irqlock>

000068ac <z_unpend_thread>:
{
    68ac:	b510      	push	{r4, lr}
    68ae:	4601      	mov	r1, r0
    68b0:	f04f 0320 	mov.w	r3, #32
    68b4:	f3ef 8411 	mrs	r4, BASEPRI
    68b8:	f383 8811 	msr	BASEPRI, r3
    68bc:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    68c0:	6880      	ldr	r0, [r0, #8]
    68c2:	f7fd fb77 	bl	3fb4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    68c6:	7b4b      	ldrb	r3, [r1, #13]
    68c8:	f023 0302 	bic.w	r3, r3, #2
    68cc:	734b      	strb	r3, [r1, #13]
		thread->base.pended_on = NULL;
    68ce:	2300      	movs	r3, #0
    68d0:	608b      	str	r3, [r1, #8]
	__asm__ volatile(
    68d2:	f384 8811 	msr	BASEPRI, r4
    68d6:	f3bf 8f6f 	isb	sy
}
    68da:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_abort_timeout(&thread->base.timeout);
    68de:	f101 0018 	add.w	r0, r1, #24
    68e2:	f000 b98d 	b.w	6c00 <z_abort_timeout>

000068e6 <z_priq_dumb_best>:
{
    68e6:	4603      	mov	r3, r0
	return list->head == list;
    68e8:	6800      	ldr	r0, [r0, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    68ea:	4283      	cmp	r3, r0
    68ec:	d003      	beq.n	68f6 <z_priq_dumb_best+0x10>
	if (n != NULL) {
    68ee:	2800      	cmp	r0, #0
    68f0:	bf38      	it	cc
    68f2:	2000      	movcc	r0, #0
    68f4:	4770      	bx	lr
	struct k_thread *thread = NULL;
    68f6:	2000      	movs	r0, #0
}
    68f8:	4770      	bx	lr

000068fa <z_ready_thread>:
{
    68fa:	b510      	push	{r4, lr}
	__asm__ volatile(
    68fc:	f04f 0320 	mov.w	r3, #32
    6900:	f3ef 8411 	mrs	r4, BASEPRI
    6904:	f383 8811 	msr	BASEPRI, r3
    6908:	f3bf 8f6f 	isb	sy
		ready_thread(thread);
    690c:	f7fd fbaa 	bl	4064 <ready_thread>
	__asm__ volatile(
    6910:	f384 8811 	msr	BASEPRI, r4
    6914:	f3bf 8f6f 	isb	sy
}
    6918:	bd10      	pop	{r4, pc}

0000691a <z_thread_timeout>:
{
    691a:	b538      	push	{r3, r4, r5, lr}
	if (thread->base.pended_on != NULL) {
    691c:	f850 3c10 	ldr.w	r3, [r0, #-16]
{
    6920:	4604      	mov	r4, r0
	struct k_thread *thread = CONTAINER_OF(timeout,
    6922:	f1a0 0118 	sub.w	r1, r0, #24
	if (thread->base.pended_on != NULL) {
    6926:	b1c3      	cbz	r3, 695a <z_thread_timeout+0x40>
	__asm__ volatile(
    6928:	f04f 0320 	mov.w	r3, #32
    692c:	f3ef 8511 	mrs	r5, BASEPRI
    6930:	f383 8811 	msr	BASEPRI, r3
    6934:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    6938:	f850 0c10 	ldr.w	r0, [r0, #-16]
    693c:	f7fd fb3a 	bl	3fb4 <z_priq_dumb_remove>
    6940:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
    6944:	f023 0302 	bic.w	r3, r3, #2
    6948:	f804 3c0b 	strb.w	r3, [r4, #-11]
		thread->base.pended_on = NULL;
    694c:	2300      	movs	r3, #0
    694e:	f844 3c10 	str.w	r3, [r4, #-16]
	__asm__ volatile(
    6952:	f385 8811 	msr	BASEPRI, r5
    6956:	f3bf 8f6f 	isb	sy
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    695a:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
    695e:	f023 0314 	bic.w	r3, r3, #20
    6962:	f804 3c0b 	strb.w	r3, [r4, #-11]
	z_ready_thread(thread);
    6966:	4608      	mov	r0, r1
}
    6968:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_ready_thread(thread);
    696c:	f7ff bfc5 	b.w	68fa <z_ready_thread>

00006970 <z_remove_thread_from_ready_q>:
{
    6970:	b510      	push	{r4, lr}
	__asm__ volatile(
    6972:	f04f 0320 	mov.w	r3, #32
    6976:	f3ef 8411 	mrs	r4, BASEPRI
    697a:	f383 8811 	msr	BASEPRI, r3
    697e:	f3bf 8f6f 	isb	sy
		unready_thread(thread);
    6982:	f7fd fd31 	bl	43e8 <unready_thread>
	__asm__ volatile(
    6986:	f384 8811 	msr	BASEPRI, r4
    698a:	f3bf 8f6f 	isb	sy
}
    698e:	bd10      	pop	{r4, pc}

00006990 <add_to_waitq_locked>:
{
    6990:	b538      	push	{r3, r4, r5, lr}
    6992:	4604      	mov	r4, r0
    6994:	460d      	mov	r5, r1
	unready_thread(thread);
    6996:	f7fd fd27 	bl	43e8 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
    699a:	7b63      	ldrb	r3, [r4, #13]
    699c:	f043 0302 	orr.w	r3, r3, #2
    69a0:	7363      	strb	r3, [r4, #13]
	if (wait_q != NULL) {
    69a2:	b1c5      	cbz	r5, 69d6 <add_to_waitq_locked+0x46>
	return list->head == list;
    69a4:	682b      	ldr	r3, [r5, #0]
		thread->base.pended_on = wait_q;
    69a6:	60a5      	str	r5, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    69a8:	429d      	cmp	r5, r3
    69aa:	bf08      	it	eq
    69ac:	2300      	moveq	r3, #0
    69ae:	2b00      	cmp	r3, #0
    69b0:	bf38      	it	cc
    69b2:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    69b4:	b183      	cbz	r3, 69d8 <add_to_waitq_locked+0x48>
	if (thread_1->base.prio < thread_2->base.prio) {
    69b6:	f994 100e 	ldrsb.w	r1, [r4, #14]
    69ba:	f993 200e 	ldrsb.w	r2, [r3, #14]
    69be:	4291      	cmp	r1, r2
    69c0:	db04      	blt.n	69cc <add_to_waitq_locked+0x3c>
	return (node == list->tail) ? NULL : node->next;
    69c2:	686a      	ldr	r2, [r5, #4]
    69c4:	429a      	cmp	r2, r3
    69c6:	d007      	beq.n	69d8 <add_to_waitq_locked+0x48>
    69c8:	681b      	ldr	r3, [r3, #0]
    69ca:	e7f3      	b.n	69b4 <add_to_waitq_locked+0x24>
	node->prev = successor->prev;
    69cc:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    69ce:	e9c4 3200 	strd	r3, r2, [r4]
	successor->prev->next = node;
    69d2:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    69d4:	605c      	str	r4, [r3, #4]
}
    69d6:	bd38      	pop	{r3, r4, r5, pc}
	node->prev = list->tail;
    69d8:	686b      	ldr	r3, [r5, #4]
    69da:	6063      	str	r3, [r4, #4]
	list->tail->next = node;
    69dc:	686b      	ldr	r3, [r5, #4]
	node->next = list;
    69de:	6025      	str	r5, [r4, #0]
	list->tail->next = node;
    69e0:	601c      	str	r4, [r3, #0]
	list->tail = node;
    69e2:	606c      	str	r4, [r5, #4]
    69e4:	e7f7      	b.n	69d6 <add_to_waitq_locked+0x46>

000069e6 <z_pend_thread>:
	pend(thread, wait_q, timeout);
    69e6:	f7fd bd47 	b.w	4478 <pend>

000069ea <z_unpend_first_thread>:
{
    69ea:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
    69ec:	f04f 0320 	mov.w	r3, #32
    69f0:	f3ef 8211 	mrs	r2, BASEPRI
    69f4:	f383 8811 	msr	BASEPRI, r3
    69f8:	f3bf 8f6f 	isb	sy
		ret = _priq_wait_best(&wait_q->waitq);
    69fc:	f7ff ff73 	bl	68e6 <z_priq_dumb_best>
    6a00:	4604      	mov	r4, r0
	__asm__ volatile(
    6a02:	f382 8811 	msr	BASEPRI, r2
    6a06:	f3bf 8f6f 	isb	sy

static inline struct k_thread *z_unpend1_no_timeout(_wait_q_t *wait_q)
{
	struct k_thread *thread = z_find_first_thread_to_unpend(wait_q, NULL);

	if (thread != NULL) {
    6a0a:	b1c8      	cbz	r0, 6a40 <z_unpend_first_thread+0x56>
	__asm__ volatile(
    6a0c:	f04f 0320 	mov.w	r3, #32
    6a10:	f3ef 8511 	mrs	r5, BASEPRI
    6a14:	f383 8811 	msr	BASEPRI, r3
    6a18:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    6a1c:	4601      	mov	r1, r0
    6a1e:	6880      	ldr	r0, [r0, #8]
    6a20:	f7fd fac8 	bl	3fb4 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    6a24:	7b63      	ldrb	r3, [r4, #13]
    6a26:	f023 0302 	bic.w	r3, r3, #2
    6a2a:	7363      	strb	r3, [r4, #13]
		thread->base.pended_on = NULL;
    6a2c:	2300      	movs	r3, #0
    6a2e:	60a3      	str	r3, [r4, #8]
	__asm__ volatile(
    6a30:	f385 8811 	msr	BASEPRI, r5
    6a34:	f3bf 8f6f 	isb	sy
    6a38:	f104 0018 	add.w	r0, r4, #24
    6a3c:	f000 f8e0 	bl	6c00 <z_abort_timeout>
}
    6a40:	4620      	mov	r0, r4
    6a42:	bd38      	pop	{r3, r4, r5, pc}

00006a44 <z_unpend_all>:
{
    6a44:	b538      	push	{r3, r4, r5, lr}
    6a46:	4605      	mov	r5, r0
	int need_sched = 0;
    6a48:	2000      	movs	r0, #0
	return list->head == list;
    6a4a:	682c      	ldr	r4, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    6a4c:	42a5      	cmp	r5, r4
    6a4e:	d000      	beq.n	6a52 <z_unpend_all+0xe>
	while ((thread = z_waitq_head(wait_q)) != NULL) {
    6a50:	b904      	cbnz	r4, 6a54 <z_unpend_all+0x10>
}
    6a52:	bd38      	pop	{r3, r4, r5, pc}
		z_unpend_thread(thread);
    6a54:	4620      	mov	r0, r4
    6a56:	f7ff ff29 	bl	68ac <z_unpend_thread>
		z_ready_thread(thread);
    6a5a:	4620      	mov	r0, r4
    6a5c:	f7ff ff4d 	bl	68fa <z_ready_thread>
		need_sched = 1;
    6a60:	2001      	movs	r0, #1
    6a62:	e7f2      	b.n	6a4a <z_unpend_all+0x6>

00006a64 <z_impl_k_wakeup>:
{
    6a64:	b510      	push	{r4, lr}
	if (z_is_thread_pending(thread)) {
    6a66:	7b43      	ldrb	r3, [r0, #13]
    6a68:	079b      	lsls	r3, r3, #30
{
    6a6a:	4604      	mov	r4, r0
	if (z_is_thread_pending(thread)) {
    6a6c:	d415      	bmi.n	6a9a <z_impl_k_wakeup+0x36>
    6a6e:	3018      	adds	r0, #24
    6a70:	f000 f8c6 	bl	6c00 <z_abort_timeout>
	if (z_abort_thread_timeout(thread) < 0) {
    6a74:	2800      	cmp	r0, #0
    6a76:	da02      	bge.n	6a7e <z_impl_k_wakeup+0x1a>
		if (thread->base.thread_state != _THREAD_SUSPENDED) {
    6a78:	7b63      	ldrb	r3, [r4, #13]
    6a7a:	2b10      	cmp	r3, #16
    6a7c:	d10d      	bne.n	6a9a <z_impl_k_wakeup+0x36>
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    6a7e:	7b63      	ldrb	r3, [r4, #13]
    6a80:	f023 0310 	bic.w	r3, r3, #16
    6a84:	7363      	strb	r3, [r4, #13]
	z_ready_thread(thread);
    6a86:	4620      	mov	r0, r4
    6a88:	f7ff ff37 	bl	68fa <z_ready_thread>
    6a8c:	f3ef 8305 	mrs	r3, IPSR
	if (!arch_is_in_isr()) {
    6a90:	b91b      	cbnz	r3, 6a9a <z_impl_k_wakeup+0x36>
}
    6a92:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		z_reschedule_unlocked();
    6a96:	f7ff beff 	b.w	6898 <z_reschedule_unlocked>
}
    6a9a:	bd10      	pop	{r4, pc}

00006a9c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6a9c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6aa0:	b923      	cbnz	r3, 6aac <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6aa2:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6aa6:	f000 0001 	and.w	r0, r0, #1
    6aaa:	4770      	bx	lr
		return false;
    6aac:	2000      	movs	r0, #0
}
    6aae:	4770      	bx	lr

00006ab0 <z_impl_k_sem_init>:
{
    6ab0:	b508      	push	{r3, lr}
	CHECKIF(limit == 0U || initial_count > limit) {
    6ab2:	b14a      	cbz	r2, 6ac8 <z_impl_k_sem_init+0x18>
    6ab4:	428a      	cmp	r2, r1
    6ab6:	d307      	bcc.n	6ac8 <z_impl_k_sem_init+0x18>
	sem->limit = limit;
    6ab8:	e9c0 1202 	strd	r1, r2, [r0, #8]
	list->tail = (sys_dnode_t *)list;
    6abc:	e9c0 0000 	strd	r0, r0, [r0]
	z_object_init(sem);
    6ac0:	f000 fa3c 	bl	6f3c <z_object_init>
	return 0;
    6ac4:	2000      	movs	r0, #0
}
    6ac6:	bd08      	pop	{r3, pc}
		return -EINVAL;
    6ac8:	f06f 0015 	mvn.w	r0, #21
    6acc:	e7fb      	b.n	6ac6 <z_impl_k_sem_init+0x16>

00006ace <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6ace:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6ad2:	b923      	cbnz	r3, 6ade <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6ad4:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6ad8:	f000 0001 	and.w	r0, r0, #1
    6adc:	4770      	bx	lr
		return false;
    6ade:	2000      	movs	r0, #0
}
    6ae0:	4770      	bx	lr

00006ae2 <k_stack_init>:
	stack->next = stack->base = buffer;
    6ae2:	e9c0 1102 	strd	r1, r1, [r0, #8]
	stack->top = stack->base + num_entries;
    6ae6:	eb01 0182 	add.w	r1, r1, r2, lsl #2
    6aea:	e9c0 0000 	strd	r0, r0, [r0]
    6aee:	6101      	str	r1, [r0, #16]
	z_object_init(stack);
    6af0:	f000 ba24 	b.w	6f3c <z_object_init>

00006af4 <z_impl_k_stack_alloc_init>:
{
    6af4:	b538      	push	{r3, r4, r5, lr}
    6af6:	4604      	mov	r4, r0
	buffer = z_thread_malloc(num_entries * sizeof(stack_data_t));
    6af8:	0088      	lsls	r0, r1, #2
{
    6afa:	460d      	mov	r5, r1
	buffer = z_thread_malloc(num_entries * sizeof(stack_data_t));
    6afc:	f7fc fc14 	bl	3328 <z_thread_malloc>
	if (buffer != NULL) {
    6b00:	4601      	mov	r1, r0
    6b02:	b138      	cbz	r0, 6b14 <z_impl_k_stack_alloc_init+0x20>
		k_stack_init(stack, buffer, num_entries);
    6b04:	4620      	mov	r0, r4
    6b06:	462a      	mov	r2, r5
    6b08:	f7ff ffeb 	bl	6ae2 <k_stack_init>
		stack->flags = K_STACK_FLAG_ALLOC;
    6b0c:	2301      	movs	r3, #1
    6b0e:	7523      	strb	r3, [r4, #20]
		ret = (int32_t)0;
    6b10:	2000      	movs	r0, #0
}
    6b12:	bd38      	pop	{r3, r4, r5, pc}
		ret = -ENOMEM;
    6b14:	f06f 000b 	mvn.w	r0, #11
	return ret;
    6b18:	e7fb      	b.n	6b12 <z_impl_k_stack_alloc_init+0x1e>

00006b1a <z_impl_k_stack_push>:
	CHECKIF(stack->next == stack->top) {
    6b1a:	e9d0 2303 	ldrd	r2, r3, [r0, #12]
    6b1e:	429a      	cmp	r2, r3
{
    6b20:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    6b24:	4605      	mov	r5, r0
    6b26:	460e      	mov	r6, r1
	CHECKIF(stack->next == stack->top) {
    6b28:	d023      	beq.n	6b72 <z_impl_k_stack_push+0x58>
	__asm__ volatile(
    6b2a:	f04f 0320 	mov.w	r3, #32
    6b2e:	f3ef 8711 	mrs	r7, BASEPRI
    6b32:	f383 8811 	msr	BASEPRI, r3
    6b36:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&stack->wait_q);
    6b3a:	f7ff ff56 	bl	69ea <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    6b3e:	4604      	mov	r4, r0
    6b40:	b170      	cbz	r0, 6b60 <z_impl_k_stack_push+0x46>
    6b42:	f04f 0800 	mov.w	r8, #0
		z_ready_thread(first_pending_thread);
    6b46:	f7ff fed8 	bl	68fa <z_ready_thread>
		z_reschedule(&stack->lock, key);
    6b4a:	f105 0008 	add.w	r0, r5, #8
    6b4e:	f8c4 8090 	str.w	r8, [r4, #144]	; 0x90
    6b52:	6166      	str	r6, [r4, #20]
    6b54:	4639      	mov	r1, r7
    6b56:	f7ff fe88 	bl	686a <z_reschedule>
	return 0;
    6b5a:	4640      	mov	r0, r8
}
    6b5c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		*(stack->next) = data;
    6b60:	68eb      	ldr	r3, [r5, #12]
    6b62:	f843 6b04 	str.w	r6, [r3], #4
		stack->next++;
    6b66:	60eb      	str	r3, [r5, #12]
	__asm__ volatile(
    6b68:	f387 8811 	msr	BASEPRI, r7
    6b6c:	f3bf 8f6f 	isb	sy
    6b70:	e7f4      	b.n	6b5c <z_impl_k_stack_push+0x42>
		return -ENOMEM;
    6b72:	f06f 000b 	mvn.w	r0, #11
    6b76:	e7f1      	b.n	6b5c <z_impl_k_stack_push+0x42>

00006b78 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6b78:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6b7c:	b923      	cbnz	r3, 6b88 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6b7e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6b82:	f000 0001 	and.w	r0, r0, #1
    6b86:	4770      	bx	lr
		return false;
    6b88:	2000      	movs	r0, #0
}
    6b8a:	4770      	bx	lr

00006b8c <k_is_in_isr>:
    6b8c:	f3ef 8005 	mrs	r0, IPSR
}
    6b90:	3800      	subs	r0, #0
    6b92:	bf18      	it	ne
    6b94:	2001      	movne	r0, #1
    6b96:	4770      	bx	lr

00006b98 <z_impl_k_busy_wait>:
	arch_busy_wait(usec_to_wait);
    6b98:	f7fb ba46 	b.w	2028 <arch_busy_wait>

00006b9c <z_impl_k_thread_name_set>:
}
    6b9c:	f06f 0046 	mvn.w	r0, #70	; 0x46
    6ba0:	4770      	bx	lr

00006ba2 <z_stack_is_user_capable>:
{
    6ba2:	b508      	push	{r3, lr}
	return z_object_find(stack) != NULL;
    6ba4:	f7f9 fa9a 	bl	dc <z_object_find>
}
    6ba8:	3800      	subs	r0, #0
    6baa:	bf18      	it	ne
    6bac:	2001      	movne	r0, #1
    6bae:	bd08      	pop	{r3, pc}

00006bb0 <z_impl_k_thread_create>:
{
    6bb0:	b5f0      	push	{r4, r5, r6, r7, lr}
    6bb2:	b087      	sub	sp, #28
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    6bb4:	2500      	movs	r5, #0
    6bb6:	9505      	str	r5, [sp, #20]
    6bb8:	9d10      	ldr	r5, [sp, #64]	; 0x40
    6bba:	9504      	str	r5, [sp, #16]
    6bbc:	9d0f      	ldr	r5, [sp, #60]	; 0x3c
    6bbe:	9503      	str	r5, [sp, #12]
    6bc0:	9d0e      	ldr	r5, [sp, #56]	; 0x38
    6bc2:	9502      	str	r5, [sp, #8]
{
    6bc4:	e9dd 6712 	ldrd	r6, r7, [sp, #72]	; 0x48
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    6bc8:	9d0d      	ldr	r5, [sp, #52]	; 0x34
    6bca:	9501      	str	r5, [sp, #4]
    6bcc:	9d0c      	ldr	r5, [sp, #48]	; 0x30
    6bce:	9500      	str	r5, [sp, #0]
{
    6bd0:	4604      	mov	r4, r0
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    6bd2:	f7fe f8c3 	bl	4d5c <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
    6bd6:	1c7b      	adds	r3, r7, #1
    6bd8:	bf08      	it	eq
    6bda:	f1b6 3fff 	cmpeq.w	r6, #4294967295	; 0xffffffff
    6bde:	d004      	beq.n	6bea <z_impl_k_thread_create+0x3a>
		schedule_new_thread(new_thread, delay);
    6be0:	4632      	mov	r2, r6
    6be2:	463b      	mov	r3, r7
    6be4:	4620      	mov	r0, r4
    6be6:	f7fe f865 	bl	4cb4 <schedule_new_thread>
}
    6bea:	4620      	mov	r0, r4
    6bec:	b007      	add	sp, #28
    6bee:	bdf0      	pop	{r4, r5, r6, r7, pc}

00006bf0 <z_init_thread_base>:
	thread_base->user_options = (uint8_t)options;
    6bf0:	7303      	strb	r3, [r0, #12]
	thread_base->sched_locked = 0U;
    6bf2:	2300      	movs	r3, #0
	node->prev = NULL;
    6bf4:	e9c0 3306 	strd	r3, r3, [r0, #24]
	thread_base->thread_state = (uint8_t)initial_state;
    6bf8:	7342      	strb	r2, [r0, #13]
	thread_base->prio = priority;
    6bfa:	7381      	strb	r1, [r0, #14]
	thread_base->sched_locked = 0U;
    6bfc:	73c3      	strb	r3, [r0, #15]
}
    6bfe:	4770      	bx	lr

00006c00 <z_abort_timeout>:
{
    6c00:	b510      	push	{r4, lr}
	__asm__ volatile(
    6c02:	f04f 0220 	mov.w	r2, #32
    6c06:	f3ef 8411 	mrs	r4, BASEPRI
    6c0a:	f382 8811 	msr	BASEPRI, r2
    6c0e:	f3bf 8f6f 	isb	sy
		if (sys_dnode_is_linked(&to->node)) {
    6c12:	6803      	ldr	r3, [r0, #0]
    6c14:	b13b      	cbz	r3, 6c26 <z_abort_timeout+0x26>
			remove_timeout(to);
    6c16:	f7fe fa6d 	bl	50f4 <remove_timeout>
			ret = 0;
    6c1a:	2000      	movs	r0, #0
	__asm__ volatile(
    6c1c:	f384 8811 	msr	BASEPRI, r4
    6c20:	f3bf 8f6f 	isb	sy
}
    6c24:	bd10      	pop	{r4, pc}
	int ret = -EINVAL;
    6c26:	f06f 0015 	mvn.w	r0, #21
    6c2a:	e7f7      	b.n	6c1c <z_abort_timeout+0x1c>

00006c2c <z_timeout_remaining>:
{
    6c2c:	b510      	push	{r4, lr}
	__asm__ volatile(
    6c2e:	f04f 0320 	mov.w	r3, #32
    6c32:	f3ef 8411 	mrs	r4, BASEPRI
    6c36:	f383 8811 	msr	BASEPRI, r3
    6c3a:	f3bf 8f6f 	isb	sy
		ticks = timeout_rem(timeout);
    6c3e:	f7fe fa8d 	bl	515c <timeout_rem>
	__asm__ volatile(
    6c42:	f384 8811 	msr	BASEPRI, r4
    6c46:	f3bf 8f6f 	isb	sy
}
    6c4a:	bd10      	pop	{r4, pc}

00006c4c <z_get_next_timeout_expiry>:
{
    6c4c:	b510      	push	{r4, lr}
	__asm__ volatile(
    6c4e:	f04f 0320 	mov.w	r3, #32
    6c52:	f3ef 8411 	mrs	r4, BASEPRI
    6c56:	f383 8811 	msr	BASEPRI, r3
    6c5a:	f3bf 8f6f 	isb	sy
		ret = next_timeout();
    6c5e:	f7fe fa63 	bl	5128 <next_timeout>
	__asm__ volatile(
    6c62:	f384 8811 	msr	BASEPRI, r4
    6c66:	f3bf 8f6f 	isb	sy
}
    6c6a:	bd10      	pop	{r4, pc}

00006c6c <z_set_timeout_expiry>:
{
    6c6c:	b570      	push	{r4, r5, r6, lr}
    6c6e:	4604      	mov	r4, r0
    6c70:	460d      	mov	r5, r1
	__asm__ volatile(
    6c72:	f04f 0320 	mov.w	r3, #32
    6c76:	f3ef 8611 	mrs	r6, BASEPRI
    6c7a:	f383 8811 	msr	BASEPRI, r3
    6c7e:	f3bf 8f6f 	isb	sy
		int next_to = next_timeout();
    6c82:	f7fe fa51 	bl	5128 <next_timeout>
		if (!imminent && (sooner || IS_ENABLED(CONFIG_SMP))) {
    6c86:	2801      	cmp	r0, #1
    6c88:	dd05      	ble.n	6c96 <z_set_timeout_expiry+0x2a>
    6c8a:	42a0      	cmp	r0, r4
    6c8c:	dd03      	ble.n	6c96 <z_set_timeout_expiry+0x2a>
			z_clock_set_timeout(ticks, is_idle);
    6c8e:	4629      	mov	r1, r5
    6c90:	4620      	mov	r0, r4
    6c92:	f7fa fb01 	bl	1298 <z_clock_set_timeout>
	__asm__ volatile(
    6c96:	f386 8811 	msr	BASEPRI, r6
    6c9a:	f3bf 8f6f 	isb	sy
}
    6c9e:	bd70      	pop	{r4, r5, r6, pc}

00006ca0 <z_tick_get_32>:
{
    6ca0:	b508      	push	{r3, lr}
	return (uint32_t)z_tick_get();
    6ca2:	f7fe fb8f 	bl	53c4 <z_tick_get>
}
    6ca6:	bd08      	pop	{r3, pc}

00006ca8 <z_timeout_end_calc>:
 * timeout object.  When used correctly, this should be called once,
 * synchronously with the user passing a new timeout value.  It should
 * not be used iteratively to adjust a timeout.
 */
uint64_t z_timeout_end_calc(k_timeout_t timeout)
{
    6ca8:	b538      	push	{r3, r4, r5, lr}
	k_ticks_t dt;

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    6caa:	1c4b      	adds	r3, r1, #1
    6cac:	bf08      	it	eq
    6cae:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    6cb2:	4604      	mov	r4, r0
    6cb4:	460d      	mov	r5, r1
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    6cb6:	d013      	beq.n	6ce0 <z_timeout_end_calc+0x38>
		return UINT64_MAX;
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    6cb8:	ea54 0105 	orrs.w	r1, r4, r5
    6cbc:	d103      	bne.n	6cc6 <z_timeout_end_calc+0x1e>
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(dt) >= 0) {
		return Z_TICK_ABS(dt);
	}
#endif
	return z_tick_get() + MAX(1, dt);
}
    6cbe:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		return z_tick_get();
    6cc2:	f7fe bb7f 	b.w	53c4 <z_tick_get>
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(dt) >= 0) {
    6cc6:	f06f 0101 	mvn.w	r1, #1
    6cca:	1a0a      	subs	r2, r1, r0
    6ccc:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
    6cd0:	eb61 0305 	sbc.w	r3, r1, r5
    6cd4:	2a00      	cmp	r2, #0
    6cd6:	f173 0100 	sbcs.w	r1, r3, #0
    6cda:	db02      	blt.n	6ce2 <z_timeout_end_calc+0x3a>
		return Z_TICK_ABS(dt);
    6cdc:	4610      	mov	r0, r2
    6cde:	4619      	mov	r1, r3
}
    6ce0:	bd38      	pop	{r3, r4, r5, pc}
	return z_tick_get() + MAX(1, dt);
    6ce2:	f7fe fb6f 	bl	53c4 <z_tick_get>
    6ce6:	2c01      	cmp	r4, #1
    6ce8:	f175 0300 	sbcs.w	r3, r5, #0
    6cec:	bfbc      	itt	lt
    6cee:	2401      	movlt	r4, #1
    6cf0:	2500      	movlt	r5, #0
    6cf2:	1820      	adds	r0, r4, r0
    6cf4:	eb45 0101 	adc.w	r1, r5, r1
    6cf8:	e7f2      	b.n	6ce0 <z_timeout_end_calc+0x38>

00006cfa <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6cfa:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6cfe:	b923      	cbnz	r3, 6d0a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6d00:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6d04:	f000 0001 	and.w	r0, r0, #1
    6d08:	4770      	bx	lr
		return false;
    6d0a:	2000      	movs	r0, #0
}
    6d0c:	4770      	bx	lr

00006d0e <z_impl_k_futex_wake>:
{
    6d0e:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    6d12:	460e      	mov	r6, r1
	obj = z_object_find(futex);
    6d14:	f7f9 f9e2 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_FUTEX) {
    6d18:	b318      	cbz	r0, 6d62 <z_impl_k_futex_wake+0x54>
    6d1a:	7983      	ldrb	r3, [r0, #6]
    6d1c:	2b0f      	cmp	r3, #15
    6d1e:	d120      	bne.n	6d62 <z_impl_k_futex_wake+0x54>
	return obj->data.futex_data;
    6d20:	6887      	ldr	r7, [r0, #8]
	if (futex_data == NULL) {
    6d22:	b1f7      	cbz	r7, 6d62 <z_impl_k_futex_wake+0x54>
	key = k_spin_lock(&futex_data->lock);
    6d24:	f107 0808 	add.w	r8, r7, #8
	__asm__ volatile(
    6d28:	f04f 0320 	mov.w	r3, #32
    6d2c:	f3ef 8911 	mrs	r9, BASEPRI
    6d30:	f383 8811 	msr	BASEPRI, r3
    6d34:	f3bf 8f6f 	isb	sy
	unsigned int woken = 0;
    6d38:	2400      	movs	r4, #0
    6d3a:	46a2      	mov	sl, r4
		thread = z_unpend_first_thread(&futex_data->wait_q);
    6d3c:	4638      	mov	r0, r7
    6d3e:	f7ff fe54 	bl	69ea <z_unpend_first_thread>
		if (thread) {
    6d42:	4605      	mov	r5, r0
    6d44:	b130      	cbz	r0, 6d54 <z_impl_k_futex_wake+0x46>
			z_ready_thread(thread);
    6d46:	f7ff fdd8 	bl	68fa <z_ready_thread>
			woken++;
    6d4a:	3401      	adds	r4, #1
    6d4c:	f8c5 a090 	str.w	sl, [r5, #144]	; 0x90
	} while (thread && wake_all);
    6d50:	2e00      	cmp	r6, #0
    6d52:	d1f3      	bne.n	6d3c <z_impl_k_futex_wake+0x2e>
	z_reschedule(&futex_data->lock, key);
    6d54:	4640      	mov	r0, r8
    6d56:	4649      	mov	r1, r9
    6d58:	f7ff fd87 	bl	686a <z_reschedule>
	return woken;
    6d5c:	4620      	mov	r0, r4
}
    6d5e:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
		return -EINVAL;
    6d62:	f06f 0015 	mvn.w	r0, #21
    6d66:	e7fa      	b.n	6d5e <z_impl_k_futex_wake+0x50>

00006d68 <z_impl_k_futex_wait>:
{
    6d68:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    6d6a:	4607      	mov	r7, r0
    6d6c:	460e      	mov	r6, r1
    6d6e:	4615      	mov	r5, r2
    6d70:	461c      	mov	r4, r3
	obj = z_object_find(futex);
    6d72:	f7f9 f9b3 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_FUTEX) {
    6d76:	b338      	cbz	r0, 6dc8 <z_impl_k_futex_wait+0x60>
    6d78:	7983      	ldrb	r3, [r0, #6]
    6d7a:	2b0f      	cmp	r3, #15
    6d7c:	d124      	bne.n	6dc8 <z_impl_k_futex_wait+0x60>
	return obj->data.futex_data;
    6d7e:	6882      	ldr	r2, [r0, #8]
	if (futex_data == NULL) {
    6d80:	b312      	cbz	r2, 6dc8 <z_impl_k_futex_wait+0x60>
	key = k_spin_lock(&futex_data->lock);
    6d82:	f102 0008 	add.w	r0, r2, #8
    6d86:	f04f 0320 	mov.w	r3, #32
    6d8a:	f3ef 8111 	mrs	r1, BASEPRI
    6d8e:	f383 8811 	msr	BASEPRI, r3
    6d92:	f3bf 8f6f 	isb	sy
	return __atomic_load_n(target, __ATOMIC_SEQ_CST);
    6d96:	f3bf 8f5b 	dmb	ish
    6d9a:	683b      	ldr	r3, [r7, #0]
    6d9c:	f3bf 8f5b 	dmb	ish
	if (atomic_get(&futex->val) != (atomic_val_t)expected) {
    6da0:	429e      	cmp	r6, r3
    6da2:	d007      	beq.n	6db4 <z_impl_k_futex_wait+0x4c>
	__asm__ volatile(
    6da4:	f381 8811 	msr	BASEPRI, r1
    6da8:	f3bf 8f6f 	isb	sy
		return -EAGAIN;
    6dac:	f06f 000a 	mvn.w	r0, #10
}
    6db0:	b003      	add	sp, #12
    6db2:	bdf0      	pop	{r4, r5, r6, r7, pc}
	ret = z_pend_curr(&futex_data->lock,
    6db4:	e9cd 5400 	strd	r5, r4, [sp]
    6db8:	f7fd fb84 	bl	44c4 <z_pend_curr>
	if (ret == -EAGAIN) {
    6dbc:	f110 0f0b 	cmn.w	r0, #11
		ret = -ETIMEDOUT;
    6dc0:	bf08      	it	eq
    6dc2:	f06f 003b 	mvneq.w	r0, #59	; 0x3b
    6dc6:	e7f3      	b.n	6db0 <z_impl_k_futex_wait+0x48>
		return -EINVAL;
    6dc8:	f06f 0015 	mvn.w	r0, #21
    6dcc:	e7f0      	b.n	6db0 <z_impl_k_futex_wait+0x48>

00006dce <k_mem_domain_add_thread>:
{
    6dce:	4603      	mov	r3, r0
    6dd0:	b510      	push	{r4, lr}
    6dd2:	4608      	mov	r0, r1
	__asm__ volatile(
    6dd4:	f04f 0220 	mov.w	r2, #32
    6dd8:	f3ef 8411 	mrs	r4, BASEPRI
    6ddc:	f382 8811 	msr	BASEPRI, r2
    6de0:	f3bf 8f6f 	isb	sy
	sys_dlist_append(&domain->mem_domain_q,
    6de4:	f101 0274 	add.w	r2, r1, #116	; 0x74
    6de8:	f103 01c0 	add.w	r1, r3, #192	; 0xc0
	node->next = list;
    6dec:	6741      	str	r1, [r0, #116]	; 0x74
	node->prev = list->tail;
    6dee:	f8d3 10c4 	ldr.w	r1, [r3, #196]	; 0xc4
    6df2:	6781      	str	r1, [r0, #120]	; 0x78
	list->tail->next = node;
    6df4:	f8d3 10c4 	ldr.w	r1, [r3, #196]	; 0xc4
    6df8:	600a      	str	r2, [r1, #0]
	list->tail = node;
    6dfa:	f8c3 20c4 	str.w	r2, [r3, #196]	; 0xc4
	thread->mem_domain_info.mem_domain = domain;
    6dfe:	67c3      	str	r3, [r0, #124]	; 0x7c
	arch_mem_domain_thread_add(thread);
    6e00:	f7fa ff50 	bl	1ca4 <arch_mem_domain_thread_add>
	__asm__ volatile(
    6e04:	f384 8811 	msr	BASEPRI, r4
    6e08:	f3bf 8f6f 	isb	sy
}
    6e0c:	bd10      	pop	{r4, pc}

00006e0e <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6e0e:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6e12:	b923      	cbnz	r3, 6e1e <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6e14:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6e18:	f000 0001 	and.w	r0, r0, #1
    6e1c:	4770      	bx	lr
		return false;
    6e1e:	2000      	movs	r0, #0
}
    6e20:	4770      	bx	lr

00006e22 <unref_check>:
{
    6e22:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
    6e24:	f04f 0320 	mov.w	r3, #32
    6e28:	f3ef 8511 	mrs	r5, BASEPRI
    6e2c:	f383 8811 	msr	BASEPRI, r3
    6e30:	f3bf 8f6f 	isb	sy
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6e34:	094c      	lsrs	r4, r1, #5
	sys_bitfield_clear_bit((mem_addr_t)&ko->perms, index);
    6e36:	3004      	adds	r0, #4
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6e38:	2201      	movs	r2, #1
	uint32_t temp = *(volatile uint32_t *)addr;
    6e3a:	f850 3024 	ldr.w	r3, [r0, r4, lsl #2]
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6e3e:	f001 011f 	and.w	r1, r1, #31
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6e42:	fa02 f101 	lsl.w	r1, r2, r1
    6e46:	ea23 0101 	bic.w	r1, r3, r1
    6e4a:	f840 1024 	str.w	r1, [r0, r4, lsl #2]
	__asm__ volatile(
    6e4e:	f385 8811 	msr	BASEPRI, r5
    6e52:	f3bf 8f6f 	isb	sy
}
    6e56:	bd30      	pop	{r4, r5, pc}

00006e58 <wordlist_cb>:
	if (sys_bitfield_test_bit((mem_addr_t)&ko->perms, ctx->parent_id) &&
    6e58:	680b      	ldr	r3, [r1, #0]
{
    6e5a:	b530      	push	{r4, r5, lr}
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6e5c:	095a      	lsrs	r2, r3, #5
	if (sys_bitfield_test_bit((mem_addr_t)&ko->perms, ctx->parent_id) &&
    6e5e:	1d04      	adds	r4, r0, #4
	uint32_t temp = *(volatile uint32_t *)addr;
    6e60:	f854 5022 	ldr.w	r5, [r4, r2, lsl #2]
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6e64:	f003 021f 	and.w	r2, r3, #31
	return temp & (1 << bit);
    6e68:	2301      	movs	r3, #1
    6e6a:	fa03 f202 	lsl.w	r2, r3, r2
    6e6e:	422a      	tst	r2, r5
    6e70:	d00d      	beq.n	6e8e <wordlist_cb+0x36>
    6e72:	6800      	ldr	r0, [r0, #0]
    6e74:	688a      	ldr	r2, [r1, #8]
    6e76:	4290      	cmp	r0, r2
    6e78:	d009      	beq.n	6e8e <wordlist_cb+0x36>
		sys_bitfield_set_bit((mem_addr_t)&ko->perms, ctx->child_id);
    6e7a:	684a      	ldr	r2, [r1, #4]
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6e7c:	0951      	lsrs	r1, r2, #5
    6e7e:	f002 021f 	and.w	r2, r2, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    6e82:	f854 0021 	ldr.w	r0, [r4, r1, lsl #2]
	*(volatile uint32_t *)addr = temp | (1 << bit);
    6e86:	4093      	lsls	r3, r2
    6e88:	4303      	orrs	r3, r0
    6e8a:	f844 3021 	str.w	r3, [r4, r1, lsl #2]
}
    6e8e:	bd30      	pop	{r4, r5, pc}

00006e90 <clear_perms_cb>:
	unref_check(ko, id);
    6e90:	f7ff bfc7 	b.w	6e22 <unref_check>

00006e94 <thread_index_get>:
{
    6e94:	b508      	push	{r3, lr}
	ko = z_object_find(thread);
    6e96:	f7f9 f921 	bl	dc <z_object_find>
	if (ko == NULL) {
    6e9a:	b108      	cbz	r0, 6ea0 <thread_index_get+0xc>
	return ko->data.thread_id;
    6e9c:	6880      	ldr	r0, [r0, #8]
}
    6e9e:	bd08      	pop	{r3, pc}
		return -1;
    6ea0:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    6ea4:	e7fb      	b.n	6e9e <thread_index_get+0xa>

00006ea6 <handler_bad_syscall>:

static uintptr_t handler_bad_syscall(uintptr_t bad_id, uintptr_t arg2,
				     uintptr_t arg3, uintptr_t arg4,
				     uintptr_t arg5, uintptr_t arg6,
				     void *ssf)
{
    6ea6:	b508      	push	{r3, lr}
    6ea8:	f7ff ffb1 	bl	6e0e <arch_is_user_context>
	LOG_ERR("Bad system call id %" PRIuPTR " invoked", bad_id);
	arch_syscall_oops(ssf);
    6eac:	9804      	ldr	r0, [sp, #16]
    6eae:	f7ff f913 	bl	60d8 <arch_syscall_oops>

00006eb2 <z_mrsh_adc_channel_setup>:
    6eb2:	b508      	push	{r3, lr}
    6eb4:	f7ff ffab 	bl	6e0e <arch_is_user_context>
    6eb8:	9804      	ldr	r0, [sp, #16]
    6eba:	f7ff f90d 	bl	60d8 <arch_syscall_oops>

00006ebe <z_priv_stack_find>:
{
    6ebe:	b508      	push	{r3, lr}
	struct z_object *obj = z_object_find(stack);
    6ec0:	f7f9 f90c 	bl	dc <z_object_find>
	return obj->data.stack_data->priv;
    6ec4:	6883      	ldr	r3, [r0, #8]
}
    6ec6:	6858      	ldr	r0, [r3, #4]
    6ec8:	bd08      	pop	{r3, pc}

00006eca <z_thread_perms_set>:
{
    6eca:	b510      	push	{r4, lr}
    6ecc:	4604      	mov	r4, r0
	int index = thread_index_get(thread);
    6ece:	4608      	mov	r0, r1
    6ed0:	f7ff ffe0 	bl	6e94 <thread_index_get>
	if (index != -1) {
    6ed4:	1c43      	adds	r3, r0, #1
    6ed6:	d00b      	beq.n	6ef0 <z_thread_perms_set+0x26>
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6ed8:	0941      	lsrs	r1, r0, #5
		sys_bitfield_set_bit((mem_addr_t)&ko->perms, index);
    6eda:	1d23      	adds	r3, r4, #4
    6edc:	f000 001f 	and.w	r0, r0, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    6ee0:	f853 4021 	ldr.w	r4, [r3, r1, lsl #2]
	*(volatile uint32_t *)addr = temp | (1 << bit);
    6ee4:	2201      	movs	r2, #1
    6ee6:	fa02 f000 	lsl.w	r0, r2, r0
    6eea:	4320      	orrs	r0, r4
    6eec:	f843 0021 	str.w	r0, [r3, r1, lsl #2]
}
    6ef0:	bd10      	pop	{r4, pc}

00006ef2 <z_thread_perms_clear>:
{
    6ef2:	b570      	push	{r4, r5, r6, lr}
    6ef4:	4604      	mov	r4, r0
	int index = thread_index_get(thread);
    6ef6:	4608      	mov	r0, r1
    6ef8:	f7ff ffcc 	bl	6e94 <thread_index_get>
	if (index != -1) {
    6efc:	1c43      	adds	r3, r0, #1
	int index = thread_index_get(thread);
    6efe:	4601      	mov	r1, r0
	if (index != -1) {
    6f00:	d010      	beq.n	6f24 <z_thread_perms_clear+0x32>
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6f02:	0945      	lsrs	r5, r0, #5
		sys_bitfield_clear_bit((mem_addr_t)&ko->perms, index);
    6f04:	1d20      	adds	r0, r4, #4
    6f06:	f001 061f 	and.w	r6, r1, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    6f0a:	f850 3025 	ldr.w	r3, [r0, r5, lsl #2]
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6f0e:	2201      	movs	r2, #1
    6f10:	40b2      	lsls	r2, r6
    6f12:	ea23 0302 	bic.w	r3, r3, r2
    6f16:	f840 3025 	str.w	r3, [r0, r5, lsl #2]
		unref_check(ko, index);
    6f1a:	4620      	mov	r0, r4
}
    6f1c:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		unref_check(ko, index);
    6f20:	f7ff bf7f 	b.w	6e22 <unref_check>
}
    6f24:	bd70      	pop	{r4, r5, r6, pc}

00006f26 <z_impl_k_object_access_grant>:
{
    6f26:	b510      	push	{r4, lr}
    6f28:	460c      	mov	r4, r1
	struct z_object *ko = z_object_find(object);
    6f2a:	f7f9 f8d7 	bl	dc <z_object_find>
	if (ko != NULL) {
    6f2e:	b120      	cbz	r0, 6f3a <z_impl_k_object_access_grant+0x14>
		z_thread_perms_set(ko, thread);
    6f30:	4621      	mov	r1, r4
}
    6f32:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		z_thread_perms_set(ko, thread);
    6f36:	f7ff bfc8 	b.w	6eca <z_thread_perms_set>
}
    6f3a:	bd10      	pop	{r4, pc}

00006f3c <z_object_init>:
{
    6f3c:	b508      	push	{r3, lr}
	ko = z_object_find(obj);
    6f3e:	f7f9 f8cd 	bl	dc <z_object_find>
	if (ko == NULL) {
    6f42:	b118      	cbz	r0, 6f4c <z_object_init+0x10>
	ko->flags |= K_OBJ_FLAG_INITIALIZED;
    6f44:	79c3      	ldrb	r3, [r0, #7]
    6f46:	f043 0301 	orr.w	r3, r3, #1
    6f4a:	71c3      	strb	r3, [r0, #7]
}
    6f4c:	bd08      	pop	{r3, pc}

00006f4e <z_object_uninit>:
{
    6f4e:	b508      	push	{r3, lr}
	ko = z_object_find(obj);
    6f50:	f7f9 f8c4 	bl	dc <z_object_find>
	if (ko == NULL) {
    6f54:	b118      	cbz	r0, 6f5e <z_object_uninit+0x10>
	ko->flags &= ~K_OBJ_FLAG_INITIALIZED;
    6f56:	79c3      	ldrb	r3, [r0, #7]
    6f58:	f023 0301 	bic.w	r3, r3, #1
    6f5c:	71c3      	strb	r3, [r0, #7]
}
    6f5e:	bd08      	pop	{r3, pc}

00006f60 <z_user_from_copy>:
{
    6f60:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    6f62:	460d      	mov	r5, r1
    6f64:	4616      	mov	r6, r2
    6f66:	4607      	mov	r7, r0
			Z_SYSCALL_MEMORY_READ(src, size)) {
    6f68:	2200      	movs	r2, #0
    6f6a:	4631      	mov	r1, r6
    6f6c:	4628      	mov	r0, r5
    6f6e:	f7ff f8e1 	bl	6134 <arch_buffer_validate>
    6f72:	4604      	mov	r4, r0
    6f74:	b120      	cbz	r0, 6f80 <z_user_from_copy+0x20>
    6f76:	f7ff ff4a 	bl	6e0e <arch_is_user_context>
	int ret = EFAULT;
    6f7a:	240e      	movs	r4, #14
}
    6f7c:	4620      	mov	r0, r4
    6f7e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	(void)memcpy(dst, src, size);
    6f80:	4632      	mov	r2, r6
    6f82:	4629      	mov	r1, r5
    6f84:	4638      	mov	r0, r7
    6f86:	f7ff f8f7 	bl	6178 <memcpy>
	ret = 0;
    6f8a:	e7f7      	b.n	6f7c <z_user_from_copy+0x1c>

00006f8c <z_user_string_copy>:
{
    6f8c:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    6f8e:	460e      	mov	r6, r1
    6f90:	4614      	mov	r4, r2
    6f92:	4605      	mov	r5, r0
	return arch_user_string_nlen(src, maxlen, err);
    6f94:	aa01      	add	r2, sp, #4
    6f96:	4621      	mov	r1, r4
    6f98:	4630      	mov	r0, r6
    6f9a:	f7fa fc4f 	bl	183c <arch_user_string_nlen>
	if (err != 0) {
    6f9e:	9f01      	ldr	r7, [sp, #4]
    6fa0:	b997      	cbnz	r7, 6fc8 <z_user_string_copy+0x3c>
	if (actual_len == maxlen) {
    6fa2:	4284      	cmp	r4, r0
    6fa4:	d104      	bne.n	6fb0 <z_user_string_copy+0x24>
    6fa6:	f7ff ff32 	bl	6e0e <arch_is_user_context>
		ret = EINVAL;
    6faa:	2016      	movs	r0, #22
}
    6fac:	b003      	add	sp, #12
    6fae:	bdf0      	pop	{r4, r5, r6, r7, pc}
    6fb0:	2401      	movs	r4, #1
    6fb2:	1904      	adds	r4, r0, r4
    6fb4:	d2f7      	bcs.n	6fa6 <z_user_string_copy+0x1a>
	ret = z_user_from_copy(dst, src, actual_len);
    6fb6:	4622      	mov	r2, r4
	dst[actual_len - 1] = '\0';
    6fb8:	442c      	add	r4, r5
	ret = z_user_from_copy(dst, src, actual_len);
    6fba:	4631      	mov	r1, r6
    6fbc:	4628      	mov	r0, r5
    6fbe:	f7ff ffcf 	bl	6f60 <z_user_from_copy>
	dst[actual_len - 1] = '\0';
    6fc2:	f804 7c01 	strb.w	r7, [r4, #-1]
    6fc6:	e7f1      	b.n	6fac <z_user_string_copy+0x20>
		ret = EFAULT;
    6fc8:	200e      	movs	r0, #14
	return ret;
    6fca:	e7ef      	b.n	6fac <z_user_string_copy+0x20>

00006fcc <k_heap_init>:
{
    6fcc:	b410      	push	{r4}
    6fce:	f100 040c 	add.w	r4, r0, #12
	list->tail = (sys_dnode_t *)list;
    6fd2:	e9c0 4403 	strd	r4, r4, [r0, #12]
}
    6fd6:	bc10      	pop	{r4}
	sys_heap_init(&h->heap, mem, bytes);
    6fd8:	f7fe bf00 	b.w	5ddc <sys_heap_init>

00006fdc <k_heap_alloc>:

SYS_INIT(statics_init, PRE_KERNEL_1, CONFIG_KERNEL_INIT_PRIORITY_OBJECTS);

void *k_heap_alloc(struct k_heap *h, size_t bytes, k_timeout_t timeout)
{
    6fdc:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    6fe0:	4604      	mov	r4, r0
    6fe2:	b085      	sub	sp, #20
    6fe4:	460e      	mov	r6, r1
	int64_t now, end = z_timeout_end_calc(timeout);
    6fe6:	4610      	mov	r0, r2
    6fe8:	4619      	mov	r1, r3
    6fea:	f7ff fe5d 	bl	6ca8 <z_timeout_end_calc>
	void *ret = NULL;
	k_spinlock_key_t key = k_spin_lock(&h->lock);
    6fee:	f104 0a14 	add.w	sl, r4, #20
	int64_t now, end = z_timeout_end_calc(timeout);
    6ff2:	4605      	mov	r5, r0
    6ff4:	460f      	mov	r7, r1
	__asm__ volatile(
    6ff6:	f04f 0220 	mov.w	r2, #32
    6ffa:	f3ef 8311 	mrs	r3, BASEPRI
    6ffe:	f382 8811 	msr	BASEPRI, r2
    7002:	f3bf 8f6f 	isb	sy
		now = z_tick_get();
		if ((ret != NULL) || ((end - now) <= 0)) {
			break;
		}

		(void) z_pend_curr(&h->lock, key, &h->wait_q,
    7006:	f104 0b0c 	add.w	fp, r4, #12
		ret = sys_heap_alloc(&h->heap, bytes);
    700a:	4631      	mov	r1, r6
    700c:	4620      	mov	r0, r4
    700e:	9303      	str	r3, [sp, #12]
    7010:	f7fe feb0 	bl	5d74 <sys_heap_alloc>
    7014:	9002      	str	r0, [sp, #8]
		now = z_tick_get();
    7016:	f7fe f9d5 	bl	53c4 <z_tick_get>
		if ((ret != NULL) || ((end - now) <= 0)) {
    701a:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    701e:	b13a      	cbz	r2, 7030 <k_heap_alloc+0x54>
	__asm__ volatile(
    7020:	f383 8811 	msr	BASEPRI, r3
    7024:	f3bf 8f6f 	isb	sy
		key = k_spin_lock(&h->lock);
	}

	k_spin_unlock(&h->lock, key);
	return ret;
}
    7028:	4610      	mov	r0, r2
    702a:	b005      	add	sp, #20
    702c:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		if ((ret != NULL) || ((end - now) <= 0)) {
    7030:	ebb5 0800 	subs.w	r8, r5, r0
    7034:	eb67 0901 	sbc.w	r9, r7, r1
    7038:	f1b8 0f01 	cmp.w	r8, #1
    703c:	f179 0100 	sbcs.w	r1, r9, #0
    7040:	dbee      	blt.n	7020 <k_heap_alloc+0x44>
		(void) z_pend_curr(&h->lock, key, &h->wait_q,
    7042:	e9cd 8900 	strd	r8, r9, [sp]
    7046:	465a      	mov	r2, fp
    7048:	4619      	mov	r1, r3
    704a:	4650      	mov	r0, sl
    704c:	f7fd fa3a 	bl	44c4 <z_pend_curr>
	__asm__ volatile(
    7050:	f04f 0220 	mov.w	r2, #32
    7054:	f3ef 8311 	mrs	r3, BASEPRI
    7058:	f382 8811 	msr	BASEPRI, r2
    705c:	f3bf 8f6f 	isb	sy
    7060:	e7d3      	b.n	700a <k_heap_alloc+0x2e>

00007062 <k_heap_free>:

void k_heap_free(struct k_heap *h, void *mem)
{
    7062:	b538      	push	{r3, r4, r5, lr}
    7064:	4604      	mov	r4, r0
    7066:	f04f 0320 	mov.w	r3, #32
    706a:	f3ef 8511 	mrs	r5, BASEPRI
    706e:	f383 8811 	msr	BASEPRI, r3
    7072:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&h->lock);

	sys_heap_free(&h->heap, mem);
    7076:	f7fe fe28 	bl	5cca <sys_heap_free>

	if (z_unpend_all(&h->wait_q) != 0) {
    707a:	f104 000c 	add.w	r0, r4, #12
    707e:	f7ff fce1 	bl	6a44 <z_unpend_all>
    7082:	b130      	cbz	r0, 7092 <k_heap_free+0x30>
		z_reschedule(&h->lock, key);
    7084:	4629      	mov	r1, r5
    7086:	f104 0014 	add.w	r0, r4, #20
	} else {
		k_spin_unlock(&h->lock, key);
	}
}
    708a:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&h->lock, key);
    708e:	f7ff bbec 	b.w	686a <z_reschedule>
	__asm__ volatile(
    7092:	f385 8811 	msr	BASEPRI, r5
    7096:	f3bf 8f6f 	isb	sy
}
    709a:	bd38      	pop	{r3, r4, r5, pc}

0000709c <k_mem_pool_alloc>:
 * backend.
 */

int k_mem_pool_alloc(struct k_mem_pool *p, struct k_mem_block *block,
		     size_t size, k_timeout_t timeout)
{
    709c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    709e:	e9dd 6706 	ldrd	r6, r7, [sp, #24]
	block->id.heap = p->heap;
    70a2:	6800      	ldr	r0, [r0, #0]
    70a4:	6048      	str	r0, [r1, #4]
{
    70a6:	4614      	mov	r4, r2
    70a8:	460d      	mov	r5, r1
	block->data = k_heap_alloc(p->heap, size, timeout);
    70aa:	4632      	mov	r2, r6
    70ac:	463b      	mov	r3, r7
    70ae:	4621      	mov	r1, r4
    70b0:	f7ff ff94 	bl	6fdc <k_heap_alloc>
    70b4:	6028      	str	r0, [r5, #0]

	/* The legacy API returns -EAGAIN on timeout expiration, but
	 * -ENOMEM if the timeout was K_NO_WAIT. Don't ask.
	 */
	if (size != 0 && block->data == NULL) {
    70b6:	b144      	cbz	r4, 70ca <k_mem_pool_alloc+0x2e>
    70b8:	b938      	cbnz	r0, 70ca <k_mem_pool_alloc+0x2e>
		return K_TIMEOUT_EQ(timeout, K_NO_WAIT) ? -ENOMEM : -EAGAIN;
    70ba:	ea56 0307 	orrs.w	r3, r6, r7
    70be:	bf0c      	ite	eq
    70c0:	f06f 000b 	mvneq.w	r0, #11
    70c4:	f06f 000a 	mvnne.w	r0, #10
	} else {
		return 0;
	}
}
    70c8:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		return 0;
    70ca:	2000      	movs	r0, #0
    70cc:	e7fc      	b.n	70c8 <k_mem_pool_alloc+0x2c>

000070ce <k_mem_pool_free_id>:

void k_mem_pool_free_id(struct k_mem_block_id *id)
{
	k_heap_free(id->heap, id->data);
    70ce:	e9d0 1000 	ldrd	r1, r0, [r0]
    70d2:	f7ff bfc6 	b.w	7062 <k_heap_free>

000070d6 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    70d6:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    70da:	b923      	cbnz	r3, 70e6 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    70dc:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    70e0:	f000 0001 	and.w	r0, r0, #1
    70e4:	4770      	bx	lr
		return false;
    70e6:	2000      	movs	r0, #0
}
    70e8:	4770      	bx	lr

000070ea <validate_any_object>:
{
    70ea:	b510      	push	{r4, lr}
	ko = z_object_find(obj);
    70ec:	f7f8 fff6 	bl	dc <z_object_find>
	ret = z_object_validate(ko, K_OBJ_ANY, _OBJ_INIT_ANY);
    70f0:	2201      	movs	r2, #1
    70f2:	2100      	movs	r1, #0
	ko = z_object_find(obj);
    70f4:	4604      	mov	r4, r0
	ret = z_object_validate(ko, K_OBJ_ANY, _OBJ_INIT_ANY);
    70f6:	f7fe fa2b 	bl	5550 <z_object_validate>
	if (ret != 0) {
    70fa:	2800      	cmp	r0, #0
}
    70fc:	bf0c      	ite	eq
    70fe:	4620      	moveq	r0, r4
    7100:	2000      	movne	r0, #0
    7102:	bd10      	pop	{r4, pc}

00007104 <_OffsetAbsSyms>:
#include "offsets_aarch64.c"
#else
#include "offsets_aarch32.c"
#endif

GEN_ABS_SYM_END
    7104:	4770      	bx	lr
