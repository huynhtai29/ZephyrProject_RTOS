
zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

00000000 <_vector_start>:

	return fd_entry->obj;
}

int z_reserve_fd(void)
{
   0:	20002400 	.word	0x20002400
#if defined(__ZEPHYR_SUPERVISOR__)
	ret = false;
#elif defined(__ZEPHYR_USER__)
	ret = true;
#else
	ret = arch_is_user_context();
   4:	00001871 	.word	0x00001871

extern int z_impl_k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout);
static inline int k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
   8:	00005a57 	.word	0x00005a57
static inline uintptr_t arch_syscall_invoke3(uintptr_t arg1, uintptr_t arg2,
					     uintptr_t arg3,
					     uintptr_t call_id)
{
	register uint32_t ret __asm__("r0") = arg1;
	register uint32_t r1 __asm__("r1") = arg2;
   c:	000018a1 	.word	0x000018a1
	register uint32_t r2 __asm__("r2") = arg3;
  10:	000018a1 	.word	0x000018a1
	register uint32_t r6 __asm__("r6") = call_id;

	__asm__ volatile("svc %[svid]\n"
  14:	000018a1 	.word	0x000018a1
	for (fd = 0; fd < ARRAY_SIZE(fdtable); fd++) {
  18:	000018a1 	.word	0x000018a1
	...
	errno = ENFILE;
  2c:	000014bd 	.word	0x000014bd
	return -1;
  30:	000018a1 	.word	0x000018a1
  34:	00000000 	.word	0x00000000
}

static inline uintptr_t arch_syscall_invoke1(uintptr_t arg1,
					     uintptr_t call_id)
{
	register uint32_t ret __asm__("r0") = arg1;
  38:	0000144d 	.word	0x0000144d
	register uint32_t r6 __asm__("r6") = call_id;

	__asm__ volatile("svc %[svid]\n"
  3c:	000059d5 	.word	0x000059d5

00000040 <_irq_vector_table>:
	}

	k_mutex_unlock(&fdtable_lock);

	return fd;
}
  40:	000016f5 000016f5 000016f5 000016f5     ................
		parm0.val = timeout;
		return (int) arch_syscall_invoke3(*(uintptr_t *)&mutex, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_MUTEX_LOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_lock(mutex, timeout);
  50:	000016f5 000016f5 000016f5 000016f5     ................
	if (z_syscall_trap()) {
		return (int) arch_syscall_invoke1(*(uintptr_t *)&mutex, K_SYSCALL_K_MUTEX_UNLOCK);
	}
#endif
	compiler_barrier();
	return z_impl_k_mutex_unlock(mutex);
  60:	000016f5 000016f5 000016f5 000016f5     ................
  70:	000016f5 000016f5 000016f5 000016f5     ................
  80:	000016f5 000016f5 000016f5 000016f5     ................
  90:	000016f5 000016f5 000016f5 000016f5     ................
  a0:	000016f5 000016f5 000016f5 000016f5     ................
  b0:	000016f5 000016f5 000016f5 000016f5     ................
  c0:	000016f5 000016f5 000016f5 000016f5     ................
  d0:	000016f5 000016f5 000016f5              ............

Disassembly of section text:

000000dc <z_object_find>:
Z_GENERIC_SECTION(.kobject_data.data) uint8_t _thread_idx_map[2] = { 0xc0,  0xff, };
      dc:	4b0a      	ldr	r3, [pc, #40]	; (108 <CONFIG_KOBJECT_TEXT_AREA+0x8>)
      de:	f3c0 2207 	ubfx	r2, r0, #8, #8
      e2:	b2c1      	uxtb	r1, r0
      e4:	5c9a      	ldrb	r2, [r3, r2]
      e6:	5c5b      	ldrb	r3, [r3, r1]
      e8:	4413      	add	r3, r2
"\x9c\x2c\x00\x20", {}, K_OBJ_MUTEX, 0 | K_OBJ_FLAG_INITIALIZED, { .unused = 0 }
      ea:	2b37      	cmp	r3, #55	; 0x37
      ec:	dc09      	bgt.n	102 <CONFIG_KOBJECT_TEXT_AREA+0x2>
%%
      ee:	220c      	movs	r2, #12
      f0:	4906      	ldr	r1, [pc, #24]	; (10c <CONFIG_KOBJECT_TEXT_AREA+0xc>)
      f2:	435a      	muls	r2, r3
      f4:	188b      	adds	r3, r1, r2
{
      f6:	588a      	ldr	r2, [r1, r2]
    return z_object_lookup((const char *)obj, sizeof(void *));
      f8:	4290      	cmp	r0, r2
      fa:	bf0c      	ite	eq
      fc:	4618      	moveq	r0, r3
      fe:	2000      	movne	r0, #0
     100:	4770      	bx	lr
void z_object_gperf_wordlist_foreach(_wordlist_cb_func_t func, void *context)
     102:	2000      	movs	r0, #0
}
     104:	4770      	bx	lr
     106:	bf00      	nop
     108:	00007167 	.word	0x00007167
     10c:	20002cdc 	.word	0x20002cdc

00000110 <z_object_gperf_wordlist_foreach>:
{
     110:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
     112:	4c07      	ldr	r4, [pc, #28]	; (130 <z_object_gperf_wordlist_foreach+0x20>)
     114:	4606      	mov	r6, r0
     116:	460f      	mov	r7, r1
    for (i = MIN_HASH_VALUE; i <= MAX_HASH_VALUE; i++) {
     118:	2500      	movs	r5, #0
        if (wordlist[i].name != NULL) {
     11a:	6823      	ldr	r3, [r4, #0]
     11c:	b113      	cbz	r3, 124 <z_object_gperf_wordlist_foreach+0x14>
            func(&wordlist[i], context);
     11e:	4639      	mov	r1, r7
     120:	4620      	mov	r0, r4
     122:	47b0      	blx	r6
    for (i = MIN_HASH_VALUE; i <= MAX_HASH_VALUE; i++) {
     124:	3501      	adds	r5, #1
     126:	2d38      	cmp	r5, #56	; 0x38
     128:	f104 040c 	add.w	r4, r4, #12
     12c:	d1f5      	bne.n	11a <z_object_gperf_wordlist_foreach+0xa>
}
     12e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
     130:	20002cdc 	.word	0x20002cdc

00000134 <_kobject_text_area_end>:
	...

000001dc <__aeabi_uldivmod>:
     1dc:	b953      	cbnz	r3, 1f4 <__aeabi_uldivmod+0x18>
     1de:	b94a      	cbnz	r2, 1f4 <__aeabi_uldivmod+0x18>
     1e0:	2900      	cmp	r1, #0
     1e2:	bf08      	it	eq
     1e4:	2800      	cmpeq	r0, #0
     1e6:	bf1c      	itt	ne
     1e8:	f04f 31ff 	movne.w	r1, #4294967295	; 0xffffffff
     1ec:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
     1f0:	f000 b96e 	b.w	4d0 <__aeabi_idiv0>
     1f4:	f1ad 0c08 	sub.w	ip, sp, #8
     1f8:	e96d ce04 	strd	ip, lr, [sp, #-16]!
     1fc:	f000 f806 	bl	20c <__udivmoddi4>
     200:	f8dd e004 	ldr.w	lr, [sp, #4]
     204:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
     208:	b004      	add	sp, #16
     20a:	4770      	bx	lr

0000020c <__udivmoddi4>:
     20c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
     210:	9d08      	ldr	r5, [sp, #32]
     212:	460e      	mov	r6, r1
     214:	4604      	mov	r4, r0
     216:	468c      	mov	ip, r1
     218:	2b00      	cmp	r3, #0
     21a:	f040 8081 	bne.w	320 <__udivmoddi4+0x114>
     21e:	428a      	cmp	r2, r1
     220:	4617      	mov	r7, r2
     222:	d945      	bls.n	2b0 <__udivmoddi4+0xa4>
     224:	fab2 f282 	clz	r2, r2
     228:	b14a      	cbz	r2, 23e <__udivmoddi4+0x32>
     22a:	f1c2 0120 	rsb	r1, r2, #32
     22e:	fa06 f302 	lsl.w	r3, r6, r2
     232:	fa20 f101 	lsr.w	r1, r0, r1
     236:	4097      	lsls	r7, r2
     238:	ea41 0c03 	orr.w	ip, r1, r3
     23c:	4094      	lsls	r4, r2
     23e:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     242:	0c23      	lsrs	r3, r4, #16
     244:	fbbc f6fe 	udiv	r6, ip, lr
     248:	b2b9      	uxth	r1, r7
     24a:	fb0e cc16 	mls	ip, lr, r6, ip
     24e:	ea43 430c 	orr.w	r3, r3, ip, lsl #16
     252:	fb06 f001 	mul.w	r0, r6, r1
     256:	4298      	cmp	r0, r3
     258:	d909      	bls.n	26e <__udivmoddi4+0x62>
     25a:	18fb      	adds	r3, r7, r3
     25c:	f106 3cff 	add.w	ip, r6, #4294967295	; 0xffffffff
     260:	f080 8115 	bcs.w	48e <CONFIG_MAIN_STACK_SIZE+0x8e>
     264:	4298      	cmp	r0, r3
     266:	f240 8112 	bls.w	48e <CONFIG_MAIN_STACK_SIZE+0x8e>
     26a:	3e02      	subs	r6, #2
     26c:	443b      	add	r3, r7
     26e:	1a1b      	subs	r3, r3, r0
     270:	b2a4      	uxth	r4, r4
     272:	fbb3 f0fe 	udiv	r0, r3, lr
     276:	fb0e 3310 	mls	r3, lr, r0, r3
     27a:	ea44 4403 	orr.w	r4, r4, r3, lsl #16
     27e:	fb00 f101 	mul.w	r1, r0, r1
     282:	42a1      	cmp	r1, r4
     284:	d909      	bls.n	29a <__udivmoddi4+0x8e>
     286:	193c      	adds	r4, r7, r4
     288:	f100 33ff 	add.w	r3, r0, #4294967295	; 0xffffffff
     28c:	f080 8101 	bcs.w	492 <CONFIG_MAIN_STACK_SIZE+0x92>
     290:	42a1      	cmp	r1, r4
     292:	f240 80fe 	bls.w	492 <CONFIG_MAIN_STACK_SIZE+0x92>
     296:	3802      	subs	r0, #2
     298:	443c      	add	r4, r7
     29a:	1a64      	subs	r4, r4, r1
     29c:	ea40 4006 	orr.w	r0, r0, r6, lsl #16
     2a0:	2100      	movs	r1, #0
     2a2:	b11d      	cbz	r5, 2ac <__udivmoddi4+0xa0>
     2a4:	40d4      	lsrs	r4, r2
     2a6:	2300      	movs	r3, #0
     2a8:	e9c5 4300 	strd	r4, r3, [r5]
     2ac:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
     2b0:	b902      	cbnz	r2, 2b4 <__udivmoddi4+0xa8>
     2b2:	deff      	udf	#255	; 0xff
     2b4:	fab2 f282 	clz	r2, r2
     2b8:	2a00      	cmp	r2, #0
     2ba:	d14f      	bne.n	35c <__udivmoddi4+0x150>
     2bc:	1bcb      	subs	r3, r1, r7
     2be:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     2c2:	fa1f f887 	uxth.w	r8, r7
     2c6:	2101      	movs	r1, #1
     2c8:	fbb3 fcfe 	udiv	ip, r3, lr
     2cc:	0c26      	lsrs	r6, r4, #16
     2ce:	fb0e 331c 	mls	r3, lr, ip, r3
     2d2:	ea46 4603 	orr.w	r6, r6, r3, lsl #16
     2d6:	fb08 f30c 	mul.w	r3, r8, ip
     2da:	42b3      	cmp	r3, r6
     2dc:	d907      	bls.n	2ee <__udivmoddi4+0xe2>
     2de:	19be      	adds	r6, r7, r6
     2e0:	f10c 30ff 	add.w	r0, ip, #4294967295	; 0xffffffff
     2e4:	d202      	bcs.n	2ec <__udivmoddi4+0xe0>
     2e6:	42b3      	cmp	r3, r6
     2e8:	f200 80eb 	bhi.w	4c2 <CONFIG_MAIN_STACK_SIZE+0xc2>
     2ec:	4684      	mov	ip, r0
     2ee:	1af6      	subs	r6, r6, r3
     2f0:	b2a3      	uxth	r3, r4
     2f2:	fbb6 f0fe 	udiv	r0, r6, lr
     2f6:	fb0e 6610 	mls	r6, lr, r0, r6
     2fa:	ea43 4406 	orr.w	r4, r3, r6, lsl #16
     2fe:	fb08 f800 	mul.w	r8, r8, r0
     302:	45a0      	cmp	r8, r4
     304:	d907      	bls.n	316 <__udivmoddi4+0x10a>
     306:	193c      	adds	r4, r7, r4
     308:	f100 33ff 	add.w	r3, r0, #4294967295	; 0xffffffff
     30c:	d202      	bcs.n	314 <__udivmoddi4+0x108>
     30e:	45a0      	cmp	r8, r4
     310:	f200 80d2 	bhi.w	4b8 <CONFIG_MAIN_STACK_SIZE+0xb8>
     314:	4618      	mov	r0, r3
     316:	eba4 0408 	sub.w	r4, r4, r8
     31a:	ea40 400c 	orr.w	r0, r0, ip, lsl #16
     31e:	e7c0      	b.n	2a2 <__udivmoddi4+0x96>
     320:	428b      	cmp	r3, r1
     322:	d908      	bls.n	336 <__udivmoddi4+0x12a>
     324:	2d00      	cmp	r5, #0
     326:	f000 80af 	beq.w	488 <CONFIG_MAIN_STACK_SIZE+0x88>
     32a:	2100      	movs	r1, #0
     32c:	e9c5 0600 	strd	r0, r6, [r5]
     330:	4608      	mov	r0, r1
     332:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
     336:	fab3 f183 	clz	r1, r3
     33a:	2900      	cmp	r1, #0
     33c:	d149      	bne.n	3d2 <__udivmoddi4+0x1c6>
     33e:	42b3      	cmp	r3, r6
     340:	d302      	bcc.n	348 <__udivmoddi4+0x13c>
     342:	4282      	cmp	r2, r0
     344:	f200 80bb 	bhi.w	4be <CONFIG_MAIN_STACK_SIZE+0xbe>
     348:	1a84      	subs	r4, r0, r2
     34a:	eb66 0303 	sbc.w	r3, r6, r3
     34e:	2001      	movs	r0, #1
     350:	469c      	mov	ip, r3
     352:	2d00      	cmp	r5, #0
     354:	d0aa      	beq.n	2ac <__udivmoddi4+0xa0>
     356:	e9c5 4c00 	strd	r4, ip, [r5]
     35a:	e7a7      	b.n	2ac <__udivmoddi4+0xa0>
     35c:	f1c2 0320 	rsb	r3, r2, #32
     360:	4097      	lsls	r7, r2
     362:	40d8      	lsrs	r0, r3
     364:	4091      	lsls	r1, r2
     366:	40de      	lsrs	r6, r3
     368:	ea4f 4e17 	mov.w	lr, r7, lsr #16
     36c:	4308      	orrs	r0, r1
     36e:	ea4f 4c10 	mov.w	ip, r0, lsr #16
     372:	fbb6 f1fe 	udiv	r1, r6, lr
     376:	fa1f f887 	uxth.w	r8, r7
     37a:	fb0e 6611 	mls	r6, lr, r1, r6
     37e:	ea4c 4606 	orr.w	r6, ip, r6, lsl #16
     382:	fb01 f308 	mul.w	r3, r1, r8
     386:	42b3      	cmp	r3, r6
     388:	fa04 f402 	lsl.w	r4, r4, r2
     38c:	d909      	bls.n	3a2 <__udivmoddi4+0x196>
     38e:	19be      	adds	r6, r7, r6
     390:	f101 3cff 	add.w	ip, r1, #4294967295	; 0xffffffff
     394:	f080 808e 	bcs.w	4b4 <CONFIG_MAIN_STACK_SIZE+0xb4>
     398:	42b3      	cmp	r3, r6
     39a:	f240 808b 	bls.w	4b4 <CONFIG_MAIN_STACK_SIZE+0xb4>
     39e:	3902      	subs	r1, #2
     3a0:	443e      	add	r6, r7
     3a2:	1af3      	subs	r3, r6, r3
     3a4:	b286      	uxth	r6, r0
     3a6:	fbb3 f0fe 	udiv	r0, r3, lr
     3aa:	fb0e 3310 	mls	r3, lr, r0, r3
     3ae:	ea46 4603 	orr.w	r6, r6, r3, lsl #16
     3b2:	fb00 f308 	mul.w	r3, r0, r8
     3b6:	42b3      	cmp	r3, r6
     3b8:	d907      	bls.n	3ca <__udivmoddi4+0x1be>
     3ba:	19be      	adds	r6, r7, r6
     3bc:	f100 3cff 	add.w	ip, r0, #4294967295	; 0xffffffff
     3c0:	d274      	bcs.n	4ac <CONFIG_MAIN_STACK_SIZE+0xac>
     3c2:	42b3      	cmp	r3, r6
     3c4:	d972      	bls.n	4ac <CONFIG_MAIN_STACK_SIZE+0xac>
     3c6:	3802      	subs	r0, #2
     3c8:	443e      	add	r6, r7
     3ca:	1af3      	subs	r3, r6, r3
     3cc:	ea40 4101 	orr.w	r1, r0, r1, lsl #16
     3d0:	e77a      	b.n	2c8 <__udivmoddi4+0xbc>
     3d2:	f1c1 0720 	rsb	r7, r1, #32
     3d6:	fa03 f401 	lsl.w	r4, r3, r1
     3da:	fa22 f307 	lsr.w	r3, r2, r7
     3de:	431c      	orrs	r4, r3
     3e0:	fa20 f907 	lsr.w	r9, r0, r7
     3e4:	fa06 f301 	lsl.w	r3, r6, r1
     3e8:	ea4f 4c14 	mov.w	ip, r4, lsr #16
     3ec:	40fe      	lsrs	r6, r7
     3ee:	ea49 0903 	orr.w	r9, r9, r3
     3f2:	ea4f 4319 	mov.w	r3, r9, lsr #16
     3f6:	fbb6 fefc 	udiv	lr, r6, ip
     3fa:	fa1f f884 	uxth.w	r8, r4
     3fe:	fb0c 661e 	mls	r6, ip, lr, r6
     402:	ea43 4606 	orr.w	r6, r3, r6, lsl #16
     406:	fb0e fa08 	mul.w	sl, lr, r8
     40a:	45b2      	cmp	sl, r6
     40c:	fa02 f201 	lsl.w	r2, r2, r1
     410:	fa00 f301 	lsl.w	r3, r0, r1
     414:	d908      	bls.n	428 <CONFIG_MAIN_STACK_SIZE+0x28>
     416:	19a6      	adds	r6, r4, r6
     418:	f10e 30ff 	add.w	r0, lr, #4294967295	; 0xffffffff
     41c:	d248      	bcs.n	4b0 <CONFIG_MAIN_STACK_SIZE+0xb0>
     41e:	45b2      	cmp	sl, r6
     420:	d946      	bls.n	4b0 <CONFIG_MAIN_STACK_SIZE+0xb0>
     422:	f1ae 0e02 	sub.w	lr, lr, #2
     426:	4426      	add	r6, r4
     428:	eba6 060a 	sub.w	r6, r6, sl
     42c:	fa1f f989 	uxth.w	r9, r9
     430:	fbb6 f0fc 	udiv	r0, r6, ip
     434:	fb0c 6610 	mls	r6, ip, r0, r6
     438:	ea49 4606 	orr.w	r6, r9, r6, lsl #16
     43c:	fb00 f808 	mul.w	r8, r0, r8
     440:	45b0      	cmp	r8, r6
     442:	d907      	bls.n	454 <CONFIG_MAIN_STACK_SIZE+0x54>
     444:	19a6      	adds	r6, r4, r6
     446:	f100 3cff 	add.w	ip, r0, #4294967295	; 0xffffffff
     44a:	d22d      	bcs.n	4a8 <CONFIG_MAIN_STACK_SIZE+0xa8>
     44c:	45b0      	cmp	r8, r6
     44e:	d92b      	bls.n	4a8 <CONFIG_MAIN_STACK_SIZE+0xa8>
     450:	3802      	subs	r0, #2
     452:	4426      	add	r6, r4
     454:	ea40 400e 	orr.w	r0, r0, lr, lsl #16
     458:	eba6 0608 	sub.w	r6, r6, r8
     45c:	fba0 8902 	umull	r8, r9, r0, r2
     460:	454e      	cmp	r6, r9
     462:	46c4      	mov	ip, r8
     464:	46ce      	mov	lr, r9
     466:	d318      	bcc.n	49a <CONFIG_MAIN_STACK_SIZE+0x9a>
     468:	d015      	beq.n	496 <CONFIG_MAIN_STACK_SIZE+0x96>
     46a:	b375      	cbz	r5, 4ca <CONFIG_MAIN_STACK_SIZE+0xca>
     46c:	ebb3 020c 	subs.w	r2, r3, ip
     470:	eb66 060e 	sbc.w	r6, r6, lr
     474:	fa06 f707 	lsl.w	r7, r6, r7
     478:	fa22 f301 	lsr.w	r3, r2, r1
     47c:	40ce      	lsrs	r6, r1
     47e:	431f      	orrs	r7, r3
     480:	e9c5 7600 	strd	r7, r6, [r5]
     484:	2100      	movs	r1, #0
     486:	e711      	b.n	2ac <__udivmoddi4+0xa0>
     488:	4629      	mov	r1, r5
     48a:	4628      	mov	r0, r5
     48c:	e70e      	b.n	2ac <__udivmoddi4+0xa0>
     48e:	4666      	mov	r6, ip
     490:	e6ed      	b.n	26e <__udivmoddi4+0x62>
     492:	4618      	mov	r0, r3
     494:	e701      	b.n	29a <__udivmoddi4+0x8e>
     496:	4543      	cmp	r3, r8
     498:	d2e7      	bcs.n	46a <CONFIG_MAIN_STACK_SIZE+0x6a>
     49a:	ebb8 0c02 	subs.w	ip, r8, r2
     49e:	eb69 0404 	sbc.w	r4, r9, r4
     4a2:	3801      	subs	r0, #1
     4a4:	46a6      	mov	lr, r4
     4a6:	e7e0      	b.n	46a <CONFIG_MAIN_STACK_SIZE+0x6a>
     4a8:	4660      	mov	r0, ip
     4aa:	e7d3      	b.n	454 <CONFIG_MAIN_STACK_SIZE+0x54>
     4ac:	4660      	mov	r0, ip
     4ae:	e78c      	b.n	3ca <__udivmoddi4+0x1be>
     4b0:	4686      	mov	lr, r0
     4b2:	e7b9      	b.n	428 <CONFIG_MAIN_STACK_SIZE+0x28>
     4b4:	4661      	mov	r1, ip
     4b6:	e774      	b.n	3a2 <__udivmoddi4+0x196>
     4b8:	3802      	subs	r0, #2
     4ba:	443c      	add	r4, r7
     4bc:	e72b      	b.n	316 <__udivmoddi4+0x10a>
     4be:	4608      	mov	r0, r1
     4c0:	e747      	b.n	352 <__udivmoddi4+0x146>
     4c2:	f1ac 0c02 	sub.w	ip, ip, #2
     4c6:	443e      	add	r6, r7
     4c8:	e711      	b.n	2ee <__udivmoddi4+0xe2>
     4ca:	4629      	mov	r1, r5
     4cc:	e6ee      	b.n	2ac <__udivmoddi4+0xa0>
     4ce:	bf00      	nop

000004d0 <__aeabi_idiv0>:
     4d0:	4770      	bx	lr
     4d2:	bf00      	nop

000004d4 <Thread_receive_a>:

	}
	
}
extern void Thread_receive_a()
{
     4d4:	b580      	push	{r7, lr}
		arch_syscall_invoke1(*(uintptr_t *)&sem, K_SYSCALL_K_SEM_GIVE);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_sem_give(sem);
     4d6:	4c11      	ldr	r4, [pc, #68]	; (51c <Thread_receive_a+0x48>)

	while (1)
	{
		printk("\n\r hello Receive Aaaaaaaaaaaaaaaaaaaaaaaaaaaaa");
     4d8:	4f11      	ldr	r7, [pc, #68]	; (520 <Thread_receive_a+0x4c>)
	if (z_syscall_trap()) {
		return (int) arch_syscall_invoke2(*(uintptr_t *)&signal, *(uintptr_t *)&result, K_SYSCALL_K_POLL_SIGNAL_RAISE);
	}
#endif
	compiler_barrier();
	return z_impl_k_poll_signal_raise(signal, result);
     4da:	4d12      	ldr	r5, [pc, #72]	; (524 <Thread_receive_a+0x50>)
     4dc:	4638      	mov	r0, r7
     4de:	f004 fe88 	bl	51f2 <printk>
     4e2:	f004 fd6f 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
     4e6:	b178      	cbz	r0, 508 <Thread_receive_a+0x34>
	register uint32_t ret __asm__("r0") = arg1;
     4e8:	4620      	mov	r0, r4
	register uint32_t r6 __asm__("r6") = call_id;
     4ea:	2684      	movs	r6, #132	; 0x84
	__asm__ volatile("svc %[svid]\n"
     4ec:	df03      	svc	3
     4ee:	f004 fd69 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
     4f2:	b168      	cbz	r0, 510 <Thread_receive_a+0x3c>
	register uint32_t ret __asm__("r0") = arg1;
     4f4:	4628      	mov	r0, r5
	register uint32_t r1 __asm__("r1") = arg2;
     4f6:	2126      	movs	r1, #38	; 0x26
	register uint32_t r6 __asm__("r6") = call_id;
     4f8:	2679      	movs	r6, #121	; 0x79
	__asm__ volatile("svc %[svid]\n"
     4fa:	df03      	svc	3
 * @return Zero if the requested time has elapsed or the number of milliseconds
 * left to sleep, if thread was woken up by \ref k_wakeup call.
 */
static inline int32_t k_msleep(int32_t ms)
{
	return k_sleep(Z_TIMEOUT_MS(ms));
     4fc:	2100      	movs	r1, #0
     4fe:	f641 109a 	movw	r0, #6554	; 0x199a
     502:	f004 fd6b 	bl	4fdc <k_sleep>
     506:	e7e9      	b.n	4dc <Thread_receive_a+0x8>
	z_impl_k_sem_give(sem);
     508:	4620      	mov	r0, r4
     50a:	f003 fdc7 	bl	409c <z_impl_k_sem_give>
     50e:	e7ee      	b.n	4ee <Thread_receive_a+0x1a>
	return z_impl_k_poll_signal_raise(signal, result);
     510:	2126      	movs	r1, #38	; 0x26
     512:	4628      	mov	r0, r5
     514:	f004 fbba 	bl	4c8c <z_impl_k_poll_signal_raise>
     518:	e7f0      	b.n	4fc <Thread_receive_a+0x28>
     51a:	bf00      	nop
     51c:	20002cc4 	.word	0x20002cc4
     520:	00007004 	.word	0x00007004
     524:	200003c8 	.word	0x200003c8

00000528 <Thread_send_a>:
{
     528:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	return z_impl_k_poll(events, num_events, timeout);
     52c:	4d24      	ldr	r5, [pc, #144]	; (5c0 <Thread_send_a+0x98>)
				printk("\n\r Take signal form polll");
     52e:	f8df 90a0 	ldr.w	r9, [pc, #160]	; 5d0 <Thread_send_a+0xa8>
	register uint32_t r2 __asm__("r2") = arg3;
     532:	2700      	movs	r7, #0
     534:	f004 fd46 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
     538:	b340      	cbz	r0, 58c <Thread_send_a+0x64>
     53a:	2200      	movs	r2, #0
	register uint32_t ret __asm__("r0") = arg1;
     53c:	4628      	mov	r0, r5
	register uint32_t r1 __asm__("r1") = arg2;
     53e:	2102      	movs	r1, #2
	register uint32_t r3 __asm__("r3") = arg4;
     540:	4613      	mov	r3, r2
	register uint32_t r6 __asm__("r6") = call_id;
     542:	2676      	movs	r6, #118	; 0x76
	__asm__ volatile("svc %[svid]\n"
     544:	df03      	svc	3
		if (rc == 0)
     546:	f010 04ff 	ands.w	r4, r0, #255	; 0xff
     54a:	d110      	bne.n	56e <Thread_send_a+0x46>
			if(my_events[0].state == K_POLL_STATE_SEM_AVAILABLE)
     54c:	68eb      	ldr	r3, [r5, #12]
     54e:	f403 33f8 	and.w	r3, r3, #126976	; 0x1f000
     552:	f5b3 5f00 	cmp.w	r3, #8192	; 0x2000
     556:	d126      	bne.n	5a6 <Thread_send_a+0x7e>
				printk("\n\r Take semaphore from poll");
     558:	481a      	ldr	r0, [pc, #104]	; (5c4 <Thread_send_a+0x9c>)
     55a:	f004 fe4a 	bl	51f2 <printk>
     55e:	f004 fd31 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
     562:	b1d0      	cbz	r0, 59a <Thread_send_a+0x72>
	register uint32_t ret __asm__("r0") = arg1;
     564:	4818      	ldr	r0, [pc, #96]	; (5c8 <Thread_send_a+0xa0>)
	register uint32_t r1 __asm__("r1") = arg2;
     566:	4621      	mov	r1, r4
	register uint32_t r2 __asm__("r2") = arg3;
     568:	4622      	mov	r2, r4
	register uint32_t r6 __asm__("r6") = call_id;
     56a:	2687      	movs	r6, #135	; 0x87
	__asm__ volatile("svc %[svid]\n"
     56c:	df03      	svc	3
		printk("\n\rNot events in poll");
     56e:	4817      	ldr	r0, [pc, #92]	; (5cc <Thread_send_a+0xa4>)
     570:	f004 fe3f 	bl	51f2 <printk>
		my_events[0].state = K_POLL_STATE_NOT_READY;
     574:	68eb      	ldr	r3, [r5, #12]
     576:	f36f 3310 	bfc	r3, #12, #5
     57a:	60eb      	str	r3, [r5, #12]
		my_events[1].signal->result = 0;
     57c:	6a6b      	ldr	r3, [r5, #36]	; 0x24
     57e:	60df      	str	r7, [r3, #12]
     580:	f004 fd20 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
     584:	b1c8      	cbz	r0, 5ba <Thread_send_a+0x92>
}

static inline uintptr_t arch_syscall_invoke0(uintptr_t call_id)
{
	register uint32_t ret __asm__("r0");
	register uint32_t r6 __asm__("r6") = call_id;
     586:	26a8      	movs	r6, #168	; 0xa8

	__asm__ volatile("svc %[svid]\n"
     588:	df03      	svc	3
			 : "=r"(ret)
			 : [svid] "i" (_SVC_CALL_SYSTEM_CALL),
			   "r" (ret), "r" (r6)
			 : "r8", "memory", "r1", "r2", "r3", "ip");

	return ret;
     58a:	e7d3      	b.n	534 <Thread_send_a+0xc>
	return z_impl_k_poll(events, num_events, timeout);
     58c:	2200      	movs	r2, #0
     58e:	2300      	movs	r3, #0
     590:	2102      	movs	r1, #2
     592:	4628      	mov	r0, r5
     594:	f004 fa18 	bl	49c8 <z_impl_k_poll>
     598:	e7d5      	b.n	546 <Thread_send_a+0x1e>
	return z_impl_k_sem_take(sem, timeout);
     59a:	2200      	movs	r2, #0
     59c:	2300      	movs	r3, #0
     59e:	480a      	ldr	r0, [pc, #40]	; (5c8 <Thread_send_a+0xa0>)
     5a0:	f003 fdc2 	bl	4128 <z_impl_k_sem_take>
     5a4:	e7e3      	b.n	56e <Thread_send_a+0x46>
			else if(my_events[1].signal->result == 0x26)
     5a6:	6a6b      	ldr	r3, [r5, #36]	; 0x24
     5a8:	68db      	ldr	r3, [r3, #12]
     5aa:	2b26      	cmp	r3, #38	; 0x26
     5ac:	d1df      	bne.n	56e <Thread_send_a+0x46>
				printk("\n\r Take signal form polll");
     5ae:	4648      	mov	r0, r9
     5b0:	f004 fe1f 	bl	51f2 <printk>
				my_events[1].signal->result = 0;
     5b4:	6a6b      	ldr	r3, [r5, #36]	; 0x24
     5b6:	60dc      	str	r4, [r3, #12]
     5b8:	e7d9      	b.n	56e <Thread_send_a+0x46>
	z_impl_k_yield();
     5ba:	f003 fbb1 	bl	3d20 <z_impl_k_yield>
	{
     5be:	e7b9      	b.n	534 <Thread_send_a+0xc>
     5c0:	20002c00 	.word	0x20002c00
     5c4:	00007033 	.word	0x00007033
     5c8:	20002cc4 	.word	0x20002cc4
     5cc:	00007069 	.word	0x00007069
     5d0:	0000704f 	.word	0x0000704f

000005d4 <device_get_binding.constprop.0>:
#ifdef __cplusplus
extern "C" {
#endif

extern struct device * z_impl_device_get_binding(const char * name);
static inline struct device * device_get_binding(const char * name)
     5d4:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
     5d8:	f004 fcf4 	bl	4fc4 <arch_is_user_context>
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
     5dc:	b120      	cbz	r0, 5e8 <device_get_binding.constprop.0+0x14>
	register uint32_t ret __asm__("r0") = arg1;
     5de:	4805      	ldr	r0, [pc, #20]	; (5f4 <device_get_binding.constprop.0+0x20>)
	register uint32_t r6 __asm__("r6") = call_id;
     5e0:	2627      	movs	r6, #39	; 0x27
	__asm__ volatile("svc %[svid]\n"
     5e2:	df03      	svc	3
		return (struct device *) arch_syscall_invoke1(*(uintptr_t *)&name, K_SYSCALL_DEVICE_GET_BINDING);
	}
#endif
	compiler_barrier();
	return z_impl_device_get_binding(name);
}
     5e4:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	return z_impl_device_get_binding(name);
     5e8:	4802      	ldr	r0, [pc, #8]	; (5f4 <device_get_binding.constprop.0+0x20>)
}
     5ea:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_device_get_binding(name);
     5ee:	f002 bc47 	b.w	2e80 <z_impl_device_get_binding>
     5f2:	bf00      	nop
     5f4:	0000707e 	.word	0x0000707e

000005f8 <main>:
	}
	
}	
struct info_message _sv;
void main(void)
{	
     5f8:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
	/*-------------Thread Send-Receive----------------------*/
	my_tid_send_a = k_thread_create(&my_thread_data_send_a,my_stack_area_send_a,
                                 MY_STACK_SIZE,
                                 Thread_send_a,
                                 NULL, NULL, NULL,
                                 5, 0, K_NO_WAIT);
     5fc:	2600      	movs	r6, #0
     5fe:	2700      	movs	r7, #0
	my_tid_send_a = k_thread_create(&my_thread_data_send_a,my_stack_area_send_a,
     600:	4a62      	ldr	r2, [pc, #392]	; (78c <main+0x194>)
     602:	4963      	ldr	r1, [pc, #396]	; (790 <main+0x198>)
     604:	4863      	ldr	r0, [pc, #396]	; (794 <main+0x19c>)
	k_thread_name_set(my_tid_send_a, "Thread_send_a");

	my_tid_send_b = k_thread_create(&my_thread_data_send_b,my_stack_area_send_b,
     606:	4d64      	ldr	r5, [pc, #400]	; (798 <main+0x1a0>)
                                 MY_STACK_SIZE,
                                 Thread_receive_a,
                                 NULL, NULL, NULL,
                                 5, 0, K_NO_WAIT);
	k_thread_name_set(my_tid_receive_a, "Thread_receive_a");	
	my_tid_receive_b = k_thread_create(&my_thread_data_receive_b,my_stack_area_receive_b,
     608:	4c64      	ldr	r4, [pc, #400]	; (79c <main+0x1a4>)
	my_tid_send_a = k_thread_create(&my_thread_data_send_a,my_stack_area_send_a,
     60a:	e9cd 6700 	strd	r6, r7, [sp]
     60e:	f004 fd19 	bl	5044 <k_thread_create.constprop.0>
     612:	4b63      	ldr	r3, [pc, #396]	; (7a0 <main+0x1a8>)
	k_thread_name_set(my_tid_send_a, "Thread_send_a");
     614:	4963      	ldr	r1, [pc, #396]	; (7a4 <main+0x1ac>)
	my_tid_send_a = k_thread_create(&my_thread_data_send_a,my_stack_area_send_a,
     616:	6018      	str	r0, [r3, #0]
	k_thread_name_set(my_tid_send_a, "Thread_send_a");
     618:	f004 fd3f 	bl	509a <k_thread_name_set>
	my_tid_send_b = k_thread_create(&my_thread_data_send_b,my_stack_area_send_b,
     61c:	4a62      	ldr	r2, [pc, #392]	; (7a8 <main+0x1b0>)
     61e:	4963      	ldr	r1, [pc, #396]	; (7ac <main+0x1b4>)
     620:	4863      	ldr	r0, [pc, #396]	; (7b0 <main+0x1b8>)
     622:	e9cd 6700 	strd	r6, r7, [sp]
     626:	f004 fd0d 	bl	5044 <k_thread_create.constprop.0>
	k_thread_name_set(my_tid_send_b, "Thread_send_b");	
     62a:	4962      	ldr	r1, [pc, #392]	; (7b4 <main+0x1bc>)
	my_tid_send_b = k_thread_create(&my_thread_data_send_b,my_stack_area_send_b,
     62c:	6028      	str	r0, [r5, #0]
	k_thread_name_set(my_tid_send_b, "Thread_send_b");	
     62e:	f004 fd34 	bl	509a <k_thread_name_set>
	my_tid_receive_a = k_thread_create(&my_thread_data_receive_a,my_stack_area_receive_a,
     632:	4a61      	ldr	r2, [pc, #388]	; (7b8 <main+0x1c0>)
     634:	4961      	ldr	r1, [pc, #388]	; (7bc <main+0x1c4>)
     636:	4862      	ldr	r0, [pc, #392]	; (7c0 <main+0x1c8>)
     638:	e9cd 6700 	strd	r6, r7, [sp]
     63c:	f004 fd02 	bl	5044 <k_thread_create.constprop.0>
     640:	4b60      	ldr	r3, [pc, #384]	; (7c4 <main+0x1cc>)
	k_thread_name_set(my_tid_receive_a, "Thread_receive_a");	
     642:	4961      	ldr	r1, [pc, #388]	; (7c8 <main+0x1d0>)
	my_tid_receive_a = k_thread_create(&my_thread_data_receive_a,my_stack_area_receive_a,
     644:	6018      	str	r0, [r3, #0]
	k_thread_name_set(my_tid_receive_a, "Thread_receive_a");	
     646:	f004 fd28 	bl	509a <k_thread_name_set>
	my_tid_receive_b = k_thread_create(&my_thread_data_receive_b,my_stack_area_receive_b,
     64a:	4a60      	ldr	r2, [pc, #384]	; (7cc <main+0x1d4>)
     64c:	4960      	ldr	r1, [pc, #384]	; (7d0 <main+0x1d8>)
     64e:	4861      	ldr	r0, [pc, #388]	; (7d4 <main+0x1dc>)
     650:	e9cd 6700 	strd	r6, r7, [sp]
     654:	f004 fcf6 	bl	5044 <k_thread_create.constprop.0>
                                 MY_STACK_SIZE,
                                 Thread_receive_b,
                                 NULL, NULL, NULL,
                                 5, 0, K_NO_WAIT);
	k_thread_name_set(my_tid_receive_b, "Thread_receive_b");	
     658:	495f      	ldr	r1, [pc, #380]	; (7d8 <main+0x1e0>)
	my_tid_receive_b = k_thread_create(&my_thread_data_receive_b,my_stack_area_receive_b,
     65a:	6020      	str	r0, [r4, #0]
	k_thread_name_set(my_tid_receive_b, "Thread_receive_b");	
     65c:	f004 fd1d 	bl	509a <k_thread_name_set>
     660:	f004 fcb0 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
     664:	2800      	cmp	r0, #0
     666:	f000 8084 	beq.w	772 <main+0x17a>
	register uint32_t ret __asm__("r0") = arg1;
     66a:	485c      	ldr	r0, [pc, #368]	; (7dc <main+0x1e4>)
	register uint32_t r6 __asm__("r6") = call_id;
     66c:	2678      	movs	r6, #120	; 0x78
	__asm__ volatile("svc %[svid]\n"
     66e:	df03      	svc	3
/*--------------POLLING-----------------*/

	k_poll_signal_init(&my_signal);
	k_poll_event_init(&my_events[0],K_POLL_TYPE_SEM_AVAILABLE,K_POLL_MODE_NOTIFY_ONLY,&my_sem);
     670:	4b5b      	ldr	r3, [pc, #364]	; (7e0 <main+0x1e8>)
     672:	485c      	ldr	r0, [pc, #368]	; (7e4 <main+0x1ec>)
     674:	2200      	movs	r2, #0
     676:	2102      	movs	r1, #2
     678:	f005 ff3c 	bl	64f4 <k_poll_event_init>
	k_poll_event_init(&my_events[1],K_POLL_TYPE_SIGNAL,K_POLL_MODE_NOTIFY_ONLY,&my_signal);
     67c:	4b57      	ldr	r3, [pc, #348]	; (7dc <main+0x1e4>)
     67e:	485a      	ldr	r0, [pc, #360]	; (7e8 <main+0x1f0>)
     680:	2200      	movs	r2, #0
     682:	2101      	movs	r1, #1
     684:	f005 ff36 	bl	64f4 <k_poll_event_init>
	k_thread_suspend(my_tid_send_b);
     688:	6828      	ldr	r0, [r5, #0]
     68a:	f004 fd38 	bl	50fe <k_thread_suspend>
	k_thread_suspend(my_tid_receive_b);
     68e:	6820      	ldr	r0, [r4, #0]
     690:	f004 fd35 	bl	50fe <k_thread_suspend>
	struct device *dev;
	struct device *dev_led0;
	bool led_is_on = true;
	int ret;
	/*-----Configure nRF52832 from Library nrf52.h-------------*/
	NRF_P0->PIN_CNF[14] = (3 << 16) | (3 << 2);
     694:	f04f 43a0 	mov.w	r3, #1342177280	; 0x50000000
     698:	4a54      	ldr	r2, [pc, #336]	; (7ec <main+0x1f4>)
     69a:	f8c3 2738 	str.w	r2, [r3, #1848]	; 0x738
    NRF_P0->PIN_CNF[15] = (3 << 16) | (3 << 2);
     69e:	f8c3 273c 	str.w	r2, [r3, #1852]	; 0x73c
    NRF_P0->PIN_CNF[16] = (3 << 16) | (3 << 2);
     6a2:	f8c3 2740 	str.w	r2, [r3, #1856]	; 0x740
    NRF_P0->PIN_CNF[13] = (3 << 16) | (3 << 2); 
     6a6:	f8c3 2734 	str.w	r2, [r3, #1844]	; 0x734
	//NRF_P0->DIRSET = 0x001E0000;
    NRF_P0->PIN_CNF[6] = 0x03;
     6aa:	2203      	movs	r2, #3
     6ac:	f8c3 2718 	str.w	r2, [r3, #1816]	; 0x718
    NRF_P0->PIN_CNF[7] = 0;
     6b0:	2200      	movs	r2, #0
     6b2:	f8c3 271c 	str.w	r2, [r3, #1820]	; 0x71c
    // Configure GPIOTE
    //EVENTS
    NRF_GPIOTE->INTENSET = (1 << 0);// Enable INTERRUPTION EVENT_IN[0]
     6b6:	4b4e      	ldr	r3, [pc, #312]	; (7f0 <main+0x1f8>)
    //NRF_GPIOTE->CONFIG[0] = (1 << 0) | (13 << 8) | (2 << 16); // Configure EVENT_IN[0]
    //NRF_GPIOTE->CONFIG[5] = (1 << 0) | (14 << 8) | (2 << 16); // Configure EVENT_IN[0]
    NRF_GPIOTE->CONFIG[6] = (1 << 0) | (15 << 8) | (2 << 16); // Configure EVENT_IN[0]
     6b8:	4a4e      	ldr	r2, [pc, #312]	; (7f4 <main+0x1fc>)
    NRF_GPIOTE->INTENSET = (1 << 0);// Enable INTERRUPTION EVENT_IN[0]
     6ba:	2401      	movs	r4, #1
     6bc:	f8c3 4304 	str.w	r4, [r3, #772]	; 0x304
    NRF_GPIOTE->CONFIG[6] = (1 << 0) | (15 << 8) | (2 << 16); // Configure EVENT_IN[0]
     6c0:	f8c3 2528 	str.w	r2, [r3, #1320]	; 0x528
    NRF_GPIOTE->CONFIG[7] = (1 << 0) | (16 << 8) | (2 << 16); // Configure EVENT_IN[0]
     6c4:	f502 7280 	add.w	r2, r2, #256	; 0x100
     6c8:	f8c3 252c 	str.w	r2, [r3, #1324]	; 0x52c
    // TASKS
    //NRF_GPIOTE->CONFIG[1] = (3 << 0) | (17 << 8) | (3 << 16) | (1 << 20);
    //NRF_GPIOTE->CONFIG[2] = (3 << 0) | (18 << 8) | (3 << 16) | (1 << 20);
    NRF_GPIOTE->CONFIG[3] = (3 << 0) | (19 << 8) | (3 << 16) | (1 << 20);
     6cc:	f502 1288 	add.w	r2, r2, #1114112	; 0x110000
     6d0:	f202 3202 	addw	r2, r2, #770	; 0x302
     6d4:	f8c3 251c 	str.w	r2, [r3, #1308]	; 0x51c
    NRF_GPIOTE->CONFIG[4] = (3 << 0) | (20 << 8) | (3 << 16) | (1 << 20);
     6d8:	f502 7280 	add.w	r2, r2, #256	; 0x100
     6dc:	f8c3 2520 	str.w	r2, [r3, #1312]	; 0x520
    //NRF_PPI->CHENSET = (15 << 0);
    //NRF_PPI->CH[0].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[0];
    //NRF_PPI->CH[0].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[1];
    //NRF_PPI->CH[1].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[5];
    //NRF_PPI->CH[1].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[2];
    NRF_PPI->CH[2].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[6];
     6e0:	f503 33c8 	add.w	r3, r3, #102400	; 0x19000
     6e4:	4a44      	ldr	r2, [pc, #272]	; (7f8 <main+0x200>)
     6e6:	f8c3 2520 	str.w	r2, [r3, #1312]	; 0x520
    NRF_PPI->CH[2].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[3];
     6ea:	f5a2 7286 	sub.w	r2, r2, #268	; 0x10c
     6ee:	f8c3 2524 	str.w	r2, [r3, #1316]	; 0x524
    NRF_PPI->CH[3].EEP = (uint32_t)&NRF_GPIOTE->EVENTS_IN[7];
     6f2:	f502 7288 	add.w	r2, r2, #272	; 0x110
     6f6:	f8c3 2528 	str.w	r2, [r3, #1320]	; 0x528
    NRF_PPI->CH[3].TEP = (uint32_t)&NRF_GPIOTE->TASKS_OUT[4];
     6fa:	f5a2 7286 	sub.w	r2, r2, #268	; 0x10c
     6fe:	f8c3 252c 	str.w	r2, [r3, #1324]	; 0x52c
    NRF_PPI->CHG[0] = (15 << 0);
     702:	220f      	movs	r2, #15
     704:	f8c3 2800 	str.w	r2, [r3, #2048]	; 0x800
    NRF_PPI->TASKS_CHG[0].EN = 1;
     708:	601c      	str	r4, [r3, #0]
	/*---------------------------------------------------------------*/
	dev = device_get_binding(LED1);
     70a:	f7ff ff63 	bl	5d4 <device_get_binding.constprop.0>
	if (dev == NULL) {
     70e:	4606      	mov	r6, r0
     710:	b3c8      	cbz	r0, 786 <main+0x18e>
		return;
	}

	ret = gpio_pin_configure(dev, PIN, GPIO_OUTPUT_ACTIVE | FLAGS);
     712:	2112      	movs	r1, #18
     714:	f004 fc72 	bl	4ffc <gpio_pin_configure.constprop.0>
	if (ret < 0) {
     718:	2800      	cmp	r0, #0
     71a:	db34      	blt.n	786 <main+0x18e>
		return;
	}
	dev_led0 = device_get_binding(LED1);
     71c:	f7ff ff5a 	bl	5d4 <device_get_binding.constprop.0>
	if (dev_led0 == NULL) {
     720:	4607      	mov	r7, r0
     722:	b380      	cbz	r0, 786 <main+0x18e>
		return;
	}

	ret = gpio_pin_configure(dev_led0, PIN0, GPIO_OUTPUT_ACTIVE | FLAGS);
     724:	2111      	movs	r1, #17
     726:	f004 fc69 	bl	4ffc <gpio_pin_configure.constprop.0>
	if (ret < 0) {
     72a:	2800      	cmp	r0, #0
     72c:	db2b      	blt.n	786 <main+0x18e>

	(void)cfg;
	__ASSERT((cfg->port_pin_mask & (gpio_port_pins_t)BIT(pin)) != 0U,
		 "Unsupported pin");

	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
     72e:	68f3      	ldr	r3, [r6, #12]
     730:	681b      	ldr	r3, [r3, #0]
		return;
	}
	while (1) {

		gpio_pin_set(dev, PIN, (int)led_is_on);
     732:	4625      	mov	r5, r4
		value = (value != 0) ? 0 : 1;
     734:	f413 2f80 	tst.w	r3, #262144	; 0x40000
     738:	f084 0401 	eor.w	r4, r4, #1
     73c:	bf0c      	ite	eq
     73e:	462b      	moveq	r3, r5
     740:	4623      	movne	r3, r4
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     742:	f44f 2180 	mov.w	r1, #262144	; 0x40000
     746:	4630      	mov	r0, r6
	if (value != 0)	{
     748:	b1bb      	cbz	r3, 77a <main+0x182>
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     74a:	f004 fcc7 	bl	50dc <gpio_port_set_bits_raw>
	if (data->invert & (gpio_port_pins_t)BIT(pin)) {
     74e:	68fb      	ldr	r3, [r7, #12]
     750:	681b      	ldr	r3, [r3, #0]
		value = (value != 0) ? 0 : 1;
     752:	f413 3f00 	tst.w	r3, #131072	; 0x20000
     756:	bf08      	it	eq
     758:	4625      	moveq	r5, r4
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     75a:	f44f 3100 	mov.w	r1, #131072	; 0x20000
     75e:	4638      	mov	r0, r7
	if (value != 0)	{
     760:	b175      	cbz	r5, 780 <main+0x188>
		ret = gpio_port_set_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     762:	f004 fcbb 	bl	50dc <gpio_port_set_bits_raw>
     766:	2100      	movs	r1, #0
     768:	f44f 4000 	mov.w	r0, #32768	; 0x8000
     76c:	f004 fc36 	bl	4fdc <k_sleep>
     770:	e7dd      	b.n	72e <main+0x136>
	z_impl_k_poll_signal_init(signal);
     772:	481a      	ldr	r0, [pc, #104]	; (7dc <main+0x1e4>)
     774:	f005 fedb 	bl	652e <z_impl_k_poll_signal_init>
     778:	e77a      	b.n	670 <main+0x78>
		ret = gpio_port_clear_bits_raw(port, (gpio_port_pins_t)BIT(pin));
     77a:	f004 fc9e 	bl	50ba <gpio_port_clear_bits_raw>
     77e:	e7e6      	b.n	74e <main+0x156>
     780:	f004 fc9b 	bl	50ba <gpio_port_clear_bits_raw>
     784:	e7ef      	b.n	766 <main+0x16e>
		gpio_pin_set(dev_led0,PIN0,(int)!led_is_on);
		led_is_on = !led_is_on;
		k_msleep(SLEEP_TIME_MS);	
	}

}
     786:	b002      	add	sp, #8
     788:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
     78c:	00000529 	.word	0x00000529
     790:	20002400 	.word	0x20002400
     794:	20000140 	.word	0x20000140
     798:	200003e4 	.word	0x200003e4
     79c:	200003dc 	.word	0x200003dc
     7a0:	200003e0 	.word	0x200003e0
     7a4:	00007085 	.word	0x00007085
     7a8:	00004fd9 	.word	0x00004fd9
     7ac:	20002600 	.word	0x20002600
     7b0:	200001e0 	.word	0x200001e0
     7b4:	00007093 	.word	0x00007093
     7b8:	000004d5 	.word	0x000004d5
     7bc:	20002800 	.word	0x20002800
     7c0:	20000000 	.word	0x20000000
     7c4:	200003d8 	.word	0x200003d8
     7c8:	000070a1 	.word	0x000070a1
     7cc:	00004fdb 	.word	0x00004fdb
     7d0:	20002a00 	.word	0x20002a00
     7d4:	200000a0 	.word	0x200000a0
     7d8:	000070b2 	.word	0x000070b2
     7dc:	200003c8 	.word	0x200003c8
     7e0:	20002cc4 	.word	0x20002cc4
     7e4:	20002c00 	.word	0x20002c00
     7e8:	20002c14 	.word	0x20002c14
     7ec:	0003000c 	.word	0x0003000c
     7f0:	40006000 	.word	0x40006000
     7f4:	00020f01 	.word	0x00020f01
     7f8:	40006118 	.word	0x40006118

000007fc <print_digits>:
}
#endif /* CONFIG_PRINTK */

static void print_digits(out_func_t out, void *ctx, printk_val_t num, int base,
			 bool pad_before, char pad_char, int min_width)
{
     7fc:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
     800:	b087      	sub	sp, #28
     802:	460f      	mov	r7, r1
     804:	4619      	mov	r1, r3
	char buf[DIGITS_BUFLEN];
	int i;

	/* Print it backwards into the end of the buffer, low digits first */
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
		buf[i] = "0123456789abcdef"[num % base];
     806:	9b10      	ldr	r3, [sp, #64]	; 0x40
{
     808:	f89d b044 	ldrb.w	fp, [sp, #68]	; 0x44
     80c:	f89d a048 	ldrb.w	sl, [sp, #72]	; 0x48
		buf[i] = "0123456789abcdef"[num % base];
     810:	4c1f      	ldr	r4, [pc, #124]	; (890 <CONFIG_HEAP_MEM_POOL_SIZE+0x90>)
{
     812:	4606      	mov	r6, r0
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     814:	2514      	movs	r5, #20
{
     816:	4610      	mov	r0, r2
		buf[i] = "0123456789abcdef"[num % base];
     818:	4698      	mov	r8, r3
     81a:	ea4f 79e3 	mov.w	r9, r3, asr #31
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     81e:	ea50 0301 	orrs.w	r3, r0, r1
     822:	d119      	bne.n	858 <CONFIG_HEAP_MEM_POOL_SIZE+0x58>
		num /= base;
	}

	if (i == DIGITS_BUFLEN - 1) {
     824:	2d14      	cmp	r5, #20
		buf[i] = '0';
	} else {
		i++;
	}

	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     826:	9c13      	ldr	r4, [sp, #76]	; 0x4c
		i++;
     828:	bf14      	ite	ne
     82a:	3501      	addne	r5, #1
		buf[i] = '0';
     82c:	2330      	moveq	r3, #48	; 0x30
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     82e:	442c      	add	r4, r5
		buf[i] = '0';
     830:	bf08      	it	eq
     832:	f88d 3014 	strbeq.w	r3, [sp, #20]
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     836:	2c15      	cmp	r4, #21
     838:	d01b      	beq.n	872 <CONFIG_HEAP_MEM_POOL_SIZE+0x72>
     83a:	3c15      	subs	r4, #21

	for (/**/; pad > 0 && pad_before; pad--) {
     83c:	2c00      	cmp	r4, #0
     83e:	dc1a      	bgt.n	876 <CONFIG_HEAP_MEM_POOL_SIZE+0x76>
		out(pad_char, ctx);
	}
	for (/**/; i < DIGITS_BUFLEN; i++) {
		out(buf[i], ctx);
     840:	f81d 0005 	ldrb.w	r0, [sp, r5]
     844:	4639      	mov	r1, r7
	for (/**/; i < DIGITS_BUFLEN; i++) {
     846:	3501      	adds	r5, #1
		out(buf[i], ctx);
     848:	47b0      	blx	r6
	for (/**/; i < DIGITS_BUFLEN; i++) {
     84a:	2d15      	cmp	r5, #21
     84c:	d1f8      	bne.n	840 <CONFIG_HEAP_MEM_POOL_SIZE+0x40>
	}
	for (/**/; pad > 0; pad--) {
     84e:	2c00      	cmp	r4, #0
     850:	dc19      	bgt.n	886 <CONFIG_HEAP_MEM_POOL_SIZE+0x86>
		out(pad_char, ctx);
	}
}
     852:	b007      	add	sp, #28
     854:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		buf[i] = "0123456789abcdef"[num % base];
     858:	4642      	mov	r2, r8
     85a:	464b      	mov	r3, r9
     85c:	f7ff fcbe 	bl	1dc <__aeabi_uldivmod>
     860:	5ca2      	ldrb	r2, [r4, r2]
     862:	f80d 2005 	strb.w	r2, [sp, r5]
     866:	4684      	mov	ip, r0
     868:	460b      	mov	r3, r1
		num /= base;
     86a:	4660      	mov	r0, ip
     86c:	4619      	mov	r1, r3
	for (i = DIGITS_BUFLEN - 1; num != 0; i--) {
     86e:	3d01      	subs	r5, #1
     870:	e7d5      	b.n	81e <CONFIG_HEAP_MEM_POOL_SIZE+0x1e>
	int pad = MAX(min_width - (DIGITS_BUFLEN - i), 0);
     872:	2400      	movs	r4, #0
	for (/**/; i < DIGITS_BUFLEN; i++) {
     874:	e7e4      	b.n	840 <CONFIG_HEAP_MEM_POOL_SIZE+0x40>
	for (/**/; pad > 0 && pad_before; pad--) {
     876:	f1bb 0f00 	cmp.w	fp, #0
     87a:	d0e1      	beq.n	840 <CONFIG_HEAP_MEM_POOL_SIZE+0x40>
		out(pad_char, ctx);
     87c:	4639      	mov	r1, r7
     87e:	4650      	mov	r0, sl
     880:	47b0      	blx	r6
	for (/**/; pad > 0 && pad_before; pad--) {
     882:	3c01      	subs	r4, #1
     884:	e7da      	b.n	83c <CONFIG_HEAP_MEM_POOL_SIZE+0x3c>
		out(pad_char, ctx);
     886:	4639      	mov	r1, r7
     888:	4650      	mov	r0, sl
     88a:	47b0      	blx	r6
	for (/**/; pad > 0; pad--) {
     88c:	3c01      	subs	r4, #1
     88e:	e7de      	b.n	84e <CONFIG_HEAP_MEM_POOL_SIZE+0x4e>
     890:	000070c3 	.word	0x000070c3

00000894 <char_out>:

static int char_out(int c, void *ctx_p)
{
	struct out_context *ctx = ctx_p;

	ctx->count++;
     894:	680b      	ldr	r3, [r1, #0]
     896:	3301      	adds	r3, #1
     898:	600b      	str	r3, [r1, #0]
	return _char_out(c);
     89a:	4b01      	ldr	r3, [pc, #4]	; (8a0 <char_out+0xc>)
     89c:	681b      	ldr	r3, [r3, #0]
     89e:	4718      	bx	r3
     8a0:	20002c28 	.word	0x20002c28

000008a4 <__printk_hook_install>:
	_char_out = fn;
     8a4:	4b01      	ldr	r3, [pc, #4]	; (8ac <__printk_hook_install+0x8>)
     8a6:	6018      	str	r0, [r3, #0]
}
     8a8:	4770      	bx	lr
     8aa:	bf00      	nop
     8ac:	20002c28 	.word	0x20002c28

000008b0 <z_vprintk>:
{
     8b0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	char length_mod = 0;
     8b4:	2600      	movs	r6, #0
{
     8b6:	b087      	sub	sp, #28
     8b8:	4605      	mov	r5, r0
     8ba:	468b      	mov	fp, r1
     8bc:	461c      	mov	r4, r3
	while (*fmt) {
     8be:	f102 39ff 	add.w	r9, r2, #4294967295	; 0xffffffff
	int min_width = -1;
     8c2:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
	enum pad_type padding = PAD_NONE;
     8c6:	4637      	mov	r7, r6
			might_format = 0;
     8c8:	2300      	movs	r3, #0
					break;
     8ca:	e007      	b.n	8dc <z_vprintk+0x2c>
		if (!might_format) {
     8cc:	b96b      	cbnz	r3, 8ea <z_vprintk+0x3a>
			if (*fmt != '%') {
     8ce:	2825      	cmp	r0, #37	; 0x25
     8d0:	f000 80fc 	beq.w	acc <z_vprintk+0x21c>
				out((int)*fmt, ctx);
     8d4:	4659      	mov	r1, fp
     8d6:	9304      	str	r3, [sp, #16]
     8d8:	47a8      	blx	r5
     8da:	9b04      	ldr	r3, [sp, #16]
	while (*fmt) {
     8dc:	f819 0f01 	ldrb.w	r0, [r9, #1]!
     8e0:	2800      	cmp	r0, #0
     8e2:	d1f3      	bne.n	8cc <z_vprintk+0x1c>
}
     8e4:	b007      	add	sp, #28
     8e6:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			switch (*fmt) {
     8ea:	287a      	cmp	r0, #122	; 0x7a
     8ec:	d80a      	bhi.n	904 <z_vprintk+0x54>
     8ee:	2862      	cmp	r0, #98	; 0x62
     8f0:	d810      	bhi.n	914 <z_vprintk+0x64>
     8f2:	2830      	cmp	r0, #48	; 0x30
     8f4:	d052      	beq.n	99c <z_vprintk+0xec>
     8f6:	d845      	bhi.n	984 <z_vprintk+0xd4>
     8f8:	2825      	cmp	r0, #37	; 0x25
     8fa:	f000 80e5 	beq.w	ac8 <z_vprintk+0x218>
     8fe:	282d      	cmp	r0, #45	; 0x2d
     900:	f000 80ea 	beq.w	ad8 <z_vprintk+0x228>
					out((int)'%', ctx);
     904:	4659      	mov	r1, fp
     906:	2025      	movs	r0, #37	; 0x25
     908:	47a8      	blx	r5
					out((int)*fmt, ctx);
     90a:	f899 0000 	ldrb.w	r0, [r9]
     90e:	4659      	mov	r1, fp
     910:	47a8      	blx	r5
     912:	e7d9      	b.n	8c8 <z_vprintk+0x18>
     914:	f1a0 0263 	sub.w	r2, r0, #99	; 0x63
     918:	2a17      	cmp	r2, #23
     91a:	d8f3      	bhi.n	904 <z_vprintk+0x54>
     91c:	a101      	add	r1, pc, #4	; (adr r1, 924 <z_vprintk+0x74>)
     91e:	f851 f022 	ldr.w	pc, [r1, r2, lsl #2]
     922:	bf00      	nop
     924:	00000ac1 	.word	0x00000ac1
     928:	000009e5 	.word	0x000009e5
     92c:	00000905 	.word	0x00000905
     930:	00000905 	.word	0x00000905
     934:	00000905 	.word	0x00000905
     938:	000009c7 	.word	0x000009c7
     93c:	000009e5 	.word	0x000009e5
     940:	00000905 	.word	0x00000905
     944:	00000905 	.word	0x00000905
     948:	000009c7 	.word	0x000009c7
     94c:	00000905 	.word	0x00000905
     950:	00000905 	.word	0x00000905
     954:	00000905 	.word	0x00000905
     958:	00000a49 	.word	0x00000a49
     95c:	00000905 	.word	0x00000905
     960:	00000905 	.word	0x00000905
     964:	00000a8b 	.word	0x00000a8b
     968:	00000905 	.word	0x00000905
     96c:	000009e5 	.word	0x000009e5
     970:	00000905 	.word	0x00000905
     974:	00000905 	.word	0x00000905
     978:	0000098d 	.word	0x0000098d
     97c:	00000905 	.word	0x00000905
     980:	000009c7 	.word	0x000009c7
			switch (*fmt) {
     984:	2839      	cmp	r0, #57	; 0x39
     986:	d915      	bls.n	9b4 <z_vprintk+0x104>
     988:	2858      	cmp	r0, #88	; 0x58
     98a:	d1bb      	bne.n	904 <z_vprintk+0x54>
				if (*fmt == 'p') {
     98c:	f899 3000 	ldrb.w	r3, [r9]
     990:	2b70      	cmp	r3, #112	; 0x70
     992:	d163      	bne.n	a5c <z_vprintk+0x1ac>
					x = va_arg(ap, unsigned int);
     994:	f854 2b04 	ldr.w	r2, [r4], #4
     998:	2300      	movs	r3, #0
     99a:	e06a      	b.n	a72 <z_vprintk+0x1c2>
				if (min_width < 0 && padding == PAD_NONE) {
     99c:	f1b8 0f00 	cmp.w	r8, #0
     9a0:	da0b      	bge.n	9ba <z_vprintk+0x10a>
     9a2:	2f00      	cmp	r7, #0
     9a4:	f000 809a 	beq.w	adc <z_vprintk+0x22c>
					min_width = *fmt - '0';
     9a8:	f1a0 0830 	sub.w	r8, r0, #48	; 0x30
					padding = PAD_SPACE_BEFORE;
     9ac:	2f00      	cmp	r7, #0
     9ae:	bf08      	it	eq
     9b0:	2702      	moveq	r7, #2
     9b2:	e793      	b.n	8dc <z_vprintk+0x2c>
				if (min_width < 0) {
     9b4:	f1b8 0f00 	cmp.w	r8, #0
     9b8:	dbf6      	blt.n	9a8 <z_vprintk+0xf8>
					min_width = 10 * min_width + *fmt - '0';
     9ba:	220a      	movs	r2, #10
     9bc:	fb02 0808 	mla	r8, r2, r8, r0
     9c0:	f1a8 0830 	sub.w	r8, r8, #48	; 0x30
     9c4:	e7f2      	b.n	9ac <z_vprintk+0xfc>
				if (*fmt == 'h' && length_mod == 'h') {
     9c6:	2868      	cmp	r0, #104	; 0x68
     9c8:	d103      	bne.n	9d2 <z_vprintk+0x122>
     9ca:	2e68      	cmp	r6, #104	; 0x68
     9cc:	d106      	bne.n	9dc <z_vprintk+0x12c>
					length_mod = 'H';
     9ce:	2648      	movs	r6, #72	; 0x48
     9d0:	e784      	b.n	8dc <z_vprintk+0x2c>
				} else if (*fmt == 'l' && length_mod == 'l') {
     9d2:	286c      	cmp	r0, #108	; 0x6c
     9d4:	d102      	bne.n	9dc <z_vprintk+0x12c>
     9d6:	2e6c      	cmp	r6, #108	; 0x6c
     9d8:	f000 8082 	beq.w	ae0 <z_vprintk+0x230>
				} else if (length_mod == 0) {
     9dc:	2e00      	cmp	r6, #0
     9de:	d191      	bne.n	904 <z_vprintk+0x54>
     9e0:	4606      	mov	r6, r0
     9e2:	e77b      	b.n	8dc <z_vprintk+0x2c>
				if (length_mod == 'z') {
     9e4:	2e7a      	cmp	r6, #122	; 0x7a
     9e6:	d103      	bne.n	9f0 <z_vprintk+0x140>
					d = va_arg(ap, int);
     9e8:	f854 2b04 	ldr.w	r2, [r4], #4
     9ec:	17d3      	asrs	r3, r2, #31
     9ee:	e008      	b.n	a02 <z_vprintk+0x152>
				} else if (length_mod == 'l') {
     9f0:	2e6c      	cmp	r6, #108	; 0x6c
     9f2:	d0f9      	beq.n	9e8 <z_vprintk+0x138>
				} else if (length_mod == 'L') {
     9f4:	2e4c      	cmp	r6, #76	; 0x4c
     9f6:	d1f7      	bne.n	9e8 <z_vprintk+0x138>
					long long lld = va_arg(ap, long long);
     9f8:	3407      	adds	r4, #7
     9fa:	f024 0407 	bic.w	r4, r4, #7
					d = (printk_val_t) lld;
     9fe:	e8f4 2302 	ldrd	r2, r3, [r4], #8
				if (*fmt != 'u' && negative(d)) {
     a02:	2875      	cmp	r0, #117	; 0x75
     a04:	d00f      	beq.n	a26 <z_vprintk+0x176>
     a06:	2a00      	cmp	r2, #0
     a08:	f173 0100 	sbcs.w	r1, r3, #0
     a0c:	da0b      	bge.n	a26 <z_vprintk+0x176>
					out((int)'-', ctx);
     a0e:	4659      	mov	r1, fp
     a10:	202d      	movs	r0, #45	; 0x2d
     a12:	e9cd 2304 	strd	r2, r3, [sp, #16]
     a16:	47a8      	blx	r5
					d = -d;
     a18:	e9dd 2304 	ldrd	r2, r3, [sp, #16]
     a1c:	4252      	negs	r2, r2
     a1e:	eb63 0343 	sbc.w	r3, r3, r3, lsl #1
					min_width--;
     a22:	f108 38ff 	add.w	r8, r8, #4294967295	; 0xffffffff
	print_digits(out, ctx, num, 10, padding != PAD_SPACE_AFTER,
     a26:	1ef9      	subs	r1, r7, #3
     a28:	bf18      	it	ne
     a2a:	2101      	movne	r1, #1
     a2c:	2f01      	cmp	r7, #1
     a2e:	bf0c      	ite	eq
     a30:	2030      	moveq	r0, #48	; 0x30
     a32:	2020      	movne	r0, #32
     a34:	e9cd 0802 	strd	r0, r8, [sp, #8]
     a38:	9101      	str	r1, [sp, #4]
     a3a:	210a      	movs	r1, #10
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
     a3c:	9100      	str	r1, [sp, #0]
     a3e:	4628      	mov	r0, r5
     a40:	4659      	mov	r1, fp
     a42:	f7ff fedb 	bl	7fc <print_digits>
     a46:	e73f      	b.n	8c8 <z_vprintk+0x18>
				out('0', ctx);
     a48:	4659      	mov	r1, fp
     a4a:	2030      	movs	r0, #48	; 0x30
     a4c:	47a8      	blx	r5
				out('x', ctx);
     a4e:	4659      	mov	r1, fp
     a50:	2078      	movs	r0, #120	; 0x78
     a52:	47a8      	blx	r5
				min_width = sizeof(void *) * 2;
     a54:	f04f 0808 	mov.w	r8, #8
				padding = PAD_ZERO_BEFORE;
     a58:	2701      	movs	r7, #1
     a5a:	e797      	b.n	98c <z_vprintk+0xdc>
				} else if (length_mod == 'l') {
     a5c:	2e6c      	cmp	r6, #108	; 0x6c
     a5e:	d099      	beq.n	994 <z_vprintk+0xe4>
				} else if (length_mod == 'L') {
     a60:	2e4c      	cmp	r6, #76	; 0x4c
     a62:	d197      	bne.n	994 <z_vprintk+0xe4>
					x = va_arg(ap, unsigned long long);
     a64:	1de3      	adds	r3, r4, #7
     a66:	f023 0307 	bic.w	r3, r3, #7
     a6a:	461c      	mov	r4, r3
     a6c:	685b      	ldr	r3, [r3, #4]
     a6e:	f854 2b08 	ldr.w	r2, [r4], #8
	print_digits(out, ctx, num, 16, padding != PAD_SPACE_AFTER,
     a72:	1ef9      	subs	r1, r7, #3
     a74:	bf18      	it	ne
     a76:	2101      	movne	r1, #1
     a78:	2f01      	cmp	r7, #1
     a7a:	bf0c      	ite	eq
     a7c:	2030      	moveq	r0, #48	; 0x30
     a7e:	2020      	movne	r0, #32
     a80:	9101      	str	r1, [sp, #4]
     a82:	e9cd 0802 	strd	r0, r8, [sp, #8]
     a86:	2110      	movs	r1, #16
     a88:	e7d8      	b.n	a3c <z_vprintk+0x18c>
				char *s = va_arg(ap, char *);
     a8a:	46a2      	mov	sl, r4
     a8c:	f85a 3b04 	ldr.w	r3, [sl], #4
				while (*s) {
     a90:	461c      	mov	r4, r3
     a92:	4621      	mov	r1, r4
     a94:	f814 0b01 	ldrb.w	r0, [r4], #1
     a98:	b940      	cbnz	r0, aac <z_vprintk+0x1fc>
				if (padding == PAD_SPACE_AFTER) {
     a9a:	2f03      	cmp	r7, #3
     a9c:	d122      	bne.n	ae4 <z_vprintk+0x234>
					int remaining = min_width - (s - start);
     a9e:	1acc      	subs	r4, r1, r3
     aa0:	eba8 0404 	sub.w	r4, r8, r4
					while (remaining-- > 0) {
     aa4:	2c00      	cmp	r4, #0
     aa6:	dc06      	bgt.n	ab6 <z_vprintk+0x206>
				char *s = va_arg(ap, char *);
     aa8:	4654      	mov	r4, sl
     aaa:	e70d      	b.n	8c8 <z_vprintk+0x18>
					out((int)(*s++), ctx);
     aac:	4659      	mov	r1, fp
     aae:	9304      	str	r3, [sp, #16]
     ab0:	47a8      	blx	r5
     ab2:	9b04      	ldr	r3, [sp, #16]
     ab4:	e7ed      	b.n	a92 <z_vprintk+0x1e2>
						out(' ', ctx);
     ab6:	4659      	mov	r1, fp
     ab8:	2020      	movs	r0, #32
     aba:	47a8      	blx	r5
     abc:	3c01      	subs	r4, #1
     abe:	e7f1      	b.n	aa4 <z_vprintk+0x1f4>
				out(c, ctx);
     ac0:	f854 0b04 	ldr.w	r0, [r4], #4
     ac4:	4659      	mov	r1, fp
     ac6:	e723      	b.n	910 <z_vprintk+0x60>
				out((int)'%', ctx);
     ac8:	4659      	mov	r1, fp
     aca:	e721      	b.n	910 <z_vprintk+0x60>
				length_mod = 0;
     acc:	461e      	mov	r6, r3
				padding = PAD_NONE;
     ace:	461f      	mov	r7, r3
				min_width = -1;
     ad0:	f04f 38ff 	mov.w	r8, #4294967295	; 0xffffffff
				might_format = 1;
     ad4:	2301      	movs	r3, #1
     ad6:	e701      	b.n	8dc <z_vprintk+0x2c>
			switch (*fmt) {
     ad8:	2703      	movs	r7, #3
     ada:	e6ff      	b.n	8dc <z_vprintk+0x2c>
					padding = PAD_ZERO_BEFORE;
     adc:	2701      	movs	r7, #1
     ade:	e6fd      	b.n	8dc <z_vprintk+0x2c>
					length_mod = 'L';
     ae0:	264c      	movs	r6, #76	; 0x4c
     ae2:	e6fb      	b.n	8dc <z_vprintk+0x2c>
				char *s = va_arg(ap, char *);
     ae4:	4654      	mov	r4, sl
			might_format = 0;
     ae6:	4603      	mov	r3, r0
     ae8:	e6f8      	b.n	8dc <z_vprintk+0x2c>
     aea:	bf00      	nop

00000aec <z_impl_k_str_out>:
#endif
}
#endif /* CONFIG_USERSPACE */

void z_impl_k_str_out(char *c, size_t n)
{
     aec:	b570      	push	{r4, r5, r6, lr}
#ifdef CONFIG_PRINTK_SYNC
	k_spinlock_key_t key = k_spin_lock(&lock);
#endif

	for (i = 0; i < n; i++) {
		_char_out(c[i]);
     aee:	4e05      	ldr	r6, [pc, #20]	; (b04 <z_impl_k_str_out+0x18>)
     af0:	4604      	mov	r4, r0
     af2:	1845      	adds	r5, r0, r1
	for (i = 0; i < n; i++) {
     af4:	42ac      	cmp	r4, r5
     af6:	d100      	bne.n	afa <z_impl_k_str_out+0xe>
	}

#ifdef CONFIG_PRINTK_SYNC
	k_spin_unlock(&lock, key);
#endif
}
     af8:	bd70      	pop	{r4, r5, r6, pc}
		_char_out(c[i]);
     afa:	6833      	ldr	r3, [r6, #0]
     afc:	f814 0b01 	ldrb.w	r0, [r4], #1
     b00:	4798      	blx	r3
	for (i = 0; i < n; i++) {
     b02:	e7f7      	b.n	af4 <z_impl_k_str_out+0x8>
     b04:	20002c28 	.word	0x20002c28

00000b08 <vprintk>:
{
     b08:	b530      	push	{r4, r5, lr}
     b0a:	b08b      	sub	sp, #44	; 0x2c
     b0c:	4604      	mov	r4, r0
     b0e:	460d      	mov	r5, r1
 * @return true if the CPU is currently running with user permissions
 */
static inline bool _is_user_context(void)
{
#ifdef CONFIG_USERSPACE
	return arch_is_user_context();
     b10:	f004 fb3e 	bl	5190 <arch_is_user_context>
	if (_is_user_context()) {
     b14:	b188      	cbz	r0, b3a <vprintk+0x32>
		struct buf_out_context ctx = { 0 };
     b16:	2228      	movs	r2, #40	; 0x28
     b18:	2100      	movs	r1, #0
     b1a:	4668      	mov	r0, sp
     b1c:	f005 f808 	bl	5b30 <memset>
		z_vprintk(buf_char_out, &ctx, fmt, ap);
     b20:	462b      	mov	r3, r5
     b22:	480a      	ldr	r0, [pc, #40]	; (b4c <vprintk+0x44>)
     b24:	4622      	mov	r2, r4
     b26:	4669      	mov	r1, sp
     b28:	f7ff fec2 	bl	8b0 <z_vprintk>
		if (ctx.buf_count) {
     b2c:	9b01      	ldr	r3, [sp, #4]
     b2e:	b113      	cbz	r3, b36 <vprintk+0x2e>
			buf_flush(&ctx);
     b30:	4668      	mov	r0, sp
     b32:	f004 fb39 	bl	51a8 <buf_flush>
}
     b36:	b00b      	add	sp, #44	; 0x2c
     b38:	bd30      	pop	{r4, r5, pc}
		struct out_context ctx = { 0 };
     b3a:	9000      	str	r0, [sp, #0]
		z_vprintk(char_out, &ctx, fmt, ap);
     b3c:	460b      	mov	r3, r1
     b3e:	4804      	ldr	r0, [pc, #16]	; (b50 <vprintk+0x48>)
     b40:	4622      	mov	r2, r4
     b42:	4669      	mov	r1, sp
     b44:	f7ff feb4 	bl	8b0 <z_vprintk>
}
     b48:	e7f5      	b.n	b36 <vprintk+0x2e>
     b4a:	bf00      	nop
     b4c:	000051d1 	.word	0x000051d1
     b50:	00000895 	.word	0x00000895

00000b54 <z_mrsh_k_str_out>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_str_out(char * c, size_t n);
uintptr_t z_mrsh_k_str_out(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     b54:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
     b56:	4d0e      	ldr	r5, [pc, #56]	; (b90 <z_mrsh_k_str_out+0x3c>)
     b58:	9a08      	ldr	r2, [sp, #32]
     b5a:	68ab      	ldr	r3, [r5, #8]
     b5c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_str_out(char *c, size_t n)
{
	Z_OOPS(Z_SYSCALL_MEMORY_READ(c, n));
     b60:	2200      	movs	r2, #0
{
     b62:	4606      	mov	r6, r0
     b64:	460f      	mov	r7, r1
     b66:	f004 ff96 	bl	5a96 <arch_buffer_validate>
     b6a:	4604      	mov	r4, r0
     b6c:	b130      	cbz	r0, b7c <z_mrsh_k_str_out+0x28>
     b6e:	f004 fb0f 	bl	5190 <arch_is_user_context>
     b72:	68ab      	ldr	r3, [r5, #8]
     b74:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
     b78:	f004 ff5f 	bl	5a3a <arch_syscall_oops>
	z_impl_k_str_out((char *)c, n);
     b7c:	4630      	mov	r0, r6
     b7e:	4639      	mov	r1, r7
     b80:	f7ff ffb4 	bl	aec <z_impl_k_str_out>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_str_out(*(char **)&arg0, *(size_t*)&arg1)
;
	_current->syscall_frame = NULL;
     b84:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
     b86:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
     b88:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
     b8c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
     b8e:	bf00      	nop
     b90:	20000524 	.word	0x20000524

00000b94 <process_event>:
 * regions.
 */
static void process_event(struct onoff_manager *mgr,
			  int evt,
			  k_spinlock_key_t key)
{
     b94:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	sys_slist_t clients;
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     b98:	f8b0 9018 	ldrh.w	r9, [r0, #24]
	__ASSERT_NO_MSG(evt != EVT_NOP);

	/* If this is a nested call record the event for processing in
	 * the top invocation.
	 */
	if (processing) {
     b9c:	f019 0808 	ands.w	r8, r9, #8
{
     ba0:	4604      	mov	r4, r0
	if (processing) {
     ba2:	d00d      	beq.n	bc0 <process_event+0x2c>
		if (evt == EVT_COMPLETE) {
     ba4:	2901      	cmp	r1, #1
			mgr->flags |= ONOFF_FLAG_COMPLETE;
     ba6:	bf0c      	ite	eq
     ba8:	f049 0910 	orreq.w	r9, r9, #16
		} else {
			__ASSERT_NO_MSG(evt == EVT_RECHECK);

			mgr->flags |= ONOFF_FLAG_RECHECK;
     bac:	f049 0920 	orrne.w	r9, r9, #32
     bb0:	f8a0 9018 	strh.w	r9, [r0, #24]
	__asm__ volatile(
		"cpsie i;"
		"isb"
		: : : "memory");
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__asm__ volatile(
     bb4:	f382 8811 	msr	BASEPRI, r2
     bb8:	f3bf 8f6f 	isb	sy
		state = mgr->flags & ONOFF_STATE_MASK;
	} while (evt != EVT_NOP);

out:
	k_spin_unlock(&mgr->lock, key);
}
     bbc:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     bc0:	f009 0907 	and.w	r9, r9, #7
		if (evt == EVT_RECHECK) {
     bc4:	2902      	cmp	r1, #2
     bc6:	d107      	bne.n	bd8 <process_event+0x44>
			evt = process_recheck(mgr);
     bc8:	4620      	mov	r0, r4
     bca:	f004 fb1f 	bl	520c <process_recheck>
		if (evt == EVT_NOP) {
     bce:	2800      	cmp	r0, #0
     bd0:	d0f0      	beq.n	bb4 <process_event+0x20>
		if (evt == EVT_COMPLETE) {
     bd2:	2801      	cmp	r0, #1
     bd4:	8b23      	ldrh	r3, [r4, #24]
     bd6:	d150      	bne.n	c7a <process_event+0xe6>
			res = mgr->last_res;
     bd8:	6967      	ldr	r7, [r4, #20]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     bda:	8b21      	ldrh	r1, [r4, #24]
	if (res < 0) {
     bdc:	2f00      	cmp	r7, #0
     bde:	da15      	bge.n	c0c <process_event+0x78>
		*clients = mgr->clients;
     be0:	6825      	ldr	r5, [r4, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     be2:	f021 0107 	bic.w	r1, r1, #7
 * @param list A pointer on the list to initialize
 */
static inline void sys_slist_init(sys_slist_t *list)
{
	list->head = NULL;
	list->tail = NULL;
     be6:	e9c4 8800 	strd	r8, r8, [r4]
     bea:	f041 0101 	orr.w	r1, r1, #1
	mgr->flags = (state & ONOFF_STATE_MASK)
     bee:	8321      	strh	r1, [r4, #24]
		onoff_transition_fn transit = NULL;
     bf0:	2600      	movs	r6, #0
		bool do_monitors = (state != (mgr->flags & ONOFF_STATE_MASK))
     bf2:	8b21      	ldrh	r1, [r4, #24]
     bf4:	f001 0a07 	and.w	sl, r1, #7
				   && !sys_slist_is_empty(&mgr->monitors);
     bf8:	45ca      	cmp	sl, r9
     bfa:	d002      	beq.n	c02 <process_event+0x6e>
		if (do_monitors
     bfc:	68a3      	ldr	r3, [r4, #8]
     bfe:	2b00      	cmp	r3, #0
     c00:	d15c      	bne.n	cbc <process_event+0x128>
		    || !sys_slist_is_empty(&clients)
     c02:	b90d      	cbnz	r5, c08 <process_event+0x74>
		    || (transit != NULL)) {
     c04:	2e00      	cmp	r6, #0
     c06:	d074      	beq.n	cf2 <process_event+0x15e>
     c08:	2300      	movs	r3, #0
     c0a:	e058      	b.n	cbe <process_event+0x12a>
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
     c0c:	f001 0307 	and.w	r3, r1, #7
		   || (state == ONOFF_STATE_RESETTING)) {
     c10:	1f58      	subs	r0, r3, #5
	} else if ((state == ONOFF_STATE_TO_ON)
     c12:	2801      	cmp	r0, #1
     c14:	d820      	bhi.n	c58 <process_event+0xc4>
		*clients = mgr->clients;
     c16:	f021 0107 	bic.w	r1, r1, #7
		if (state == ONOFF_STATE_TO_ON) {
     c1a:	2b06      	cmp	r3, #6
		*clients = mgr->clients;
     c1c:	6825      	ldr	r5, [r4, #0]
	list->head = NULL;
     c1e:	b289      	uxth	r1, r1
	list->tail = NULL;
     c20:	e9c4 8800 	strd	r8, r8, [r4]
		if (state == ONOFF_STATE_TO_ON) {
     c24:	d10c      	bne.n	c40 <process_event+0xac>
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
     c26:	2d00      	cmp	r5, #0
     c28:	462b      	mov	r3, r5
     c2a:	bf38      	it	cc
     c2c:	2300      	movcc	r3, #0
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
     c2e:	b12b      	cbz	r3, c3c <process_event+0xa8>
				mgr->refs += 1U;
     c30:	8b60      	ldrh	r0, [r4, #26]
 *
 * @return a pointer on the next node (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_next_no_check(sys_snode_t *node);

Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
     c32:	681b      	ldr	r3, [r3, #0]
     c34:	3001      	adds	r0, #1
     c36:	8360      	strh	r0, [r4, #26]
			SYS_SLIST_FOR_EACH_CONTAINER(clients, cp, node) {
     c38:	2b00      	cmp	r3, #0
     c3a:	d1f8      	bne.n	c2e <process_event+0x9a>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c3c:	f041 0102 	orr.w	r1, r1, #2
	mgr->flags = (state & ONOFF_STATE_MASK)
     c40:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
     c42:	4620      	mov	r0, r4
     c44:	f004 fae2 	bl	520c <process_recheck>
     c48:	4606      	mov	r6, r0
     c4a:	2800      	cmp	r0, #0
     c4c:	d0d1      	beq.n	bf2 <process_event+0x5e>
			mgr->flags |= ONOFF_FLAG_RECHECK;
     c4e:	8b23      	ldrh	r3, [r4, #24]
     c50:	f043 0320 	orr.w	r3, r3, #32
     c54:	8323      	strh	r3, [r4, #24]
     c56:	e7cb      	b.n	bf0 <process_event+0x5c>
	} else if (state == ONOFF_STATE_TO_OFF) {
     c58:	2b04      	cmp	r3, #4
     c5a:	d10c      	bne.n	c76 <process_event+0xe2>
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c5c:	f021 0107 	bic.w	r1, r1, #7
     c60:	b289      	uxth	r1, r1
	mgr->flags = (state & ONOFF_STATE_MASK)
     c62:	8321      	strh	r1, [r4, #24]
		if (process_recheck(mgr) != EVT_NOP) {
     c64:	4620      	mov	r0, r4
     c66:	f004 fad1 	bl	520c <process_recheck>
     c6a:	4605      	mov	r5, r0
     c6c:	2800      	cmp	r0, #0
     c6e:	d0bf      	beq.n	bf0 <process_event+0x5c>
			mgr->flags |= ONOFF_FLAG_RECHECK;
     c70:	f041 0120 	orr.w	r1, r1, #32
     c74:	8321      	strh	r1, [r4, #24]
     c76:	2500      	movs	r5, #0
     c78:	e7ba      	b.n	bf0 <process_event+0x5c>
		} else if (evt == EVT_START) {
     c7a:	2803      	cmp	r0, #3
     c7c:	d109      	bne.n	c92 <process_event+0xfe>
			transit = mgr->transitions->start;
     c7e:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c80:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->start;
     c84:	680e      	ldr	r6, [r1, #0]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c86:	f043 0306 	orr.w	r3, r3, #6
	mgr->flags = (state & ONOFF_STATE_MASK)
     c8a:	8323      	strh	r3, [r4, #24]
}
     c8c:	2500      	movs	r5, #0
		res = 0;
     c8e:	462f      	mov	r7, r5
     c90:	e7af      	b.n	bf2 <process_event+0x5e>
		} else if (evt == EVT_STOP) {
     c92:	2804      	cmp	r0, #4
     c94:	d106      	bne.n	ca4 <process_event+0x110>
			transit = mgr->transitions->stop;
     c96:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c98:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->stop;
     c9c:	684e      	ldr	r6, [r1, #4]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     c9e:	f043 0304 	orr.w	r3, r3, #4
     ca2:	e7f2      	b.n	c8a <process_event+0xf6>
		} else if (evt == EVT_RESET) {
     ca4:	2805      	cmp	r0, #5
     ca6:	d106      	bne.n	cb6 <process_event+0x122>
			transit = mgr->transitions->reset;
     ca8:	6921      	ldr	r1, [r4, #16]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     caa:	f023 0307 	bic.w	r3, r3, #7
			transit = mgr->transitions->reset;
     cae:	688e      	ldr	r6, [r1, #8]
		     | (mgr->flags & ~ONOFF_STATE_MASK);
     cb0:	f043 0305 	orr.w	r3, r3, #5
     cb4:	e7e9      	b.n	c8a <process_event+0xf6>
     cb6:	2500      	movs	r5, #0
		onoff_transition_fn transit = NULL;
     cb8:	462e      	mov	r6, r5
     cba:	e7e8      	b.n	c8e <process_event+0xfa>
				   && !sys_slist_is_empty(&mgr->monitors);
     cbc:	2301      	movs	r3, #1
			uint32_t flags = mgr->flags | ONOFF_FLAG_PROCESSING;
     cbe:	f041 0108 	orr.w	r1, r1, #8
			mgr->flags = flags;
     cc2:	8321      	strh	r1, [r4, #24]
     cc4:	f382 8811 	msr	BASEPRI, r2
     cc8:	f3bf 8f6f 	isb	sy
			if (do_monitors) {
     ccc:	bb03      	cbnz	r3, d10 <process_event+0x17c>
			if (!sys_slist_is_empty(&clients)) {
     cce:	2d00      	cmp	r5, #0
     cd0:	d140      	bne.n	d54 <process_event+0x1c0>
			if (transit != NULL) {
     cd2:	b116      	cbz	r6, cda <process_event+0x146>
				transit(mgr, transition_complete);
     cd4:	4925      	ldr	r1, [pc, #148]	; (d6c <process_event+0x1d8>)
     cd6:	4620      	mov	r0, r4
     cd8:	47b0      	blx	r6
	__asm__ volatile(
     cda:	f04f 0320 	mov.w	r3, #32
     cde:	f3ef 8211 	mrs	r2, BASEPRI
     ce2:	f383 8811 	msr	BASEPRI, r3
     ce6:	f3bf 8f6f 	isb	sy
			mgr->flags &= ~ONOFF_FLAG_PROCESSING;
     cea:	8b23      	ldrh	r3, [r4, #24]
     cec:	f023 0308 	bic.w	r3, r3, #8
     cf0:	8323      	strh	r3, [r4, #24]
		if ((mgr->flags & ONOFF_FLAG_COMPLETE) != 0) {
     cf2:	8b23      	ldrh	r3, [r4, #24]
     cf4:	06d9      	lsls	r1, r3, #27
     cf6:	d531      	bpl.n	d5c <process_event+0x1c8>
			mgr->flags &= ~ONOFF_FLAG_COMPLETE;
     cf8:	f023 0310 	bic.w	r3, r3, #16
     cfc:	8323      	strh	r3, [r4, #24]
			evt = EVT_COMPLETE;
     cfe:	2101      	movs	r1, #1
		state = mgr->flags & ONOFF_STATE_MASK;
     d00:	f8b4 9018 	ldrh.w	r9, [r4, #24]
     d04:	f009 0907 	and.w	r9, r9, #7
	} while (evt != EVT_NOP);
     d08:	2900      	cmp	r1, #0
     d0a:	f47f af5b 	bne.w	bc4 <process_event+0x30>
out:
     d0e:	e751      	b.n	bb4 <process_event+0x20>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
     d10:	68a1      	ldr	r1, [r4, #8]
     d12:	2900      	cmp	r1, #0
     d14:	d0db      	beq.n	cce <process_event+0x13a>
	return node->next;
     d16:	680b      	ldr	r3, [r1, #0]
		mon->callback(mgr, mon, state, res);
     d18:	f8d1 b004 	ldr.w	fp, [r1, #4]
     d1c:	2b00      	cmp	r3, #0
     d1e:	bf38      	it	cc
     d20:	2300      	movcc	r3, #0
     d22:	4699      	mov	r9, r3
     d24:	4652      	mov	r2, sl
     d26:	463b      	mov	r3, r7
     d28:	4620      	mov	r0, r4
     d2a:	47d8      	blx	fp
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(mlist, mon, tmp, node) {
     d2c:	f1b9 0f00 	cmp.w	r9, #0
     d30:	d0cd      	beq.n	cce <process_event+0x13a>
     d32:	f8d9 3000 	ldr.w	r3, [r9]
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
     d36:	4649      	mov	r1, r9
     d38:	e7ee      	b.n	d18 <process_event+0x184>
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
     d3a:	4639      	mov	r1, r7
     d3c:	f10b 0004 	add.w	r0, fp, #4
 *
 * @return A pointer to the first node of the list
 */
static inline sys_snode_t *sys_slist_get_not_empty(sys_slist_t *list);

Z_GENLIST_GET_NOT_EMPTY(slist, snode)
     d40:	682d      	ldr	r5, [r5, #0]
     d42:	f004 fa00 	bl	5146 <sys_notify_finalize>
	if (cb) {
     d46:	4681      	mov	r9, r0
     d48:	b120      	cbz	r0, d54 <process_event+0x1c0>
		cb(mgr, cli, state, res);
     d4a:	463b      	mov	r3, r7
     d4c:	4652      	mov	r2, sl
     d4e:	4659      	mov	r1, fp
     d50:	4620      	mov	r0, r4
     d52:	47c8      	blx	r9
     d54:	46ab      	mov	fp, r5
	while (!sys_slist_is_empty(list)) {
     d56:	2d00      	cmp	r5, #0
     d58:	d1ef      	bne.n	d3a <process_event+0x1a6>
     d5a:	e7ba      	b.n	cd2 <process_event+0x13e>
		} else if ((mgr->flags & ONOFF_FLAG_RECHECK) != 0) {
     d5c:	f013 0120 	ands.w	r1, r3, #32
			mgr->flags &= ~ONOFF_FLAG_RECHECK;
     d60:	bf1e      	ittt	ne
     d62:	f023 0320 	bicne.w	r3, r3, #32
     d66:	8323      	strhne	r3, [r4, #24]
			evt = EVT_RECHECK;
     d68:	2102      	movne	r1, #2
     d6a:	e7c9      	b.n	d00 <process_event+0x16c>
     d6c:	00005263 	.word	0x00005263

00000d70 <z_mrsh_z_sys_mutex_kernel_lock>:
#include <syscalls/mutex.h>

extern int z_vrfy_z_sys_mutex_kernel_lock(struct sys_mutex * mutex, k_timeout_t timeout);
uintptr_t z_mrsh_z_sys_mutex_kernel_lock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     d70:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
     d72:	4c0e      	ldr	r4, [pc, #56]	; (dac <z_mrsh_z_sys_mutex_kernel_lock+0x3c>)
     d74:	68a3      	ldr	r3, [r4, #8]
{
     d76:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
     d78:	9a08      	ldr	r2, [sp, #32]
     d7a:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
     d7e:	460f      	mov	r7, r1
{
	/* sys_mutex memory is never touched, just used to lookup the
	 * underlying k_mutex, but we don't want threads using mutexes
	 * that are outside their memory domain
	 */
	return Z_SYSCALL_MEMORY_WRITE(addr, sizeof(struct sys_mutex));
     d80:	2201      	movs	r2, #1
     d82:	2104      	movs	r1, #4
     d84:	4605      	mov	r5, r0
     d86:	f004 fe86 	bl	5a96 <arch_buffer_validate>
     d8a:	b140      	cbz	r0, d9e <z_mrsh_z_sys_mutex_kernel_lock+0x2e>
     d8c:	f004 fd29 	bl	57e2 <arch_is_user_context>

static inline int z_vrfy_z_sys_mutex_kernel_lock(struct sys_mutex *mutex,
						 k_timeout_t timeout)
{
	if (check_sys_mutex_addr(mutex)) {
		return -EACCES;
     d90:	f06f 000c 	mvn.w	r0, #12
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_z_sys_mutex_kernel_lock(*(struct sys_mutex **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
     d94:	68a3      	ldr	r3, [r4, #8]
     d96:	2200      	movs	r2, #0
     d98:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
     d9c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	}

	return z_impl_z_sys_mutex_kernel_lock(mutex, timeout);
     d9e:	463a      	mov	r2, r7
     da0:	4633      	mov	r3, r6
     da2:	4628      	mov	r0, r5
     da4:	f004 fd27 	bl	57f6 <z_impl_z_sys_mutex_kernel_lock>
     da8:	e7f4      	b.n	d94 <z_mrsh_z_sys_mutex_kernel_lock+0x24>
     daa:	bf00      	nop
     dac:	20000524 	.word	0x20000524

00000db0 <z_impl_z_sys_mutex_kernel_unlock>:
}
#include <syscalls/z_sys_mutex_kernel_lock_mrsh.c>

int z_impl_z_sys_mutex_kernel_unlock(struct sys_mutex *mutex)
{
     db0:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	obj = z_object_find(mutex);
     db4:	f7ff f992 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_SYS_MUTEX) {
     db8:	b1c0      	cbz	r0, dec <z_impl_z_sys_mutex_kernel_unlock+0x3c>
     dba:	7983      	ldrb	r3, [r0, #6]
     dbc:	2b0e      	cmp	r3, #14
     dbe:	d115      	bne.n	dec <z_impl_z_sys_mutex_kernel_unlock+0x3c>
	return obj->data.mutex;
     dc0:	6882      	ldr	r2, [r0, #8]
	struct k_mutex *kernel_mutex = get_k_mutex(mutex);

	if (kernel_mutex == NULL || kernel_mutex->lock_count == 0) {
     dc2:	b19a      	cbz	r2, dec <z_impl_z_sys_mutex_kernel_unlock+0x3c>
     dc4:	68d3      	ldr	r3, [r2, #12]
     dc6:	b18b      	cbz	r3, dec <z_impl_z_sys_mutex_kernel_unlock+0x3c>
		return -EINVAL;
	}

	if (kernel_mutex->owner != _current) {
     dc8:	4b0b      	ldr	r3, [pc, #44]	; (df8 <z_impl_z_sys_mutex_kernel_unlock+0x48>)
     dca:	6891      	ldr	r1, [r2, #8]
     dcc:	689b      	ldr	r3, [r3, #8]
     dce:	4299      	cmp	r1, r3
     dd0:	d10f      	bne.n	df2 <z_impl_z_sys_mutex_kernel_unlock+0x42>
	ret = arch_is_user_context();
     dd2:	f004 fd06 	bl	57e2 <arch_is_user_context>
	if (z_syscall_trap()) {
     dd6:	b128      	cbz	r0, de4 <z_impl_z_sys_mutex_kernel_unlock+0x34>
	register uint32_t ret __asm__("r0") = arg1;
     dd8:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
     dda:	266d      	movs	r6, #109	; 0x6d
	__asm__ volatile("svc %[svid]\n"
     ddc:	df03      	svc	3
		return -EPERM;
	}

	k_mutex_unlock(kernel_mutex);
	return 0;
     dde:	2000      	movs	r0, #0
}
     de0:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return z_impl_k_mutex_unlock(mutex);
     de4:	4610      	mov	r0, r2
     de6:	f002 fa4f 	bl	3288 <z_impl_k_mutex_unlock>
     dea:	e7f8      	b.n	dde <z_impl_z_sys_mutex_kernel_unlock+0x2e>
		return -EINVAL;
     dec:	f06f 0015 	mvn.w	r0, #21
     df0:	e7f6      	b.n	de0 <z_impl_z_sys_mutex_kernel_unlock+0x30>
		return -EPERM;
     df2:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
     df6:	e7f3      	b.n	de0 <z_impl_z_sys_mutex_kernel_unlock+0x30>
     df8:	20000524 	.word	0x20000524

00000dfc <z_mrsh_z_sys_mutex_kernel_unlock>:
#include <syscalls/mutex.h>

extern int z_vrfy_z_sys_mutex_kernel_unlock(struct sys_mutex * mutex);
uintptr_t z_mrsh_z_sys_mutex_kernel_unlock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
     dfc:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
     dfe:	4c0c      	ldr	r4, [pc, #48]	; (e30 <z_mrsh_z_sys_mutex_kernel_unlock+0x34>)
     e00:	9a06      	ldr	r2, [sp, #24]
     e02:	68a3      	ldr	r3, [r4, #8]
	return Z_SYSCALL_MEMORY_WRITE(addr, sizeof(struct sys_mutex));
     e04:	2104      	movs	r1, #4
     e06:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
     e0a:	2201      	movs	r2, #1
{
     e0c:	4605      	mov	r5, r0
     e0e:	f004 fe42 	bl	5a96 <arch_buffer_validate>
     e12:	b140      	cbz	r0, e26 <z_mrsh_z_sys_mutex_kernel_unlock+0x2a>
	return arch_is_user_context();
     e14:	f004 fce5 	bl	57e2 <arch_is_user_context>

static inline int z_vrfy_z_sys_mutex_kernel_unlock(struct sys_mutex *mutex)
{
	if (check_sys_mutex_addr(mutex)) {
		return -EACCES;
     e18:	f06f 000c 	mvn.w	r0, #12
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_z_sys_mutex_kernel_unlock(*(struct sys_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
     e1c:	68a3      	ldr	r3, [r4, #8]
     e1e:	2200      	movs	r2, #0
     e20:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
     e24:	bd38      	pop	{r3, r4, r5, pc}
	}

	return z_impl_z_sys_mutex_kernel_unlock(mutex);
     e26:	4628      	mov	r0, r5
     e28:	f7ff ffc2 	bl	db0 <z_impl_z_sys_mutex_kernel_unlock>
     e2c:	e7f6      	b.n	e1c <z_mrsh_z_sys_mutex_kernel_unlock+0x20>
     e2e:	bf00      	nop
     e30:	20000524 	.word	0x20000524

00000e34 <console_out>:
		return c;
	}

#endif  /* CONFIG_UART_CONSOLE_DEBUG_SERVER_HOOKS */

	if ('\n' == c) {
     e34:	280a      	cmp	r0, #10
{
     e36:	b538      	push	{r3, r4, r5, lr}
     e38:	4d06      	ldr	r5, [pc, #24]	; (e54 <console_out+0x20>)
     e3a:	4604      	mov	r4, r0
	if ('\n' == c) {
     e3c:	d103      	bne.n	e46 <console_out+0x12>
		uart_poll_out(uart_console_dev, '\r');
     e3e:	6828      	ldr	r0, [r5, #0]
     e40:	210d      	movs	r1, #13
     e42:	f004 fcf9 	bl	5838 <uart_poll_out>
	}
	uart_poll_out(uart_console_dev, c);
     e46:	6828      	ldr	r0, [r5, #0]
     e48:	b2e1      	uxtb	r1, r4
     e4a:	f004 fcf5 	bl	5838 <uart_poll_out>

	return c;
}
     e4e:	4620      	mov	r0, r4
     e50:	bd38      	pop	{r3, r4, r5, pc}
     e52:	bf00      	nop
     e54:	200003e8 	.word	0x200003e8

00000e58 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(struct device *arg)
{
     e58:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
static inline bool arch_is_user_context(void)
{
	uint32_t value;

	/* check for handler mode */
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
     e5c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
     e60:	b98b      	cbnz	r3, e86 <uart_console_init+0x2e>
		return false;
	}

	/* if not handler mode, return mode information */
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
     e62:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
     e66:	07db      	lsls	r3, r3, #31
     e68:	d50d      	bpl.n	e86 <uart_console_init+0x2e>
	register uint32_t ret __asm__("r0") = arg1;
     e6a:	4809      	ldr	r0, [pc, #36]	; (e90 <uart_console_init+0x38>)
	register uint32_t r6 __asm__("r6") = call_id;
     e6c:	2627      	movs	r6, #39	; 0x27
	__asm__ volatile("svc %[svid]\n"
     e6e:	df03      	svc	3

	ARG_UNUSED(arg);

	uart_console_dev = device_get_binding(CONFIG_UART_CONSOLE_ON_DEV_NAME);
     e70:	4b08      	ldr	r3, [pc, #32]	; (e94 <uart_console_init+0x3c>)
     e72:	6018      	str	r0, [r3, #0]
	__stdout_hook_install(console_out);
     e74:	4808      	ldr	r0, [pc, #32]	; (e98 <uart_console_init+0x40>)
     e76:	f001 f859 	bl	1f2c <__stdout_hook_install>
	__printk_hook_install(console_out);
     e7a:	4807      	ldr	r0, [pc, #28]	; (e98 <uart_console_init+0x40>)
     e7c:	f7ff fd12 	bl	8a4 <__printk_hook_install>
#endif

	uart_console_hook_install();

	return 0;
}
     e80:	2000      	movs	r0, #0
     e82:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
	return z_impl_device_get_binding(name);
     e86:	4802      	ldr	r0, [pc, #8]	; (e90 <uart_console_init+0x38>)
     e88:	f001 fffa 	bl	2e80 <z_impl_device_get_binding>
     e8c:	e7f0      	b.n	e70 <uart_console_init+0x18>
     e8e:	bf00      	nop
     e90:	000070d4 	.word	0x000070d4
     e94:	200003e8 	.word	0x200003e8
     e98:	00000e35 	.word	0x00000e35

00000e9c <onoff_stop>:
	return (clock_control_subsys_t)offset;
}

static void onoff_stop(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
     e9c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	struct nrf_clock_control_data *data =
     ea0:	4f0e      	ldr	r7, [pc, #56]	; (edc <onoff_stop+0x40>)
     ea2:	68fa      	ldr	r2, [r7, #12]
	size_t offset = (size_t)(mgr - data->mgr);
     ea4:	1a84      	subs	r4, r0, r2
     ea6:	10a3      	asrs	r3, r4, #2
     ea8:	4c0d      	ldr	r4, [pc, #52]	; (ee0 <onoff_stop+0x44>)
     eaa:	435c      	muls	r4, r3
{
     eac:	4605      	mov	r5, r0
     eae:	b2e4      	uxtb	r4, r4
	err = set_off_state(&subdata->flags, ctx);
     eb0:	200c      	movs	r0, #12
     eb2:	fb00 2004 	mla	r0, r0, r4, r2
{
     eb6:	460e      	mov	r6, r1
	err = set_off_state(&subdata->flags, ctx);
     eb8:	2140      	movs	r1, #64	; 0x40
     eba:	4408      	add	r0, r1
     ebc:	f004 fce9 	bl	5892 <set_off_state>
	if (err < 0) {
     ec0:	1e01      	subs	r1, r0, #0
     ec2:	db05      	blt.n	ed0 <onoff_stop+0x34>
	get_sub_config(dev, type)->stop();
     ec4:	687b      	ldr	r3, [r7, #4]
     ec6:	eb03 04c4 	add.w	r4, r3, r4, lsl #3
     eca:	6863      	ldr	r3, [r4, #4]
     ecc:	4798      	blx	r3
	return 0;
     ece:	2100      	movs	r1, #0
	int res;

	res = stop(DEVICE_GET(clock_nrf), get_subsys(mgr), CTX_ONOFF);
	notify(mgr, res);
     ed0:	4628      	mov	r0, r5
     ed2:	4633      	mov	r3, r6
}
     ed4:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	notify(mgr, res);
     ed8:	4718      	bx	r3
     eda:	bf00      	nop
     edc:	20002c48 	.word	0x20002c48
     ee0:	b6db6db7 	.word	0xb6db6db7

00000ee4 <onoff_start>:
	notify(mgr, 0);
}

static void onoff_start(struct onoff_manager *mgr,
			onoff_notify_fn notify)
{
     ee4:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	struct nrf_clock_control_data *data =
     ee8:	f8df 8050 	ldr.w	r8, [pc, #80]	; f3c <onoff_start+0x58>
     eec:	f8d8 600c 	ldr.w	r6, [r8, #12]
	size_t offset = (size_t)(mgr - data->mgr);
     ef0:	1b84      	subs	r4, r0, r6
     ef2:	10a3      	asrs	r3, r4, #2
     ef4:	4c0f      	ldr	r4, [pc, #60]	; (f34 <onoff_start+0x50>)
     ef6:	435c      	muls	r4, r3
     ef8:	b2e4      	uxtb	r4, r4
	err = set_starting_state(&subdata->flags, ctx);
     efa:	250c      	movs	r5, #12
     efc:	4365      	muls	r5, r4
{
     efe:	4681      	mov	r9, r0
	err = set_starting_state(&subdata->flags, ctx);
     f00:	f105 0040 	add.w	r0, r5, #64	; 0x40
{
     f04:	460f      	mov	r7, r1
	err = set_starting_state(&subdata->flags, ctx);
     f06:	4430      	add	r0, r6
     f08:	2140      	movs	r1, #64	; 0x40
     f0a:	f004 fcdb 	bl	58c4 <set_starting_state>
	if (err < 0) {
     f0e:	1e01      	subs	r1, r0, #0
     f10:	db0a      	blt.n	f28 <onoff_start+0x44>
	subdata->cb = data->cb;
     f12:	4a09      	ldr	r2, [pc, #36]	; (f38 <onoff_start+0x54>)
     f14:	1973      	adds	r3, r6, r5
	subdata->user_data = data->user_data;
     f16:	e9c3 270e 	strd	r2, r7, [r3, #56]	; 0x38
	 get_sub_config(dev, type)->start();
     f1a:	f8d8 3004 	ldr.w	r3, [r8, #4]
     f1e:	f853 3034 	ldr.w	r3, [r3, r4, lsl #3]
	err = async_start(DEVICE_GET(clock_nrf), get_subsys(mgr),
			  &data, CTX_ONOFF);
	if (err < 0) {
		notify(mgr, err);
	}
}
     f22:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	 get_sub_config(dev, type)->start();
     f26:	4718      	bx	r3
		notify(mgr, err);
     f28:	4648      	mov	r0, r9
     f2a:	463b      	mov	r3, r7
}
     f2c:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
		notify(mgr, err);
     f30:	4718      	bx	r3
     f32:	bf00      	nop
     f34:	b6db6db7 	.word	0xb6db6db7
     f38:	00005927 	.word	0x00005927
     f3c:	20002c48 	.word	0x20002c48

00000f40 <clk_init>:
	static const struct onoff_transitions transitions = {
		.start = onoff_start,
		.stop = onoff_stop
	};

	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
     f40:	2200      	movs	r2, #0
{
     f42:	b570      	push	{r4, r5, r6, lr}
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
     f44:	2101      	movs	r1, #1
{
     f46:	4604      	mov	r4, r0
	IRQ_CONNECT(DT_INST_IRQN(0), DT_INST_IRQ(0, priority),
     f48:	4610      	mov	r0, r2
     f4a:	f000 faff 	bl	154c <z_arm_irq_priority_set>
		    nrf_power_clock_isr, 0, 0);

	irq_enable(DT_INST_IRQN(0));
     f4e:	2000      	movs	r0, #0
     f50:	f000 faec 	bl	152c <arch_irq_enable>
    return false;
}

NRF_STATIC_INLINE void nrf_clock_lf_src_set(NRF_CLOCK_Type * p_reg, nrf_clock_lfclk_t source)
{
    p_reg->LFCLKSRC = (uint32_t)(source);
     f54:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
	clock_irqs_enable();

	for (enum clock_control_nrf_type i = 0;
		i < CLOCK_CONTROL_NRF_TYPE_COUNT; i++) {
		struct nrf_clock_control_sub_data *subdata =
						get_sub_data(dev, i);
     f58:	68e6      	ldr	r6, [r4, #12]

		err = onoff_manager_init(get_onoff_manager(dev, i),
     f5a:	490c      	ldr	r1, [pc, #48]	; (f8c <clk_init+0x4c>)
    p_reg->INTENSET = mask;
     f5c:	2203      	movs	r2, #3
    p_reg->LFCLKSRC = (uint32_t)(source);
     f5e:	2501      	movs	r5, #1
     f60:	f8c3 5518 	str.w	r5, [r3, #1304]	; 0x518
     f64:	4630      	mov	r0, r6
    p_reg->INTENSET = mask;
     f66:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
     f6a:	f004 f988 	bl	527e <onoff_manager_init>
					 &transitions);
		if (err < 0) {
     f6e:	2800      	cmp	r0, #0
     f70:	db0a      	blt.n	f88 <clk_init+0x48>
			return err;
		}

		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
     f72:	6435      	str	r5, [r6, #64]	; 0x40
						get_sub_data(dev, i);
     f74:	68e4      	ldr	r4, [r4, #12]
		err = onoff_manager_init(get_onoff_manager(dev, i),
     f76:	4905      	ldr	r1, [pc, #20]	; (f8c <clk_init+0x4c>)
     f78:	f104 001c 	add.w	r0, r4, #28
     f7c:	f004 f97f 	bl	527e <onoff_manager_init>
		if (err < 0) {
     f80:	2800      	cmp	r0, #0
		subdata->flags = CLOCK_CONTROL_STATUS_OFF;
     f82:	bfa4      	itt	ge
     f84:	64e5      	strge	r5, [r4, #76]	; 0x4c
	}

	return 0;
     f86:	2000      	movge	r0, #0
}
     f88:	bd70      	pop	{r4, r5, r6, pc}
     f8a:	bf00      	nop
     f8c:	00006b4c 	.word	0x00006b4c

00000f90 <clkstarted_handle.constprop.0>:
static void clkstarted_handle(struct device *dev,
     f90:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	struct nrf_clock_control_sub_data *sub_data = get_sub_data(dev, type);
     f94:	4e0b      	ldr	r6, [pc, #44]	; (fc4 <clkstarted_handle.constprop.0+0x34>)
static void clkstarted_handle(struct device *dev,
     f96:	4601      	mov	r1, r0
	clock_control_cb_t callback = sub_data->cb;
     f98:	230c      	movs	r3, #12
	struct nrf_clock_control_sub_data *sub_data = get_sub_data(dev, type);
     f9a:	68f0      	ldr	r0, [r6, #12]
	clock_control_cb_t callback = sub_data->cb;
     f9c:	434b      	muls	r3, r1
     f9e:	18c4      	adds	r4, r0, r3
	void *user_data = sub_data->user_data;
     fa0:	e9d4 570e 	ldrd	r5, r7, [r4, #56]	; 0x38
	sub_data->cb = NULL;
     fa4:	2200      	movs	r2, #0
	set_on_state(&sub_data->flags);
     fa6:	3340      	adds	r3, #64	; 0x40
	sub_data->cb = NULL;
     fa8:	63a2      	str	r2, [r4, #56]	; 0x38
	set_on_state(&sub_data->flags);
     faa:	4418      	add	r0, r3
     fac:	f004 fca8 	bl	5900 <set_on_state>
	if (callback) {
     fb0:	b12d      	cbz	r5, fbe <clkstarted_handle.constprop.0+0x2e>
		callback(dev, (clock_control_subsys_t)type, user_data);
     fb2:	463a      	mov	r2, r7
     fb4:	4630      	mov	r0, r6
     fb6:	462b      	mov	r3, r5
}
     fb8:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		callback(dev, (clock_control_subsys_t)type, user_data);
     fbc:	4718      	bx	r3
}
     fbe:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
     fc2:	bf00      	nop
     fc4:	20002c48 	.word	0x20002c48

00000fc8 <generic_hfclk_start>:
{
     fc8:	b508      	push	{r3, lr}
     fca:	f04f 0320 	mov.w	r3, #32
     fce:	f3ef 8111 	mrs	r1, BASEPRI
     fd2:	f383 8811 	msr	BASEPRI, r3
     fd6:	f3bf 8f6f 	isb	sy
	hfclk_users |= HF_USER_GENERIC;
     fda:	4a13      	ldr	r2, [pc, #76]	; (1028 <generic_hfclk_start+0x60>)
     fdc:	6813      	ldr	r3, [r2, #0]
     fde:	f043 0002 	orr.w	r0, r3, #2
	if (hfclk_users & HF_USER_BT) {
     fe2:	f013 0301 	ands.w	r3, r3, #1
	hfclk_users |= HF_USER_GENERIC;
     fe6:	6010      	str	r0, [r2, #0]
	if (hfclk_users & HF_USER_BT) {
     fe8:	d00e      	beq.n	1008 <generic_hfclk_start+0x40>
                    (nrf_clock_hfclk_t)((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_SRC_Msk)
     fea:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
     fee:	f8d2 340c 	ldr.w	r3, [r2, #1036]	; 0x40c
            if ((p_reg->HFCLKSTAT & CLOCK_HFCLKSTAT_STATE_Msk)
     ff2:	f8d2 240c 	ldr.w	r2, [r2, #1036]	; 0x40c
		if (type == NRF_CLOCK_HFCLK_HIGH_ACCURACY) {
     ff6:	f013 0301 	ands.w	r3, r3, #1
     ffa:	d005      	beq.n	1008 <generic_hfclk_start+0x40>
	struct nrf_clock_control_data *data =
     ffc:	4b0b      	ldr	r3, [pc, #44]	; (102c <generic_hfclk_start+0x64>)
	return &data->subsys[CLOCK_CONTROL_NRF_TYPE_HFCLK].flags;
     ffe:	68d8      	ldr	r0, [r3, #12]
			set_on_state(get_hf_flags());
    1000:	3040      	adds	r0, #64	; 0x40
    1002:	f004 fc7d 	bl	5900 <set_on_state>
			already_started = true;
    1006:	2301      	movs	r3, #1
	__asm__ volatile(
    1008:	f381 8811 	msr	BASEPRI, r1
    100c:	f3bf 8f6f 	isb	sy
	if (already_started) {
    1010:	b123      	cbz	r3, 101c <generic_hfclk_start+0x54>
}
    1012:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		clkstarted_handle(DEVICE_GET(clock_nrf),
    1016:	2000      	movs	r0, #0
    1018:	f7ff bfba 	b.w	f90 <clkstarted_handle.constprop.0>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    101c:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    1020:	2201      	movs	r2, #1
    1022:	601a      	str	r2, [r3, #0]
}
    1024:	bd08      	pop	{r3, pc}
    1026:	bf00      	nop
    1028:	2000044c 	.word	0x2000044c
    102c:	20002c48 	.word	0x20002c48

00001030 <lfclk_stop>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    1030:	4b05      	ldr	r3, [pc, #20]	; (1048 <lfclk_stop+0x18>)
    1032:	2200      	movs	r2, #0
    1034:	601a      	str	r2, [r3, #0]
{
    1036:	b082      	sub	sp, #8
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    1038:	681b      	ldr	r3, [r3, #0]
    103a:	9301      	str	r3, [sp, #4]
    (void)dummy;
    103c:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    103e:	4b03      	ldr	r3, [pc, #12]	; (104c <lfclk_stop+0x1c>)
    1040:	2201      	movs	r2, #1
    1042:	601a      	str	r2, [r3, #0]
}
    1044:	b002      	add	sp, #8
    1046:	4770      	bx	lr
    1048:	40000104 	.word	0x40000104
    104c:	4000000c 	.word	0x4000000c

00001050 <generic_hfclk_stop>:
 * @return Previous value of @a target.
 */
#ifdef CONFIG_ATOMIC_OPERATIONS_BUILTIN
static inline atomic_val_t atomic_and(atomic_t *target, atomic_val_t value)
{
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    1050:	4a0d      	ldr	r2, [pc, #52]	; (1088 <generic_hfclk_stop+0x38>)
    1052:	f3bf 8f5b 	dmb	ish
{
    1056:	b082      	sub	sp, #8
    1058:	e852 3f00 	ldrex	r3, [r2]
    105c:	f023 0102 	bic.w	r1, r3, #2
    1060:	e842 1000 	strex	r0, r1, [r2]
    1064:	2800      	cmp	r0, #0
    1066:	d1f7      	bne.n	1058 <generic_hfclk_stop+0x8>
    1068:	f3bf 8f5b 	dmb	ish
	if (atomic_and(&hfclk_users, ~HF_USER_GENERIC) & HF_USER_BT) {
    106c:	f013 0301 	ands.w	r3, r3, #1
    1070:	d107      	bne.n	1082 <generic_hfclk_stop+0x32>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    1072:	4a06      	ldr	r2, [pc, #24]	; (108c <generic_hfclk_stop+0x3c>)
    1074:	6013      	str	r3, [r2, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    1076:	6813      	ldr	r3, [r2, #0]
    1078:	9301      	str	r3, [sp, #4]
    (void)dummy;
    107a:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    107c:	4b04      	ldr	r3, [pc, #16]	; (1090 <generic_hfclk_stop+0x40>)
    107e:	2201      	movs	r2, #1
    1080:	601a      	str	r2, [r3, #0]
}
    1082:	b002      	add	sp, #8
    1084:	4770      	bx	lr
    1086:	bf00      	nop
    1088:	2000044c 	.word	0x2000044c
    108c:	40000100 	.word	0x40000100
    1090:	40000004 	.word	0x40000004

00001094 <lfclk_start>:
{
    1094:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	if (!once) {
    1098:	4c0a      	ldr	r4, [pc, #40]	; (10c4 <lfclk_start+0x30>)
    109a:	7822      	ldrb	r2, [r4, #0]
    109c:	b942      	cbnz	r2, 10b0 <lfclk_start+0x1c>
	ret = arch_is_user_context();
    109e:	f004 fbe5 	bl	586c <arch_is_user_context>
	if (z_syscall_trap()) {
    10a2:	b150      	cbz	r0, 10ba <lfclk_start+0x26>
	register uint32_t ret __asm__("r0") = arg1;
    10a4:	f44f 70a5 	mov.w	r0, #330	; 0x14a
	register uint32_t r6 __asm__("r6") = call_id;
    10a8:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    10aa:	df03      	svc	3
		once = true;
    10ac:	2301      	movs	r3, #1
    10ae:	7023      	strb	r3, [r4, #0]
    10b0:	4b05      	ldr	r3, [pc, #20]	; (10c8 <lfclk_start+0x34>)
    10b2:	2201      	movs	r2, #1
    10b4:	601a      	str	r2, [r3, #0]
}
    10b6:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	z_impl_k_busy_wait(usec_to_wait);
    10ba:	f44f 70a5 	mov.w	r0, #330	; 0x14a
    10be:	f005 f864 	bl	618a <z_impl_k_busy_wait>
    10c2:	e7f3      	b.n	10ac <lfclk_start+0x18>
    10c4:	20000ea0 	.word	0x20000ea0
    10c8:	40000008 	.word	0x40000008

000010cc <api_blocking_start>:
{
    10cc:	e92d 4170 	stmdb	sp!, {r4, r5, r6, r8, lr}
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10d0:	2301      	movs	r3, #1
{
    10d2:	b08b      	sub	sp, #44	; 0x2c
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10d4:	2500      	movs	r5, #0
    10d6:	e9cd 5306 	strd	r5, r3, [sp, #24]
    10da:	ab08      	add	r3, sp, #32
    10dc:	e9cd 3308 	strd	r3, r3, [sp, #32]
	struct clock_control_async_data data = {
    10e0:	4b0f      	ldr	r3, [pc, #60]	; (1120 <api_blocking_start+0x54>)
    10e2:	9501      	str	r5, [sp, #4]
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10e4:	ac04      	add	r4, sp, #16
	err = api_start(dev, subsys, &data);
    10e6:	aa01      	add	r2, sp, #4
	struct k_sem sem = Z_SEM_INITIALIZER(sem, 0, 1);
    10e8:	e9cd 4404 	strd	r4, r4, [sp, #16]
	struct clock_control_async_data data = {
    10ec:	e9cd 3402 	strd	r3, r4, [sp, #8]
	err = api_start(dev, subsys, &data);
    10f0:	f004 fc52 	bl	5998 <api_start>
	if (err < 0) {
    10f4:	2800      	cmp	r0, #0
    10f6:	db08      	blt.n	110a <api_blocking_start+0x3e>
    10f8:	f004 fbb8 	bl	586c <arch_is_user_context>
	if (z_syscall_trap()) {
    10fc:	b140      	cbz	r0, 1110 <api_blocking_start+0x44>
		return (int) arch_syscall_invoke3(*(uintptr_t *)&sem, parm0.split.lo, parm0.split.hi, K_SYSCALL_K_SEM_TAKE);
    10fe:	4620      	mov	r0, r4
	register uint32_t r1 __asm__("r1") = arg2;
    1100:	f44f 4180 	mov.w	r1, #16384	; 0x4000
	register uint32_t r2 __asm__("r2") = arg3;
    1104:	462a      	mov	r2, r5
	register uint32_t r6 __asm__("r6") = call_id;
    1106:	2687      	movs	r6, #135	; 0x87
	__asm__ volatile("svc %[svid]\n"
    1108:	df03      	svc	3
}
    110a:	b00b      	add	sp, #44	; 0x2c
    110c:	e8bd 8170 	ldmia.w	sp!, {r4, r5, r6, r8, pc}
	return z_impl_k_sem_take(sem, timeout);
    1110:	f44f 4280 	mov.w	r2, #16384	; 0x4000
    1114:	2300      	movs	r3, #0
    1116:	4620      	mov	r0, r4
    1118:	f003 f806 	bl	4128 <z_impl_k_sem_take>
	return k_sem_take(&sem, K_MSEC(500));
    111c:	e7f5      	b.n	110a <api_blocking_start+0x3e>
    111e:	bf00      	nop
    1120:	00005939 	.word	0x00005939

00001124 <nrf_power_clock_isr>:
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    1124:	4b18      	ldr	r3, [pc, #96]	; (1188 <nrf_power_clock_isr+0x64>)
	}
#endif
}

void nrf_power_clock_isr(void *arg)
{
    1126:	b507      	push	{r0, r1, r2, lr}
    1128:	681a      	ldr	r2, [r3, #0]
	bool ret = nrf_clock_event_check(NRF_CLOCK, evt) &&
    112a:	b1b2      	cbz	r2, 115a <nrf_power_clock_isr+0x36>
    return p_reg->INTENSET & mask;
    112c:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    1130:	f8d2 2304 	ldr.w	r2, [r2, #772]	; 0x304
	if (ret) {
    1134:	07d0      	lsls	r0, r2, #31
    1136:	d510      	bpl.n	115a <nrf_power_clock_isr+0x36>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    1138:	2200      	movs	r2, #0
    113a:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    113c:	681b      	ldr	r3, [r3, #0]
    113e:	9300      	str	r3, [sp, #0]
    (void)dummy;
    1140:	9b00      	ldr	r3, [sp, #0]
	struct device *dev = DEVICE_GET(clock_nrf);

	if (clock_event_check_and_clean(NRF_CLOCK_EVENT_HFCLKSTARTED,
					NRF_CLOCK_INT_HF_STARTED_MASK)) {
		struct nrf_clock_control_sub_data *data =
				get_sub_data(dev, CLOCK_CONTROL_NRF_TYPE_HFCLK);
    1142:	4b12      	ldr	r3, [pc, #72]	; (118c <nrf_power_clock_isr+0x68>)
		 * HFCLKSTARTED may be generated twice.
		 *
		 * Also software should be notified about clock being on only
		 * if generic request occured.
		 */
		if ((GET_STATUS(data->flags) == CLOCK_CONTROL_STATUS_STARTING)
    1144:	68db      	ldr	r3, [r3, #12]
    1146:	6c18      	ldr	r0, [r3, #64]	; 0x40
    1148:	f010 0007 	ands.w	r0, r0, #7
    114c:	d105      	bne.n	115a <nrf_power_clock_isr+0x36>
			&& (hfclk_users & HF_USER_GENERIC)) {
    114e:	4b10      	ldr	r3, [pc, #64]	; (1190 <nrf_power_clock_isr+0x6c>)
    1150:	681b      	ldr	r3, [r3, #0]
    1152:	0799      	lsls	r1, r3, #30
    1154:	d501      	bpl.n	115a <nrf_power_clock_isr+0x36>
			clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_HFCLK);
    1156:	f7ff ff1b 	bl	f90 <clkstarted_handle.constprop.0>
    return (bool)*((volatile uint32_t *)((uint8_t *)p_reg + event));
    115a:	4b0e      	ldr	r3, [pc, #56]	; (1194 <nrf_power_clock_isr+0x70>)
    115c:	681a      	ldr	r2, [r3, #0]
	bool ret = nrf_clock_event_check(NRF_CLOCK, evt) &&
    115e:	b182      	cbz	r2, 1182 <nrf_power_clock_isr+0x5e>
    return p_reg->INTENSET & mask;
    1160:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    1164:	f8d2 2304 	ldr.w	r2, [r2, #772]	; 0x304
	if (ret) {
    1168:	0792      	lsls	r2, r2, #30
    116a:	d50a      	bpl.n	1182 <nrf_power_clock_isr+0x5e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    116c:	2200      	movs	r2, #0
    116e:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    1170:	681b      	ldr	r3, [r3, #0]
    1172:	9301      	str	r3, [sp, #4]
    (void)dummy;
    1174:	9b01      	ldr	r3, [sp, #4]
					NRF_CLOCK_INT_LF_STARTED_MASK)) {
		if (IS_ENABLED(
			CONFIG_CLOCK_CONTROL_NRF_K32SRC_RC_CALIBRATION)) {
			z_nrf_clock_calibration_lfclk_started();
		}
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    1176:	2001      	movs	r0, #1
	usb_power_isr();

	if (IS_ENABLED(CONFIG_CLOCK_CONTROL_NRF_K32SRC_RC_CALIBRATION)) {
		z_nrf_clock_calibration_isr();
	}
}
    1178:	b003      	add	sp, #12
    117a:	f85d eb04 	ldr.w	lr, [sp], #4
		clkstarted_handle(dev, CLOCK_CONTROL_NRF_TYPE_LFCLK);
    117e:	f7ff bf07 	b.w	f90 <clkstarted_handle.constprop.0>
}
    1182:	b003      	add	sp, #12
    1184:	f85d fb04 	ldr.w	pc, [sp], #4
    1188:	40000100 	.word	0x40000100
    118c:	20002c48 	.word	0x20002c48
    1190:	2000044c 	.word	0x2000044c
    1194:	40000104 	.word	0x40000104

00001198 <z_nrf_clock_control_lf_on>:
{
    1198:	b510      	push	{r4, lr}
	return __atomic_exchange_n(target, value, __ATOMIC_SEQ_CST);
    119a:	4911      	ldr	r1, [pc, #68]	; (11e0 <z_nrf_clock_control_lf_on+0x48>)
    119c:	f3bf 8f5b 	dmb	ish
    11a0:	4604      	mov	r4, r0
    11a2:	2201      	movs	r2, #1
    11a4:	e851 3f00 	ldrex	r3, [r1]
    11a8:	e841 2000 	strex	r0, r2, [r1]
    11ac:	2800      	cmp	r0, #0
    11ae:	d1f9      	bne.n	11a4 <z_nrf_clock_control_lf_on+0xc>
    11b0:	f3bf 8f5b 	dmb	ish
	if (atomic_set(&on, 1) == 0) {
    11b4:	b943      	cbnz	r3, 11c8 <z_nrf_clock_control_lf_on+0x30>
				get_onoff_manager(DEVICE_GET(clock_nrf),
    11b6:	490b      	ldr	r1, [pc, #44]	; (11e4 <z_nrf_clock_control_lf_on+0x4c>)
	return &data->mgr[type];
    11b8:	68c8      	ldr	r0, [r1, #12]
 */
static inline void sys_notify_init_spinwait(struct sys_notify *notify)
{
	__ASSERT_NO_MSG(notify != NULL);

	*notify = (struct sys_notify){
    11ba:	490b      	ldr	r1, [pc, #44]	; (11e8 <z_nrf_clock_control_lf_on+0x50>)
		err = onoff_request(mgr, &cli);
    11bc:	301c      	adds	r0, #28
    11be:	604b      	str	r3, [r1, #4]
    11c0:	60cb      	str	r3, [r1, #12]
    11c2:	608a      	str	r2, [r1, #8]
    11c4:	f004 f86e 	bl	52a4 <onoff_request>
	switch (start_mode) {
    11c8:	2c01      	cmp	r4, #1
    11ca:	d006      	beq.n	11da <z_nrf_clock_control_lf_on+0x42>
    11cc:	2c02      	cmp	r4, #2
    11ce:	d106      	bne.n	11de <z_nrf_clock_control_lf_on+0x46>
		lfclk_spinwait(CLOCK_CONTROL_NRF_K32SRC);
    11d0:	2001      	movs	r0, #1
}
    11d2:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		lfclk_spinwait(NRF_CLOCK_LFCLK_RC);
    11d6:	f004 bbbe 	b.w	5956 <lfclk_spinwait>
    11da:	2000      	movs	r0, #0
    11dc:	e7f9      	b.n	11d2 <z_nrf_clock_control_lf_on+0x3a>
}
    11de:	bd10      	pop	{r4, pc}
    11e0:	20000450 	.word	0x20000450
    11e4:	20002c48 	.word	0x20002c48
    11e8:	200003ec 	.word	0x200003ec

000011ec <handle_next_cycle_case>:
 * counter progresses during that time it means that 1 cycle elapsed and
 * interrupt is set pending.
 */
static void handle_next_cycle_case(uint32_t t)
{
	set_comparator(t + 2);
    11ec:	1c82      	adds	r2, r0, #2

#ifndef NRF_DECLARE_ONLY

NRF_STATIC_INLINE  void nrf_rtc_cc_set(NRF_RTC_Type * p_reg, uint32_t ch, uint32_t cc_val)
{
    p_reg->CC[ch] = cc_val;
    11ee:	4b08      	ldr	r3, [pc, #32]	; (1210 <handle_next_cycle_case+0x24>)
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    11f0:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    11f4:	f8c3 2540 	str.w	r2, [r3, #1344]	; 0x540
#endif
}

NRF_STATIC_INLINE uint32_t nrf_rtc_counter_get(NRF_RTC_Type const * p_reg)
{
     return p_reg->COUNTER;
    11f8:	f8d3 2504 	ldr.w	r2, [r3, #1284]	; 0x504
	while (t != counter()) {
    11fc:	4290      	cmp	r0, r2
    11fe:	d100      	bne.n	1202 <handle_next_cycle_case+0x16>
		 * generated. Trigger interrupt.
		 */
		t = counter();
		set_comparator(t + 2);
	}
}
    1200:	4770      	bx	lr
    1202:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
		set_comparator(t + 2);
    1206:	1c82      	adds	r2, r0, #2
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    1208:	f022 427f 	bic.w	r2, r2, #4278190080	; 0xff000000
    120c:	e7f2      	b.n	11f4 <handle_next_cycle_case+0x8>
    120e:	bf00      	nop
    1210:	40011000 	.word	0x40011000

00001214 <event_clear>:
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0;
    1214:	4b04      	ldr	r3, [pc, #16]	; (1228 <event_clear+0x14>)
    1216:	2200      	movs	r2, #0
{
    1218:	b082      	sub	sp, #8
    121a:	601a      	str	r2, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    121c:	681b      	ldr	r3, [r3, #0]
    121e:	9301      	str	r3, [sp, #4]
    (void)dummy;
    1220:	9b01      	ldr	r3, [sp, #4]
}
    1222:	b002      	add	sp, #8
    1224:	4770      	bx	lr
    1226:	bf00      	nop
    1228:	40011140 	.word	0x40011140

0000122c <rtc_nrf_isr>:
 * probably better abstract that at some point (e.g. query and reset
 * it by pointer at runtime, maybe?) so we don't have this leaky
 * symbol.
 */
void rtc_nrf_isr(void *arg)
{
    122c:	b508      	push	{r3, lr}
	ARG_UNUSED(arg);
	event_clear();
    122e:	f7ff fff1 	bl	1214 <event_clear>
    return p_reg->CC[ch];
    1232:	4b07      	ldr	r3, [pc, #28]	; (1250 <rtc_nrf_isr+0x24>)

	uint32_t t = get_comparator();
	uint32_t dticks = counter_sub(t, last_count) / CYC_PER_TICK;
    1234:	4a07      	ldr	r2, [pc, #28]	; (1254 <rtc_nrf_isr+0x28>)
    1236:	f8d3 0540 	ldr.w	r0, [r3, #1344]	; 0x540
    123a:	6813      	ldr	r3, [r2, #0]
	return (a - b) & COUNTER_MAX;
    123c:	1ac0      	subs	r0, r0, r3
    123e:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000

	last_count += dticks * CYC_PER_TICK;
    1242:	4403      	add	r3, r0
    1244:	6013      	str	r3, [r2, #0]
		 */
		set_absolute_alarm(last_count + CYC_PER_TICK);
	}

	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
}
    1246:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_clock_announce(IS_ENABLED(CONFIG_TICKLESS_KERNEL) ? dticks : (dticks > 0));
    124a:	f003 bb11 	b.w	4870 <z_clock_announce>
    124e:	bf00      	nop
    1250:	40011000 	.word	0x40011000
    1254:	20000454 	.word	0x20000454

00001258 <z_clock_driver_init>:

int z_clock_driver_init(struct device *device)
{
    1258:	b538      	push	{r3, r4, r5, lr}
}

NRF_STATIC_INLINE void nrf_rtc_prescaler_set(NRF_RTC_Type * p_reg, uint32_t val)
{
    NRFX_ASSERT(val <= (RTC_PRESCALER_PRESCALER_Msk >> RTC_PRESCALER_PRESCALER_Pos));
    p_reg->PRESCALER = val;
    125a:	4d10      	ldr	r5, [pc, #64]	; (129c <z_clock_driver_init+0x44>)
    125c:	2400      	movs	r4, #0
    125e:	f8c5 4508 	str.w	r4, [r5, #1288]	; 0x508
	ARG_UNUSED(device);

	/* TODO: replace with counter driver to access RTC */
	nrf_rtc_prescaler_set(RTC, 0);
	event_clear();
    1262:	f7ff ffd7 	bl	1214 <event_clear>
 */
__STATIC_INLINE void __NVIC_ClearPendingIRQ(IRQn_Type IRQn)
{
  if ((int32_t)(IRQn) >= 0)
  {
    NVIC->ICPR[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    1266:	4b0e      	ldr	r3, [pc, #56]	; (12a0 <z_clock_driver_init+0x48>)
    1268:	f44f 3200 	mov.w	r2, #131072	; 0x20000
    126c:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
    p_reg->INTENSET = mask;
    1270:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    1274:	f8c5 3304 	str.w	r3, [r5, #772]	; 0x304
	NVIC_ClearPendingIRQ(RTC_IRQn);
	int_enable();

	IRQ_CONNECT(RTC_IRQn, 1, rtc_nrf_isr, 0, 0);
    1278:	4622      	mov	r2, r4
    127a:	2101      	movs	r1, #1
    127c:	2011      	movs	r0, #17
    127e:	f000 f965 	bl	154c <z_arm_irq_priority_set>
	irq_enable(RTC_IRQn);
    1282:	2011      	movs	r0, #17
    1284:	f000 f952 	bl	152c <arch_irq_enable>
    return (uint32_t)p_reg + task;
}

NRF_STATIC_INLINE void nrf_rtc_task_trigger(NRF_RTC_Type * p_reg, nrf_rtc_task_t task)
{
    *(__IO uint32_t *)((uint32_t)p_reg + task) = 1;
    1288:	4a06      	ldr	r2, [pc, #24]	; (12a4 <z_clock_driver_init+0x4c>)
    128a:	2301      	movs	r3, #1
    128c:	6013      	str	r3, [r2, #0]

	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		set_comparator(counter() + CYC_PER_TICK);
	}

	z_nrf_clock_control_lf_on(NRF_LFCLK_START_MODE_NOWAIT);
    128e:	4620      	mov	r0, r4
    1290:	602b      	str	r3, [r5, #0]
    1292:	f7ff ff81 	bl	1198 <z_nrf_clock_control_lf_on>

	return 0;
}
    1296:	4620      	mov	r0, r4
    1298:	bd38      	pop	{r3, r4, r5, pc}
    129a:	bf00      	nop
    129c:	40011000 	.word	0x40011000
    12a0:	e000e100 	.word	0xe000e100
    12a4:	40011008 	.word	0x40011008

000012a8 <z_clock_set_timeout>:

void z_clock_set_timeout(int32_t ticks, bool idle)
{
    12a8:	e92d 4178 	stmdb	sp!, {r3, r4, r5, r6, r8, lr}
	}

	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);

	uint32_t unannounced = counter_sub(counter(), last_count);
    12ac:	4b30      	ldr	r3, [pc, #192]	; (1370 <z_clock_set_timeout+0xc8>)
     return p_reg->COUNTER;
    12ae:	4c31      	ldr	r4, [pc, #196]	; (1374 <z_clock_set_timeout+0xcc>)
    12b0:	6819      	ldr	r1, [r3, #0]
    12b2:	f8d4 2504 	ldr.w	r2, [r4, #1284]	; 0x504
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    12b6:	4d30      	ldr	r5, [pc, #192]	; (1378 <z_clock_set_timeout+0xd0>)
	return (a - b) & COUNTER_MAX;
    12b8:	1a52      	subs	r2, r2, r1
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
    12ba:	f1b0 3fff 	cmp.w	r0, #4294967295	; 0xffffffff
    12be:	bf08      	it	eq
    12c0:	4628      	moveq	r0, r5
	/* If we haven't announced for more than half the 24-bit wrap
	 * duration, then force an announce to avoid loss of a wrap
	 * event.  This can happen if new timeouts keep being set
	 * before the existing one triggers the interrupt.
	 */
	if (unannounced >= COUNTER_HALF_SPAN) {
    12c2:	0216      	lsls	r6, r2, #8
	return (a - b) & COUNTER_MAX;
    12c4:	f022 437f 	bic.w	r3, r2, #4278190080	; 0xff000000
	if (unannounced >= COUNTER_HALF_SPAN) {
    12c8:	d43b      	bmi.n	1342 <z_clock_set_timeout+0x9a>
	ticks = MAX(MIN(ticks - 1, (int32_t)MAX_TICKS), 0);
    12ca:	3801      	subs	r0, #1
    12cc:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    12d0:	42a8      	cmp	r0, r5
    12d2:	bfa8      	it	ge
    12d4:	4628      	movge	r0, r5
	}

	/* Get the cycles from last_count to the tick boundary after
	 * the requested ticks have passed starting now.
	 */
	cyc = ticks * CYC_PER_TICK + 1 + unannounced;
    12d6:	3301      	adds	r3, #1
    p_reg->INTENCLR = mask;
    12d8:	f44f 3680 	mov.w	r6, #65536	; 0x10000
    12dc:	4418      	add	r0, r3
    12de:	f8c4 6308 	str.w	r6, [r4, #776]	; 0x308
	 */
	if (cyc > MAX_CYCLES) {
		cyc = MAX_CYCLES;
	}

	cyc += last_count;
    12e2:	42a8      	cmp	r0, r5
    12e4:	bf94      	ite	ls
    12e6:	180d      	addls	r5, r1, r0
    12e8:	194d      	addhi	r5, r1, r5
     return p_reg->COUNTER;
    12ea:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
    return p_reg->CC[ch];
    12ee:	f8d4 1540 	ldr.w	r1, [r4, #1344]	; 0x540
	event_clear();
    12f2:	f7ff ff8f 	bl	1214 <event_clear>
	return (a - b) & COUNTER_MAX;
    12f6:	1a09      	subs	r1, r1, r0
    12f8:	f021 417f 	bic.w	r1, r1, #4278190080	; 0xff000000
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    12fc:	f020 437f 	bic.w	r3, r0, #4278190080	; 0xff000000
	if (counter_sub(prev_val, now) == 1) {
    1300:	2901      	cmp	r1, #1
    p_reg->CC[ch] = cc_val;
    1302:	f8c4 3540 	str.w	r3, [r4, #1344]	; 0x540
}

NRF_STATIC_INLINE void nrf_rtc_event_enable(NRF_RTC_Type * p_reg, uint32_t mask)
{
    p_reg->EVTENSET = mask;
    1306:	f8c4 6344 	str.w	r6, [r4, #836]	; 0x344
    130a:	d10b      	bne.n	1324 <z_clock_set_timeout+0x7c>
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    130c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    1310:	b9cb      	cbnz	r3, 1346 <z_clock_set_timeout+0x9e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    1312:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    1316:	07da      	lsls	r2, r3, #31
    1318:	d515      	bpl.n	1346 <z_clock_set_timeout+0x9e>
	register uint32_t ret __asm__("r0") = arg1;
    131a:	200f      	movs	r0, #15
	register uint32_t r6 __asm__("r6") = call_id;
    131c:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    131e:	df03      	svc	3
		event_clear();
    1320:	f7ff ff78 	bl	1214 <event_clear>
    1324:	4b15      	ldr	r3, [pc, #84]	; (137c <z_clock_set_timeout+0xd4>)
    1326:	f44f 3200 	mov.w	r2, #131072	; 0x20000
    132a:	f8c3 2180 	str.w	r2, [r3, #384]	; 0x180
     return p_reg->COUNTER;
    132e:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    1332:	1a2b      	subs	r3, r5, r0
    1334:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
	if (diff == 1) {
    1338:	2b01      	cmp	r3, #1
    133a:	d108      	bne.n	134e <z_clock_set_timeout+0xa6>
		handle_next_cycle_case(t);
    133c:	f7ff ff56 	bl	11ec <handle_next_cycle_case>
    1340:	e00f      	b.n	1362 <z_clock_set_timeout+0xba>
		ticks = 0;
    1342:	2000      	movs	r0, #0
    1344:	e7c7      	b.n	12d6 <z_clock_set_timeout+0x2e>
	z_impl_k_busy_wait(usec_to_wait);
    1346:	200f      	movs	r0, #15
    1348:	f004 ff1f 	bl	618a <z_impl_k_busy_wait>
    134c:	e7e8      	b.n	1320 <z_clock_set_timeout+0x78>
	nrf_rtc_cc_set(RTC, 0, cyc & COUNTER_MAX);
    134e:	f025 437f 	bic.w	r3, r5, #4278190080	; 0xff000000
    p_reg->CC[ch] = cc_val;
    1352:	f8c4 3540 	str.w	r3, [r4, #1344]	; 0x540
     return p_reg->COUNTER;
    1356:	f8d4 0504 	ldr.w	r0, [r4, #1284]	; 0x504
	return (a - b) & COUNTER_MAX;
    135a:	1a2d      	subs	r5, r5, r0
    135c:	3d02      	subs	r5, #2
	if (diff > MAX_CYCLES) {
    135e:	022b      	lsls	r3, r5, #8
    1360:	d4ec      	bmi.n	133c <z_clock_set_timeout+0x94>
    p_reg->INTENSET = mask;
    1362:	f44f 3380 	mov.w	r3, #65536	; 0x10000
    1366:	f8c4 3304 	str.w	r3, [r4, #772]	; 0x304
	set_protected_absolute_alarm(cyc);
}
    136a:	e8bd 8178 	ldmia.w	sp!, {r3, r4, r5, r6, r8, pc}
    136e:	bf00      	nop
    1370:	20000454 	.word	0x20000454
    1374:	40011000 	.word	0x40011000
    1378:	007fffff 	.word	0x007fffff
    137c:	e000e100 	.word	0xe000e100

00001380 <z_clock_elapsed>:
	__asm__ volatile(
    1380:	f04f 0220 	mov.w	r2, #32
    1384:	f3ef 8311 	mrs	r3, BASEPRI
    1388:	f382 8811 	msr	BASEPRI, r2
    138c:	f3bf 8f6f 	isb	sy
     return p_reg->COUNTER;
    1390:	4a06      	ldr	r2, [pc, #24]	; (13ac <z_clock_elapsed+0x2c>)
    1392:	f8d2 0504 	ldr.w	r0, [r2, #1284]	; 0x504
	if (!IS_ENABLED(CONFIG_TICKLESS_KERNEL)) {
		return 0;
	}

	k_spinlock_key_t key = k_spin_lock(&lock);
	uint32_t ret = counter_sub(counter(), last_count) / CYC_PER_TICK;
    1396:	4a06      	ldr	r2, [pc, #24]	; (13b0 <z_clock_elapsed+0x30>)
	return (a - b) & COUNTER_MAX;
    1398:	6812      	ldr	r2, [r2, #0]
    139a:	1a80      	subs	r0, r0, r2
    139c:	f020 407f 	bic.w	r0, r0, #4278190080	; 0xff000000
	__asm__ volatile(
    13a0:	f383 8811 	msr	BASEPRI, r3
    13a4:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&lock, key);
	return ret;
}
    13a8:	4770      	bx	lr
    13aa:	bf00      	nop
    13ac:	40011000 	.word	0x40011000
    13b0:	20000454 	.word	0x20000454

000013b4 <_DoInit>:
*
*/
#define INIT()  do {                                            \
                  if (_SEGGER_RTT.acID[0] == '\0') { _DoInit(); }  \
                } while (0)
static void _DoInit(void) {
    13b4:	b510      	push	{r4, lr}
  SEGGER_RTT_CB* p;
  //
  // Initialize control block
  //
  p = &_SEGGER_RTT;
  p->MaxNumUpBuffers    = SEGGER_RTT_MAX_NUM_UP_BUFFERS;
    13b6:	4c11      	ldr	r4, [pc, #68]	; (13fc <_DoInit+0x48>)
  p->MaxNumDownBuffers  = SEGGER_RTT_MAX_NUM_DOWN_BUFFERS;
  //
  // Initialize up buffer 0
  //
  p->aUp[0].sName         = "Terminal";
    13b8:	4a11      	ldr	r2, [pc, #68]	; (1400 <_DoInit+0x4c>)
    13ba:	61a2      	str	r2, [r4, #24]
  p->MaxNumUpBuffers    = SEGGER_RTT_MAX_NUM_UP_BUFFERS;
    13bc:	2303      	movs	r3, #3
  p->MaxNumDownBuffers  = SEGGER_RTT_MAX_NUM_DOWN_BUFFERS;
    13be:	e9c4 3304 	strd	r3, r3, [r4, #16]
  p->aUp[0].pBuffer       = _acUpBuffer;
    13c2:	4b10      	ldr	r3, [pc, #64]	; (1404 <_DoInit+0x50>)
    13c4:	61e3      	str	r3, [r4, #28]
  p->aUp[0].WrOff         = 0u;
  p->aUp[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
  //
  // Initialize down buffer 0
  //
  p->aDown[0].sName         = "Terminal";
    13c6:	6622      	str	r2, [r4, #96]	; 0x60
  p->aUp[0].SizeOfBuffer  = sizeof(_acUpBuffer);
    13c8:	f44f 6380 	mov.w	r3, #1024	; 0x400
  p->aDown[0].pBuffer       = _acDownBuffer;
    13cc:	4a0e      	ldr	r2, [pc, #56]	; (1408 <_DoInit+0x54>)
  //
  // Finish initialization of the control block.
  // Copy Id string in three steps to make sure "SEGGER RTT" is not found
  // in initializer memory (usually flash) by J-Link
  //
  strcpy(&p->acID[7], "RTT");
    13ce:	490f      	ldr	r1, [pc, #60]	; (140c <_DoInit+0x58>)
  p->aUp[0].SizeOfBuffer  = sizeof(_acUpBuffer);
    13d0:	6223      	str	r3, [r4, #32]
  p->aDown[0].pBuffer       = _acDownBuffer;
    13d2:	6662      	str	r2, [r4, #100]	; 0x64
  p->aUp[0].RdOff         = 0u;
    13d4:	2300      	movs	r3, #0
  p->aDown[0].SizeOfBuffer  = sizeof(_acDownBuffer);
    13d6:	2210      	movs	r2, #16
  strcpy(&p->acID[7], "RTT");
    13d8:	1de0      	adds	r0, r4, #7
  p->aUp[0].RdOff         = 0u;
    13da:	62a3      	str	r3, [r4, #40]	; 0x28
  p->aUp[0].WrOff         = 0u;
    13dc:	6263      	str	r3, [r4, #36]	; 0x24
  p->aUp[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
    13de:	62e3      	str	r3, [r4, #44]	; 0x2c
  p->aDown[0].RdOff         = 0u;
    13e0:	6723      	str	r3, [r4, #112]	; 0x70
  p->aDown[0].WrOff         = 0u;
    13e2:	66e3      	str	r3, [r4, #108]	; 0x6c
  p->aDown[0].Flags         = SEGGER_RTT_MODE_DEFAULT;
    13e4:	6763      	str	r3, [r4, #116]	; 0x74
  p->aDown[0].SizeOfBuffer  = sizeof(_acDownBuffer);
    13e6:	66a2      	str	r2, [r4, #104]	; 0x68
  strcpy(&p->acID[7], "RTT");
    13e8:	f004 fb61 	bl	5aae <strcpy>
  strcpy(&p->acID[0], "SEGGER");
    13ec:	4908      	ldr	r1, [pc, #32]	; (1410 <_DoInit+0x5c>)
    13ee:	4620      	mov	r0, r4
    13f0:	f004 fb5d 	bl	5aae <strcpy>
  p->acID[6] = ' ';
    13f4:	2320      	movs	r3, #32
    13f6:	71a3      	strb	r3, [r4, #6]
}
    13f8:	bd10      	pop	{r4, pc}
    13fa:	bf00      	nop
    13fc:	20000458 	.word	0x20000458
    1400:	000070eb 	.word	0x000070eb
    1404:	20000eb1 	.word	0x20000eb1
    1408:	20000ea1 	.word	0x20000ea1
    140c:	000070f4 	.word	0x000070f4
    1410:	000070f8 	.word	0x000070f8

00001414 <arch_swap>:
#ifdef CONFIG_EXECUTION_BENCHMARKING
	read_timer_start_of_swap();
#endif

	/* store off key and return value */
	_current->arch.basepri = key;
    1414:	4a0a      	ldr	r2, [pc, #40]	; (1440 <arch_swap+0x2c>)
	_current->arch.swap_return_value = _k_neg_eagain;
    1416:	490b      	ldr	r1, [pc, #44]	; (1444 <arch_swap+0x30>)
	_current->arch.basepri = key;
    1418:	6893      	ldr	r3, [r2, #8]
	_current->arch.swap_return_value = _k_neg_eagain;
    141a:	6809      	ldr	r1, [r1, #0]
    141c:	f8c3 1090 	str.w	r1, [r3, #144]	; 0x90

#if defined(CONFIG_CPU_CORTEX_M)
	/* set pending bit to make sure we will take a PendSV exception */
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    1420:	4909      	ldr	r1, [pc, #36]	; (1448 <arch_swap+0x34>)
	_current->arch.basepri = key;
    1422:	f8c3 008c 	str.w	r0, [r3, #140]	; 0x8c
	SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    1426:	684b      	ldr	r3, [r1, #4]
    1428:	f043 5380 	orr.w	r3, r3, #268435456	; 0x10000000
    142c:	604b      	str	r3, [r1, #4]
    142e:	2300      	movs	r3, #0
    1430:	f383 8811 	msr	BASEPRI, r3
    1434:	f3bf 8f6f 	isb	sy
#endif

	/* Context switch is performed here. Returning implies the
	 * thread has been context-switched-in again.
	 */
	return _current->arch.swap_return_value;
    1438:	6893      	ldr	r3, [r2, #8]
}
    143a:	f8d3 0090 	ldr.w	r0, [r3, #144]	; 0x90
    143e:	4770      	bx	lr
    1440:	20000524 	.word	0x20000524
    1444:	00006bd0 	.word	0x00006bd0
    1448:	e000ed00 	.word	0xe000ed00

0000144c <z_arm_pendsv>:
    pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_TRACING */

    /* load _kernel into r1 and current k_thread into r2 */
    ldr r1, =_kernel
    144c:	4919      	ldr	r1, [pc, #100]	; (14b4 <z_arm_pendsv+0x68>)
    ldr r2, [r1, #_kernel_offset_to_current]
    144e:	688a      	ldr	r2, [r1, #8]

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
    1450:	f04f 0038 	mov.w	r0, #56	; 0x38
    add r0, r2
    1454:	4410      	add	r0, r2

    /* save callee-saved + psp in thread */
#if defined(CONFIG_CPU_CORTEX_M)
    mrs ip, PSP
    1456:	f3ef 8c09 	mrs	ip, PSP
    mov r6, r11
    mov r7, ip
    /* store r8-12 */
    stmea r0!, {r3-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    stmia r0, {v1-v8, ip}
    145a:	e880 1ff0 	stmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}

    /* Protect the kernel state while we play with the thread lists */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    145e:	2020      	movs	r0, #32
    msr BASEPRI, r0
    1460:	f380 8811 	msr	BASEPRI, r0
    isb /* Make the effect of disabling interrupts be realized immediately */
    1464:	f3bf 8f6f 	isb	sy
     * the new thread is context-switched in since all decisions
     * to pend PendSV have been taken with the current kernel
     * state and this is what we're handling currently.
     */
#if defined(CONFIG_CPU_CORTEX_M)
    ldr v4, =_SCS_ICSR
    1468:	4f13      	ldr	r7, [pc, #76]	; (14b8 <z_arm_pendsv+0x6c>)
    ldr v3, =_SCS_ICSR_UNPENDSV
    146a:	f04f 6600 	mov.w	r6, #134217728	; 0x8000000
#endif

    /* _kernel is still in r1 */

    /* fetch the thread to run from the ready queue cache */
    ldr r2, [r1, #_kernel_offset_to_ready_q_cache]
    146e:	6a4a      	ldr	r2, [r1, #36]	; 0x24

    str r2, [r1, #_kernel_offset_to_current]
    1470:	608a      	str	r2, [r1, #8]
     * has been handled.
     */

    /* _SCS_ICSR is still in v4 and _SCS_ICSR_UNPENDSV in v3 */
#if defined(CONFIG_CPU_CORTEX_M)
    str v3, [v4, #0]
    1472:	603e      	str	r6, [r7, #0]

    ldr r0, [r4]
    movs.n r3, #0
    str r3, [r4]
#else
    ldr r0, [r2, #_thread_offset_to_basepri]
    1474:	f8d2 008c 	ldr.w	r0, [r2, #140]	; 0x8c
    movs r3, #0
    1478:	2300      	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
    147a:	f8c2 308c 	str.w	r3, [r2, #140]	; 0x8c
    /* restore r4-r7, go back 9*4 bytes to the start of the stored block */
    subs r0, #36
    ldmia r0!, {r4-r7}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* restore BASEPRI for the incoming thread */
    msr BASEPRI, r0
    147e:	f380 8811 	msr	BASEPRI, r0
    isb
#endif

#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
    /* Re-program dynamic memory map */
    push {r2,lr}
    1482:	b504      	push	{r2, lr}
    mov r0, r2 /* _current thread */
    1484:	4610      	mov	r0, r2
    bl z_arm_configure_dynamic_mpu_regions
    1486:	f000 fbd5 	bl	1c34 <z_arm_configure_dynamic_mpu_regions>
    pop {r2,lr}
    148a:	e8bd 4004 	ldmia.w	sp!, {r2, lr}
#endif

#ifdef CONFIG_USERSPACE
    /* restore mode */
    ldr r0, [r2, #_thread_offset_to_mode]
    148e:	f8d2 0094 	ldr.w	r0, [r2, #148]	; 0x94
    mrs r3, CONTROL
    1492:	f3ef 8314 	mrs	r3, CONTROL
    bic r3, #1
    1496:	f023 0301 	bic.w	r3, r3, #1
    orr r3, r0
    149a:	ea43 0300 	orr.w	r3, r3, r0
    msr CONTROL, r3
    149e:	f383 8814 	msr	CONTROL, r3

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    14a2:	f3bf 8f6f 	isb	sy

#endif

    /* load callee-saved + psp from thread */
    add r0, r2, #_thread_offset_to_callee_saved
    14a6:	f102 0038 	add.w	r0, r2, #56	; 0x38
    ldmia r0, {v1-v8, ip}
    14aa:	e890 1ff0 	ldmia.w	r0, {r4, r5, r6, r7, r8, r9, sl, fp, ip}
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
    msr PSP, ip
    14ae:	f38c 8809 	msr	PSP, ip

    /*
     * Cortex-M: return from PendSV exception
     * Cortex-R: return to the caller (_IntExit or z_arm_svc)
     */
    bx lr
    14b2:	4770      	bx	lr
    ldr r1, =_kernel
    14b4:	20000524 	.word	0x20000524
    ldr v4, =_SCS_ICSR
    14b8:	e000ed04 	.word	0xe000ed04

000014bc <z_arm_svc>:
  bne _stack_frame_endif
_stack_frame_msp:
  mrs r0, MSP
_stack_frame_endif:
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst lr, #0x4    /* did we come from thread mode ? */
    14bc:	f01e 0f04 	tst.w	lr, #4
    ite eq  /* if zero (equal), came from handler mode */
    14c0:	bf0c      	ite	eq
        mrseq r0, MSP   /* handler mode, stack frame is on MSP */
    14c2:	f3ef 8008 	mrseq	r0, MSP
        mrsne r0, PSP   /* thread mode, stack frame is on PSP */
    14c6:	f3ef 8009 	mrsne	r0, PSP
#endif


    /* Figure out what SVC call number was invoked */

    ldr r1, [r0, #24]   /* grab address of PC from stack frame */
    14ca:	6981      	ldr	r1, [r0, #24]
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    subs r1, r1, #2
    ldrb r1, [r1]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldrb r1, [r1, #-2]
    14cc:	f811 1c02 	ldrb.w	r1, [r1, #-2]
    * 1: irq_offload (if configured)
    * 2: kernel panic or oops (software generated fatal exception)
    * 3: System call (if user mode supported)
    */
#if defined(CONFIG_USERSPACE)
    mrs r2, CONTROL
    14d0:	f3ef 8214 	mrs	r2, CONTROL

    cmp r1, #3
    14d4:	2903      	cmp	r1, #3
    beq _do_syscall
    14d6:	d008      	beq.n	14ea <_do_syscall>
     */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    movs r3, #0x1
    tst r2, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    tst r2, #0x1
    14d8:	f012 0f01 	tst.w	r2, #1
#endif
    bne _oops
    14dc:	d101      	bne.n	14e2 <_oops>

#endif /* CONFIG_USERSPACE */

    cmp r1, #2
    14de:	2902      	cmp	r1, #2
    beq _oops
    14e0:	d0ff      	beq.n	14e2 <_oops>

000014e2 <_oops>:
    /* exception return is done in z_arm_int_exit() */
    b z_arm_int_exit
#endif

_oops:
    push {r0, lr}
    14e2:	b501      	push	{r0, lr}
    bl z_do_kernel_oops
    14e4:	f004 fa9d 	bl	5a22 <z_do_kernel_oops>
    /* return from SVC exception is done here */
    pop {r0, pc}
    14e8:	bd01      	pop	{r0, pc}

000014ea <_do_syscall>:
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    movs r3, #24
    ldr r1, [r0, r3]   /* grab address of PC from stack frame */
    mov r8, r1
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r8, [r0, #24]   /* grab address of PC from stack frame */
    14ea:	f8d0 8018 	ldr.w	r8, [r0, #24]
#endif
    ldr r1, =z_arm_do_syscall
    14ee:	490d      	ldr	r1, [pc, #52]	; (1524 <valid_syscall_id+0x24>)
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    str r1, [r0, r3]   /* overwrite the PC to point to z_arm_do_syscall */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    str r1, [r0, #24]   /* overwrite the PC to point to z_arm_do_syscall */
    14f0:	6181      	str	r1, [r0, #24]
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    ldr r3, =K_SYSCALL_LIMIT
    cmp r6, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* validate syscall limit */
    ldr ip, =K_SYSCALL_LIMIT
    14f2:	f44f 7c86 	mov.w	ip, #268	; 0x10c
    cmp r6, ip
    14f6:	4566      	cmp	r6, ip
#endif
    /* The supplied syscall_id must be lower than the limit
     * (Requires unsigned integer comparison)
     */
    blo valid_syscall_id
    14f8:	d302      	bcc.n	1500 <valid_syscall_id>

    /* bad syscall id.  Set arg1 to bad id and set call_id to SYSCALL_BAD */
    str r6, [r0]
    14fa:	6006      	str	r6, [r0, #0]
    ldr r6, =K_SYSCALL_BAD
    14fc:	f240 160b 	movw	r6, #267	; 0x10b

00001500 <valid_syscall_id>:

    /* Bad syscalls treated as valid syscalls with ID K_SYSCALL_BAD. */

valid_syscall_id:
    ldr r0, =_kernel
    1500:	4809      	ldr	r0, [pc, #36]	; (1528 <valid_syscall_id+0x28>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1502:	6880      	ldr	r0, [r0, #8]
    dsb
    /* set mode to privileged, r2 still contains value from CONTROL */
    movs r3, #1
    bics r2, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r1, [r0, #_thread_offset_to_mode]
    1504:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    bic r1, #1
    1508:	f021 0101 	bic.w	r1, r1, #1
    /* Store (privileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    150c:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
    dsb
    1510:	f3bf 8f4f 	dsb	sy
    /* set mode to privileged, r2 still contains value from CONTROL */
    bic r2, #1
    1514:	f022 0201 	bic.w	r2, r2, #1
#endif
    msr CONTROL, r2
    1518:	f382 8814 	msr	CONTROL, r2

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    151c:	f3bf 8f6f 	isb	sy
    ldr r1, [r0, #_thread_offset_to_stack_info_start]    /* stack_info.start */
    msr PSPLIM, r1
#endif /* CONFIG_BUILTIN_STACK_GUARD */

    /* return from SVC to the modified LR - z_arm_do_syscall */
    bx lr
    1520:	4770      	bx	lr
    1522:	0000      	.short	0x0000
    ldr r1, =z_arm_do_syscall
    1524:	000017b9 	.word	0x000017b9
    ldr r0, =_kernel
    1528:	20000524 	.word	0x20000524

0000152c <arch_irq_enable>:
#define REG_FROM_IRQ(irq) (irq / NUM_IRQS_PER_REG)
#define BIT_FROM_IRQ(irq) (irq % NUM_IRQS_PER_REG)

void arch_irq_enable(unsigned int irq)
{
	NVIC_EnableIRQ((IRQn_Type)irq);
    152c:	b243      	sxtb	r3, r0
  if ((int32_t)(IRQn) >= 0)
    152e:	2b00      	cmp	r3, #0
    1530:	db08      	blt.n	1544 <arch_irq_enable+0x18>
    NVIC->ISER[(((uint32_t)IRQn) >> 5UL)] = (uint32_t)(1UL << (((uint32_t)IRQn) & 0x1FUL));
    1532:	2201      	movs	r2, #1
    1534:	f000 001f 	and.w	r0, r0, #31
    1538:	fa02 f000 	lsl.w	r0, r2, r0
    153c:	095b      	lsrs	r3, r3, #5
    153e:	4a02      	ldr	r2, [pc, #8]	; (1548 <arch_irq_enable+0x1c>)
    1540:	f842 0023 	str.w	r0, [r2, r3, lsl #2]
}
    1544:	4770      	bx	lr
    1546:	bf00      	nop
    1548:	e000e100 	.word	0xe000e100

0000154c <z_arm_irq_priority_set>:
	 */
	__ASSERT(prio <= (BIT(NUM_IRQ_PRIO_BITS) - 1),
		 "invalid priority %d! values must be less than %lu\n",
		 prio - _IRQ_PRIO_OFFSET,
		 BIT(NUM_IRQ_PRIO_BITS) - (_IRQ_PRIO_OFFSET));
	NVIC_SetPriority((IRQn_Type)irq, prio);
    154c:	b243      	sxtb	r3, r0
  \param [in]  priority  Priority to set.
  \note    The priority cannot be set for every processor exception.
 */
__STATIC_INLINE void __NVIC_SetPriority(IRQn_Type IRQn, uint32_t priority)
{
  if ((int32_t)(IRQn) >= 0)
    154e:	2b00      	cmp	r3, #0
  {
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1550:	bfa8      	it	ge
    1552:	f103 4360 	addge.w	r3, r3, #3758096384	; 0xe0000000
	prio += _IRQ_PRIO_OFFSET;
    1556:	f101 0101 	add.w	r1, r1, #1
  }
  else
  {
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    155a:	bfb8      	it	lt
    155c:	4b06      	ldrlt	r3, [pc, #24]	; (1578 <z_arm_irq_priority_set+0x2c>)
    155e:	ea4f 1141 	mov.w	r1, r1, lsl #5
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1562:	bfac      	ite	ge
    1564:	f503 4361 	addge.w	r3, r3, #57600	; 0xe100
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1568:	f000 000f 	andlt.w	r0, r0, #15
    156c:	b2c9      	uxtb	r1, r1
    156e:	bfb4      	ite	lt
    1570:	5419      	strblt	r1, [r3, r0]
    NVIC->IP[((uint32_t)IRQn)]               = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    1572:	f883 1300 	strbge.w	r1, [r3, #768]	; 0x300
}
    1576:	4770      	bx	lr
    1578:	e000ed14 	.word	0xe000ed14

0000157c <arch_user_mode_enter>:
					void *p1, void *p2, void *p3)
{

	/* Set up privileged stack before entering user mode */
	_current->arch.priv_stack_start =
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    157c:	4c0c      	ldr	r4, [pc, #48]	; (15b0 <arch_user_mode_enter+0x34>)
{
    157e:	4698      	mov	r8, r3
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    1580:	68a3      	ldr	r3, [r4, #8]
{
    1582:	b583      	push	{r0, r1, r7, lr}
    1584:	4605      	mov	r5, r0
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    1586:	f8d3 0080 	ldr.w	r0, [r3, #128]	; 0x80
{
    158a:	4617      	mov	r7, r2
    158c:	460e      	mov	r6, r1
		(uint32_t)z_priv_stack_find(_current->stack_obj);
    158e:	f005 f8b6 	bl	66fe <z_priv_stack_find>
	_current->arch.priv_stack_start =
    1592:	68a4      	ldr	r4, [r4, #8]
#else
	_current->arch.priv_stack_start += MPU_GUARD_ALIGN_AND_SIZE;
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */
#endif /* CONFIG_MPU_STACK_GUARD */

	z_arm_userspace_enter(user_entry, p1, p2, p3,
    1594:	e9d4 321b 	ldrd	r3, r2, [r4, #108]	; 0x6c
    1598:	1a9b      	subs	r3, r3, r2
	_current->arch.priv_stack_start =
    159a:	f8c4 0098 	str.w	r0, [r4, #152]	; 0x98
	z_arm_userspace_enter(user_entry, p1, p2, p3,
    159e:	9301      	str	r3, [sp, #4]
    15a0:	6ea3      	ldr	r3, [r4, #104]	; 0x68
    15a2:	9300      	str	r3, [sp, #0]
    15a4:	463a      	mov	r2, r7
    15a6:	4643      	mov	r3, r8
    15a8:	4631      	mov	r1, r6
    15aa:	4628      	mov	r0, r5
    15ac:	f000 f8c2 	bl	1734 <z_arm_userspace_enter>
    15b0:	20000524 	.word	0x20000524

000015b4 <arch_new_thread>:
{
    15b4:	b530      	push	{r4, r5, lr}
	if ((thread->base.user_options & K_USER) != 0) {
    15b6:	7b01      	ldrb	r1, [r0, #12]
	iframe->a1 = (uint32_t)entry;
    15b8:	f842 3c20 	str.w	r3, [r2, #-32]
	iframe->a2 = (uint32_t)p1;
    15bc:	9b03      	ldr	r3, [sp, #12]
    15be:	f842 3c1c 	str.w	r3, [r2, #-28]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    15c2:	4d0e      	ldr	r5, [pc, #56]	; (15fc <arch_new_thread+0x48>)
	iframe->a3 = (uint32_t)p2;
    15c4:	9b04      	ldr	r3, [sp, #16]
    15c6:	f842 3c18 	str.w	r3, [r2, #-24]
	if ((thread->base.user_options & K_USER) != 0) {
    15ca:	f011 0f04 	tst.w	r1, #4
	iframe->a4 = (uint32_t)p3;
    15ce:	9b05      	ldr	r3, [sp, #20]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    15d0:	490b      	ldr	r1, [pc, #44]	; (1600 <arch_new_thread+0x4c>)
	iframe->a4 = (uint32_t)p3;
    15d2:	f842 3c14 	str.w	r3, [r2, #-20]
		iframe->pc = (uint32_t)arch_user_mode_enter;
    15d6:	bf18      	it	ne
    15d8:	4629      	movne	r1, r5
	iframe->xpsr =
    15da:	f04f 7380 	mov.w	r3, #16777216	; 0x1000000
    15de:	f842 3c04 	str.w	r3, [r2, #-4]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
    15e2:	f1a2 0420 	sub.w	r4, r2, #32
	thread->arch.basepri = 0;
    15e6:	2300      	movs	r3, #0
	iframe->pc &= 0xfffffffe;
    15e8:	f021 0101 	bic.w	r1, r1, #1
    15ec:	f842 1c08 	str.w	r1, [r2, #-8]
	thread->arch.priv_stack_start = 0;
    15f0:	e9c0 3325 	strd	r3, r3, [r0, #148]	; 0x94
	thread->callee_saved.psp = (uint32_t)iframe;
    15f4:	6584      	str	r4, [r0, #88]	; 0x58
	thread->arch.basepri = 0;
    15f6:	f8c0 308c 	str.w	r3, [r0, #140]	; 0x8c
}
    15fa:	bd30      	pop	{r4, r5, pc}
    15fc:	0000157d 	.word	0x0000157d
    1600:	00005345 	.word	0x00005345

00001604 <z_check_thread_stack_fail>:
 * @return The lowest allowed stack frame pointer, if error is a
 *         thread stack corruption, otherwise return 0.
 */
uint32_t z_check_thread_stack_fail(const uint32_t fault_addr, const uint32_t psp)
{
	const struct k_thread *thread = _current;
    1604:	4b10      	ldr	r3, [pc, #64]	; (1648 <z_check_thread_stack_fail+0x44>)
    1606:	689b      	ldr	r3, [r3, #8]
{
    1608:	b510      	push	{r4, lr}
    160a:	4604      	mov	r4, r0

	if (!thread) {
    160c:	b1bb      	cbz	r3, 163e <z_check_thread_stack_fail+0x3a>
#else
	uint32_t guard_len = MPU_GUARD_ALIGN_AND_SIZE;
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */

#if defined(CONFIG_USERSPACE)
	if (thread->arch.priv_stack_start) {
    160e:	f8d3 0098 	ldr.w	r0, [r3, #152]	; 0x98
    1612:	b168      	cbz	r0, 1630 <z_check_thread_stack_fail+0x2c>
 */
__STATIC_FORCEINLINE uint32_t __get_CONTROL(void)
{
  uint32_t result;

  __ASM volatile ("MRS %0, control" : "=r" (result) );
    1614:	f3ef 8214 	mrs	r2, CONTROL
		/* User thread */
		if ((__get_CONTROL() & CONTROL_nPRIV_Msk) == 0) {
    1618:	f012 0201 	ands.w	r2, r2, #1
    161c:	d105      	bne.n	162a <z_check_thread_stack_fail+0x26>
			/* User thread in privilege mode */
			if (IS_MPU_GUARD_VIOLATION(
    161e:	3416      	adds	r4, #22
    1620:	d10f      	bne.n	1642 <z_check_thread_stack_fail+0x3e>
		/* Thread stack corruption */
		return thread->stack_info.start;
	}
#endif /* CONFIG_USERSPACE */

	return 0;
    1622:	4288      	cmp	r0, r1
    1624:	bf98      	it	ls
    1626:	2000      	movls	r0, #0
}
    1628:	bd10      	pop	{r4, pc}
			if (psp < (uint32_t)thread->stack_obj) {
    162a:	f8d3 0080 	ldr.w	r0, [r3, #128]	; 0x80
    162e:	e7f8      	b.n	1622 <z_check_thread_stack_fail+0x1e>
		if (IS_MPU_GUARD_VIOLATION(thread->stack_info.start -
    1630:	3416      	adds	r4, #22
    1632:	d1f9      	bne.n	1628 <z_check_thread_stack_fail+0x24>
    1634:	6e9b      	ldr	r3, [r3, #104]	; 0x68
    1636:	428b      	cmp	r3, r1
    1638:	bf88      	it	hi
    163a:	4618      	movhi	r0, r3
    163c:	e7f4      	b.n	1628 <z_check_thread_stack_fail+0x24>
	return 0;
    163e:	4618      	mov	r0, r3
    1640:	e7f2      	b.n	1628 <z_check_thread_stack_fail+0x24>
    1642:	4610      	mov	r0, r2
    1644:	e7f0      	b.n	1628 <z_check_thread_stack_fail+0x24>
    1646:	bf00      	nop
    1648:	20000524 	.word	0x20000524

0000164c <arch_switch_to_main_thread>:
}
#endif /* CONFIG_FPU && CONFIG_FPU_SHARING */

void arch_switch_to_main_thread(struct k_thread *main_thread, char *stack_ptr,
				k_thread_entry_t _main)
{
    164c:	b508      	push	{r3, lr}
    164e:	4604      	mov	r4, r0
    1650:	460e      	mov	r6, r1
    1652:	4615      	mov	r5, r2
	 * to set up access permissions for fixed memory sections, such
	 * as Application Memory or No-Cacheable SRAM area.
	 *
	 * This function is invoked once, upon system initialization.
	 */
	z_arm_configure_static_mpu_regions();
    1654:	f000 fad2 	bl	1bfc <z_arm_configure_static_mpu_regions>
#endif
	_current = main_thread;
    1658:	4b08      	ldr	r3, [pc, #32]	; (167c <arch_switch_to_main_thread+0x30>)
#if defined(CONFIG_MPU_STACK_GUARD) || defined(CONFIG_USERSPACE)
	/*
	 * If stack protection is enabled, make sure to set it
	 * before jumping to thread entry function
	 */
	z_arm_configure_dynamic_mpu_regions(main_thread);
    165a:	4620      	mov	r0, r4
	_current = main_thread;
    165c:	609c      	str	r4, [r3, #8]
	z_arm_configure_dynamic_mpu_regions(main_thread);
    165e:	f000 fae9 	bl	1c34 <z_arm_configure_dynamic_mpu_regions>

	/*
	 * Set PSP to the highest address of the main stack
	 * before enabling interrupts and jumping to main.
	 */
	__asm__ volatile (
    1662:	4628      	mov	r0, r5
    1664:	f386 8809 	msr	PSP, r6
    1668:	2100      	movs	r1, #0
    166a:	b663      	cpsie	if
    166c:	f381 8811 	msr	BASEPRI, r1
    1670:	f3bf 8f6f 	isb	sy
    1674:	2200      	movs	r2, #0
    1676:	2300      	movs	r3, #0
    1678:	f003 fe64 	bl	5344 <z_thread_entry>
	:
	: "r" (_main), "r" (stack_ptr)
	: "r0" /* not to be overwritten by msr PSP, %1 */
	);

	CODE_UNREACHABLE;
    167c:	20000524 	.word	0x20000524

00001680 <z_arm_cpu_idle_init>:
 * void z_arm_cpu_idle_init(void);
 */

SECTION_FUNC(TEXT, z_arm_cpu_idle_init)
#if defined(CONFIG_CPU_CORTEX_M)
	ldr	r1, =_SCB_SCR
    1680:	4901      	ldr	r1, [pc, #4]	; (1688 <z_arm_cpu_idle_init+0x8>)
	movs.n	r2, #_SCR_INIT_BITS
    1682:	2210      	movs	r2, #16
	str	r2, [r1]
    1684:	600a      	str	r2, [r1, #0]
#endif
	bx	lr
    1686:	4770      	bx	lr
	ldr	r1, =_SCB_SCR
    1688:	e000ed10 	.word	0xe000ed10

0000168c <arch_cpu_idle>:
	 * before entering low power state.
	 *
	 * Set PRIMASK before configuring BASEPRI to prevent interruption
	 * before wake-up.
	 */
	cpsid	i
    168c:	b672      	cpsid	i

	/*
	 * Set wake-up interrupt priority to the lowest and synchronise to
	 * ensure that this is visible to the WFI instruction.
	 */
	eors.n	r0, r0
    168e:	4040      	eors	r0, r0
	msr	BASEPRI, r0
    1690:	f380 8811 	msr	BASEPRI, r0
	isb
    1694:	f3bf 8f6f 	isb	sy

	/*
	 * Wait for all memory transactions to complete before entering low
	 * power state.
	 */
	dsb
    1698:	f3bf 8f4f 	dsb	sy

	/* Enter low power state */
	wfi
    169c:	bf30      	wfi

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
    169e:	b662      	cpsie	i
	isb
    16a0:	f3bf 8f6f 	isb	sy

	bx	lr
    16a4:	4770      	bx	lr
    16a6:	bf00      	nop

000016a8 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
    16a8:	bf30      	wfi
    b z_SysNmiOnReset
    16aa:	f7ff bffd 	b.w	16a8 <z_SysNmiOnReset>
    16ae:	bf00      	nop

000016b0 <z_arm_prep_c>:
#else
#define VECTOR_ADDRESS CONFIG_SRAM_BASE_ADDRESS
#endif
static inline void relocate_vector_table(void)
{
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    16b0:	4a0e      	ldr	r2, [pc, #56]	; (16ec <z_arm_prep_c+0x3c>)
 * This routine prepares for the execution of and runs C code.
 *
 * @return N/A
 */
void z_arm_prep_c(void)
{
    16b2:	b508      	push	{r3, lr}
	SCB->VTOR = VECTOR_ADDRESS & SCB_VTOR_TBLOFF_Msk;
    16b4:	4b0e      	ldr	r3, [pc, #56]	; (16f0 <z_arm_prep_c+0x40>)
    16b6:	f022 027f 	bic.w	r2, r2, #127	; 0x7f
    16ba:	609a      	str	r2, [r3, #8]
  \details Acts as a special kind of Data Memory Barrier.
           It completes when all explicit memory accesses before this instruction complete.
 */
__STATIC_FORCEINLINE void __DSB(void)
{
  __ASM volatile ("dsb 0xF":::"memory");
    16bc:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    16c0:	f3bf 8f6f 	isb	sy
	SCB->CPACR &= (~(CPACR_CP10_Msk | CPACR_CP11_Msk));
    16c4:	f8d3 2088 	ldr.w	r2, [r3, #136]	; 0x88
    16c8:	f422 0270 	bic.w	r2, r2, #15728640	; 0xf00000
    16cc:	f8c3 2088 	str.w	r2, [r3, #136]	; 0x88
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    16d0:	f3ef 8314 	mrs	r3, CONTROL
	__set_CONTROL(__get_CONTROL() & (~(CONTROL_FPCA_Msk)));
    16d4:	f023 0304 	bic.w	r3, r3, #4
  __ASM volatile ("MSR control, %0" : : "r" (control) : "memory");
    16d8:	f383 8814 	msr	CONTROL, r3
	relocate_vector_table();
#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
    16dc:	f001 fc32 	bl	2f44 <z_bss_zero>
	z_data_copy();
    16e0:	f001 fc3a 	bl	2f58 <z_data_copy>
#if defined(CONFIG_ARMV7_R) && defined(CONFIG_INIT_STACKS)
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
    16e4:	f000 fa58 	bl	1b98 <z_arm_interrupt_init>
	z_cstart();
    16e8:	f001 fc80 	bl	2fec <z_cstart>
    16ec:	00000000 	.word	0x00000000
    16f0:	e000ed00 	.word	0xe000ed00

000016f4 <_isr_wrapper>:
 * @return N/A
 */
SECTION_FUNC(TEXT, _isr_wrapper)

#if defined(CONFIG_CPU_CORTEX_M)
	push {r0,lr}		/* r0, lr are now the first items on the stack */
    16f4:	b501      	push	{r0, lr}
	 * Disable interrupts to prevent nesting while exiting idle state. This
	 * is only necessary for the Cortex-M because it is the only ARM
	 * architecture variant that automatically enables interrupts when
	 * entering an ISR.
	 */
	cpsid i  /* PRIMASK = 1 */
    16f6:	b672      	cpsid	i
#endif

	/* is this a wakeup from idle ? */
	ldr r2, =_kernel
    16f8:	4a0b      	ldr	r2, [pc, #44]	; (1728 <_isr_wrapper+0x34>)
	/* requested idle duration, in ticks */
	ldr r0, [r2, #_kernel_offset_to_idle]
    16fa:	6a10      	ldr	r0, [r2, #32]
	cmp r0, #0
    16fc:	2800      	cmp	r0, #0
	str r1, [r2, #_kernel_offset_to_idle]
	bl z_sys_power_save_idle_exit
_idle_state_cleared:

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	ittt ne
    16fe:	bf1e      	ittt	ne
	movne	r1, #0
    1700:	2100      	movne	r1, #0
		/* clear kernel idle state */
		strne	r1, [r2, #_kernel_offset_to_idle]
    1702:	6211      	strne	r1, [r2, #32]
		blne	z_sys_power_save_idle_exit
    1704:	f004 fb08 	blne	5d18 <z_sys_power_save_idle_exit>
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

#if defined(CONFIG_CPU_CORTEX_M)
	cpsie i		/* re-enable interrupts (PRIMASK = 0) */
    1708:	b662      	cpsie	i
#endif

#endif /* CONFIG_SYS_POWER_MANAGEMENT */

#if defined(CONFIG_CPU_CORTEX_M)
	mrs r0, IPSR	/* get exception number */
    170a:	f3ef 8005 	mrs	r0, IPSR
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	ldr r1, =16
	subs r0, r1	/* get IRQ number */
	lsls r0, #3	/* table is 8-byte wide */
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	sub r0, r0, #16	/* get IRQ number */
    170e:	f1a0 0010 	sub.w	r0, r0, #16
	lsl r0, r0, #3	/* table is 8-byte wide */
    1712:	ea4f 00c0 	mov.w	r0, r0, lsl #3
	 * interface function.
	 */
	cpsie i
#endif /* !CONFIG_CPU_CORTEX_M */

	ldr r1, =_sw_isr_table
    1716:	4905      	ldr	r1, [pc, #20]	; (172c <_isr_wrapper+0x38>)
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
    1718:	4401      	add	r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
    171a:	c909      	ldmia	r1!, {r0, r3}
#ifdef CONFIG_EXECUTION_BENCHMARKING
	push {r0, r3}	/* Save r0 and r3 into stack */
	bl read_timer_end_of_isr
	pop {r0, r3}	/* Restore r0 and r3 regs */
#endif /* CONFIG_EXECUTION_BENCHMARKING */
	blx r3		/* call ISR */
    171c:	4798      	blx	r3

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
	pop {r0, r3}
	mov lr, r3
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	pop {r0, lr}
    171e:	e8bd 4001 	ldmia.w	sp!, {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
    1722:	4903      	ldr	r1, [pc, #12]	; (1730 <_isr_wrapper+0x3c>)
	bx r1
    1724:	4708      	bx	r1
    1726:	0000      	.short	0x0000
	ldr r2, =_kernel
    1728:	20000524 	.word	0x20000524
	ldr r1, =_sw_isr_table
    172c:	000069e0 	.word	0x000069e0
	ldr r1, =z_arm_int_exit
    1730:	00001b7d 	.word	0x00001b7d

00001734 <z_arm_userspace_enter>:
 * z_arm_userspace_enter(user_entry, p1, p2, p3,
 *                        stack_info.start, stack_info.size);
 */
SECTION_FUNC(TEXT,z_arm_userspace_enter)
    /* move user_entry to lr */
    mov lr, r0
    1734:	4686      	mov	lr, r0

    /* prepare to set stack to privileged stack */
    ldr r0, =_kernel
    1736:	481e      	ldr	r0, [pc, #120]	; (17b0 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1738:	6880      	ldr	r0, [r0, #8]
    ldr r1, =CONFIG_PRIVILEGED_STACK_SIZE
    add r0, r0, r1
    /* Restore p1 from ip */
    mov r1, ip
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r0, [r0, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    173a:	f8d0 0098 	ldr.w	r0, [r0, #152]	; 0x98
    ldr ip, =CONFIG_PRIVILEGED_STACK_SIZE
    173e:	f44f 6c80 	mov.w	ip, #1024	; 0x400
    add r0, r0, ip
    1742:	4460      	add	r0, ip

    /* store current stack pointer to ip
     * the current stack pointer is needed to retrieve
     * stack_info.start and stack_info.size
     */
    mov ip, sp
    1744:	46ec      	mov	ip, sp
     * modifying PSP via MSR instruction is not subject to stack limit
     * checking, so we do not need to clear PSPLIM before setting PSP.
     * The operation is safe since, by design, the privileged stack is
     * located in memory higher than the default (user) thread stack.
     */
    msr PSP, r0
    1746:	f380 8809 	msr	PSP, r0
    ldr r0, [r0, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    msr PSPLIM, r0
#endif

    /* push args to stack */
    push {r1,r2,r3,lr}
    174a:	b50e      	push	{r1, r2, r3, lr}
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    mov r1, ip
    push {r0,r1}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    push {r0,ip}
    174c:	e92d 1001 	stmdb	sp!, {r0, ip}
     *
     * Note that the risk for overflow is higher if using the normal thread
     * stack, since we do not control how much stack is actually left, when
     * user invokes z_arm_userspace_enter().
     */
    ldr r0, =_kernel
    1750:	4817      	ldr	r0, [pc, #92]	; (17b0 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1752:	6880      	ldr	r0, [r0, #8]
    bl z_arm_configure_dynamic_mpu_regions
    1754:	f000 fa6e 	bl	1c34 <z_arm_configure_dynamic_mpu_regions>
    ldr r3, [r3, #4]
    mov ip, r3

    push {r0,r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r0,ip}
    1758:	e8bd 1001 	ldmia.w	sp!, {r0, ip}

    /* load up stack info from user stack */
    ldr r0, [ip]
    175c:	f8dc 0000 	ldr.w	r0, [ip]
    ldr ip, [ip, #4]
    1760:	f8dc c004 	ldr.w	ip, [ip, #4]

    push {r0,ip}
    1764:	e92d 1001 	stmdb	sp!, {r0, ip}
#endif

    /* clear the user stack area to clean out privileged data */
    /* from right past the guard right up to the end */
    mov r2, ip
    1768:	4662      	mov	r2, ip
#ifdef CONFIG_INIT_STACKS
    ldr r1,=0xaaaaaaaa
#else
    eors.n r1, r1
    176a:	4049      	eors	r1, r1
#endif
    bl memset
    176c:	f004 f9e0 	bl	5b30 <memset>

#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    pop {r0, r1}
    mov ip, r1
#elif (defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE))
    pop {r0,ip}
    1770:	e8bd 1001 	ldmia.w	sp!, {r0, ip}
#endif

    /* r0 contains user stack start, ip contains user stack size */
    add r0, r0, ip   /* calculate top of stack */
    1774:	4460      	add	r0, ip
    mov ip, r4
    pop {r1,r2,r3,r4}
    mov lr, r4
    mov r4, ip
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r1,r2,r3,lr}
    1776:	e8bd 400e 	ldmia.w	sp!, {r1, r2, r3, lr}

    pop {r0, ip}
#endif

    /* set stack to user stack */
    msr PSP, r0
    177a:	f380 8809 	msr	PSP, r0
    msr BASEPRI, ip
    isb
#endif

    /* restore r0 */
    mov r0, lr
    177e:	4670      	mov	r0, lr
    mov ip, r3
    /* Store (unprivileged) mode in thread's mode state variable */
    ldr r2, =_thread_offset_to_mode
    str r1, [r0, r2]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    push {r0, r1}
    1780:	b403      	push	{r0, r1}
    ldr r0, =_kernel
    1782:	480b      	ldr	r0, [pc, #44]	; (17b0 <z_arm_userspace_enter+0x7c>)
    ldr r0, [r0, #_kernel_offset_to_current]
    1784:	6880      	ldr	r0, [r0, #8]
    ldr r1, [r0, #_thread_offset_to_mode]
    1786:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    orrs r1, r1, #1
    178a:	f051 0101 	orrs.w	r1, r1, #1
    mrs ip, CONTROL
    178e:	f3ef 8c14 	mrs	ip, CONTROL
    orrs ip, ip, #1
    1792:	f05c 0c01 	orrs.w	ip, ip, #1
    /* Store (unprivileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    1796:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
#endif
    dsb
    179a:	f3bf 8f4f 	dsb	sy
    msr CONTROL, ip
    179e:	f38c 8814 	msr	CONTROL, ip

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    17a2:	f3bf 8f6f 	isb	sy
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    pop {r0, r1, r2, r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    pop {r0, r1}
    17a6:	bc03      	pop	{r0, r1}
    push {r0, r1}
    ldr r0, =z_thread_entry
    mov ip, r0
    pop {r0, r1}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr ip, =z_thread_entry
    17a8:	f8df c008 	ldr.w	ip, [pc, #8]	; 17b4 <z_arm_userspace_enter+0x80>
#endif
    bx ip
    17ac:	4760      	bx	ip
    17ae:	0000      	.short	0x0000
    ldr r0, =_kernel
    17b0:	20000524 	.word	0x20000524
    ldr ip, =z_thread_entry
    17b4:	00005345 	.word	0x00005345

000017b8 <z_arm_do_syscall>:
    pop {r0, r1}

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)

    /* setup privileged stack */
    ldr ip, =_kernel
    17b8:	f8df c088 	ldr.w	ip, [pc, #136]	; 1844 <dispatch_syscall+0x5a>
    ldr ip, [ip, #_kernel_offset_to_current]
    17bc:	f8dc c008 	ldr.w	ip, [ip, #8]
    ldr ip, [ip, #_thread_offset_to_priv_stack_start]    /* priv stack ptr */
    17c0:	f8dc c098 	ldr.w	ip, [ip, #152]	; 0x98
    add ip, #CONFIG_PRIVILEGED_STACK_SIZE
    17c4:	f50c 6c80 	add.w	ip, ip, #1024	; 0x400

    /* Store current SP and LR at the beginning of the priv stack */
    subs ip, #8
    17c8:	f1bc 0c08 	subs.w	ip, ip, #8
    str sp, [ip, #0]
    17cc:	f8cc d000 	str.w	sp, [ip]
    str lr, [ip, #4]
    17d0:	f8cc e004 	str.w	lr, [ip, #4]
#endif

    /* switch to privileged stack */
    msr PSP, ip
    17d4:	f38c 8809 	msr	PSP, ip
    mov lr, r0
    /* Restore r0 */
    mov r0, ip

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr ip, =K_SYSCALL_BAD
    17d8:	f240 1c0b 	movw	ip, #267	; 0x10b
    cmp r6, ip
    17dc:	4566      	cmp	r6, ip
    bne valid_syscall
    17de:	d103      	bne.n	17e8 <valid_syscall>

    /* BAD SYSCALL path */
    /* fixup stack frame on the privileged stack, adding ssf */
    mov ip, sp
    17e0:	46ec      	mov	ip, sp
    push {r4,r5,ip,lr}
    17e2:	e92d 5030 	stmdb	sp!, {r4, r5, ip, lr}
    b dispatch_syscall
    17e6:	e000      	b.n	17ea <dispatch_syscall>

000017e8 <valid_syscall>:

valid_syscall:
    /* push args to complete stack frame */
    push {r4,r5}
    17e8:	b430      	push	{r4, r5}

000017ea <dispatch_syscall>:

dispatch_syscall:
    ldr ip, =_k_syscall_table
    17ea:	f8df c05c 	ldr.w	ip, [pc, #92]	; 1848 <dispatch_syscall+0x5e>
    lsl r6, #2
    17ee:	ea4f 0686 	mov.w	r6, r6, lsl #2
    add ip, r6
    17f2:	44b4      	add	ip, r6
    ldr ip, [ip]	/* load table address */
    17f4:	f8dc c000 	ldr.w	ip, [ip]
    /* execute function from dispatch table */
    blx ip
    17f8:	47e0      	blx	ip

    /* restore LR */
    ldr lr, [sp,#12]
    17fa:	f8dd e00c 	ldr.w	lr, [sp, #12]
    /* Restore r0 */
    mov r0, ip

#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    /* set stack back to unprivileged stack */
    ldr ip, [sp,#8]
    17fe:	f8dd c008 	ldr.w	ip, [sp, #8]
    msr PSP, ip
    1802:	f38c 8809 	msr	PSP, ip
    /* Restore interrupt lock status */
    msr BASEPRI, r2
    isb
#endif

    push {r0, r1}
    1806:	b403      	push	{r0, r1}
    mrs r2, CONTROL
    orrs r2, r2, r3
    msr CONTROL, r2
    pop {r2, r3}
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    ldr r0, =_kernel
    1808:	480e      	ldr	r0, [pc, #56]	; (1844 <dispatch_syscall+0x5a>)
    ldr r0, [r0, #_kernel_offset_to_current]
    180a:	6880      	ldr	r0, [r0, #8]
    ldr r1, [r0, #_thread_offset_to_mode]
    180c:	f8d0 1094 	ldr.w	r1, [r0, #148]	; 0x94
    orrs r1, r1, #1
    1810:	f051 0101 	orrs.w	r1, r1, #1
    /* Store (unprivileged) mode in thread's mode state variable */
    str r1, [r0, #_thread_offset_to_mode]
    1814:	f8c0 1094 	str.w	r1, [r0, #148]	; 0x94
    dsb
    1818:	f3bf 8f4f 	dsb	sy
    /* drop privileges by setting bit 0 in CONTROL */
    mrs ip, CONTROL
    181c:	f3ef 8c14 	mrs	ip, CONTROL
    orrs ip, ip, #1
    1820:	f05c 0c01 	orrs.w	ip, ip, #1
    msr CONTROL, ip
    1824:	f38c 8814 	msr	CONTROL, ip

    /* ISB is not strictly necessary here (stack pointer is not being
     * touched), but it's recommended to avoid executing pre-fetched
     * instructions with the previous privilege.
     */
    isb
    1828:	f3bf 8f6f 	isb	sy
    pop {r0, r1}
    182c:	bc03      	pop	{r0, r1}

    /* Zero out volatile (caller-saved) registers so as to not leak state from
     * kernel mode. The C calling convention for the syscall handler will
     * restore the others to original values.
     */
    mov r1, #0
    182e:	f04f 0100 	mov.w	r1, #0
    mov r2, #0
    1832:	f04f 0200 	mov.w	r2, #0
    mov r3, #0
    1836:	f04f 0300 	mov.w	r3, #0

    /*
     * return back to original function that called SVC, add 1 to force thumb
     * mode
     */
    mov ip, r8
    183a:	46c4      	mov	ip, r8
    orrs ip, ip, #1
    183c:	f05c 0c01 	orrs.w	ip, ip, #1

#endif
    bx ip
    1840:	4760      	bx	ip
    1842:	0000      	.short	0x0000
    ldr ip, =_kernel
    1844:	20000524 	.word	0x20000524
    ldr ip, =_k_syscall_table
    1848:	00006bd4 	.word	0x00006bd4

0000184c <arch_user_string_nlen>:

/*
 * size_t arch_user_string_nlen(const char *s, size_t maxsize, int *err_arg)
 */
SECTION_FUNC(TEXT, arch_user_string_nlen)
    push {r0, r1, r2, r4, r5, lr}
    184c:	b537      	push	{r0, r1, r2, r4, r5, lr}

    /* sp+4 is error value, init to -1 */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    ldr r3, =-1
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    mov.w r3, #-1
    184e:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
#endif
    str	r3, [sp, #4]
    1852:	9301      	str	r3, [sp, #4]

    /* Perform string length calculation */
    movs r3, #0		/* r3 is the counter */
    1854:	2300      	movs	r3, #0

00001856 <z_arm_user_string_nlen_fault_start>:

strlen_loop:
z_arm_user_string_nlen_fault_start:
    /* r0 contains the string. r5 = *(r0 + r3]). This could fault. */
    ldrb r5, [r0, r3]
    1856:	5cc5      	ldrb	r5, [r0, r3]

00001858 <z_arm_user_string_nlen_fault_end>:
z_arm_user_string_nlen_fault_end:
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cmp r5, #0
    beq strlen_done
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    cbz	r5, strlen_done
    1858:	b11d      	cbz	r5, 1862 <strlen_done>
#endif
    cmp	r3, r1
    185a:	428b      	cmp	r3, r1
    beq.n strlen_done
    185c:	d001      	beq.n	1862 <strlen_done>

    adds r3, #1
    185e:	3301      	adds	r3, #1
    b.n	strlen_loop
    1860:	e7f9      	b.n	1856 <z_arm_user_string_nlen_fault_start>

00001862 <strlen_done>:

strlen_done:
    /* Move length calculation from r3 to r0 (return value register) */
    mov	r0, r3
    1862:	4618      	mov	r0, r3

    /* Clear error value since we succeeded */
    movs r1, #0
    1864:	2100      	movs	r1, #0
    str	r1, [sp, #4]
    1866:	9101      	str	r1, [sp, #4]

00001868 <z_arm_user_string_nlen_fixup>:

z_arm_user_string_nlen_fixup:
    /* Write error value to err pointer parameter */
    ldr	r1, [sp, #4]
    1868:	9901      	ldr	r1, [sp, #4]
    str	r1, [r2, #0]
    186a:	6011      	str	r1, [r2, #0]

    add	sp, #12
    186c:	b003      	add	sp, #12
    pop	{r4, r5, pc}
    186e:	bd30      	pop	{r4, r5, pc}

00001870 <__start>:
 * search for a __start symbol instead, so create that alias here.
 */
SECTION_SUBSEC_FUNC(TEXT,_reset_section,__start)

#if defined(CONFIG_PLATFORM_SPECIFIC_INIT)
    bl z_platform_init
    1870:	f004 f98e 	bl	5b90 <z_platform_init>

    /* lock interrupts: will get unlocked when switch to main task */
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
    cpsid i
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
    movs.n r0, #_EXC_IRQ_DEFAULT_PRIO
    1874:	2020      	movs	r0, #32
    msr BASEPRI, r0
    1876:	f380 8811 	msr	BASEPRI, r0

    /*
     * Set PSP and use it to boot without using MSP, so that it
     * gets set to z_interrupt_stacks during initialization.
     */
    ldr r0, =z_interrupt_stacks
    187a:	4808      	ldr	r0, [pc, #32]	; (189c <__start+0x2c>)
    ldr r1, =CONFIG_ISR_STACK_SIZE
    187c:	f44f 6100 	mov.w	r1, #2048	; 0x800
    adds r0, r0, r1
    1880:	1840      	adds	r0, r0, r1
    msr PSP, r0
    1882:	f380 8809 	msr	PSP, r0
    mrs r0, CONTROL
    1886:	f3ef 8014 	mrs	r0, CONTROL
    movs r1, #2
    188a:	2102      	movs	r1, #2
    orrs r0, r1 /* CONTROL_SPSEL_Msk */
    188c:	4308      	orrs	r0, r1
    msr CONTROL, r0
    188e:	f380 8814 	msr	CONTROL, r0
    /*
     * When changing the stack pointer, software must use an ISB instruction
     * immediately after the MSR instruction. This ensures that instructions
     * after the ISB instruction execute using the new stack pointer.
     */
    isb
    1892:	f3bf 8f6f 	isb	sy
    /*
     * 'bl' jumps the furthest of the branch instructions that are
     * supported on all platforms. So it is used when jumping to z_arm_prep_c
     * (even though we do not intend to return).
     */
    bl z_arm_prep_c
    1896:	f7ff ff0b 	bl	16b0 <z_arm_prep_c>
    189a:	0000      	.short	0x0000
    ldr r0, =z_interrupt_stacks
    189c:	20001540 	.word	0x20001540

000018a0 <z_arm_bus_fault>:
#else
#error Unknown ARM architecture
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
SECTION_SUBSEC_FUNC(TEXT,__fault,z_arm_exc_spurious)

	mrs r0, MSP
    18a0:	f3ef 8008 	mrs	r0, MSP
	mrs r1, PSP
    18a4:	f3ef 8109 	mrs	r1, PSP
	mov r2, lr /* EXC_RETURN */
    18a8:	4672      	mov	r2, lr

	push {r0, lr}
    18aa:	b501      	push	{r0, lr}

	bl z_arm_fault
    18ac:	f000 f8dc 	bl	1a68 <z_arm_fault>

	pop {r0, pc}
    18b0:	bd01      	pop	{r0, pc}
    18b2:	bf00      	nop

000018b4 <mem_manage_fault>:
 *
 * @return error code to identify the fatal error reason
 */
static uint32_t mem_manage_fault(z_arch_esf_t *esf, int from_hard_fault,
			      bool *recoverable)
{
    18b4:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	uint32_t mmfar = -EINVAL;

	PR_FAULT_INFO("***** MPU FAULT *****");

	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    18b6:	4c2a      	ldr	r4, [pc, #168]	; (1960 <mem_manage_fault+0xac>)
{
    18b8:	4605      	mov	r5, r0
    18ba:	4616      	mov	r6, r2
	return arch_is_user_context();
    18bc:	f004 f8d2 	bl	5a64 <arch_is_user_context>
	if ((SCB->CFSR & SCB_CFSR_MSTKERR_Msk) != 0) {
    18c0:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18c2:	06d8      	lsls	r0, r3, #27
    18c4:	d501      	bpl.n	18ca <mem_manage_fault+0x16>
    18c6:	f004 f8cd 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  Stacking error (context area might be"
			" not valid)");
	}
	if ((SCB->CFSR & SCB_CFSR_MUNSTKERR_Msk) != 0) {
    18ca:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18cc:	071a      	lsls	r2, r3, #28
    18ce:	d501      	bpl.n	18d4 <mem_manage_fault+0x20>
    18d0:	f004 f8c8 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  Unstacking error");
	}
	if ((SCB->CFSR & SCB_CFSR_DACCVIOL_Msk) != 0) {
    18d4:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18d6:	079b      	lsls	r3, r3, #30
    18d8:	d530      	bpl.n	193c <mem_manage_fault+0x88>
    18da:	f004 f8c3 	bl	5a64 <arch_is_user_context>
		 * The MMFAR address is valid only if this bit is 1.
		 *
		 * Software must follow this sequence because another higher
		 * priority exception might change the MMFAR value.
		 */
		mmfar = SCB->MMFAR;
    18de:	6b62      	ldr	r2, [r4, #52]	; 0x34

		if ((SCB->CFSR & SCB_CFSR_MMARVALID_Msk) != 0) {
    18e0:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18e2:	0618      	lsls	r0, r3, #24
    18e4:	d506      	bpl.n	18f4 <mem_manage_fault+0x40>
    18e6:	f004 f8bd 	bl	5a64 <arch_is_user_context>
			PR_EXC("  MMFAR Address: 0x%x", mmfar);
			if (from_hard_fault) {
    18ea:	b119      	cbz	r1, 18f4 <mem_manage_fault+0x40>
				/* clear SCB_MMAR[VALID] to reset */
				SCB->CFSR &= ~SCB_CFSR_MMARVALID_Msk;
    18ec:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    18ee:	f023 0380 	bic.w	r3, r3, #128	; 0x80
    18f2:	62a3      	str	r3, [r4, #40]	; 0x28
			}
		}
	}
	if ((SCB->CFSR & SCB_CFSR_IACCVIOL_Msk) != 0) {
    18f4:	491a      	ldr	r1, [pc, #104]	; (1960 <mem_manage_fault+0xac>)
    18f6:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    18f8:	07db      	lsls	r3, r3, #31
    18fa:	d501      	bpl.n	1900 <mem_manage_fault+0x4c>
    18fc:	f004 f8b2 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  Instruction Access Violation");
	}
#if defined(CONFIG_ARMV7_M_ARMV8_M_FP)
	if ((SCB->CFSR & SCB_CFSR_MLSPERR_Msk) != 0) {
    1900:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1902:	069c      	lsls	r4, r3, #26
    1904:	d501      	bpl.n	190a <mem_manage_fault+0x56>
    1906:	f004 f8ad 	bl	5a64 <arch_is_user_context>
	 * if the memory violation error is a stack corruption.
	 *
	 * By design, being a Stacking MemManage fault is a necessary
	 * and sufficient condition for a thread stack corruption.
	 */
	if (SCB->CFSR & SCB_CFSR_MSTKERR_Msk) {
    190a:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    190c:	06d8      	lsls	r0, r3, #27
    190e:	d418      	bmi.n	1942 <mem_manage_fault+0x8e>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    1910:	2000      	movs	r0, #0
		"Stacking error without stack guard / User-mode support\n");
#endif /* CONFIG_MPU_STACK_GUARD || CONFIG_USERSPACE */
	}

	/* clear MMFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_MEMFAULTSR_Msk;
    1912:	4a13      	ldr	r2, [pc, #76]	; (1960 <mem_manage_fault+0xac>)
    1914:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1916:	f043 03ff 	orr.w	r3, r3, #255	; 0xff
    191a:	6293      	str	r3, [r2, #40]	; 0x28
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    191c:	4b11      	ldr	r3, [pc, #68]	; (1964 <mem_manage_fault+0xb0>)
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    191e:	69aa      	ldr	r2, [r5, #24]
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1920:	f023 0301 	bic.w	r3, r3, #1
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1924:	4293      	cmp	r3, r2
    1926:	d819      	bhi.n	195c <mem_manage_fault+0xa8>
    1928:	4b0f      	ldr	r3, [pc, #60]	; (1968 <mem_manage_fault+0xb4>)
    192a:	f023 0301 	bic.w	r3, r3, #1
    192e:	4293      	cmp	r3, r2
    1930:	d914      	bls.n	195c <mem_manage_fault+0xa8>
			esf->basic.pc = (uint32_t)(exceptions[i].fixup);
    1932:	4b0e      	ldr	r3, [pc, #56]	; (196c <mem_manage_fault+0xb8>)
    1934:	61ab      	str	r3, [r5, #24]
			return true;
    1936:	2301      	movs	r3, #1

	/* Assess whether system shall ignore/recover from this MPU fault. */
	*recoverable = memory_fault_recoverable(esf);
    1938:	7033      	strb	r3, [r6, #0]

	return reason;
}
    193a:	bd70      	pop	{r4, r5, r6, pc}
	uint32_t mmfar = -EINVAL;
    193c:	f06f 0215 	mvn.w	r2, #21
    1940:	e7d8      	b.n	18f4 <mem_manage_fault+0x40>
		if (SCB->ICSR & SCB_ICSR_RETTOBASE_Msk) {
    1942:	684b      	ldr	r3, [r1, #4]
    1944:	051b      	lsls	r3, r3, #20
    1946:	d5e3      	bpl.n	1910 <mem_manage_fault+0x5c>
			uint32_t min_stack_ptr = z_check_thread_stack_fail(mmfar,
    1948:	4629      	mov	r1, r5
    194a:	4610      	mov	r0, r2
    194c:	f7ff fe5a 	bl	1604 <z_check_thread_stack_fail>
			if (min_stack_ptr) {
    1950:	2800      	cmp	r0, #0
    1952:	d0dd      	beq.n	1910 <mem_manage_fault+0x5c>
  __ASM volatile ("MSR psp, %0" : : "r" (topOfProcStack) : );
    1954:	f380 8809 	msr	PSP, r0
				reason = K_ERR_STACK_CHK_FAIL;
    1958:	2002      	movs	r0, #2
    195a:	e7da      	b.n	1912 <mem_manage_fault+0x5e>
	return false;
    195c:	2300      	movs	r3, #0
    195e:	e7eb      	b.n	1938 <mem_manage_fault+0x84>
    1960:	e000ed00 	.word	0xe000ed00
    1964:	00001857 	.word	0x00001857
    1968:	00001859 	.word	0x00001859
    196c:	00001869 	.word	0x00001869

00001970 <usage_fault.isra.0>:
 *
 * See z_arm_fault_dump() for example.
 *
 * @return error code to identify the fatal error reason
 */
static uint32_t usage_fault(const z_arch_esf_t *esf)
    1970:	b508      	push	{r3, lr}
    1972:	f004 f877 	bl	5a64 <arch_is_user_context>
	uint32_t reason = K_ERR_CPU_EXCEPTION;

	PR_FAULT_INFO("***** USAGE FAULT *****");

	/* bits are sticky: they stack and must be reset */
	if ((SCB->CFSR & SCB_CFSR_DIVBYZERO_Msk) != 0) {
    1976:	4a14      	ldr	r2, [pc, #80]	; (19c8 <usage_fault.isra.0+0x58>)
    1978:	6a93      	ldr	r3, [r2, #40]	; 0x28
    197a:	0198      	lsls	r0, r3, #6
    197c:	d501      	bpl.n	1982 <usage_fault.isra.0+0x12>
    197e:	f004 f871 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  Division by zero");
	}
	if ((SCB->CFSR & SCB_CFSR_UNALIGNED_Msk) != 0) {
    1982:	6a93      	ldr	r3, [r2, #40]	; 0x28
    1984:	01d9      	lsls	r1, r3, #7
    1986:	d501      	bpl.n	198c <usage_fault.isra.0+0x1c>
    1988:	f004 f86c 	bl	5a64 <arch_is_user_context>
		 */
		reason = K_ERR_STACK_CHK_FAIL;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
	}
#endif /* CONFIG_ARMV8_M_MAINLINE */
	if ((SCB->CFSR & SCB_CFSR_NOCP_Msk) != 0) {
    198c:	6a93      	ldr	r3, [r2, #40]	; 0x28
    198e:	031b      	lsls	r3, r3, #12
    1990:	d501      	bpl.n	1996 <usage_fault.isra.0+0x26>
    1992:	f004 f867 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  No coprocessor instructions");
	}
	if ((SCB->CFSR & SCB_CFSR_INVPC_Msk) != 0) {
    1996:	4a0c      	ldr	r2, [pc, #48]	; (19c8 <usage_fault.isra.0+0x58>)
    1998:	6a93      	ldr	r3, [r2, #40]	; 0x28
    199a:	0358      	lsls	r0, r3, #13
    199c:	d501      	bpl.n	19a2 <usage_fault.isra.0+0x32>
    199e:	f004 f861 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  Illegal load of EXC_RETURN into PC");
	}
	if ((SCB->CFSR & SCB_CFSR_INVSTATE_Msk) != 0) {
    19a2:	6a93      	ldr	r3, [r2, #40]	; 0x28
    19a4:	0399      	lsls	r1, r3, #14
    19a6:	d501      	bpl.n	19ac <usage_fault.isra.0+0x3c>
    19a8:	f004 f85c 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  Illegal use of the EPSR");
	}
	if ((SCB->CFSR & SCB_CFSR_UNDEFINSTR_Msk) != 0) {
    19ac:	6a93      	ldr	r3, [r2, #40]	; 0x28
    19ae:	03db      	lsls	r3, r3, #15
    19b0:	d501      	bpl.n	19b6 <usage_fault.isra.0+0x46>
    19b2:	f004 f857 	bl	5a64 <arch_is_user_context>
		PR_FAULT_INFO("  Attempt to execute undefined instruction");
	}

	/* clear UFSR sticky bits */
	SCB->CFSR |= SCB_CFSR_USGFAULTSR_Msk;
    19b6:	4a04      	ldr	r2, [pc, #16]	; (19c8 <usage_fault.isra.0+0x58>)
    19b8:	6a93      	ldr	r3, [r2, #40]	; 0x28
    19ba:	ea6f 4303 	mvn.w	r3, r3, lsl #16
    19be:	ea6f 4313 	mvn.w	r3, r3, lsr #16
    19c2:	6293      	str	r3, [r2, #40]	; 0x28

	return reason;
}
    19c4:	2000      	movs	r0, #0
    19c6:	bd08      	pop	{r3, pc}
    19c8:	e000ed00 	.word	0xe000ed00

000019cc <bus_fault>:
{
    19cc:	b538      	push	{r3, r4, r5, lr}
	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    19ce:	4c22      	ldr	r4, [pc, #136]	; (1a58 <bus_fault+0x8c>)
{
    19d0:	4605      	mov	r5, r0
    19d2:	f004 f847 	bl	5a64 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_STKERR_Msk) {
    19d6:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19d8:	04d8      	lsls	r0, r3, #19
    19da:	d501      	bpl.n	19e0 <bus_fault+0x14>
    19dc:	f004 f842 	bl	5a64 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_UNSTKERR_Msk) {
    19e0:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19e2:	051b      	lsls	r3, r3, #20
    19e4:	d501      	bpl.n	19ea <bus_fault+0x1e>
    19e6:	f004 f83d 	bl	5a64 <arch_is_user_context>
	if (SCB->CFSR & SCB_CFSR_PRECISERR_Msk) {
    19ea:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19ec:	0598      	lsls	r0, r3, #22
    19ee:	d50c      	bpl.n	1a0a <bus_fault+0x3e>
    19f0:	f004 f838 	bl	5a64 <arch_is_user_context>
		STORE_xFAR(bfar, SCB->BFAR);
    19f4:	6ba3      	ldr	r3, [r4, #56]	; 0x38
		if ((SCB->CFSR & SCB_CFSR_BFARVALID_Msk) != 0) {
    19f6:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    19f8:	041b      	lsls	r3, r3, #16
    19fa:	d506      	bpl.n	1a0a <bus_fault+0x3e>
    19fc:	f004 f832 	bl	5a64 <arch_is_user_context>
			if (from_hard_fault) {
    1a00:	b119      	cbz	r1, 1a0a <bus_fault+0x3e>
				SCB->CFSR &= ~SCB_CFSR_BFARVALID_Msk;
    1a02:	6aa3      	ldr	r3, [r4, #40]	; 0x28
    1a04:	f423 4300 	bic.w	r3, r3, #32768	; 0x8000
    1a08:	62a3      	str	r3, [r4, #40]	; 0x28
	if (SCB->CFSR & SCB_CFSR_IMPRECISERR_Msk) {
    1a0a:	4913      	ldr	r1, [pc, #76]	; (1a58 <bus_fault+0x8c>)
    1a0c:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a0e:	055c      	lsls	r4, r3, #21
    1a10:	d501      	bpl.n	1a16 <bus_fault+0x4a>
    1a12:	f004 f827 	bl	5a64 <arch_is_user_context>
	if ((SCB->CFSR & SCB_CFSR_IBUSERR_Msk) != 0) {
    1a16:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a18:	05d8      	lsls	r0, r3, #23
    1a1a:	d516      	bpl.n	1a4a <bus_fault+0x7e>
    1a1c:	f004 f822 	bl	5a64 <arch_is_user_context>
	SCB->CFSR |= SCB_CFSR_BUSFAULTSR_Msk;
    1a20:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a22:	f443 437f 	orr.w	r3, r3, #65280	; 0xff00
    1a26:	628b      	str	r3, [r1, #40]	; 0x28
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1a28:	4b0c      	ldr	r3, [pc, #48]	; (1a5c <bus_fault+0x90>)
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1a2a:	69a9      	ldr	r1, [r5, #24]
		uint32_t start = (uint32_t)exceptions[i].start & ~0x1;
    1a2c:	f023 0301 	bic.w	r3, r3, #1
		if (esf->basic.pc >= start && esf->basic.pc < end) {
    1a30:	428b      	cmp	r3, r1
    1a32:	d80e      	bhi.n	1a52 <bus_fault+0x86>
    1a34:	4b0a      	ldr	r3, [pc, #40]	; (1a60 <bus_fault+0x94>)
    1a36:	f023 0301 	bic.w	r3, r3, #1
    1a3a:	428b      	cmp	r3, r1
    1a3c:	d909      	bls.n	1a52 <bus_fault+0x86>
			esf->basic.pc = (uint32_t)(exceptions[i].fixup);
    1a3e:	4b09      	ldr	r3, [pc, #36]	; (1a64 <bus_fault+0x98>)
    1a40:	61ab      	str	r3, [r5, #24]
			return true;
    1a42:	2301      	movs	r3, #1
	*recoverable = memory_fault_recoverable(esf);
    1a44:	7013      	strb	r3, [r2, #0]
}
    1a46:	2000      	movs	r0, #0
    1a48:	bd38      	pop	{r3, r4, r5, pc}
	} else if (SCB->CFSR & SCB_CFSR_LSPERR_Msk) {
    1a4a:	6a8b      	ldr	r3, [r1, #40]	; 0x28
    1a4c:	049b      	lsls	r3, r3, #18
    1a4e:	d4e5      	bmi.n	1a1c <bus_fault+0x50>
    1a50:	e7e6      	b.n	1a20 <bus_fault+0x54>
	return false;
    1a52:	2300      	movs	r3, #0
    1a54:	e7f6      	b.n	1a44 <bus_fault+0x78>
    1a56:	bf00      	nop
    1a58:	e000ed00 	.word	0xe000ed00
    1a5c:	00001857 	.word	0x00001857
    1a60:	00001859 	.word	0x00001859
    1a64:	00001869 	.word	0x00001869

00001a68 <z_arm_fault>:
 * @param psp PSP value immediately after the exception occurred
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 *
 */
void z_arm_fault(uint32_t msp, uint32_t psp, uint32_t exc_return)
{
    1a68:	b570      	push	{r4, r5, r6, lr}
	uint32_t reason = K_ERR_CPU_EXCEPTION;
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    1a6a:	4b3c      	ldr	r3, [pc, #240]	; (1b5c <z_arm_fault+0xf4>)
    1a6c:	685c      	ldr	r4, [r3, #4]
{
    1a6e:	b08a      	sub	sp, #40	; 0x28
    1a70:	460d      	mov	r5, r1
	int fault = SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk;
    1a72:	f3c4 0408 	ubfx	r4, r4, #0, #9
    1a76:	2600      	movs	r6, #0
    1a78:	f386 8811 	msr	BASEPRI, r6
    1a7c:	f3bf 8f6f 	isb	sy
	if ((exc_return & EXC_RETURN_INDICATOR_PREFIX) !=
    1a80:	f002 437f 	and.w	r3, r2, #4278190080	; 0xff000000
    1a84:	f1b3 4f7f 	cmp.w	r3, #4278190080	; 0xff000000
    1a88:	d105      	bne.n	1a96 <z_arm_fault+0x2e>
	if ((exc_return & EXC_RETURN_MODE_THREAD) &&
    1a8a:	f002 030c 	and.w	r3, r2, #12
    1a8e:	2b08      	cmp	r3, #8
    1a90:	d103      	bne.n	1a9a <z_arm_fault+0x32>
    1a92:	f003 ffe7 	bl	5a64 <arch_is_user_context>
		return NULL;
    1a96:	4635      	mov	r5, r6
    1a98:	e003      	b.n	1aa2 <z_arm_fault+0x3a>
		if (exc_return & EXC_RETURN_MODE_THREAD) {
    1a9a:	0712      	lsls	r2, r2, #28
    1a9c:	d401      	bmi.n	1aa2 <z_arm_fault+0x3a>
			ptr_esf = (z_arch_esf_t *)msp;
    1a9e:	4605      	mov	r5, r0
			*nested_exc = true;
    1aa0:	2601      	movs	r6, #1
	*recoverable = false;
    1aa2:	2200      	movs	r2, #0
    1aa4:	1ee3      	subs	r3, r4, #3
    1aa6:	f88d 2007 	strb.w	r2, [sp, #7]
	switch (fault) {
    1aaa:	2b03      	cmp	r3, #3
    1aac:	d80c      	bhi.n	1ac8 <z_arm_fault+0x60>
    1aae:	e8df f003 	tbb	[pc, r3]
    1ab2:	4802      	.short	0x4802
    1ab4:	454c      	.short	0x454c
    1ab6:	f003 ffd5 	bl	5a64 <arch_is_user_context>
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    1aba:	4b28      	ldr	r3, [pc, #160]	; (1b5c <z_arm_fault+0xf4>)
	*recoverable = false;
    1abc:	f88d 2007 	strb.w	r2, [sp, #7]
	if ((SCB->HFSR & SCB_HFSR_VECTTBL_Msk) != 0) {
    1ac0:	6adc      	ldr	r4, [r3, #44]	; 0x2c
    1ac2:	f014 0402 	ands.w	r4, r4, #2
    1ac6:	d003      	beq.n	1ad0 <z_arm_fault+0x68>
    1ac8:	f003 ffcc 	bl	5a64 <arch_is_user_context>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
    1acc:	2400      	movs	r4, #0
}
    1ace:	e00e      	b.n	1aee <z_arm_fault+0x86>
	} else if ((SCB->HFSR & SCB_HFSR_FORCED_Msk) != 0) {
    1ad0:	6adb      	ldr	r3, [r3, #44]	; 0x2c
    1ad2:	005b      	lsls	r3, r3, #1
    1ad4:	d50b      	bpl.n	1aee <z_arm_fault+0x86>
    1ad6:	f003 ffc5 	bl	5a64 <arch_is_user_context>
		if (SCB_MMFSR != 0) {
    1ada:	4b21      	ldr	r3, [pc, #132]	; (1b60 <z_arm_fault+0xf8>)
    1adc:	781b      	ldrb	r3, [r3, #0]
    1ade:	b1f3      	cbz	r3, 1b1e <z_arm_fault+0xb6>
			reason = mem_manage_fault(esf, 1, recoverable);
    1ae0:	f10d 0207 	add.w	r2, sp, #7
    1ae4:	2101      	movs	r1, #1
		reason = mem_manage_fault(esf, 0, recoverable);
    1ae6:	4628      	mov	r0, r5
    1ae8:	f7ff fee4 	bl	18b4 <mem_manage_fault>
		reason = usage_fault(esf);
    1aec:	4604      	mov	r4, r0
	 esf = get_esf(msp, psp, exc_return, &nested_exc);
	__ASSERT(esf != NULL,
		"ESF could not be retrieved successfully. Shall never occur.");

	reason = fault_handle(esf, fault, &recoverable);
	if (recoverable) {
    1aee:	f89d 3007 	ldrb.w	r3, [sp, #7]
    1af2:	b993      	cbnz	r3, 1b1a <z_arm_fault+0xb2>
		return;
	}

	/* Copy ESF */
	memcpy(&esf_copy, esf, sizeof(z_arch_esf_t));
    1af4:	2220      	movs	r2, #32
    1af6:	4629      	mov	r1, r5
    1af8:	a802      	add	r0, sp, #8
    1afa:	f003 ffee 	bl	5ada <memcpy>
	/* Overwrite stacked IPSR to mark a nested exception,
	 * or a return to Thread mode. Note that this may be
	 * required, if the retrieved ESF contents are invalid
	 * due to, for instance, a stacking error.
	 */
	if (nested_exc) {
    1afe:	9b09      	ldr	r3, [sp, #36]	; 0x24
    1b00:	b33e      	cbz	r6, 1b52 <z_arm_fault+0xea>
		if ((esf_copy.basic.xpsr & IPSR_ISR_Msk) == 0) {
    1b02:	f3c3 0208 	ubfx	r2, r3, #0, #9
    1b06:	b922      	cbnz	r2, 1b12 <z_arm_fault+0xaa>
			esf_copy.basic.xpsr |= IPSR_ISR_Msk;
    1b08:	ea6f 2353 	mvn.w	r3, r3, lsr #9
    1b0c:	ea6f 2343 	mvn.w	r3, r3, lsl #9
		}
	} else {
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    1b10:	9309      	str	r3, [sp, #36]	; 0x24
	}

	z_arm_fatal_error(reason, &esf_copy);
    1b12:	a902      	add	r1, sp, #8
    1b14:	4620      	mov	r0, r4
    1b16:	f003 ff74 	bl	5a02 <z_arm_fatal_error>
}
    1b1a:	b00a      	add	sp, #40	; 0x28
    1b1c:	bd70      	pop	{r4, r5, r6, pc}
		} else if (SCB_BFSR != 0) {
    1b1e:	4b11      	ldr	r3, [pc, #68]	; (1b64 <z_arm_fault+0xfc>)
    1b20:	781b      	ldrb	r3, [r3, #0]
    1b22:	b133      	cbz	r3, 1b32 <z_arm_fault+0xca>
			reason = bus_fault(esf, 1, recoverable);
    1b24:	f10d 0207 	add.w	r2, sp, #7
    1b28:	2101      	movs	r1, #1
		reason = bus_fault(esf, 0, recoverable);
    1b2a:	4628      	mov	r0, r5
    1b2c:	f7ff ff4e 	bl	19cc <bus_fault>
    1b30:	e7dc      	b.n	1aec <z_arm_fault+0x84>
		} else if (SCB_UFSR != 0) {
    1b32:	4b0d      	ldr	r3, [pc, #52]	; (1b68 <z_arm_fault+0x100>)
    1b34:	881b      	ldrh	r3, [r3, #0]
    1b36:	b29b      	uxth	r3, r3
    1b38:	2b00      	cmp	r3, #0
    1b3a:	d0d8      	beq.n	1aee <z_arm_fault+0x86>
		reason = usage_fault(esf);
    1b3c:	f7ff ff18 	bl	1970 <usage_fault.isra.0>
    1b40:	e7d4      	b.n	1aec <z_arm_fault+0x84>
		reason = mem_manage_fault(esf, 0, recoverable);
    1b42:	f10d 0207 	add.w	r2, sp, #7
    1b46:	2100      	movs	r1, #0
    1b48:	e7cd      	b.n	1ae6 <z_arm_fault+0x7e>
		reason = bus_fault(esf, 0, recoverable);
    1b4a:	f10d 0207 	add.w	r2, sp, #7
    1b4e:	2100      	movs	r1, #0
    1b50:	e7eb      	b.n	1b2a <z_arm_fault+0xc2>
		esf_copy.basic.xpsr &= ~(IPSR_ISR_Msk);
    1b52:	f423 73ff 	bic.w	r3, r3, #510	; 0x1fe
    1b56:	f023 0301 	bic.w	r3, r3, #1
    1b5a:	e7d9      	b.n	1b10 <z_arm_fault+0xa8>
    1b5c:	e000ed00 	.word	0xe000ed00
    1b60:	e000ed28 	.word	0xe000ed28
    1b64:	e000ed29 	.word	0xe000ed29
    1b68:	e000ed2a 	.word	0xe000ed2a

00001b6c <z_arm_fault_init>:
 */
void z_arm_fault_init(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	SCB->CCR |= SCB_CCR_DIV_0_TRP_Msk;
    1b6c:	4a02      	ldr	r2, [pc, #8]	; (1b78 <z_arm_fault_init+0xc>)
    1b6e:	6953      	ldr	r3, [r2, #20]
    1b70:	f043 0310 	orr.w	r3, r3, #16
    1b74:	6153      	str	r3, [r2, #20]
	 * Stack to attempt to descend into secure region, in which case a
	 * Secure Hard Fault will occur and we can track the fault from there.
	 */
	SCB->CCR |= SCB_CCR_STKOFHFNMIGN_Msk;
#endif /* CONFIG_BUILTIN_STACK_GUARD */
}
    1b76:	4770      	bx	lr
    1b78:	e000ed00 	.word	0xe000ed00

00001b7c <z_arm_exc_exit>:
 */

SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)

#ifdef CONFIG_PREEMPT_ENABLED
	ldr r3, =_kernel
    1b7c:	4b04      	ldr	r3, [pc, #16]	; (1b90 <_EXIT_EXC+0x2>)

	ldr r1, [r3, #_kernel_offset_to_current]
    1b7e:	6899      	ldr	r1, [r3, #8]
	ldr r0, [r3, #_kernel_offset_to_ready_q_cache]
    1b80:	6a58      	ldr	r0, [r3, #36]	; 0x24
	cmp r0, r1
    1b82:	4288      	cmp	r0, r1
	beq _EXIT_EXC
    1b84:	d003      	beq.n	1b8e <_EXIT_EXC>

	/* context switch required, pend the PendSV exception */
	ldr r1, =_SCS_ICSR
    1b86:	4903      	ldr	r1, [pc, #12]	; (1b94 <_EXIT_EXC+0x6>)
	ldr r2, =_SCS_ICSR_PENDSV
    1b88:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
	str r2, [r1]
    1b8c:	600a      	str	r2, [r1, #0]

00001b8e <_EXIT_EXC>:
#else
	pop {r0, lr}
#endif /* CONFIG_ARMV6_M_ARMV8_M_BASELINE */
#endif /* CONFIG_STACK_SENTINEL */

	bx lr
    1b8e:	4770      	bx	lr
	ldr r3, =_kernel
    1b90:	20000524 	.word	0x20000524
	ldr r1, =_SCS_ICSR
    1b94:	e000ed04 	.word	0xe000ed04

00001b98 <z_arm_interrupt_init>:
    1b98:	4804      	ldr	r0, [pc, #16]	; (1bac <z_arm_interrupt_init+0x14>)
 * @return N/A
 */

void z_arm_interrupt_init(void)
{
	int irq = 0;
    1b9a:	2300      	movs	r3, #0
    1b9c:	2120      	movs	r1, #32
    1b9e:	18c2      	adds	r2, r0, r3

	for (; irq < CONFIG_NUM_IRQS; irq++) {
    1ba0:	3301      	adds	r3, #1
    1ba2:	2b27      	cmp	r3, #39	; 0x27
    1ba4:	f882 1300 	strb.w	r1, [r2, #768]	; 0x300
    1ba8:	d1f9      	bne.n	1b9e <z_arm_interrupt_init+0x6>
		NVIC_SetPriority((IRQn_Type)irq, _IRQ_PRIO_OFFSET);
	}
}
    1baa:	4770      	bx	lr
    1bac:	e000e100 	.word	0xe000e100

00001bb0 <z_impl_k_thread_abort>:
#include <sys/__assert.h>

extern void z_thread_single_abort(struct k_thread *thread);

void z_impl_k_thread_abort(k_tid_t thread)
{
    1bb0:	b538      	push	{r3, r4, r5, lr}
    1bb2:	4604      	mov	r4, r0
	__asm__ volatile(
    1bb4:	f04f 0320 	mov.w	r3, #32
    1bb8:	f3ef 8511 	mrs	r5, BASEPRI
    1bbc:	f383 8811 	msr	BASEPRI, r3
    1bc0:	f3bf 8f6f 	isb	sy
	key = irq_lock();

	__ASSERT(!(thread->base.user_options & K_ESSENTIAL),
		 "essential thread aborted");

	z_thread_single_abort(thread);
    1bc4:	f001 ff12 	bl	39ec <z_thread_single_abort>
	z_thread_monitor_exit(thread);

	if (_current == thread) {
    1bc8:	4b0a      	ldr	r3, [pc, #40]	; (1bf4 <z_impl_k_thread_abort+0x44>)
    1bca:	689b      	ldr	r3, [r3, #8]
    1bcc:	42a3      	cmp	r3, r4
    1bce:	d10b      	bne.n	1be8 <z_impl_k_thread_abort+0x38>
		if ((SCB->ICSR & SCB_ICSR_VECTACTIVE_Msk) == 0) {
    1bd0:	4b09      	ldr	r3, [pc, #36]	; (1bf8 <z_impl_k_thread_abort+0x48>)
    1bd2:	685a      	ldr	r2, [r3, #4]
    1bd4:	f3c2 0208 	ubfx	r2, r2, #0, #9
    1bd8:	b912      	cbnz	r2, 1be0 <z_impl_k_thread_abort+0x30>
	int ret;
	z_check_stack_sentinel();
#ifndef CONFIG_ARM
	sys_trace_thread_switched_out();
#endif
	ret = arch_swap(key);
    1bda:	4628      	mov	r0, r5
    1bdc:	f7ff fc1a 	bl	1414 <arch_swap>
			(void)z_swap_irqlock(key);
			CODE_UNREACHABLE;
		} else {
			SCB->ICSR |= SCB_ICSR_PENDSVSET_Msk;
    1be0:	685a      	ldr	r2, [r3, #4]
    1be2:	f042 5280 	orr.w	r2, r2, #268435456	; 0x10000000
    1be6:	605a      	str	r2, [r3, #4]
		}
	}

	/* The abort handler might have altered the ready queue. */
	z_reschedule_irqlock(key);
    1be8:	4628      	mov	r0, r5
}
    1bea:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule_irqlock(key);
    1bee:	f004 b993 	b.w	5f18 <z_reschedule_irqlock>
    1bf2:	bf00      	nop
    1bf4:	20000524 	.word	0x20000524
    1bf8:	e000ed00 	.word	0xe000ed00

00001bfc <z_arm_configure_static_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_static_mpu_regions(void)
{
    1bfc:	b51f      	push	{r0, r1, r2, r3, r4, lr}
		.size = (uint32_t)&_nocache_ram_size,
		.attr = K_MEM_PARTITION_P_RW_U_NA_NOCACHE,
		};
#endif /* CONFIG_NOCACHE_MEMORY */
#if defined(CONFIG_ARCH_HAS_RAMFUNC_SUPPORT)
		const struct k_mem_partition ramfunc_region =
    1bfe:	4b08      	ldr	r3, [pc, #32]	; (1c20 <z_arm_configure_static_mpu_regions+0x24>)
    1c00:	9301      	str	r3, [sp, #4]
    1c02:	4b08      	ldr	r3, [pc, #32]	; (1c24 <z_arm_configure_static_mpu_regions+0x28>)
    1c04:	9302      	str	r3, [sp, #8]
    1c06:	4b08      	ldr	r3, [pc, #32]	; (1c28 <z_arm_configure_static_mpu_regions+0x2c>)
    1c08:	9303      	str	r3, [sp, #12]

	/* Define a constant array of k_mem_partition objects
	 * to hold the configuration of the respective static
	 * MPU regions.
	 */
	const struct k_mem_partition *static_regions[] = {
    1c0a:	ab01      	add	r3, sp, #4
    1c0c:	9300      	str	r3, [sp, #0]
	/* Configure the static MPU regions within firmware SRAM boundaries.
	 * Start address of the image is given by _image_ram_start. The end
	 * of the firmware SRAM area is marked by __kernel_ram_end, taking
	 * into account the unused SRAM area, as well.
	 */
	arm_core_mpu_configure_static_mpu_regions(static_regions,
    1c0e:	4a07      	ldr	r2, [pc, #28]	; (1c2c <z_arm_configure_static_mpu_regions+0x30>)
    1c10:	4b07      	ldr	r3, [pc, #28]	; (1c30 <z_arm_configure_static_mpu_regions+0x34>)
    1c12:	2101      	movs	r1, #1
    1c14:	4668      	mov	r0, sp
    1c16:	f000 f93d 	bl	1e94 <arm_core_mpu_configure_static_mpu_regions>
	};

	arm_core_mpu_mark_areas_for_dynamic_regions(dyn_region_areas,
		ARRAY_SIZE(dyn_region_areas));
#endif /* CONFIG_MPU_REQUIRES_NON_OVERLAPPING_REGIONS */
}
    1c1a:	b005      	add	sp, #20
    1c1c:	f85d fb04 	ldr.w	pc, [sp], #4
    1c20:	20000000 	.word	0x20000000
    1c24:	00000000 	.word	0x00000000
    1c28:	060b0000 	.word	0x060b0000
    1c2c:	20000000 	.word	0x20000000
    1c30:	20010000 	.word	0x20010000

00001c34 <z_arm_configure_dynamic_mpu_regions>:
 *
 * For some MPU architectures, such as the unmodified ARMv8-M MPU,
 * the function must execute with MPU enabled.
 */
void z_arm_configure_dynamic_mpu_regions(struct k_thread *thread)
{
    1c34:	b570      	push	{r4, r5, r6, lr}
    1c36:	4604      	mov	r4, r0
    1c38:	b094      	sub	sp, #80	; 0x50
    1c3a:	f003 ff1d 	bl	5a78 <arch_is_user_context>
#if defined(CONFIG_USERSPACE)
	struct k_mem_partition thread_stack;

	/* Memory domain */
	LOG_DBG("configure thread %p's domain", thread);
	struct k_mem_domain *mem_domain = thread->mem_domain_info.mem_domain;
    1c3e:	6fe1      	ldr	r1, [r4, #124]	; 0x7c

	if (mem_domain) {
    1c40:	b1d1      	cbz	r1, 1c78 <z_arm_configure_dynamic_mpu_regions+0x44>
    1c42:	f003 ff19 	bl	5a78 <arch_is_user_context>
		LOG_DBG("configure domain: %p", mem_domain);
		uint32_t num_partitions = mem_domain->num_partitions;
    1c46:	f891 50c8 	ldrb.w	r5, [r1, #200]	; 0xc8
    1c4a:	f003 ff15 	bl	5a78 <arch_is_user_context>
		struct k_mem_partition partition;
		int i;

		LOG_DBG("configure domain: %p", mem_domain);

		for (i = 0; i < CONFIG_MAX_DOMAIN_PARTITIONS; i++) {
    1c4e:	460a      	mov	r2, r1
    1c50:	f101 06c0 	add.w	r6, r1, #192	; 0xc0
	uint8_t region_num = 0U;
    1c54:	2100      	movs	r1, #0
			partition = mem_domain->partitions[i];
			if (partition.size == 0) {
    1c56:	6853      	ldr	r3, [r2, #4]
    1c58:	b15b      	cbz	r3, 1c72 <z_arm_configure_dynamic_mpu_regions+0x3e>
    1c5a:	f003 ff0d 	bl	5a78 <arch_is_user_context>
			}
			LOG_DBG("set region 0x%lx 0x%x",
				partition.start, partition.size);
			__ASSERT(region_num < _MAX_DYNAMIC_MPU_REGIONS_NUM,
				"Out-of-bounds error for dynamic region map.");
			dynamic_regions[region_num] =
    1c5e:	ab14      	add	r3, sp, #80	; 0x50
    1c60:	eb03 0381 	add.w	r3, r3, r1, lsl #2
				&mem_domain->partitions[i];

			region_num++;
			num_partitions--;
			if (num_partitions == 0U) {
    1c64:	3d01      	subs	r5, #1
			region_num++;
    1c66:	f101 0101 	add.w	r1, r1, #1
			dynamic_regions[region_num] =
    1c6a:	f843 2c44 	str.w	r2, [r3, #-68]
			region_num++;
    1c6e:	b2c9      	uxtb	r1, r1
			if (num_partitions == 0U) {
    1c70:	d002      	beq.n	1c78 <z_arm_configure_dynamic_mpu_regions+0x44>
		for (i = 0; i < CONFIG_MAX_DOMAIN_PARTITIONS; i++) {
    1c72:	320c      	adds	r2, #12
    1c74:	4296      	cmp	r6, r2
    1c76:	d1ee      	bne.n	1c56 <z_arm_configure_dynamic_mpu_regions+0x22>
    1c78:	f003 fefe 	bl	5a78 <arch_is_user_context>
			}
		}
	}
	/* Thread user stack */
	LOG_DBG("configure user thread %p's context", thread);
	if (thread->arch.priv_stack_start) {
    1c7c:	f8d4 3098 	ldr.w	r3, [r4, #152]	; 0x98
    1c80:	b183      	cbz	r3, 1ca4 <z_arm_configure_dynamic_mpu_regions+0x70>
		/* K_USER thread stack needs a region */
		uint32_t base = (uint32_t)thread->stack_obj;
		uint32_t size = thread->stack_info.size +
    1c82:	e9d4 031a 	ldrd	r0, r3, [r4, #104]	; 0x68
		uint32_t base = (uint32_t)thread->stack_obj;
    1c86:	f8d4 2080 	ldr.w	r2, [r4, #128]	; 0x80
		uint32_t size = thread->stack_info.size +
    1c8a:	4403      	add	r3, r0
    1c8c:	1a9b      	subs	r3, r3, r2
			(thread->stack_info.start - base);

		__ASSERT(region_num < _MAX_DYNAMIC_MPU_REGIONS_NUM,
			"Out-of-bounds error for dynamic region map.");
		thread_stack = (const struct k_mem_partition)
    1c8e:	e9cd 2300 	strd	r2, r3, [sp]
    1c92:	4b07      	ldr	r3, [pc, #28]	; (1cb0 <z_arm_configure_dynamic_mpu_regions+0x7c>)
    1c94:	9302      	str	r3, [sp, #8]
			{base, size, K_MEM_PARTITION_P_RW_U_RW};

		dynamic_regions[region_num] = &thread_stack;
    1c96:	ab14      	add	r3, sp, #80	; 0x50
    1c98:	eb03 0381 	add.w	r3, r3, r1, lsl #2

		region_num++;
    1c9c:	3101      	adds	r1, #1
		dynamic_regions[region_num] = &thread_stack;
    1c9e:	f843 dc44 	str.w	sp, [r3, #-68]
		region_num++;
    1ca2:	b2c9      	uxtb	r1, r1

	region_num++;
#endif /* CONFIG_MPU_STACK_GUARD */

	/* Configure the dynamic MPU regions */
	arm_core_mpu_configure_dynamic_mpu_regions(
    1ca4:	a803      	add	r0, sp, #12
    1ca6:	f000 f91b 	bl	1ee0 <arm_core_mpu_configure_dynamic_mpu_regions>
		(const struct k_mem_partition **)dynamic_regions,
		region_num);
}
    1caa:	b014      	add	sp, #80	; 0x50
    1cac:	bd70      	pop	{r4, r5, r6, pc}
    1cae:	bf00      	nop
    1cb0:	130b0000 	.word	0x130b0000

00001cb4 <arch_mem_domain_thread_add>:
	return ARM_CORE_MPU_MAX_DOMAIN_PARTITIONS_GET(available_regions);
}

void arch_mem_domain_thread_add(struct k_thread *thread)
{
	if (_current != thread) {
    1cb4:	4b03      	ldr	r3, [pc, #12]	; (1cc4 <arch_mem_domain_thread_add+0x10>)
    1cb6:	689b      	ldr	r3, [r3, #8]
    1cb8:	4283      	cmp	r3, r0
    1cba:	d101      	bne.n	1cc0 <arch_mem_domain_thread_add+0xc>

	/* Request to configure memory domain for a thread.
	 * This triggers re-programming of the entire dynamic
	 * memory map.
	 */
	z_arm_configure_dynamic_mpu_regions(thread);
    1cbc:	f7ff bfba 	b.w	1c34 <z_arm_configure_dynamic_mpu_regions>
}
    1cc0:	4770      	bx	lr
    1cc2:	bf00      	nop
    1cc4:	20000524 	.word	0x20000524

00001cc8 <is_enabled_region>:
    1cc8:	f04f 0320 	mov.w	r3, #32
    1ccc:	f3ef 8211 	mrs	r2, BASEPRI
    1cd0:	f383 8811 	msr	BASEPRI, r3
    1cd4:	f3bf 8f6f 	isb	sy
	/* Lock IRQs to ensure RNR value is correct when reading RASR. */
	unsigned int key;
	uint32_t rasr;

	key = irq_lock();
	MPU->RNR = index;
    1cd8:	4b04      	ldr	r3, [pc, #16]	; (1cec <is_enabled_region+0x24>)
    1cda:	6098      	str	r0, [r3, #8]
	rasr = MPU->RASR;
    1cdc:	6918      	ldr	r0, [r3, #16]
	__asm__ volatile(
    1cde:	f382 8811 	msr	BASEPRI, r2
    1ce2:	f3bf 8f6f 	isb	sy
	irq_unlock(key);

	return (rasr & MPU_RASR_ENABLE_Msk) ? 1 : 0;
}
    1ce6:	f000 0001 	and.w	r0, r0, #1
    1cea:	4770      	bx	lr
    1cec:	e000ed90 	.word	0xe000ed90

00001cf0 <mpu_configure_region>:
/* This internal function programs an MPU region
 * of a given configuration at a given MPU index.
 */
static int mpu_configure_region(const uint8_t index,
	const struct k_mem_partition *new_region)
{
    1cf0:	b538      	push	{r3, r4, r5, lr}
    1cf2:	4604      	mov	r4, r0
    1cf4:	f003 fed1 	bl	5a9a <arch_is_user_context>

	LOG_DBG("Configure MPU region at index 0x%x", index);

	/* Populate internal ARM MPU region configuration structure. */
	region_conf.base = new_region->start;
	get_region_attr_from_k_mem_partition_info(&region_conf.attr,
    1cf8:	e9d1 5300 	ldrd	r5, r3, [r1]
	if (size <= 32U) {
    1cfc:	2b20      	cmp	r3, #32
    1cfe:	6889      	ldr	r1, [r1, #8]
    1d00:	d912      	bls.n	1d28 <mpu_configure_region+0x38>
	if (size > (1UL << 31)) {
    1d02:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
    1d06:	d811      	bhi.n	1d2c <mpu_configure_region+0x3c>
	return ((32 - __builtin_clz(size - 1) - 2 + 1) << MPU_RASR_SIZE_Pos) &
    1d08:	3b01      	subs	r3, #1
    1d0a:	fab3 f383 	clz	r3, r3
    1d0e:	f1c3 031f 	rsb	r3, r3, #31
    1d12:	005b      	lsls	r3, r3, #1
	if (index > (get_num_regions() - 1)) {
    1d14:	2c07      	cmp	r4, #7
	p_attr->rasr = attr->rasr_attr | size_to_mpu_rasr_size(size);
    1d16:	ea41 0103 	orr.w	r1, r1, r3
    1d1a:	d909      	bls.n	1d30 <mpu_configure_region+0x40>
    1d1c:	f003 febd 	bl	5a9a <arch_is_user_context>
		return -EINVAL;
    1d20:	f06f 0415 	mvn.w	r4, #21
		&new_region->attr, new_region->start, new_region->size);

	/* Allocate and program region */
	return region_allocate_and_init(index,
		(const struct arm_mpu_region *)&region_conf);
}
    1d24:	4620      	mov	r0, r4
    1d26:	bd38      	pop	{r3, r4, r5, pc}
		return REGION_32B;
    1d28:	2308      	movs	r3, #8
    1d2a:	e7f3      	b.n	1d14 <mpu_configure_region+0x24>
		return REGION_4G;
    1d2c:	233e      	movs	r3, #62	; 0x3e
    1d2e:	e7f1      	b.n	1d14 <mpu_configure_region+0x24>
    1d30:	f003 feb3 	bl	5a9a <arch_is_user_context>
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1d34:	f025 051f 	bic.w	r5, r5, #31
	MPU->RNR = index;
    1d38:	4805      	ldr	r0, [pc, #20]	; (1d50 <mpu_configure_region+0x60>)
				| MPU_RBAR_VALID_Msk | index;
    1d3a:	4325      	orrs	r5, r4
    1d3c:	f045 0510 	orr.w	r5, r5, #16
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1d40:	f041 0101 	orr.w	r1, r1, #1
	MPU->RNR = index;
    1d44:	6084      	str	r4, [r0, #8]
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1d46:	60c5      	str	r5, [r0, #12]
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1d48:	6101      	str	r1, [r0, #16]
    1d4a:	f003 fea6 	bl	5a9a <arch_is_user_context>
	return region_allocate_and_init(index,
    1d4e:	e7e9      	b.n	1d24 <mpu_configure_region+0x34>
    1d50:	e000ed90 	.word	0xe000ed90

00001d54 <arm_core_mpu_enable>:
void arm_core_mpu_enable(void)
{
	/* Enable MPU and use the default memory map as a
	 * background region for privileged software access.
	 */
	MPU->CTRL = MPU_CTRL_ENABLE_Msk | MPU_CTRL_PRIVDEFENA_Msk;
    1d54:	4b03      	ldr	r3, [pc, #12]	; (1d64 <arm_core_mpu_enable+0x10>)
    1d56:	2205      	movs	r2, #5
    1d58:	605a      	str	r2, [r3, #4]
  __ASM volatile ("dsb 0xF":::"memory");
    1d5a:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
    1d5e:	f3bf 8f6f 	isb	sy

	/* Make sure that all the registers are set before proceeding */
	__DSB();
	__ISB();
}
    1d62:	4770      	bx	lr
    1d64:	e000ed90 	.word	0xe000ed90

00001d68 <arm_core_mpu_disable>:
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
    1d68:	f3bf 8f5f 	dmb	sy
{
	/* Force any outstanding transfers to complete before disabling MPU */
	__DMB();

	/* Disable MPU */
	MPU->CTRL = 0;
    1d6c:	4b01      	ldr	r3, [pc, #4]	; (1d74 <arm_core_mpu_disable+0xc>)
    1d6e:	2200      	movs	r2, #0
    1d70:	605a      	str	r2, [r3, #4]
}
    1d72:	4770      	bx	lr
    1d74:	e000ed90 	.word	0xe000ed90

00001d78 <arm_mpu_init>:
 */
static int arm_mpu_init(struct device *arg)
{
	uint32_t r_index;

	if (mpu_config.num_regions > get_num_regions()) {
    1d78:	4915      	ldr	r1, [pc, #84]	; (1dd0 <arm_mpu_init+0x58>)
{
    1d7a:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (mpu_config.num_regions > get_num_regions()) {
    1d7c:	680c      	ldr	r4, [r1, #0]
    1d7e:	2c08      	cmp	r4, #8
    1d80:	d822      	bhi.n	1dc8 <arm_mpu_init+0x50>
	MPU->RNR = index;
    1d82:	4d14      	ldr	r5, [pc, #80]	; (1dd4 <arm_mpu_init+0x5c>)
    1d84:	f003 fe89 	bl	5a9a <arch_is_user_context>
	/* Architecture-specific configuration */
	mpu_init();

	/* Program fixed regions configured at SOC definition. */
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    1d88:	260c      	movs	r6, #12
	arm_core_mpu_disable();
    1d8a:	f7ff ffed 	bl	1d68 <arm_core_mpu_disable>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    1d8e:	2200      	movs	r2, #0
    1d90:	4294      	cmp	r4, r2
    1d92:	d105      	bne.n	1da0 <arm_mpu_init+0x28>
	}

	/* Update the number of programmed MPU regions. */
	static_regions_num = mpu_config.num_regions;
    1d94:	4b10      	ldr	r3, [pc, #64]	; (1dd8 <arm_mpu_init+0x60>)
    1d96:	701c      	strb	r4, [r3, #0]


	arm_core_mpu_enable();
    1d98:	f7ff ffdc 	bl	1d54 <arm_core_mpu_enable>
	__ASSERT(
		(MPU->TYPE & MPU_TYPE_DREGION_Msk) >> MPU_TYPE_DREGION_Pos ==
		NUM_MPU_REGIONS,
		"Invalid number of MPU regions\n");
#endif /* CORTEX_M0PLUS || CPU_CORTEX_M3 || CPU_CORTEX_M4 */
	return 0;
    1d9c:	2000      	movs	r0, #0
}
    1d9e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		region_init(r_index, &mpu_config.mpu_regions[r_index]);
    1da0:	fb06 f302 	mul.w	r3, r6, r2
    1da4:	6848      	ldr	r0, [r1, #4]
    1da6:	60aa      	str	r2, [r5, #8]
    1da8:	18c7      	adds	r7, r0, r3
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1daa:	58c3      	ldr	r3, [r0, r3]
    1dac:	f023 031f 	bic.w	r3, r3, #31
				| MPU_RBAR_VALID_Msk | index;
    1db0:	4313      	orrs	r3, r2
    1db2:	f043 0310 	orr.w	r3, r3, #16
	MPU->RBAR = (region_conf->base & MPU_RBAR_ADDR_Msk)
    1db6:	60eb      	str	r3, [r5, #12]
	MPU->RASR = region_conf->attr.rasr | MPU_RASR_ENABLE_Msk;
    1db8:	68bb      	ldr	r3, [r7, #8]
    1dba:	f043 0301 	orr.w	r3, r3, #1
    1dbe:	612b      	str	r3, [r5, #16]
    1dc0:	f003 fe6b 	bl	5a9a <arch_is_user_context>
	for (r_index = 0U; r_index < mpu_config.num_regions; r_index++) {
    1dc4:	3201      	adds	r2, #1
    1dc6:	e7e3      	b.n	1d90 <arm_mpu_init+0x18>
		return -1;
    1dc8:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    1dcc:	e7e7      	b.n	1d9e <arm_mpu_init+0x26>
    1dce:	bf00      	nop
    1dd0:	00006b58 	.word	0x00006b58
    1dd4:	e000ed90 	.word	0xe000ed90
    1dd8:	200012b1 	.word	0x200012b1

00001ddc <arm_core_mpu_get_max_available_dyn_regions>:
	return get_num_regions() - static_regions_num;
    1ddc:	4b02      	ldr	r3, [pc, #8]	; (1de8 <arm_core_mpu_get_max_available_dyn_regions+0xc>)
    1dde:	7818      	ldrb	r0, [r3, #0]
}
    1de0:	f1c0 0008 	rsb	r0, r0, #8
    1de4:	4770      	bx	lr
    1de6:	bf00      	nop
    1de8:	200012b1 	.word	0x200012b1

00001dec <arm_core_mpu_buffer_validate>:
{
    1dec:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    1df0:	2900      	cmp	r1, #0
	/* Lock IRQs to ensure RNR value is correct when reading RBAR, RASR. */
	unsigned int key;
	uint32_t rbar, rasr;

	key = irq_lock();
	MPU->RNR = r_index;
    1df2:	4e27      	ldr	r6, [pc, #156]	; (1e90 <arm_core_mpu_buffer_validate+0xa4>)
	r_addr_start = rbar & MPU_RBAR_ADDR_Msk;
	r_size_lshift = ((rasr & MPU_RASR_SIZE_Msk) >>
			MPU_RASR_SIZE_Pos) + 1;
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;

	size = size == 0 ? 0 : size - 1;
    1df4:	f101 35ff 	add.w	r5, r1, #4294967295	; 0xffffffff
    1df8:	4604      	mov	r4, r0
    1dfa:	4617      	mov	r7, r2
static inline int mpu_buffer_validate(void *addr, size_t size, int write)
{
	int32_t r_index;

	/* Iterate all mpu regions in reversed order */
	for (r_index = get_num_regions() - 1; r_index >= 0;  r_index--) {
    1dfc:	bf08      	it	eq
    1dfe:	2500      	moveq	r5, #0
    1e00:	2107      	movs	r1, #7
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;
    1e02:	f04f 0801 	mov.w	r8, #1
		if (!is_enabled_region(r_index) ||
    1e06:	4608      	mov	r0, r1
    1e08:	f7ff ff5e 	bl	1cc8 <is_enabled_region>
    1e0c:	2800      	cmp	r0, #0
    1e0e:	d037      	beq.n	1e80 <arm_core_mpu_buffer_validate+0x94>
	__asm__ volatile(
    1e10:	f04f 0320 	mov.w	r3, #32
    1e14:	f3ef 8011 	mrs	r0, BASEPRI
    1e18:	f383 8811 	msr	BASEPRI, r3
    1e1c:	f3bf 8f6f 	isb	sy
	MPU->RNR = r_index;
    1e20:	60b1      	str	r1, [r6, #8]
	rbar = MPU->RBAR;
    1e22:	68f2      	ldr	r2, [r6, #12]
	rasr = MPU->RASR;
    1e24:	6933      	ldr	r3, [r6, #16]
	__asm__ volatile(
    1e26:	f380 8811 	msr	BASEPRI, r0
    1e2a:	f3bf 8f6f 	isb	sy
	return __builtin_add_overflow(a, b, result);
}

static inline bool u32_add_overflow(uint32_t a, uint32_t b, uint32_t *result)
{
	return __builtin_add_overflow(a, b, result);
    1e2e:	1960      	adds	r0, r4, r5
    1e30:	d226      	bcs.n	1e80 <arm_core_mpu_buffer_validate+0x94>
	r_addr_start = rbar & MPU_RBAR_ADDR_Msk;
    1e32:	f022 021f 	bic.w	r2, r2, #31
	if ((start >= r_addr_start) && (end <= r_addr_end)) {
    1e36:	4294      	cmp	r4, r2
    1e38:	d322      	bcc.n	1e80 <arm_core_mpu_buffer_validate+0x94>
	r_size_lshift = ((rasr & MPU_RASR_SIZE_Msk) >>
    1e3a:	f3c3 0344 	ubfx	r3, r3, #1, #5
    1e3e:	3301      	adds	r3, #1
	r_addr_end = r_addr_start + (1UL << r_size_lshift) - 1;
    1e40:	fa08 f303 	lsl.w	r3, r8, r3
    1e44:	3a01      	subs	r2, #1
    1e46:	4413      	add	r3, r2
	if ((start >= r_addr_start) && (end <= r_addr_end)) {
    1e48:	4283      	cmp	r3, r0
    1e4a:	d319      	bcc.n	1e80 <arm_core_mpu_buffer_validate+0x94>
	__asm__ volatile(
    1e4c:	f04f 0320 	mov.w	r3, #32
    1e50:	f3ef 8211 	mrs	r2, BASEPRI
    1e54:	f383 8811 	msr	BASEPRI, r3
    1e58:	f3bf 8f6f 	isb	sy
	MPU->RNR = r_index;
    1e5c:	60b1      	str	r1, [r6, #8]
	rasr = MPU->RASR;
    1e5e:	6933      	ldr	r3, [r6, #16]
	__asm__ volatile(
    1e60:	f382 8811 	msr	BASEPRI, r2
    1e64:	f3bf 8f6f 	isb	sy
	return (rasr & MPU_RASR_AP_Msk) >> MPU_RASR_AP_Pos;
    1e68:	0e19      	lsrs	r1, r3, #24
    1e6a:	f3c3 6302 	ubfx	r3, r3, #24, #3
	if (write) {
    1e6e:	b167      	cbz	r7, 1e8a <arm_core_mpu_buffer_validate+0x9e>
		return r_ap == P_RW_U_RW;
    1e70:	3b03      	subs	r3, #3
    1e72:	4259      	negs	r1, r3
    1e74:	4159      	adcs	r1, r3
		/* For ARM MPU, higher region number takes priority.
		 * Since we iterate all mpu regions in reversed order, so
		 * we can stop the iteration immediately once we find the
		 * matched region that grants permission or denies access.
		 */
		if (is_user_accessible_region(r_index, write)) {
    1e76:	fab1 f181 	clz	r1, r1
    1e7a:	0949      	lsrs	r1, r1, #5
    1e7c:	4249      	negs	r1, r1
	return mpu_buffer_validate(addr, size, write);
    1e7e:	e001      	b.n	1e84 <arm_core_mpu_buffer_validate+0x98>
	for (r_index = get_num_regions() - 1; r_index >= 0;  r_index--) {
    1e80:	3901      	subs	r1, #1
    1e82:	d2c0      	bcs.n	1e06 <arm_core_mpu_buffer_validate+0x1a>
}
    1e84:	4608      	mov	r0, r1
    1e86:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return r_ap & MPU_USER_READ_ACCESSIBLE_Msk;
    1e8a:	f001 0102 	and.w	r1, r1, #2
    1e8e:	e7f2      	b.n	1e76 <arm_core_mpu_buffer_validate+0x8a>
    1e90:	e000ed90 	.word	0xe000ed90

00001e94 <arm_core_mpu_configure_static_mpu_regions>:
{
    1e94:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
static int mpu_configure_static_mpu_regions(const struct k_mem_partition
	*static_regions[], const uint8_t regions_num,
	const uint32_t background_area_base,
	const uint32_t background_area_end)
{
	int mpu_reg_index = static_regions_num;
    1e96:	4c11      	ldr	r4, [pc, #68]	; (1edc <arm_core_mpu_configure_static_mpu_regions+0x48>)
    1e98:	4607      	mov	r7, r0
	int reg_index = start_reg_index;
    1e9a:	7820      	ldrb	r0, [r4, #0]
{
    1e9c:	460e      	mov	r6, r1
	for (i = 0; i < regions_num; i++) {
    1e9e:	2500      	movs	r5, #0
    1ea0:	42b5      	cmp	r5, r6
    1ea2:	da11      	bge.n	1ec8 <arm_core_mpu_configure_static_mpu_regions+0x34>
		if (regions[i]->size == 0U) {
    1ea4:	f857 1025 	ldr.w	r1, [r7, r5, lsl #2]
    1ea8:	684b      	ldr	r3, [r1, #4]
    1eaa:	b1ab      	cbz	r3, 1ed8 <arm_core_mpu_configure_static_mpu_regions+0x44>
		((part->size & (part->size - 1)) == 0U)
    1eac:	1e5a      	subs	r2, r3, #1
		&&
    1eae:	4213      	tst	r3, r2
    1eb0:	d10c      	bne.n	1ecc <arm_core_mpu_configure_static_mpu_regions+0x38>
		&&
    1eb2:	2b1f      	cmp	r3, #31
    1eb4:	d90a      	bls.n	1ecc <arm_core_mpu_configure_static_mpu_regions+0x38>
		((part->start & (part->size - 1)) == 0U);
    1eb6:	680b      	ldr	r3, [r1, #0]
		&&
    1eb8:	421a      	tst	r2, r3
    1eba:	d107      	bne.n	1ecc <arm_core_mpu_configure_static_mpu_regions+0x38>
		reg_index = mpu_configure_region(reg_index, regions[i]);
    1ebc:	b2c0      	uxtb	r0, r0
    1ebe:	f7ff ff17 	bl	1cf0 <mpu_configure_region>
		if (reg_index == -EINVAL) {
    1ec2:	f110 0f16 	cmn.w	r0, #22
    1ec6:	d106      	bne.n	1ed6 <arm_core_mpu_configure_static_mpu_regions+0x42>
	ARG_UNUSED(background_area_end);

	mpu_reg_index = mpu_configure_regions(static_regions,
		regions_num, mpu_reg_index, true);

	static_regions_num = mpu_reg_index;
    1ec8:	7020      	strb	r0, [r4, #0]
}
    1eca:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    1ecc:	f003 fde5 	bl	5a9a <arch_is_user_context>
			return -EINVAL;
    1ed0:	f06f 0015 	mvn.w	r0, #21
    1ed4:	e7f8      	b.n	1ec8 <arm_core_mpu_configure_static_mpu_regions+0x34>
		reg_index++;
    1ed6:	3001      	adds	r0, #1
	for (i = 0; i < regions_num; i++) {
    1ed8:	3501      	adds	r5, #1
    1eda:	e7e1      	b.n	1ea0 <arm_core_mpu_configure_static_mpu_regions+0xc>
    1edc:	200012b1 	.word	0x200012b1

00001ee0 <arm_core_mpu_configure_dynamic_mpu_regions>:
{
    1ee0:	b538      	push	{r3, r4, r5, lr}
 * performed, the error signal is propagated to the caller of the function.
 */
static int mpu_configure_dynamic_mpu_regions(const struct k_mem_partition
	*dynamic_regions[], uint8_t regions_num)
{
	int mpu_reg_index = static_regions_num;
    1ee2:	4b10      	ldr	r3, [pc, #64]	; (1f24 <arm_core_mpu_configure_dynamic_mpu_regions+0x44>)
    1ee4:	4605      	mov	r5, r0
	int reg_index = start_reg_index;
    1ee6:	7818      	ldrb	r0, [r3, #0]
{
    1ee8:	460c      	mov	r4, r1
	for (i = 0; i < regions_num; i++) {
    1eea:	2200      	movs	r2, #0
    1eec:	42a2      	cmp	r2, r4
    1eee:	db07      	blt.n	1f00 <arm_core_mpu_configure_dynamic_mpu_regions+0x20>
	 */

	mpu_reg_index = mpu_configure_regions(dynamic_regions,
		regions_num, mpu_reg_index, false);

	if (mpu_reg_index != -EINVAL) {
    1ef0:	f110 0f16 	cmn.w	r0, #22
    1ef4:	d003      	beq.n	1efe <arm_core_mpu_configure_dynamic_mpu_regions+0x1e>
/** Clear and disable the given MPU region.
* \param rnr Region number to be cleared.
*/
__STATIC_INLINE void ARM_MPU_ClrRegion(uint32_t rnr)
{
  MPU->RNR = rnr;
    1ef6:	4a0c      	ldr	r2, [pc, #48]	; (1f28 <arm_core_mpu_configure_dynamic_mpu_regions+0x48>)
  MPU->RASR = 0U;
    1ef8:	2100      	movs	r1, #0

		/* Disable the non-programmed MPU regions. */
		for (int i = mpu_reg_index; i < get_num_regions(); i++) {
    1efa:	2807      	cmp	r0, #7
    1efc:	dd0d      	ble.n	1f1a <arm_core_mpu_configure_dynamic_mpu_regions+0x3a>
}
    1efe:	bd38      	pop	{r3, r4, r5, pc}
		if (regions[i]->size == 0U) {
    1f00:	f855 1022 	ldr.w	r1, [r5, r2, lsl #2]
    1f04:	684b      	ldr	r3, [r1, #4]
    1f06:	b133      	cbz	r3, 1f16 <arm_core_mpu_configure_dynamic_mpu_regions+0x36>
		reg_index = mpu_configure_region(reg_index, regions[i]);
    1f08:	b2c0      	uxtb	r0, r0
    1f0a:	f7ff fef1 	bl	1cf0 <mpu_configure_region>
		if (reg_index == -EINVAL) {
    1f0e:	f110 0f16 	cmn.w	r0, #22
    1f12:	d0f4      	beq.n	1efe <arm_core_mpu_configure_dynamic_mpu_regions+0x1e>
		reg_index++;
    1f14:	3001      	adds	r0, #1
	for (i = 0; i < regions_num; i++) {
    1f16:	3201      	adds	r2, #1
    1f18:	e7e8      	b.n	1eec <arm_core_mpu_configure_dynamic_mpu_regions+0xc>
  MPU->RNR = rnr;
    1f1a:	6090      	str	r0, [r2, #8]
  MPU->RASR = 0U;
    1f1c:	6111      	str	r1, [r2, #16]
    1f1e:	3001      	adds	r0, #1
    1f20:	e7eb      	b.n	1efa <arm_core_mpu_configure_dynamic_mpu_regions+0x1a>
    1f22:	bf00      	nop
    1f24:	200012b1 	.word	0x200012b1
    1f28:	e000ed90 	.word	0xe000ed90

00001f2c <__stdout_hook_install>:

static int (*_stdout_hook)(int) = _stdout_hook_default;

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
    1f2c:	4b01      	ldr	r3, [pc, #4]	; (1f34 <__stdout_hook_install+0x8>)
    1f2e:	6018      	str	r0, [r3, #0]
}
    1f30:	4770      	bx	lr
    1f32:	bf00      	nop
    1f34:	20002c2c 	.word	0x20002c2c

00001f38 <z_impl_zephyr_fputc>:

int z_impl_zephyr_fputc(int c, FILE *stream)
{
	return (stdout == stream) ? _stdout_hook(c) : EOF;
    1f38:	2902      	cmp	r1, #2
    1f3a:	d102      	bne.n	1f42 <z_impl_zephyr_fputc+0xa>
    1f3c:	4b02      	ldr	r3, [pc, #8]	; (1f48 <z_impl_zephyr_fputc+0x10>)
    1f3e:	681b      	ldr	r3, [r3, #0]
    1f40:	4718      	bx	r3
}
    1f42:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    1f46:	4770      	bx	lr
    1f48:	20002c2c 	.word	0x20002c2c

00001f4c <z_mrsh_zephyr_fputc>:
#include <syscalls/libc-hooks.h>

extern int z_vrfy_zephyr_fputc(int c, FILE * stream);
uintptr_t z_mrsh_zephyr_fputc(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    1f4c:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    1f4e:	4c06      	ldr	r4, [pc, #24]	; (1f68 <z_mrsh_zephyr_fputc+0x1c>)
    1f50:	9a04      	ldr	r2, [sp, #16]
    1f52:	68a3      	ldr	r3, [r4, #8]
    1f54:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_zephyr_fputc(int c, FILE *stream)
{
	return z_impl_zephyr_fputc(c, stream);
    1f58:	f7ff ffee 	bl	1f38 <z_impl_zephyr_fputc>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_zephyr_fputc(*(int*)&arg0, *(FILE **)&arg1)
;
	_current->syscall_frame = NULL;
    1f5c:	68a3      	ldr	r3, [r4, #8]
    1f5e:	2200      	movs	r2, #0
    1f60:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    1f64:	bd10      	pop	{r4, pc}
    1f66:	bf00      	nop
    1f68:	20000524 	.word	0x20000524

00001f6c <z_impl_zephyr_fwrite>:
{
	size_t i;
	size_t j;
	const unsigned char *p;

	if ((stream != stdout) || (nitems == 0) || (size == 0)) {
    1f6c:	2b02      	cmp	r3, #2
{
    1f6e:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    1f72:	4606      	mov	r6, r0
    1f74:	460c      	mov	r4, r1
    1f76:	4615      	mov	r5, r2
	if ((stream != stdout) || (nitems == 0) || (size == 0)) {
    1f78:	d115      	bne.n	1fa6 <z_impl_zephyr_fwrite+0x3a>
    1f7a:	b1b2      	cbz	r2, 1faa <z_impl_zephyr_fwrite+0x3e>
    1f7c:	b181      	cbz	r1, 1fa0 <z_impl_zephyr_fwrite+0x34>
	p = ptr;
	i = nitems;
	do {
		j = size;
		do {
			if (_stdout_hook((int) *p++) == EOF) {
    1f7e:	f8df 9030 	ldr.w	r9, [pc, #48]	; 1fb0 <z_impl_zephyr_fwrite+0x44>
    1f82:	4617      	mov	r7, r2
		j = size;
    1f84:	46b0      	mov	r8, r6
    1f86:	4426      	add	r6, r4
			if (_stdout_hook((int) *p++) == EOF) {
    1f88:	f8d9 3000 	ldr.w	r3, [r9]
    1f8c:	f818 0b01 	ldrb.w	r0, [r8], #1
    1f90:	4798      	blx	r3
    1f92:	3001      	adds	r0, #1
    1f94:	d003      	beq.n	1f9e <z_impl_zephyr_fwrite+0x32>
				goto done;
			}
			j--;
		} while (j > 0);
    1f96:	4546      	cmp	r6, r8
    1f98:	d1f6      	bne.n	1f88 <z_impl_zephyr_fwrite+0x1c>

		i--;
	} while (i > 0);
    1f9a:	3f01      	subs	r7, #1
    1f9c:	d1f2      	bne.n	1f84 <z_impl_zephyr_fwrite+0x18>

done:
	return (nitems - i);
    1f9e:	1bec      	subs	r4, r5, r7
}
    1fa0:	4620      	mov	r0, r4
    1fa2:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
		return 0;
    1fa6:	2400      	movs	r4, #0
    1fa8:	e7fa      	b.n	1fa0 <z_impl_zephyr_fwrite+0x34>
    1faa:	4614      	mov	r4, r2
    1fac:	e7f8      	b.n	1fa0 <z_impl_zephyr_fwrite+0x34>
    1fae:	bf00      	nop
    1fb0:	20002c2c 	.word	0x20002c2c

00001fb4 <z_mrsh_zephyr_fwrite>:
#include <syscalls/libc-hooks.h>

extern size_t z_vrfy_zephyr_fwrite(const void *_MLIBC_RESTRICT ptr, size_t size, size_t nitems, FILE *_MLIBC_RESTRICT stream);
uintptr_t z_mrsh_zephyr_fwrite(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    1fb4:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    1fb8:	4f12      	ldr	r7, [pc, #72]	; (2004 <z_mrsh_zephyr_fwrite+0x50>)
{
    1fba:	469a      	mov	sl, r3
	_current->syscall_frame = ssf;
    1fbc:	68bb      	ldr	r3, [r7, #8]
{
    1fbe:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
    1fc0:	9a0a      	ldr	r2, [sp, #40]	; 0x28
    1fc2:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return __builtin_mul_overflow(a, b, result);
}

static inline bool size_mul_overflow(size_t a, size_t b, size_t *result)
{
	return __builtin_mul_overflow(a, b, result);
    1fc6:	fba6 3401 	umull	r3, r4, r6, r1
{
    1fca:	4680      	mov	r8, r0
    1fcc:	460d      	mov	r5, r1
    1fce:	46b9      	mov	r9, r7
    1fd0:	b92c      	cbnz	r4, 1fde <z_mrsh_zephyr_fwrite+0x2a>
static inline size_t z_vrfy_zephyr_fwrite(const void *_MLIBC_RESTRICT ptr,
					  size_t size, size_t nitems,
					  FILE *_MLIBC_RESTRICT stream)
{

	Z_OOPS(Z_SYSCALL_MEMORY_ARRAY_READ(ptr, nitems, size));
    1fd2:	4622      	mov	r2, r4
    1fd4:	4619      	mov	r1, r3
    1fd6:	f003 fd5e 	bl	5a96 <arch_buffer_validate>
    1fda:	4604      	mov	r4, r0
    1fdc:	b138      	cbz	r0, 1fee <z_mrsh_zephyr_fwrite+0x3a>
    1fde:	f003 fdca 	bl	5b76 <arch_is_user_context>
    1fe2:	f8d9 3008 	ldr.w	r3, [r9, #8]
    1fe6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    1fea:	f003 fd26 	bl	5a3a <arch_syscall_oops>
	return z_impl_zephyr_fwrite((const void *_MLIBC_RESTRICT)ptr, size,
    1fee:	4653      	mov	r3, sl
    1ff0:	4632      	mov	r2, r6
    1ff2:	4629      	mov	r1, r5
    1ff4:	4640      	mov	r0, r8
    1ff6:	f7ff ffb9 	bl	1f6c <z_impl_zephyr_fwrite>
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	size_t ret = z_vrfy_zephyr_fwrite(*(const void *_MLIBC_RESTRICT*)&arg0, *(size_t*)&arg1, *(size_t*)&arg2, *(FILE *_MLIBC_RESTRICT*)&arg3)
;
	_current->syscall_frame = NULL;
    1ffa:	68bb      	ldr	r3, [r7, #8]
    1ffc:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2000:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    2004:	20000524 	.word	0x20000524

00002008 <nordicsemi_nrf52_init>:
	__asm__ volatile(
    2008:	f04f 0320 	mov.w	r3, #32
    200c:	f3ef 8211 	mrs	r2, BASEPRI
    2010:	f383 8811 	msr	BASEPRI, r3
    2014:	f3bf 8f6f 	isb	sy

	key = irq_lock();

#ifdef CONFIG_NRF_ENABLE_ICACHE
	/* Enable the instruction cache */
	NRF_NVMC->ICACHECNF = NVMC_ICACHECNF_CACHEEN_Msk;
    2018:	4906      	ldr	r1, [pc, #24]	; (2034 <nordicsemi_nrf52_init+0x2c>)
    201a:	2301      	movs	r3, #1
    201c:	f8c1 3540 	str.w	r3, [r1, #1344]	; 0x540
#endif

#if NRF_POWER_HAS_DCDCEN
NRF_STATIC_INLINE void nrf_power_dcdcen_set(NRF_POWER_Type * p_reg, bool enable)
{
    p_reg->DCDCEN = (enable ? POWER_DCDCEN_DCDCEN_Enabled : POWER_DCDCEN_DCDCEN_Disabled) <<
    2020:	f04f 4180 	mov.w	r1, #1073741824	; 0x40000000
    2024:	f8c1 3578 	str.w	r3, [r1, #1400]	; 0x578
	__asm__ volatile(
    2028:	f382 8811 	msr	BASEPRI, r2
    202c:	f3bf 8f6f 	isb	sy
	NMI_INIT();

	irq_unlock(key);

	return 0;
}
    2030:	2000      	movs	r0, #0
    2032:	4770      	bx	lr
    2034:	4001e000 	.word	0x4001e000

00002038 <arch_busy_wait>:

#else // NRFX_CHECK(NRFX_DELAY_DWT_BASED)

NRF_STATIC_INLINE void nrfx_coredep_delay_us(uint32_t time_us)
{
    if (time_us == 0)
    2038:	b120      	cbz	r0, 2044 <arch_busy_wait+0xc>
    };

    typedef void (* delay_func_t)(uint32_t);
    const delay_func_t delay_cycles =
        // Set LSB to 1 to execute the code in the Thumb mode.
        (delay_func_t)((((uint32_t)delay_machine_code) | 1));
    203a:	4b03      	ldr	r3, [pc, #12]	; (2048 <arch_busy_wait+0x10>)
    uint32_t cycles = time_us * NRFX_DELAY_CPU_FREQ_MHZ;
    delay_cycles(cycles);
    203c:	0180      	lsls	r0, r0, #6
    203e:	f043 0301 	orr.w	r3, r3, #1
    2042:	4718      	bx	r3

void arch_busy_wait(uint32_t time_us)
{
	nrfx_coredep_delay_us(time_us);
}
    2044:	4770      	bx	lr
    2046:	bf00      	nop
    2048:	00006b20 	.word	0x00006b20

0000204c <gpio_nrfx_init>:
}

#define GPIOTE_NODE DT_INST(0, nordic_nrf_gpiote)

static int gpio_nrfx_init(struct device *port)
{
    204c:	b508      	push	{r3, lr}
	static bool gpio_initialized;

	if (!gpio_initialized) {
    204e:	4b09      	ldr	r3, [pc, #36]	; (2074 <gpio_nrfx_init+0x28>)
    2050:	781a      	ldrb	r2, [r3, #0]
    2052:	b96a      	cbnz	r2, 2070 <gpio_nrfx_init+0x24>
		gpio_initialized = true;
    2054:	2101      	movs	r1, #1
    2056:	7019      	strb	r1, [r3, #0]
		IRQ_CONNECT(DT_IRQN(GPIOTE_NODE), DT_IRQ(GPIOTE_NODE, priority),
    2058:	2006      	movs	r0, #6
    205a:	2105      	movs	r1, #5
    205c:	f7ff fa76 	bl	154c <z_arm_irq_priority_set>
			    gpiote_event_handler, NULL, 0);

		irq_enable(DT_IRQN(GPIOTE_NODE));
    2060:	2006      	movs	r0, #6
    2062:	f7ff fa63 	bl	152c <arch_irq_enable>
    return ((uint32_t)p_reg + event);
}

NRF_STATIC_INLINE void nrf_gpiote_int_enable(NRF_GPIOTE_Type * p_reg, uint32_t mask)
{
    p_reg->INTENSET = mask;
    2066:	4b04      	ldr	r3, [pc, #16]	; (2078 <gpio_nrfx_init+0x2c>)
    2068:	f04f 4200 	mov.w	r2, #2147483648	; 0x80000000
    206c:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
		nrf_gpiote_int_enable(NRF_GPIOTE, NRF_GPIOTE_INT_PORT_MASK);
	}

	return 0;
}
    2070:	2000      	movs	r0, #0
    2072:	bd08      	pop	{r3, pc}
    2074:	200012b2 	.word	0x200012b2
    2078:	40006000 	.word	0x40006000

0000207c <gpio_nrfx_config>:
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    207c:	4b2b      	ldr	r3, [pc, #172]	; (212c <gpio_nrfx_config+0xb0>)
{
    207e:	b5f0      	push	{r4, r5, r6, r7, lr}
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    2080:	6846      	ldr	r6, [r0, #4]
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    2082:	482b      	ldr	r0, [pc, #172]	; (2130 <gpio_nrfx_config+0xb4>)
    2084:	4013      	ands	r3, r2
    2086:	4283      	cmp	r3, r0
    2088:	d040      	beq.n	210c <gpio_nrfx_config+0x90>
    208a:	d80d      	bhi.n	20a8 <gpio_nrfx_config+0x2c>
    208c:	2b06      	cmp	r3, #6
    208e:	d015      	beq.n	20bc <gpio_nrfx_config+0x40>
    2090:	d805      	bhi.n	209e <gpio_nrfx_config+0x22>
    2092:	b19b      	cbz	r3, 20bc <gpio_nrfx_config+0x40>
    2094:	2b02      	cmp	r3, #2
    2096:	d03b      	beq.n	2110 <gpio_nrfx_config+0x94>
    2098:	f06f 0015 	mvn.w	r0, #21
    209c:	e035      	b.n	210a <gpio_nrfx_config+0x8e>
    209e:	f5b3 1f80 	cmp.w	r3, #1048576	; 0x100000
    20a2:	d1f9      	bne.n	2098 <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_H0S1;
    20a4:	2301      	movs	r3, #1
    20a6:	e009      	b.n	20bc <gpio_nrfx_config+0x40>
	switch (flags & (GPIO_DS_LOW_MASK | GPIO_DS_HIGH_MASK |
    20a8:	4822      	ldr	r0, [pc, #136]	; (2134 <gpio_nrfx_config+0xb8>)
    20aa:	4283      	cmp	r3, r0
    20ac:	d032      	beq.n	2114 <gpio_nrfx_config+0x98>
    20ae:	f5b3 0fa0 	cmp.w	r3, #5242880	; 0x500000
    20b2:	d031      	beq.n	2118 <gpio_nrfx_config+0x9c>
    20b4:	f5b3 0f80 	cmp.w	r3, #4194304	; 0x400000
    20b8:	d1ee      	bne.n	2098 <gpio_nrfx_config+0x1c>
		drive = NRF_GPIO_PIN_S0H1;
    20ba:	2302      	movs	r3, #2
	if ((flags & GPIO_PULL_UP) != 0) {
    20bc:	06d0      	lsls	r0, r2, #27
		pull = NRF_GPIO_PIN_NOPULL;
    20be:	bf54      	ite	pl
    20c0:	f3c2 1540 	ubfxpl	r5, r2, #5, #1
		pull = NRF_GPIO_PIN_PULLUP;
    20c4:	2503      	movmi	r5, #3
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    20c6:	f482 7480 	eor.w	r4, r2, #256	; 0x100
	if ((flags & GPIO_OUTPUT) != 0) {
    20ca:	0597      	lsls	r7, r2, #22
	dir = ((flags & GPIO_OUTPUT) != 0)
    20cc:	f3c2 2040 	ubfx	r0, r2, #9, #1
		: NRF_GPIO_PIN_INPUT_DISCONNECT;
    20d0:	f3c4 2400 	ubfx	r4, r4, #8, #1
	if ((flags & GPIO_OUTPUT) != 0) {
    20d4:	d507      	bpl.n	20e6 <gpio_nrfx_config+0x6a>
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    20d6:	f412 6f00 	tst.w	r2, #2048	; 0x800
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    20da:	6877      	ldr	r7, [r6, #4]
		if ((flags & GPIO_OUTPUT_INIT_HIGH) != 0) {
    20dc:	d01e      	beq.n	211c <gpio_nrfx_config+0xa0>
			nrf_gpio_port_out_set(reg, BIT(pin));
    20de:	2201      	movs	r2, #1
    20e0:	408a      	lsls	r2, r1
}


NRF_STATIC_INLINE void nrf_gpio_port_out_set(NRF_GPIO_Type * p_reg, uint32_t set_mask)
{
    p_reg->OUTSET = set_mask;
    20e2:	f8c7 2508 	str.w	r2, [r7, #1288]	; 0x508
	nrf_gpio_cfg(NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin),
    20e6:	7a32      	ldrb	r2, [r6, #8]
    20e8:	f001 011f 	and.w	r1, r1, #31
    20ec:	ea41 1142 	orr.w	r1, r1, r2, lsl #5
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    20f0:	ea40 0244 	orr.w	r2, r0, r4, lsl #1
    20f4:	ea42 2303 	orr.w	r3, r2, r3, lsl #8
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    20f8:	f501 71e0 	add.w	r1, r1, #448	; 0x1c0
    20fc:	f04f 42a0 	mov.w	r2, #1342177280	; 0x50000000
                               | ((uint32_t)drive << GPIO_PIN_CNF_DRIVE_Pos)
    2100:	ea43 0385 	orr.w	r3, r3, r5, lsl #2
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    2104:	f842 3021 	str.w	r3, [r2, r1, lsl #2]
	return 0;
    2108:	2000      	movs	r0, #0
}
    210a:	bdf0      	pop	{r4, r5, r6, r7, pc}
		drive = NRF_GPIO_PIN_H0D1;
    210c:	2307      	movs	r3, #7
    210e:	e7d5      	b.n	20bc <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0S1;
    2110:	2304      	movs	r3, #4
    2112:	e7d3      	b.n	20bc <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_D0H1;
    2114:	2305      	movs	r3, #5
    2116:	e7d1      	b.n	20bc <gpio_nrfx_config+0x40>
		drive = NRF_GPIO_PIN_H0H1;
    2118:	2303      	movs	r3, #3
    211a:	e7cf      	b.n	20bc <gpio_nrfx_config+0x40>
		} else if ((flags & GPIO_OUTPUT_INIT_LOW) != 0) {
    211c:	0552      	lsls	r2, r2, #21
			nrf_gpio_port_out_clear(reg, BIT(pin));
    211e:	bf42      	ittt	mi
    2120:	2201      	movmi	r2, #1
    2122:	408a      	lslmi	r2, r1
}


NRF_STATIC_INLINE void nrf_gpio_port_out_clear(NRF_GPIO_Type * p_reg, uint32_t clr_mask)
{
    p_reg->OUTCLR = clr_mask;
    2124:	f8c7 250c 	strmi.w	r2, [r7, #1292]	; 0x50c
}
    2128:	e7dd      	b.n	20e6 <gpio_nrfx_config+0x6a>
    212a:	bf00      	nop
    212c:	00f00006 	.word	0x00f00006
    2130:	00100006 	.word	0x00100006
    2134:	00400002 	.word	0x00400002

00002138 <gpio_nrfx_pin_interrupt_configure>:
{
    2138:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
	struct gpio_nrfx_data *data = get_port_data(port);
    213a:	68c4      	ldr	r4, [r0, #12]
	uint32_t abs_pin = NRF_GPIO_PIN_MAP(get_port_cfg(port)->port_num, pin);
    213c:	6840      	ldr	r0, [r0, #4]
    213e:	7a00      	ldrb	r0, [r0, #8]
    2140:	f001 051f 	and.w	r5, r1, #31
	if ((mode == GPIO_INT_MODE_EDGE) &&
    2144:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    2148:	ea45 1540 	orr.w	r5, r5, r0, lsl #5
    214c:	d10a      	bne.n	2164 <gpio_nrfx_pin_interrupt_configure+0x2c>
    return (nrf_gpio_pin_dir_t)((reg->PIN_CNF[pin_number] &
    214e:	f505 70e0 	add.w	r0, r5, #448	; 0x1c0
    2152:	f04f 46a0 	mov.w	r6, #1342177280	; 0x50000000
    2156:	f856 0020 	ldr.w	r0, [r6, r0, lsl #2]
    215a:	07c7      	lsls	r7, r0, #31
    215c:	d507      	bpl.n	216e <gpio_nrfx_pin_interrupt_configure+0x36>
		return -ENOTSUP;
    215e:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2162:	e0b4      	b.n	22ce <gpio_nrfx_pin_interrupt_configure+0x196>
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    2164:	f5b2 5f00 	cmp.w	r2, #8192	; 0x2000
    2168:	68e0      	ldr	r0, [r4, #12]
    216a:	f000 80b2 	beq.w	22d2 <gpio_nrfx_pin_interrupt_configure+0x19a>
    216e:	68e6      	ldr	r6, [r4, #12]
    2170:	2001      	movs	r0, #1
    2172:	4088      	lsls	r0, r1
    2174:	4330      	orrs	r0, r6
    2176:	6966      	ldr	r6, [r4, #20]
    2178:	60e0      	str	r0, [r4, #12]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    217a:	2001      	movs	r0, #1
    217c:	4088      	lsls	r0, r1
    217e:	f5b2 3fa0 	cmp.w	r2, #81920	; 0x14000
    2182:	69a2      	ldr	r2, [r4, #24]
    2184:	bf0c      	ite	eq
    2186:	4306      	orreq	r6, r0
    2188:	4386      	bicne	r6, r0
	WRITE_BIT(data->double_edge, pin, trig == GPIO_INT_TRIG_BOTH);
    218a:	f5b3 2fc0 	cmp.w	r3, #393216	; 0x60000
    218e:	bf0c      	ite	eq
    2190:	4302      	orreq	r2, r0
    2192:	4382      	bicne	r2, r0
    2194:	61a2      	str	r2, [r4, #24]
    2196:	6922      	ldr	r2, [r4, #16]
	WRITE_BIT(data->trig_edge, pin, mode == GPIO_INT_MODE_EDGE);
    2198:	6166      	str	r6, [r4, #20]
	WRITE_BIT(data->int_active_level, pin, trig == GPIO_INT_TRIG_HIGH);
    219a:	f5b3 2f80 	cmp.w	r3, #262144	; 0x40000
    219e:	bf0c      	ite	eq
    21a0:	4310      	orreq	r0, r2
    21a2:	ea22 0000 	bicne.w	r0, r2, r0
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_int_enable_check(NRF_GPIOTE_Type const * p_reg, uint32_t mask)
{
    return p_reg->INTENSET & mask;
    21a6:	4a5b      	ldr	r2, [pc, #364]	; (2314 <gpio_nrfx_pin_interrupt_configure+0x1dc>)
    21a8:	6120      	str	r0, [r4, #16]
    21aa:	f8d2 0304 	ldr.w	r0, [r2, #772]	; 0x304
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    21ae:	2300      	movs	r3, #0
    21b0:	b2c0      	uxtb	r0, r0
                        ((polarity << GPIOTE_CONFIG_POLARITY_Pos) & GPIOTE_CONFIG_POLARITY_Msk);
}

NRF_STATIC_INLINE uint32_t nrf_gpiote_event_pin_get(NRF_GPIOTE_Type const * p_reg, uint32_t idx)
{
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    21b2:	f503 76a2 	add.w	r6, r3, #324	; 0x144
    21b6:	f852 6026 	ldr.w	r6, [r2, r6, lsl #2]
    21ba:	f3c6 2604 	ubfx	r6, r6, #8, #5
		if ((nrf_gpiote_event_pin_get(NRF_GPIOTE, i) == abs_pin)
    21be:	42b5      	cmp	r5, r6
    21c0:	f040 808c 	bne.w	22dc <gpio_nrfx_pin_interrupt_configure+0x1a4>
		    && (intenset & BIT(i))) {
    21c4:	fa20 f603 	lsr.w	r6, r0, r3
    21c8:	07f6      	lsls	r6, r6, #31
    21ca:	f140 8087 	bpl.w	22dc <gpio_nrfx_pin_interrupt_configure+0x1a4>
			(void)atomic_and(mask, ~BIT(i));
    21ce:	2001      	movs	r0, #1
    21d0:	4098      	lsls	r0, r3
	return __atomic_fetch_and(target, value, __ATOMIC_SEQ_CST);
    21d2:	4e51      	ldr	r6, [pc, #324]	; (2318 <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    21d4:	f3bf 8f5b 	dmb	ish
    21d8:	43c7      	mvns	r7, r0
    21da:	e856 cf00 	ldrex	ip, [r6]
    21de:	ea0c 0c07 	and.w	ip, ip, r7
    21e2:	e846 ce00 	strex	lr, ip, [r6]
    21e6:	f1be 0f00 	cmp.w	lr, #0
    21ea:	d1f6      	bne.n	21da <gpio_nrfx_pin_interrupt_configure+0xa2>
    21ec:	f3bf 8f5b 	dmb	ish
   p_reg->CONFIG[idx] &= ~GPIOTE_CONFIG_MODE_Event;
    21f0:	009b      	lsls	r3, r3, #2
    21f2:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    21f6:	f503 43c0 	add.w	r3, r3, #24576	; 0x6000
    21fa:	f8d3 6510 	ldr.w	r6, [r3, #1296]	; 0x510
    21fe:	f026 0601 	bic.w	r6, r6, #1
    2202:	f8c3 6510 	str.w	r6, [r3, #1296]	; 0x510
    p_reg->INTENCLR = mask;
    2206:	f8c2 0308 	str.w	r0, [r2, #776]	; 0x308
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    220a:	00aa      	lsls	r2, r5, #2
    220c:	f102 42a0 	add.w	r2, r2, #1342177280	; 0x50000000
	if (data->pin_int_en & BIT(pin)) {
    2210:	68e0      	ldr	r0, [r4, #12]
    2212:	f8d2 3700 	ldr.w	r3, [r2, #1792]	; 0x700
    2216:	40c8      	lsrs	r0, r1
    2218:	f423 3340 	bic.w	r3, r3, #196608	; 0x30000
    221c:	f010 0001 	ands.w	r0, r0, #1
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    2220:	f8c2 3700 	str.w	r3, [r2, #1792]	; 0x700
    2224:	d053      	beq.n	22ce <gpio_nrfx_pin_interrupt_configure+0x196>
		if (data->trig_edge & BIT(pin)) {
    2226:	6960      	ldr	r0, [r4, #20]
    2228:	40c8      	lsrs	r0, r1
    222a:	f010 0001 	ands.w	r0, r0, #1
    222e:	d060      	beq.n	22f2 <gpio_nrfx_pin_interrupt_configure+0x1ba>
			if (data->double_edge & BIT(pin)) {
    2230:	69a3      	ldr	r3, [r4, #24]
	return __atomic_fetch_or(target, value, __ATOMIC_SEQ_CST);
    2232:	4a39      	ldr	r2, [pc, #228]	; (2318 <gpio_nrfx_pin_interrupt_configure+0x1e0>)
    2234:	40cb      	lsrs	r3, r1
    2236:	07db      	lsls	r3, r3, #31
			} else if ((data->int_active_level & BIT(pin)) != 0U) {
    2238:	bf5f      	itttt	pl
    223a:	6923      	ldrpl	r3, [r4, #16]
    223c:	fa23 f101 	lsrpl.w	r1, r3, r1
    2240:	f001 0101 	andpl.w	r1, r1, #1
    2244:	f1c1 0102 	rsbpl	r1, r1, #2
    2248:	bf54      	ite	pl
    224a:	b2c9      	uxtbpl	r1, r1
				pol = NRF_GPIOTE_POLARITY_TOGGLE;
    224c:	2103      	movmi	r1, #3
    224e:	2300      	movs	r3, #0
		atomic_val_t prev = atomic_or(mask, BIT(channel));
    2250:	2601      	movs	r6, #1
    2252:	fa06 f403 	lsl.w	r4, r6, r3
    2256:	f3bf 8f5b 	dmb	ish
    225a:	e852 0f00 	ldrex	r0, [r2]
    225e:	ea40 0704 	orr.w	r7, r0, r4
    2262:	e842 7c00 	strex	ip, r7, [r2]
    2266:	f1bc 0f00 	cmp.w	ip, #0
    226a:	d1f6      	bne.n	225a <gpio_nrfx_pin_interrupt_configure+0x122>
    226c:	f3bf 8f5b 	dmb	ish
		if ((prev & BIT(channel)) == 0) {
    2270:	40d8      	lsrs	r0, r3
    2272:	f010 0001 	ands.w	r0, r0, #1
    2276:	d136      	bne.n	22e6 <gpio_nrfx_pin_interrupt_configure+0x1ae>
  p_reg->CONFIG[idx] &= ~(GPIOTE_CONFIG_PORT_PIN_Msk | GPIOTE_CONFIG_POLARITY_Msk);
    2278:	009a      	lsls	r2, r3, #2
    227a:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    227e:	f502 42c0 	add.w	r2, r2, #24576	; 0x6000
			nrf_gpiote_event_t evt =
    2282:	3340      	adds	r3, #64	; 0x40
    2284:	f8d2 6510 	ldr.w	r6, [r2, #1296]	; 0x510
    2288:	f426 3647 	bic.w	r6, r6, #203776	; 0x31c00
    228c:	f426 7640 	bic.w	r6, r6, #768	; 0x300
    2290:	009b      	lsls	r3, r3, #2
    2292:	f8c2 6510 	str.w	r6, [r2, #1296]	; 0x510
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    2296:	022d      	lsls	r5, r5, #8
    return ((uint32_t)p_reg + event);
    2298:	b29b      	uxth	r3, r3
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    229a:	f8d2 6510 	ldr.w	r6, [r2, #1296]	; 0x510
    229e:	f405 55f8 	and.w	r5, r5, #7936	; 0x1f00
    return ((uint32_t)p_reg + event);
    22a2:	f103 4380 	add.w	r3, r3, #1073741824	; 0x40000000
    22a6:	f503 43c0 	add.w	r3, r3, #24576	; 0x6000
  p_reg->CONFIG[idx] |= ((pin << GPIOTE_CONFIG_PSEL_Pos) & GPIOTE_CONFIG_PORT_PIN_Msk) |
    22aa:	ea45 4501 	orr.w	r5, r5, r1, lsl #16
    22ae:	4335      	orrs	r5, r6
    22b0:	f8c2 5510 	str.w	r5, [r2, #1296]	; 0x510
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    22b4:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    22b6:	681b      	ldr	r3, [r3, #0]
    22b8:	9301      	str	r3, [sp, #4]
    (void)dummy;
    22ba:	9b01      	ldr	r3, [sp, #4]
   p_reg->CONFIG[idx] |= GPIOTE_CONFIG_MODE_Event;
    22bc:	f8d2 3510 	ldr.w	r3, [r2, #1296]	; 0x510
    22c0:	f043 0301 	orr.w	r3, r3, #1
    22c4:	f8c2 3510 	str.w	r3, [r2, #1296]	; 0x510
    p_reg->INTENSET = mask;
    22c8:	4b12      	ldr	r3, [pc, #72]	; (2314 <gpio_nrfx_pin_interrupt_configure+0x1dc>)
    22ca:	f8c3 4304 	str.w	r4, [r3, #772]	; 0x304
}
    22ce:	b003      	add	sp, #12
    22d0:	bdf0      	pop	{r4, r5, r6, r7, pc}
	WRITE_BIT(data->pin_int_en, pin, mode != GPIO_INT_MODE_DISABLED);
    22d2:	2601      	movs	r6, #1
    22d4:	408e      	lsls	r6, r1
    22d6:	ea20 0006 	bic.w	r0, r0, r6
    22da:	e74c      	b.n	2176 <gpio_nrfx_pin_interrupt_configure+0x3e>
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    22dc:	3301      	adds	r3, #1
    22de:	2b08      	cmp	r3, #8
    22e0:	f47f af67 	bne.w	21b2 <gpio_nrfx_pin_interrupt_configure+0x7a>
    22e4:	e791      	b.n	220a <gpio_nrfx_pin_interrupt_configure+0xd2>
	for (uint8_t channel = 0; channel < GPIOTE_CH_NUM; ++channel) {
    22e6:	3301      	adds	r3, #1
    22e8:	2b08      	cmp	r3, #8
    22ea:	d1b2      	bne.n	2252 <gpio_nrfx_pin_interrupt_configure+0x11a>
	return -ENODEV;
    22ec:	f06f 0012 	mvn.w	r0, #18
    22f0:	e7ed      	b.n	22ce <gpio_nrfx_pin_interrupt_configure+0x196>
	if ((BIT(pin) & data->int_active_level) != 0U) {
    22f2:	6923      	ldr	r3, [r4, #16]
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    22f4:	f8d2 5700 	ldr.w	r5, [r2, #1792]	; 0x700
    22f8:	fa23 f101 	lsr.w	r1, r3, r1
    22fc:	f001 0101 	and.w	r1, r1, #1
    2300:	f1c1 0103 	rsb	r1, r1, #3
    2304:	f425 3340 	bic.w	r3, r5, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    2308:	ea43 4101 	orr.w	r1, r3, r1, lsl #16
    230c:	f8c2 1700 	str.w	r1, [r2, #1792]	; 0x700
}
    2310:	e7dd      	b.n	22ce <gpio_nrfx_pin_interrupt_configure+0x196>
    2312:	bf00      	nop
    2314:	40006000 	.word	0x40006000
    2318:	2000051c 	.word	0x2000051c

0000231c <gpiote_event_handler>:
{
    231c:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    231e:	494e      	ldr	r1, [pc, #312]	; (2458 <gpiote_event_handler+0x13c>)
    2320:	680d      	ldr	r5, [r1, #0]
	if (port_event) {
    2322:	2d00      	cmp	r5, #0
    2324:	d061      	beq.n	23ea <gpiote_event_handler+0xce>
	struct gpio_nrfx_data *data = get_port_data(port);
    2326:	4b4d      	ldr	r3, [pc, #308]	; (245c <gpiote_event_handler+0x140>)
    2328:	68da      	ldr	r2, [r3, #12]
	const struct gpio_nrfx_cfg *cfg = get_port_cfg(port);
    232a:	f8d3 c004 	ldr.w	ip, [r3, #4]
	uint32_t out = data->pin_int_en;
    232e:	68d3      	ldr	r3, [r2, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    2330:	e9d2 0405 	ldrd	r0, r4, [r2, #20]
    2334:	4320      	orrs	r0, r4
    2336:	ea23 0300 	bic.w	r3, r3, r0
	uint32_t port_in = nrf_gpio_port_in_read(cfg->port);
    233a:	f8dc 0004 	ldr.w	r0, [ip, #4]
	uint32_t pin_states = ~(port_in ^ data->int_active_level);
    233e:	6912      	ldr	r2, [r2, #16]
    return p_reg->IN;
    2340:	f8d0 4510 	ldr.w	r4, [r0, #1296]	; 0x510
    2344:	4054      	eors	r4, r2
	uint32_t out = pin_states & level_pins;
    2346:	ea23 0404 	bic.w	r4, r3, r4
	uint32_t bit = 1U << pin;
    234a:	2001      	movs	r0, #1
	uint32_t pin = 0U;
    234c:	2600      	movs	r6, #0
	while (level_pins) {
    234e:	2b00      	cmp	r3, #0
    2350:	d135      	bne.n	23be <gpiote_event_handler+0xa2>
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2352:	600b      	str	r3, [r1, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    2354:	680b      	ldr	r3, [r1, #0]
    2356:	9300      	str	r3, [sp, #0]
    (void)dummy;
    2358:	9b00      	ldr	r3, [sp, #0]
    return p_reg->INTENSET & mask;
    235a:	4841      	ldr	r0, [pc, #260]	; (2460 <gpiote_event_handler+0x144>)
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    235c:	2300      	movs	r3, #0
		if (nrf_gpiote_int_enable_check(NRF_GPIOTE, BIT(i)) &&
    235e:	2601      	movs	r6, #1
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2360:	461f      	mov	r7, r3
    return p_reg->INTENSET & mask;
    2362:	f8d0 2304 	ldr.w	r2, [r0, #772]	; 0x304
    2366:	fa06 f103 	lsl.w	r1, r6, r3
    236a:	4211      	tst	r1, r2
    236c:	d013      	beq.n	2396 <gpiote_event_handler+0x7a>
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    236e:	009a      	lsls	r2, r3, #2
    2370:	f102 4280 	add.w	r2, r2, #1073741824	; 0x40000000
    2374:	f502 42c2 	add.w	r2, r2, #24832	; 0x6100
    2378:	6811      	ldr	r1, [r2, #0]
    237a:	b161      	cbz	r1, 2396 <gpiote_event_handler+0x7a>
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    237c:	f503 71a2 	add.w	r1, r3, #324	; 0x144
    2380:	f850 1021 	ldr.w	r1, [r0, r1, lsl #2]
    *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event)) = 0;
    2384:	6017      	str	r7, [r2, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)nrf_gpiote_event_address_get(p_reg, event));
    2386:	6812      	ldr	r2, [r2, #0]
    2388:	9201      	str	r2, [sp, #4]
    return ((p_reg->CONFIG[idx] & GPIOTE_CONFIG_PORT_PIN_Msk) >> GPIOTE_CONFIG_PSEL_Pos);
    238a:	f3c1 2104 	ubfx	r1, r1, #8, #5
			fired_triggers[abs_pin / 32U] |= BIT(abs_pin % 32);
    238e:	fa06 f101 	lsl.w	r1, r6, r1
    (void)dummy;
    2392:	9a01      	ldr	r2, [sp, #4]
    2394:	430c      	orrs	r4, r1
	for (size_t i = 0; i < GPIOTE_CH_NUM; i++) {
    2396:	3301      	adds	r3, #1
    2398:	2b08      	cmp	r3, #8
    239a:	d1e2      	bne.n	2362 <gpiote_event_handler+0x46>
	if (fired_triggers[0]) {
    239c:	bb3c      	cbnz	r4, 23ee <gpiote_event_handler+0xd2>
	if (port_event) {
    239e:	b165      	cbz	r5, 23ba <gpiote_event_handler+0x9e>
	const struct gpio_nrfx_data *data = get_port_data(port);
    23a0:	4b2e      	ldr	r3, [pc, #184]	; (245c <gpiote_event_handler+0x140>)
    23a2:	68d8      	ldr	r0, [r3, #12]
	const struct gpio_nrfx_cfg *cfg = get_port_cfg(port);
    23a4:	685e      	ldr	r6, [r3, #4]
	uint32_t out = data->pin_int_en;
    23a6:	68c1      	ldr	r1, [r0, #12]
	out &= ~data->trig_edge & ~data->double_edge;
    23a8:	e9d0 3205 	ldrd	r3, r2, [r0, #20]
    23ac:	4313      	orrs	r3, r2
    23ae:	ea21 0103 	bic.w	r1, r1, r3
	uint32_t bit = 1U << pin;
    23b2:	2401      	movs	r4, #1
	uint32_t pin = 0U;
    23b4:	2500      	movs	r5, #0
	while (level_pins) {
    23b6:	2900      	cmp	r1, #0
    23b8:	d131      	bne.n	241e <gpiote_event_handler+0x102>
}
    23ba:	b003      	add	sp, #12
    23bc:	bdf0      	pop	{r4, r5, r6, r7, pc}
		if (level_pins & bit) {
    23be:	4203      	tst	r3, r0
    23c0:	d010      	beq.n	23e4 <gpiote_event_handler+0xc8>
			uint32_t abs_pin = NRF_GPIO_PIN_MAP(cfg->port_num, pin);
    23c2:	f89c 7008 	ldrb.w	r7, [ip, #8]
    23c6:	f006 021f 	and.w	r2, r6, #31
    23ca:	ea42 1247 	orr.w	r2, r2, r7, lsl #5
    23ce:	0092      	lsls	r2, r2, #2
    23d0:	f102 42a0 	add.w	r2, r2, #1342177280	; 0x50000000
			level_pins &= ~bit;
    23d4:	ea23 0300 	bic.w	r3, r3, r0
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    23d8:	f8d2 7700 	ldr.w	r7, [r2, #1792]	; 0x700
    23dc:	f427 3740 	bic.w	r7, r7, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    23e0:	f8c2 7700 	str.w	r7, [r2, #1792]	; 0x700
		++pin;
    23e4:	3601      	adds	r6, #1
		bit <<= 1;
    23e6:	0040      	lsls	r0, r0, #1
    23e8:	e7b1      	b.n	234e <gpiote_event_handler+0x32>
	uint32_t fired_triggers[GPIO_COUNT] = {0};
    23ea:	462c      	mov	r4, r5
    23ec:	e7b5      	b.n	235a <gpiote_event_handler+0x3e>
	struct gpio_nrfx_data *data = get_port_data(port);
    23ee:	4f1b      	ldr	r7, [pc, #108]	; (245c <gpiote_event_handler+0x140>)
					struct device *port,
					uint32_t pins)
{
	struct gpio_callback *cb, *tmp;

	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    23f0:	68fb      	ldr	r3, [r7, #12]
    23f2:	6859      	ldr	r1, [r3, #4]
    23f4:	2900      	cmp	r1, #0
    23f6:	d0d2      	beq.n	239e <gpiote_event_handler+0x82>
	return node->next;
    23f8:	680e      	ldr	r6, [r1, #0]
    23fa:	2e00      	cmp	r6, #0
    23fc:	bf38      	it	cc
    23fe:	2600      	movcc	r6, #0
		if (cb->pin_mask & pins) {
    2400:	688a      	ldr	r2, [r1, #8]
    2402:	4022      	ands	r2, r4
    2404:	d002      	beq.n	240c <gpiote_event_handler+0xf0>
			__ASSERT(cb->handler, "No callback handler!");
			cb->handler(port, cb, cb->pin_mask & pins);
    2406:	684b      	ldr	r3, [r1, #4]
    2408:	4638      	mov	r0, r7
    240a:	4798      	blx	r3
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(list, cb, tmp, node) {
    240c:	2e00      	cmp	r6, #0
    240e:	d0c6      	beq.n	239e <gpiote_event_handler+0x82>
    2410:	6833      	ldr	r3, [r6, #0]
    2412:	2b00      	cmp	r3, #0
    2414:	bf38      	it	cc
    2416:	2300      	movcc	r3, #0
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    2418:	4631      	mov	r1, r6
    241a:	461e      	mov	r6, r3
    241c:	e7f0      	b.n	2400 <gpiote_event_handler+0xe4>
		if (level_pins & bit) {
    241e:	420c      	tst	r4, r1
    2420:	d017      	beq.n	2452 <gpiote_event_handler+0x136>
			uint32_t abs_pin = NRF_GPIO_PIN_MAP(cfg->port_num, pin);
    2422:	7a32      	ldrb	r2, [r6, #8]
    2424:	f005 031f 	and.w	r3, r5, #31
    2428:	ea43 1342 	orr.w	r3, r3, r2, lsl #5
    242c:	009b      	lsls	r3, r3, #2
	if ((BIT(pin) & data->int_active_level) != 0U) {
    242e:	6902      	ldr	r2, [r0, #16]
    2430:	f103 43a0 	add.w	r3, r3, #1342177280	; 0x50000000
    2434:	40ea      	lsrs	r2, r5
    uint32_t cnf = reg->PIN_CNF[pin_number] & ~GPIO_PIN_CNF_SENSE_Msk;
    2436:	f8d3 7700 	ldr.w	r7, [r3, #1792]	; 0x700
    243a:	f002 0201 	and.w	r2, r2, #1
    243e:	f1c2 0203 	rsb	r2, r2, #3
    2442:	f427 3740 	bic.w	r7, r7, #196608	; 0x30000
    reg->PIN_CNF[pin_number] = cnf | (sense_config << GPIO_PIN_CNF_SENSE_Pos);
    2446:	ea47 4202 	orr.w	r2, r7, r2, lsl #16
    244a:	f8c3 2700 	str.w	r2, [r3, #1792]	; 0x700
			level_pins &= ~bit;
    244e:	ea21 0104 	bic.w	r1, r1, r4
		++pin;
    2452:	3501      	adds	r5, #1
		bit <<= 1;
    2454:	0064      	lsls	r4, r4, #1
    2456:	e7ae      	b.n	23b6 <gpiote_event_handler+0x9a>
    2458:	4000617c 	.word	0x4000617c
    245c:	20002c78 	.word	0x20002c78
    2460:	40006000 	.word	0x40006000

00002464 <z_mrsh_gpio_config>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
uintptr_t z_mrsh_gpio_config(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2464:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    2468:	f8df 804c 	ldr.w	r8, [pc, #76]	; 24b8 <z_mrsh_gpio_config+0x54>
    246c:	f8d8 3008 	ldr.w	r3, [r8, #8]
{
    2470:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    2472:	9a08      	ldr	r2, [sp, #32]
    2474:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_config(*(struct device **)&arg0, *(gpio_pin_t*)&arg1, *(gpio_flags_t*)&arg2)
    2478:	b2ce      	uxtb	r6, r1
{
    247a:	4604      	mov	r4, r0
#include <syscall_handler.h>

static inline int z_vrfy_gpio_config(struct device *port,
				     gpio_pin_t pin, gpio_flags_t flags)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, pin_configure));
    247c:	f7fd fe2e 	bl	dc <z_object_find>
					 enum k_objects otype,
					 enum _obj_init_check init)
{
	int ret;

	ret = z_object_validate(ko, otype, init);
    2480:	2200      	movs	r2, #0
    2482:	211b      	movs	r1, #27
    2484:	f002 fcf0 	bl	4e68 <z_object_validate>
    2488:	4642      	mov	r2, r8
    248a:	4605      	mov	r5, r0
    248c:	b130      	cbz	r0, 249c <z_mrsh_gpio_config+0x38>
    248e:	f003 fbd3 	bl	5c38 <arch_is_user_context>
    2492:	6893      	ldr	r3, [r2, #8]
    2494:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2498:	f003 facf 	bl	5a3a <arch_syscall_oops>
    249c:	68a3      	ldr	r3, [r4, #8]
    249e:	681b      	ldr	r3, [r3, #0]
    24a0:	2b00      	cmp	r3, #0
    24a2:	d0f4      	beq.n	248e <z_mrsh_gpio_config+0x2a>
	return api->pin_configure(port, pin, flags);
    24a4:	463a      	mov	r2, r7
    24a6:	4631      	mov	r1, r6
    24a8:	4620      	mov	r0, r4
    24aa:	4798      	blx	r3
;
	_current->syscall_frame = NULL;
    24ac:	f8d8 3008 	ldr.w	r3, [r8, #8]
    24b0:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    24b4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    24b8:	20000524 	.word	0x20000524

000024bc <z_mrsh_gpio_port_get_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_get_raw(struct device * port, gpio_port_value_t * value);
uintptr_t z_mrsh_gpio_port_get_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    24bc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    24be:	4e17      	ldr	r6, [pc, #92]	; (251c <z_mrsh_gpio_port_get_raw+0x60>)
    24c0:	9a08      	ldr	r2, [sp, #32]
    24c2:	68b3      	ldr	r3, [r6, #8]
    24c4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    24c8:	460d      	mov	r5, r1
    24ca:	4604      	mov	r4, r0
#include <syscalls/gpio_config_mrsh.c>

static inline int z_vrfy_gpio_port_get_raw(struct device *port,
					   gpio_port_value_t *value)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_get_raw));
    24cc:	f7fd fe06 	bl	dc <z_object_find>
    24d0:	2200      	movs	r2, #0
    24d2:	211b      	movs	r1, #27
    24d4:	f002 fcc8 	bl	4e68 <z_object_validate>
    24d8:	4632      	mov	r2, r6
    24da:	b178      	cbz	r0, 24fc <z_mrsh_gpio_port_get_raw+0x40>
    24dc:	f003 fbac 	bl	5c38 <arch_is_user_context>
    24e0:	6893      	ldr	r3, [r2, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(value, sizeof(gpio_port_value_t)));
    24e2:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    24e6:	f003 faa8 	bl	5a3a <arch_syscall_oops>
	return api->port_get_raw(port, value);
    24ea:	68a3      	ldr	r3, [r4, #8]
    24ec:	4629      	mov	r1, r5
    24ee:	685b      	ldr	r3, [r3, #4]
    24f0:	4620      	mov	r0, r4
    24f2:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_get_raw(*(struct device **)&arg0, *(gpio_port_value_t **)&arg1)
;
	_current->syscall_frame = NULL;
    24f4:	68b3      	ldr	r3, [r6, #8]
    24f6:	f8c3 7084 	str.w	r7, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    24fa:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_get_raw));
    24fc:	68a3      	ldr	r3, [r4, #8]
    24fe:	685b      	ldr	r3, [r3, #4]
    2500:	2b00      	cmp	r3, #0
    2502:	d0eb      	beq.n	24dc <z_mrsh_gpio_port_get_raw+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(value, sizeof(gpio_port_value_t)));
    2504:	2201      	movs	r2, #1
    2506:	2104      	movs	r1, #4
    2508:	4628      	mov	r0, r5
    250a:	f003 fac4 	bl	5a96 <arch_buffer_validate>
    250e:	4607      	mov	r7, r0
    2510:	2800      	cmp	r0, #0
    2512:	d0ea      	beq.n	24ea <z_mrsh_gpio_port_get_raw+0x2e>
    2514:	f003 fb90 	bl	5c38 <arch_is_user_context>
    2518:	68b3      	ldr	r3, [r6, #8]
    251a:	e7e2      	b.n	24e2 <z_mrsh_gpio_port_get_raw+0x26>
    251c:	20000524 	.word	0x20000524

00002520 <z_mrsh_gpio_port_set_masked_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_set_masked_raw(struct device * port, gpio_port_pins_t mask, gpio_port_value_t value);
uintptr_t z_mrsh_gpio_port_set_masked_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2520:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    2524:	f8df 804c 	ldr.w	r8, [pc, #76]	; 2574 <z_mrsh_gpio_port_set_masked_raw+0x54>
    2528:	f8d8 3008 	ldr.w	r3, [r8, #8]
{
    252c:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    252e:	9a08      	ldr	r2, [sp, #32]
    2530:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2534:	460e      	mov	r6, r1
    2536:	4604      	mov	r4, r0
#include <syscalls/gpio_port_get_raw_mrsh.c>

static inline int z_vrfy_gpio_port_set_masked_raw(struct device *port,
		gpio_port_pins_t mask, gpio_port_value_t value)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_set_masked_raw));
    2538:	f7fd fdd0 	bl	dc <z_object_find>
    253c:	2200      	movs	r2, #0
    253e:	211b      	movs	r1, #27
    2540:	f002 fc92 	bl	4e68 <z_object_validate>
    2544:	4642      	mov	r2, r8
    2546:	4605      	mov	r5, r0
    2548:	b130      	cbz	r0, 2558 <z_mrsh_gpio_port_set_masked_raw+0x38>
    254a:	f003 fb75 	bl	5c38 <arch_is_user_context>
    254e:	6893      	ldr	r3, [r2, #8]
    2550:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2554:	f003 fa71 	bl	5a3a <arch_syscall_oops>
    2558:	68a3      	ldr	r3, [r4, #8]
    255a:	689b      	ldr	r3, [r3, #8]
    255c:	2b00      	cmp	r3, #0
    255e:	d0f4      	beq.n	254a <z_mrsh_gpio_port_set_masked_raw+0x2a>
	return api->port_set_masked_raw(port, mask, value);
    2560:	463a      	mov	r2, r7
    2562:	4631      	mov	r1, r6
    2564:	4620      	mov	r0, r4
    2566:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_set_masked_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1, *(gpio_port_value_t*)&arg2)
;
	_current->syscall_frame = NULL;
    2568:	f8d8 3008 	ldr.w	r3, [r8, #8]
    256c:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2570:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    2574:	20000524 	.word	0x20000524

00002578 <z_mrsh_gpio_port_set_bits_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_set_bits_raw(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_set_bits_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2578:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    257a:	4f11      	ldr	r7, [pc, #68]	; (25c0 <z_mrsh_gpio_port_set_bits_raw+0x48>)
    257c:	9a08      	ldr	r2, [sp, #32]
    257e:	68bb      	ldr	r3, [r7, #8]
    2580:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2584:	460e      	mov	r6, r1
    2586:	4604      	mov	r4, r0
#include <syscalls/gpio_port_set_masked_raw_mrsh.c>

static inline int z_vrfy_gpio_port_set_bits_raw(struct device *port,
						gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_set_bits_raw));
    2588:	f7fd fda8 	bl	dc <z_object_find>
    258c:	2200      	movs	r2, #0
    258e:	211b      	movs	r1, #27
    2590:	f002 fc6a 	bl	4e68 <z_object_validate>
    2594:	463a      	mov	r2, r7
    2596:	4605      	mov	r5, r0
    2598:	b130      	cbz	r0, 25a8 <z_mrsh_gpio_port_set_bits_raw+0x30>
    259a:	f003 fb4d 	bl	5c38 <arch_is_user_context>
    259e:	6893      	ldr	r3, [r2, #8]
    25a0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    25a4:	f003 fa49 	bl	5a3a <arch_syscall_oops>
    25a8:	68a3      	ldr	r3, [r4, #8]
    25aa:	68db      	ldr	r3, [r3, #12]
    25ac:	2b00      	cmp	r3, #0
    25ae:	d0f4      	beq.n	259a <z_mrsh_gpio_port_set_bits_raw+0x22>
	return api->port_set_bits_raw(port, pins);
    25b0:	4631      	mov	r1, r6
    25b2:	4620      	mov	r0, r4
    25b4:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_set_bits_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    25b6:	68bb      	ldr	r3, [r7, #8]
    25b8:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    25bc:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    25be:	bf00      	nop
    25c0:	20000524 	.word	0x20000524

000025c4 <z_mrsh_gpio_port_clear_bits_raw>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_clear_bits_raw(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    25c4:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    25c6:	4f11      	ldr	r7, [pc, #68]	; (260c <z_mrsh_gpio_port_clear_bits_raw+0x48>)
    25c8:	9a08      	ldr	r2, [sp, #32]
    25ca:	68bb      	ldr	r3, [r7, #8]
    25cc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    25d0:	460e      	mov	r6, r1
    25d2:	4604      	mov	r4, r0
#include <syscalls/gpio_port_set_bits_raw_mrsh.c>

static inline int z_vrfy_gpio_port_clear_bits_raw(struct device *port,
						  gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_clear_bits_raw));
    25d4:	f7fd fd82 	bl	dc <z_object_find>
    25d8:	2200      	movs	r2, #0
    25da:	211b      	movs	r1, #27
    25dc:	f002 fc44 	bl	4e68 <z_object_validate>
    25e0:	463a      	mov	r2, r7
    25e2:	4605      	mov	r5, r0
    25e4:	b130      	cbz	r0, 25f4 <z_mrsh_gpio_port_clear_bits_raw+0x30>
    25e6:	f003 fb27 	bl	5c38 <arch_is_user_context>
    25ea:	6893      	ldr	r3, [r2, #8]
    25ec:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    25f0:	f003 fa23 	bl	5a3a <arch_syscall_oops>
    25f4:	68a3      	ldr	r3, [r4, #8]
    25f6:	691b      	ldr	r3, [r3, #16]
    25f8:	2b00      	cmp	r3, #0
    25fa:	d0f4      	beq.n	25e6 <z_mrsh_gpio_port_clear_bits_raw+0x22>
	return api->port_clear_bits_raw(port, pins);
    25fc:	4631      	mov	r1, r6
    25fe:	4620      	mov	r0, r4
    2600:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_clear_bits_raw(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    2602:	68bb      	ldr	r3, [r7, #8]
    2604:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2608:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    260a:	bf00      	nop
    260c:	20000524 	.word	0x20000524

00002610 <z_mrsh_gpio_port_toggle_bits>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_port_toggle_bits(struct device * port, gpio_port_pins_t pins);
uintptr_t z_mrsh_gpio_port_toggle_bits(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2610:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2612:	4f11      	ldr	r7, [pc, #68]	; (2658 <z_mrsh_gpio_port_toggle_bits+0x48>)
    2614:	9a08      	ldr	r2, [sp, #32]
    2616:	68bb      	ldr	r3, [r7, #8]
    2618:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    261c:	460e      	mov	r6, r1
    261e:	4604      	mov	r4, r0
#include <syscalls/gpio_port_clear_bits_raw_mrsh.c>

static inline int z_vrfy_gpio_port_toggle_bits(struct device *port,
					       gpio_port_pins_t pins)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, port_toggle_bits));
    2620:	f7fd fd5c 	bl	dc <z_object_find>
    2624:	2200      	movs	r2, #0
    2626:	211b      	movs	r1, #27
    2628:	f002 fc1e 	bl	4e68 <z_object_validate>
    262c:	463a      	mov	r2, r7
    262e:	4605      	mov	r5, r0
    2630:	b130      	cbz	r0, 2640 <z_mrsh_gpio_port_toggle_bits+0x30>
    2632:	f003 fb01 	bl	5c38 <arch_is_user_context>
    2636:	6893      	ldr	r3, [r2, #8]
    2638:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    263c:	f003 f9fd 	bl	5a3a <arch_syscall_oops>
    2640:	68a3      	ldr	r3, [r4, #8]
    2642:	695b      	ldr	r3, [r3, #20]
    2644:	2b00      	cmp	r3, #0
    2646:	d0f4      	beq.n	2632 <z_mrsh_gpio_port_toggle_bits+0x22>
	return api->port_toggle_bits(port, pins);
    2648:	4631      	mov	r1, r6
    264a:	4620      	mov	r0, r4
    264c:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_port_toggle_bits(*(struct device **)&arg0, *(gpio_port_pins_t*)&arg1)
;
	_current->syscall_frame = NULL;
    264e:	68bb      	ldr	r3, [r7, #8]
    2650:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2654:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    2656:	bf00      	nop
    2658:	20000524 	.word	0x20000524

0000265c <z_mrsh_gpio_pin_interrupt_configure>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_pin_interrupt_configure(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
uintptr_t z_mrsh_gpio_pin_interrupt_configure(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    265c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    2660:	4d19      	ldr	r5, [pc, #100]	; (26c8 <z_mrsh_gpio_pin_interrupt_configure+0x6c>)
    2662:	68ab      	ldr	r3, [r5, #8]
{
    2664:	4614      	mov	r4, r2
	_current->syscall_frame = ssf;
    2666:	9a08      	ldr	r2, [sp, #32]
    2668:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_pin_interrupt_configure(*(struct device **)&arg0, *(gpio_pin_t*)&arg1, *(gpio_flags_t*)&arg2)
    266c:	fa5f f881 	uxtb.w	r8, r1
{
    2670:	4607      	mov	r7, r0

static inline int z_vrfy_gpio_pin_interrupt_configure(struct device *port,
						      gpio_pin_t pin,
						      gpio_flags_t flags)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(port, pin_interrupt_configure));
    2672:	f7fd fd33 	bl	dc <z_object_find>
    2676:	2200      	movs	r2, #0
    2678:	211b      	movs	r1, #27
    267a:	f002 fbf5 	bl	4e68 <z_object_validate>
    267e:	b130      	cbz	r0, 268e <z_mrsh_gpio_pin_interrupt_configure+0x32>
    2680:	f003 fada 	bl	5c38 <arch_is_user_context>
    2684:	68ab      	ldr	r3, [r5, #8]
    2686:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    268a:	f003 f9d6 	bl	5a3a <arch_syscall_oops>
    268e:	68bb      	ldr	r3, [r7, #8]
    2690:	699e      	ldr	r6, [r3, #24]
    2692:	2e00      	cmp	r6, #0
    2694:	d0f4      	beq.n	2680 <z_mrsh_gpio_pin_interrupt_configure+0x24>
	if (((flags & GPIO_INT_LEVELS_LOGICAL) != 0) &&
    2696:	0423      	lsls	r3, r4, #16
    2698:	d508      	bpl.n	26ac <z_mrsh_gpio_pin_interrupt_configure+0x50>
	    ((data->invert & (gpio_port_pins_t)BIT(pin)) != 0)) {
    269a:	68fa      	ldr	r2, [r7, #12]
    269c:	2301      	movs	r3, #1
    269e:	6812      	ldr	r2, [r2, #0]
    26a0:	fa03 f308 	lsl.w	r3, r3, r8
	if (((flags & GPIO_INT_LEVELS_LOGICAL) != 0) &&
    26a4:	4213      	tst	r3, r2
		flags ^= (GPIO_INT_LOW_0 | GPIO_INT_HIGH_1);
    26a6:	bf18      	it	ne
    26a8:	f484 24c0 	eorne.w	r4, r4, #393216	; 0x60000
	return api->pin_interrupt_configure(port, pin, mode, trig);
    26ac:	f404 23c0 	and.w	r3, r4, #393216	; 0x60000
    26b0:	f404 32b0 	and.w	r2, r4, #90112	; 0x16000
    26b4:	4641      	mov	r1, r8
    26b6:	4638      	mov	r0, r7
    26b8:	47b0      	blx	r6
;
	_current->syscall_frame = NULL;
    26ba:	68ab      	ldr	r3, [r5, #8]
    26bc:	2200      	movs	r2, #0
    26be:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    26c2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    26c6:	bf00      	nop
    26c8:	20000524 	.word	0x20000524

000026cc <z_mrsh_gpio_get_pending_int>:
#include <syscalls/gpio.h>

extern int z_vrfy_gpio_get_pending_int(struct device * dev);
uintptr_t z_mrsh_gpio_get_pending_int(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    26cc:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    26ce:	4e10      	ldr	r6, [pc, #64]	; (2710 <z_mrsh_gpio_get_pending_int+0x44>)
    26d0:	9a06      	ldr	r2, [sp, #24]
    26d2:	68b3      	ldr	r3, [r6, #8]
    26d4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    26d8:	4604      	mov	r4, r0
}
#include <syscalls/gpio_pin_interrupt_configure_mrsh.c>

static inline int z_vrfy_gpio_get_pending_int(struct device *dev)
{
	Z_OOPS(Z_SYSCALL_DRIVER_GPIO(dev, get_pending_int));
    26da:	f7fd fcff 	bl	dc <z_object_find>
    26de:	2200      	movs	r2, #0
    26e0:	211b      	movs	r1, #27
    26e2:	f002 fbc1 	bl	4e68 <z_object_validate>
    26e6:	4632      	mov	r2, r6
    26e8:	4605      	mov	r5, r0
    26ea:	b130      	cbz	r0, 26fa <z_mrsh_gpio_get_pending_int+0x2e>
    26ec:	f003 faa4 	bl	5c38 <arch_is_user_context>
    26f0:	6893      	ldr	r3, [r2, #8]
    26f2:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    26f6:	f003 f9a0 	bl	5a3a <arch_syscall_oops>
    26fa:	68a3      	ldr	r3, [r4, #8]
    26fc:	6a1b      	ldr	r3, [r3, #32]
    26fe:	2b00      	cmp	r3, #0
    2700:	d0f4      	beq.n	26ec <z_mrsh_gpio_get_pending_int+0x20>

	if (api->get_pending_int == NULL) {
		return -ENOTSUP;
	}

	return api->get_pending_int(dev);
    2702:	4620      	mov	r0, r4
    2704:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_gpio_get_pending_int(*(struct device **)&arg0)
;
	_current->syscall_frame = NULL;
    2706:	68b3      	ldr	r3, [r6, #8]
    2708:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    270c:	bd70      	pop	{r4, r5, r6, pc}
    270e:	bf00      	nop
    2710:	20000524 	.word	0x20000524

00002714 <uart_nrfx_err_check>:
    p_reg->INTENCLR = mask;
}

NRF_STATIC_INLINE uint32_t nrf_uart_errorsrc_get_and_clear(NRF_UART_Type * p_reg)
{
    uint32_t errsrc_mask = p_reg->ERRORSRC;
    2714:	4b02      	ldr	r3, [pc, #8]	; (2720 <uart_nrfx_err_check+0xc>)
    2716:	f8d3 0480 	ldr.w	r0, [r3, #1152]	; 0x480
    p_reg->ERRORSRC = errsrc_mask;
    271a:	f8c3 0480 	str.w	r0, [r3, #1152]	; 0x480
/** Console I/O function */
static int uart_nrfx_err_check(struct device *dev)
{
	/* register bitfields maps to the defines in uart.h */
	return nrf_uart_errorsrc_get_and_clear(uart0_addr);
}
    271e:	4770      	bx	lr
    2720:	40002000 	.word	0x40002000

00002724 <uart_nrfx_configure>:

static int uart_nrfx_configure(struct device *dev,
			       const struct uart_config *cfg)
{
    2724:	b530      	push	{r4, r5, lr}
		break;
	default:
		return -ENOTSUP;
	}
#else
	if (cfg->stop_bits != UART_CFG_STOP_BITS_1) {
    2726:	794b      	ldrb	r3, [r1, #5]
    2728:	2b01      	cmp	r3, #1
    272a:	d11e      	bne.n	276a <uart_nrfx_configure+0x46>
		return -ENOTSUP;
	}
#endif

	if (cfg->data_bits != UART_CFG_DATA_BITS_8) {
    272c:	798b      	ldrb	r3, [r1, #6]
    272e:	2b03      	cmp	r3, #3
    2730:	d11b      	bne.n	276a <uart_nrfx_configure+0x46>
		return -ENOTSUP;
	}

	switch (cfg->flow_ctrl) {
    2732:	79ca      	ldrb	r2, [r1, #7]
    2734:	b10a      	cbz	r2, 273a <uart_nrfx_configure+0x16>
    2736:	2a01      	cmp	r2, #1
    2738:	d117      	bne.n	276a <uart_nrfx_configure+0x46>
	}

#if defined(UART_CONFIG_PARITYTYPE_Msk)
	uart_cfg.paritytype = NRF_UART_PARITYTYPE_EVEN;
#endif
	switch (cfg->parity) {
    273a:	790c      	ldrb	r4, [r1, #4]
    273c:	b114      	cbz	r4, 2744 <uart_nrfx_configure+0x20>
    273e:	2c02      	cmp	r4, #2
    2740:	d113      	bne.n	276a <uart_nrfx_configure+0x46>
    2742:	240e      	movs	r4, #14
#endif
	default:
		return -ENOTSUP;
	}

	if (baudrate_set(dev, cfg->baudrate) != 0) {
    2744:	680b      	ldr	r3, [r1, #0]
	switch (baudrate) {
    2746:	f5b3 4f16 	cmp.w	r3, #38400	; 0x9600
    274a:	d05f      	beq.n	280c <uart_nrfx_configure+0xe8>
    274c:	d82b      	bhi.n	27a6 <uart_nrfx_configure+0x82>
    274e:	f5b3 5f16 	cmp.w	r3, #9600	; 0x2580
    2752:	d05d      	beq.n	2810 <uart_nrfx_configure+0xec>
    2754:	d814      	bhi.n	2780 <uart_nrfx_configure+0x5c>
    2756:	f5b3 6f96 	cmp.w	r3, #1200	; 0x4b0
    275a:	d05b      	beq.n	2814 <uart_nrfx_configure+0xf0>
    275c:	d808      	bhi.n	2770 <uart_nrfx_configure+0x4c>
    275e:	f5b3 7f96 	cmp.w	r3, #300	; 0x12c
    2762:	d05a      	beq.n	281a <uart_nrfx_configure+0xf6>
    2764:	f5b3 7f16 	cmp.w	r3, #600	; 0x258
    2768:	d05a      	beq.n	2820 <uart_nrfx_configure+0xfc>
    276a:	f06f 0022 	mvn.w	r0, #34	; 0x22
    276e:	e04c      	b.n	280a <uart_nrfx_configure+0xe6>
    2770:	f5b3 6f16 	cmp.w	r3, #2400	; 0x960
    2774:	d057      	beq.n	2826 <uart_nrfx_configure+0x102>
    2776:	f5b3 5f96 	cmp.w	r3, #4800	; 0x12c0
    277a:	d1f6      	bne.n	276a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_4800;
    277c:	4b34      	ldr	r3, [pc, #208]	; (2850 <uart_nrfx_configure+0x12c>)
    277e:	e039      	b.n	27f4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2780:	f5b3 4fe1 	cmp.w	r3, #28800	; 0x7080
    2784:	d052      	beq.n	282c <uart_nrfx_configure+0x108>
    2786:	d807      	bhi.n	2798 <uart_nrfx_configure+0x74>
    2788:	f5b3 5f61 	cmp.w	r3, #14400	; 0x3840
    278c:	d050      	beq.n	2830 <uart_nrfx_configure+0x10c>
    278e:	f5b3 4f96 	cmp.w	r3, #19200	; 0x4b00
    2792:	d1ea      	bne.n	276a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_19200;
    2794:	4b2f      	ldr	r3, [pc, #188]	; (2854 <uart_nrfx_configure+0x130>)
    2796:	e02d      	b.n	27f4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2798:	f647 2512 	movw	r5, #31250	; 0x7a12
    279c:	42ab      	cmp	r3, r5
    279e:	d1e4      	bne.n	276a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_31250;
    27a0:	f44f 0300 	mov.w	r3, #8388608	; 0x800000
    27a4:	e026      	b.n	27f4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    27a6:	f5b3 3f61 	cmp.w	r3, #230400	; 0x38400
    27aa:	d044      	beq.n	2836 <uart_nrfx_configure+0x112>
    27ac:	d811      	bhi.n	27d2 <uart_nrfx_configure+0xae>
    27ae:	f5b3 3f96 	cmp.w	r3, #76800	; 0x12c00
    27b2:	d042      	beq.n	283a <uart_nrfx_configure+0x116>
    27b4:	d808      	bhi.n	27c8 <uart_nrfx_configure+0xa4>
    27b6:	f64d 25c0 	movw	r5, #56000	; 0xdac0
    27ba:	42ab      	cmp	r3, r5
    27bc:	d03f      	beq.n	283e <uart_nrfx_configure+0x11a>
    27be:	f5b3 4f61 	cmp.w	r3, #57600	; 0xe100
    27c2:	d1d2      	bne.n	276a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_57600;
    27c4:	4b24      	ldr	r3, [pc, #144]	; (2858 <uart_nrfx_configure+0x134>)
    27c6:	e015      	b.n	27f4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    27c8:	f5b3 3fe1 	cmp.w	r3, #115200	; 0x1c200
    27cc:	d1cd      	bne.n	276a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_115200;
    27ce:	4b23      	ldr	r3, [pc, #140]	; (285c <uart_nrfx_configure+0x138>)
    27d0:	e010      	b.n	27f4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    27d2:	f5b3 2f61 	cmp.w	r3, #921600	; 0xe1000
    27d6:	d035      	beq.n	2844 <uart_nrfx_configure+0x120>
    27d8:	d807      	bhi.n	27ea <uart_nrfx_configure+0xc6>
    27da:	4d21      	ldr	r5, [pc, #132]	; (2860 <uart_nrfx_configure+0x13c>)
    27dc:	42ab      	cmp	r3, r5
    27de:	d033      	beq.n	2848 <uart_nrfx_configure+0x124>
    27e0:	f5b3 2fe1 	cmp.w	r3, #460800	; 0x70800
    27e4:	d1c1      	bne.n	276a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_460800;
    27e6:	4b1f      	ldr	r3, [pc, #124]	; (2864 <uart_nrfx_configure+0x140>)
    27e8:	e004      	b.n	27f4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    27ea:	4d1f      	ldr	r5, [pc, #124]	; (2868 <uart_nrfx_configure+0x144>)
    27ec:	42ab      	cmp	r3, r5
    27ee:	d1bc      	bne.n	276a <uart_nrfx_configure+0x46>
		nrf_baudrate = NRF_UART_BAUDRATE_1000000;
    27f0:	f04f 5380 	mov.w	r3, #268435456	; 0x10000000
                    | (uint32_t)p_cfg->hwfc;
}

NRF_STATIC_INLINE void nrf_uart_baudrate_set(NRF_UART_Type * p_reg, nrf_uart_baudrate_t baudrate)
{
    p_reg->BAUDRATE = baudrate;
    27f4:	4d1d      	ldr	r5, [pc, #116]	; (286c <uart_nrfx_configure+0x148>)
                    | (uint32_t)p_cfg->hwfc;
    27f6:	4322      	orrs	r2, r4
    p_reg->BAUDRATE = baudrate;
    27f8:	f8c5 3524 	str.w	r3, [r5, #1316]	; 0x524
    p_reg->CONFIG = (uint32_t)p_cfg->parity
    27fc:	f8c5 256c 	str.w	r2, [r5, #1388]	; 0x56c
		return -ENOTSUP;
	}

	nrf_uart_configure(uart0_addr, &uart_cfg);

	get_dev_data(dev)->uart_config = *cfg;
    2800:	68c3      	ldr	r3, [r0, #12]
    2802:	c903      	ldmia	r1, {r0, r1}
    2804:	e883 0003 	stmia.w	r3, {r0, r1}

	return 0;
    2808:	2000      	movs	r0, #0
}
    280a:	bd30      	pop	{r4, r5, pc}
		nrf_baudrate = NRF_UART_BAUDRATE_38400;
    280c:	4b18      	ldr	r3, [pc, #96]	; (2870 <uart_nrfx_configure+0x14c>)
    280e:	e7f1      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_9600;
    2810:	4b18      	ldr	r3, [pc, #96]	; (2874 <uart_nrfx_configure+0x150>)
    2812:	e7ef      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_1200;
    2814:	f44f 239e 	mov.w	r3, #323584	; 0x4f000
    2818:	e7ec      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = 0x00014000;
    281a:	f44f 33a0 	mov.w	r3, #81920	; 0x14000
    281e:	e7e9      	b.n	27f4 <uart_nrfx_configure+0xd0>
	switch (baudrate) {
    2820:	f44f 331c 	mov.w	r3, #159744	; 0x27000
    2824:	e7e6      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_2400;
    2826:	f44f 231d 	mov.w	r3, #643072	; 0x9d000
    282a:	e7e3      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_28800;
    282c:	4b12      	ldr	r3, [pc, #72]	; (2878 <uart_nrfx_configure+0x154>)
    282e:	e7e1      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_14400;
    2830:	f44f 136c 	mov.w	r3, #3866624	; 0x3b0000
    2834:	e7de      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_230400;
    2836:	4b11      	ldr	r3, [pc, #68]	; (287c <uart_nrfx_configure+0x158>)
    2838:	e7dc      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_76800;
    283a:	4b11      	ldr	r3, [pc, #68]	; (2880 <uart_nrfx_configure+0x15c>)
    283c:	e7da      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_56000;
    283e:	f44f 0365 	mov.w	r3, #15007744	; 0xe50000
    2842:	e7d7      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_921600;
    2844:	4b0f      	ldr	r3, [pc, #60]	; (2884 <uart_nrfx_configure+0x160>)
    2846:	e7d5      	b.n	27f4 <uart_nrfx_configure+0xd0>
		nrf_baudrate = NRF_UART_BAUDRATE_250000;
    2848:	f04f 6380 	mov.w	r3, #67108864	; 0x4000000
    284c:	e7d2      	b.n	27f4 <uart_nrfx_configure+0xd0>
    284e:	bf00      	nop
    2850:	0013b000 	.word	0x0013b000
    2854:	004ea000 	.word	0x004ea000
    2858:	00ebf000 	.word	0x00ebf000
    285c:	01d7e000 	.word	0x01d7e000
    2860:	0003d090 	.word	0x0003d090
    2864:	075f7000 	.word	0x075f7000
    2868:	000f4240 	.word	0x000f4240
    286c:	40002000 	.word	0x40002000
    2870:	009d5000 	.word	0x009d5000
    2874:	00275000 	.word	0x00275000
    2878:	0075f000 	.word	0x0075f000
    287c:	03afb000 	.word	0x03afb000
    2880:	013a9000 	.word	0x013a9000
    2884:	0ebed000 	.word	0x0ebed000

00002888 <uart_nrfx_poll_in>:
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    2888:	4b08      	ldr	r3, [pc, #32]	; (28ac <uart_nrfx_poll_in+0x24>)
    288a:	681a      	ldr	r2, [r3, #0]
{
    288c:	b082      	sub	sp, #8
	if (!nrf_uart_event_check(uart0_addr, NRF_UART_EVENT_RXDRDY)) {
    288e:	b152      	cbz	r2, 28a6 <uart_nrfx_poll_in+0x1e>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    2890:	2000      	movs	r0, #0
    2892:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    2894:	681b      	ldr	r3, [r3, #0]
    2896:	9301      	str	r3, [sp, #4]
    (void)dummy;
    2898:	9b01      	ldr	r3, [sp, #4]
    return p_reg->RXD;
    289a:	4b05      	ldr	r3, [pc, #20]	; (28b0 <uart_nrfx_poll_in+0x28>)
    289c:	f8d3 3518 	ldr.w	r3, [r3, #1304]	; 0x518
    28a0:	700b      	strb	r3, [r1, #0]
}
    28a2:	b002      	add	sp, #8
    28a4:	4770      	bx	lr
		return -1;
    28a6:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    28aa:	e7fa      	b.n	28a2 <uart_nrfx_poll_in+0x1a>
    28ac:	40002108 	.word	0x40002108
    28b0:	40002000 	.word	0x40002000

000028b4 <uart_nrfx_poll_out>:
{
    28b4:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    28b6:	460e      	mov	r6, r1
	if (!k_is_in_isr()) {
    28b8:	f003 fc61 	bl	617e <k_is_in_isr>
    28bc:	4d1b      	ldr	r5, [pc, #108]	; (292c <uart_nrfx_poll_out+0x78>)
    28be:	bb88      	cbnz	r0, 2924 <uart_nrfx_poll_out+0x70>
    28c0:	2464      	movs	r4, #100	; 0x64
	return __atomic_compare_exchange_n(target, &old_value, new_value,
    28c2:	2701      	movs	r7, #1
    28c4:	f3bf 8f5b 	dmb	ish
    28c8:	e855 3f00 	ldrex	r3, [r5]
    28cc:	2b00      	cmp	r3, #0
    28ce:	d103      	bne.n	28d8 <uart_nrfx_poll_out+0x24>
    28d0:	e845 7200 	strex	r2, r7, [r5]
    28d4:	2a00      	cmp	r2, #0
    28d6:	d1f7      	bne.n	28c8 <uart_nrfx_poll_out+0x14>
    28d8:	f3bf 8f5b 	dmb	ish
		while (atomic_cas((atomic_t *) lock,
    28dc:	d007      	beq.n	28ee <uart_nrfx_poll_out+0x3a>
	return z_impl_k_sleep(timeout);
    28de:	2021      	movs	r0, #33	; 0x21
    28e0:	2100      	movs	r1, #0
    28e2:	3c01      	subs	r4, #1
    28e4:	f001 fa7a 	bl	3ddc <z_impl_k_sleep>
			if (--safety_cnt == 0) {
    28e8:	f014 04ff 	ands.w	r4, r4, #255	; 0xff
    28ec:	d1ea      	bne.n	28c4 <uart_nrfx_poll_out+0x10>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    28ee:	4c10      	ldr	r4, [pc, #64]	; (2930 <uart_nrfx_poll_out+0x7c>)
    28f0:	2200      	movs	r2, #0
    28f2:	6022      	str	r2, [r4, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    28f4:	6822      	ldr	r2, [r4, #0]
    28f6:	9201      	str	r2, [sp, #4]
    (void)dummy;
    28f8:	9a01      	ldr	r2, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    28fa:	4a0e      	ldr	r2, [pc, #56]	; (2934 <uart_nrfx_poll_out+0x80>)
    28fc:	2101      	movs	r1, #1
    28fe:	6011      	str	r1, [r2, #0]
    p_reg->TXD = txd;
    2900:	f8c2 6514 	str.w	r6, [r2, #1300]	; 0x514
    2904:	f44f 767a 	mov.w	r6, #1000	; 0x3e8
    return (bool)*(volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event);
    2908:	6823      	ldr	r3, [r4, #0]
	NRFX_WAIT_FOR(event_txdrdy_check(), 1000, 1, res);
    290a:	b923      	cbnz	r3, 2916 <uart_nrfx_poll_out+0x62>
    290c:	2001      	movs	r0, #1
    290e:	f003 f9af 	bl	5c70 <nrfx_busy_wait>
    2912:	3e01      	subs	r6, #1
    2914:	d1f8      	bne.n	2908 <uart_nrfx_poll_out+0x54>
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    2916:	4b08      	ldr	r3, [pc, #32]	; (2938 <uart_nrfx_poll_out+0x84>)
    2918:	2201      	movs	r2, #1
    291a:	601a      	str	r2, [r3, #0]
	*lock = 0;
    291c:	2300      	movs	r3, #0
    291e:	602b      	str	r3, [r5, #0]
}
    2920:	b003      	add	sp, #12
    2922:	bdf0      	pop	{r4, r5, r6, r7, pc}
		*lock = 1;
    2924:	2301      	movs	r3, #1
    2926:	602b      	str	r3, [r5, #0]
    2928:	e7e1      	b.n	28ee <uart_nrfx_poll_out+0x3a>
    292a:	bf00      	nop
    292c:	20000520 	.word	0x20000520
    2930:	4000211c 	.word	0x4000211c
    2934:	40002008 	.word	0x40002008
    2938:	4000200c 	.word	0x4000200c

0000293c <uart_nrfx_init>:
 * @param dev UART device struct
 *
 * @return 0 on success
 */
static int uart_nrfx_init(struct device *dev)
{
    293c:	b537      	push	{r0, r1, r2, r4, r5, lr}
    p_reg->OUTSET = set_mask;
    293e:	f04f 43a0 	mov.w	r3, #1342177280	; 0x50000000
    p_reg->ENABLE = UART_ENABLE_ENABLE_Disabled;
    2942:	4c17      	ldr	r4, [pc, #92]	; (29a0 <uart_nrfx_init+0x64>)
    2944:	2200      	movs	r2, #0
    2946:	2140      	movs	r1, #64	; 0x40
    2948:	f8c4 2500 	str.w	r2, [r4, #1280]	; 0x500
    p_reg->PSELRXD = pselrxd;
    294c:	2508      	movs	r5, #8
    294e:	f8c3 1508 	str.w	r1, [r3, #1288]	; 0x508
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    2952:	2103      	movs	r1, #3
    2954:	f8c3 1718 	str.w	r1, [r3, #1816]	; 0x718
    2958:	f8c3 2720 	str.w	r2, [r3, #1824]	; 0x720
    295c:	f8c4 5514 	str.w	r5, [r4, #1300]	; 0x514
    p_reg->PSELTXD = pseltxd;
    2960:	2506      	movs	r5, #6
    2962:	f8c4 550c 	str.w	r5, [r4, #1292]	; 0x50c
    p_reg->OUTSET = set_mask;
    2966:	2520      	movs	r5, #32
    2968:	f8c3 5508 	str.w	r5, [r3, #1288]	; 0x508
    reg->PIN_CNF[pin_number] = ((uint32_t)dir << GPIO_PIN_CNF_DIR_Pos)
    296c:	f8c3 1714 	str.w	r1, [r3, #1812]	; 0x714
    2970:	f8c3 271c 	str.w	r2, [r3, #1820]	; 0x71c
    p_reg->PSELRTS = pselrts;
    2974:	2305      	movs	r3, #5
    2976:	f8c4 3508 	str.w	r3, [r4, #1288]	; 0x508
    p_reg->PSELCTS = pselcts;
    297a:	2307      	movs	r3, #7
	}

	nrf_uart_hwfc_pins_set(uart0_addr, RTS_PIN, CTS_PIN);

	/* Set initial configuration */
	err = uart_nrfx_configure(dev, &get_dev_data(dev)->uart_config);
    297c:	68c1      	ldr	r1, [r0, #12]
    297e:	f8c4 3510 	str.w	r3, [r4, #1296]	; 0x510
    2982:	f7ff fecf 	bl	2724 <uart_nrfx_configure>
	if (err) {
    2986:	b948      	cbnz	r0, 299c <uart_nrfx_init+0x60>
    p_reg->ENABLE = UART_ENABLE_ENABLE_Enabled;
    2988:	2304      	movs	r3, #4
    298a:	f8c4 3500 	str.w	r3, [r4, #1280]	; 0x500
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event)) = 0x0UL;
    298e:	4b05      	ldr	r3, [pc, #20]	; (29a4 <uart_nrfx_init+0x68>)
    2990:	6018      	str	r0, [r3, #0]
    volatile uint32_t dummy = *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)event));
    2992:	681b      	ldr	r3, [r3, #0]
    2994:	9301      	str	r3, [sp, #4]
    (void)dummy;
    2996:	9b01      	ldr	r3, [sp, #4]
    *((volatile uint32_t *)((uint8_t *)p_reg + (uint32_t)task)) = 0x1UL;
    2998:	2301      	movs	r3, #1
    299a:	6023      	str	r3, [r4, #0]
#if HW_FLOW_CONTROL_AVAILABLE
	k_delayed_work_init(&uart0_cb.tx_timeout_work, tx_timeout);
#endif
#endif
	return 0;
}
    299c:	b003      	add	sp, #12
    299e:	bd30      	pop	{r4, r5, pc}
    29a0:	40002000 	.word	0x40002000
    29a4:	40002108 	.word	0x40002108

000029a8 <z_mrsh_uart_err_check>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_err_check(struct device * dev);
uintptr_t z_mrsh_uart_err_check(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    29a8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    29aa:	4e10      	ldr	r6, [pc, #64]	; (29ec <z_mrsh_uart_err_check+0x44>)
    29ac:	9a06      	ldr	r2, [sp, #24]
    29ae:	68b3      	ldr	r3, [r6, #8]
    29b0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    29b4:	4604      	mov	r4, r0
	{							 \
		Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, op_)); \
		z_impl_uart_ ## op_(dev); \
	}

UART_SIMPLE(err_check)
    29b6:	f7fd fb91 	bl	dc <z_object_find>
    29ba:	2200      	movs	r2, #0
    29bc:	2126      	movs	r1, #38	; 0x26
    29be:	f002 fa53 	bl	4e68 <z_object_validate>
    29c2:	4632      	mov	r2, r6
    29c4:	4605      	mov	r5, r0
    29c6:	b130      	cbz	r0, 29d6 <z_mrsh_uart_err_check+0x2e>
    29c8:	f003 f948 	bl	5c5c <arch_is_user_context>
    29cc:	6893      	ldr	r3, [r2, #8]
    29ce:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    29d2:	f003 f832 	bl	5a3a <arch_syscall_oops>
    29d6:	68a3      	ldr	r3, [r4, #8]
    29d8:	689b      	ldr	r3, [r3, #8]
    29da:	2b00      	cmp	r3, #0
    29dc:	d0f4      	beq.n	29c8 <z_mrsh_uart_err_check+0x20>
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	if (api->err_check != NULL) {
		return api->err_check(dev);
    29de:	4620      	mov	r0, r4
    29e0:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_err_check(*(struct device **)&arg0)
;
	_current->syscall_frame = NULL;
    29e2:	68b3      	ldr	r3, [r6, #8]
    29e4:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    29e8:	bd70      	pop	{r4, r5, r6, pc}
    29ea:	bf00      	nop
    29ec:	20000524 	.word	0x20000524

000029f0 <z_mrsh_uart_poll_in>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_poll_in(struct device * dev, unsigned char * p_char);
uintptr_t z_mrsh_uart_poll_in(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    29f0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    29f2:	4e17      	ldr	r6, [pc, #92]	; (2a50 <z_mrsh_uart_poll_in+0x60>)
    29f4:	9a08      	ldr	r2, [sp, #32]
    29f6:	68b3      	ldr	r3, [r6, #8]
    29f8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    29fc:	460d      	mov	r5, r1
    29fe:	4604      	mov	r4, r0
#include <syscalls/uart_err_check_mrsh.c>

static inline int z_vrfy_uart_poll_in(struct device *dev,
				      unsigned char *p_char)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_in));
    2a00:	f7fd fb6c 	bl	dc <z_object_find>
    2a04:	2200      	movs	r2, #0
    2a06:	2126      	movs	r1, #38	; 0x26
    2a08:	f002 fa2e 	bl	4e68 <z_object_validate>
    2a0c:	4632      	mov	r2, r6
    2a0e:	b178      	cbz	r0, 2a30 <z_mrsh_uart_poll_in+0x40>
    2a10:	f003 f924 	bl	5c5c <arch_is_user_context>
    2a14:	6893      	ldr	r3, [r2, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(p_char, sizeof(unsigned char)));
    2a16:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2a1a:	f003 f80e 	bl	5a3a <arch_syscall_oops>
static inline int z_impl_uart_poll_in(struct device *dev, unsigned char *p_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	return api->poll_in(dev, p_char);
    2a1e:	68a3      	ldr	r3, [r4, #8]
    2a20:	4629      	mov	r1, r5
    2a22:	681b      	ldr	r3, [r3, #0]
    2a24:	4620      	mov	r0, r4
    2a26:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_poll_in(*(struct device **)&arg0, *(unsigned char **)&arg1)
;
	_current->syscall_frame = NULL;
    2a28:	68b3      	ldr	r3, [r6, #8]
    2a2a:	f8c3 7084 	str.w	r7, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2a2e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_in));
    2a30:	68a3      	ldr	r3, [r4, #8]
    2a32:	681b      	ldr	r3, [r3, #0]
    2a34:	2b00      	cmp	r3, #0
    2a36:	d0eb      	beq.n	2a10 <z_mrsh_uart_poll_in+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(p_char, sizeof(unsigned char)));
    2a38:	2201      	movs	r2, #1
    2a3a:	4611      	mov	r1, r2
    2a3c:	4628      	mov	r0, r5
    2a3e:	f003 f82a 	bl	5a96 <arch_buffer_validate>
    2a42:	4607      	mov	r7, r0
    2a44:	2800      	cmp	r0, #0
    2a46:	d0ea      	beq.n	2a1e <z_mrsh_uart_poll_in+0x2e>
    2a48:	f003 f908 	bl	5c5c <arch_is_user_context>
    2a4c:	68b3      	ldr	r3, [r6, #8]
    2a4e:	e7e2      	b.n	2a16 <z_mrsh_uart_poll_in+0x26>
    2a50:	20000524 	.word	0x20000524

00002a54 <z_mrsh_uart_poll_out>:
#include <syscalls/uart.h>

extern void z_vrfy_uart_poll_out(struct device * dev, unsigned char out_char);
uintptr_t z_mrsh_uart_poll_out(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2a54:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2a56:	4f11      	ldr	r7, [pc, #68]	; (2a9c <z_mrsh_uart_poll_out+0x48>)
    2a58:	9a08      	ldr	r2, [sp, #32]
    2a5a:	68bb      	ldr	r3, [r7, #8]
    2a5c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_uart_poll_out(*(struct device **)&arg0, *(unsigned char*)&arg1)
    2a60:	b2ce      	uxtb	r6, r1
{
    2a62:	4605      	mov	r5, r0
#include <syscalls/uart_poll_in_mrsh.c>

static inline void z_vrfy_uart_poll_out(struct device *dev,
					unsigned char out_char)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, poll_out));
    2a64:	f7fd fb3a 	bl	dc <z_object_find>
    2a68:	2200      	movs	r2, #0
    2a6a:	2126      	movs	r1, #38	; 0x26
    2a6c:	f002 f9fc 	bl	4e68 <z_object_validate>
    2a70:	463a      	mov	r2, r7
    2a72:	4604      	mov	r4, r0
    2a74:	b130      	cbz	r0, 2a84 <z_mrsh_uart_poll_out+0x30>
    2a76:	f003 f8f1 	bl	5c5c <arch_is_user_context>
    2a7a:	6893      	ldr	r3, [r2, #8]
    2a7c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2a80:	f002 ffdb 	bl	5a3a <arch_syscall_oops>
    2a84:	68ab      	ldr	r3, [r5, #8]
    2a86:	685b      	ldr	r3, [r3, #4]
    2a88:	2b00      	cmp	r3, #0
    2a8a:	d0f4      	beq.n	2a76 <z_mrsh_uart_poll_out+0x22>
						unsigned char out_char)
{
	const struct uart_driver_api *api =
		(const struct uart_driver_api *)dev->driver_api;

	api->poll_out(dev, out_char);
    2a8c:	4628      	mov	r0, r5
    2a8e:	4631      	mov	r1, r6
    2a90:	4798      	blx	r3
;
	_current->syscall_frame = NULL;
    2a92:	68bb      	ldr	r3, [r7, #8]
	return 0;
}
    2a94:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    2a96:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    2a9a:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    2a9c:	20000524 	.word	0x20000524

00002aa0 <z_mrsh_uart_config_get>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_config_get(struct device * dev, struct uart_config * cfg);
uintptr_t z_mrsh_uart_config_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2aa0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2aa2:	4e1a      	ldr	r6, [pc, #104]	; (2b0c <z_mrsh_uart_config_get+0x6c>)
    2aa4:	9a08      	ldr	r2, [sp, #32]
    2aa6:	68b3      	ldr	r3, [r6, #8]
    2aa8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2aac:	460d      	mov	r5, r1
    2aae:	4604      	mov	r4, r0
#include <syscalls/uart_poll_out_mrsh.c>

static inline int z_vrfy_uart_config_get(struct device *dev,
		struct uart_config *cfg)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2ab0:	f7fd fb14 	bl	dc <z_object_find>
    2ab4:	2200      	movs	r2, #0
    2ab6:	2126      	movs	r1, #38	; 0x26
    2ab8:	f002 f9d6 	bl	4e68 <z_object_validate>
    2abc:	4637      	mov	r7, r6
    2abe:	b1a8      	cbz	r0, 2aec <z_mrsh_uart_config_get+0x4c>
    2ac0:	f003 f8cc 	bl	5c5c <arch_is_user_context>
    2ac4:	68bb      	ldr	r3, [r7, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(cfg, sizeof(struct uart_config)));
    2ac6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2aca:	f002 ffb6 	bl	5a3a <arch_syscall_oops>
{
	const struct uart_driver_api *api =
				(const struct uart_driver_api *)dev->driver_api;

	if (api->config_get != NULL) {
		return api->config_get(dev, cfg);
    2ace:	4629      	mov	r1, r5
    2ad0:	4620      	mov	r0, r4
    2ad2:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_config_get(*(struct device **)&arg0, *(struct uart_config **)&arg1)
;
	_current->syscall_frame = NULL;
    2ad4:	68bb      	ldr	r3, [r7, #8]
    2ad6:	2200      	movs	r2, #0
    2ad8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2adc:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (api->config_get != NULL) {
    2ade:	68a3      	ldr	r3, [r4, #8]
    2ae0:	691b      	ldr	r3, [r3, #16]
    2ae2:	2b00      	cmp	r3, #0
    2ae4:	d1f3      	bne.n	2ace <z_mrsh_uart_config_get+0x2e>
	}

	return -ENOTSUP;
    2ae6:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2aea:	e7f3      	b.n	2ad4 <z_mrsh_uart_config_get+0x34>
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2aec:	68a3      	ldr	r3, [r4, #8]
    2aee:	691b      	ldr	r3, [r3, #16]
    2af0:	2b00      	cmp	r3, #0
    2af2:	d0e5      	beq.n	2ac0 <z_mrsh_uart_config_get+0x20>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(cfg, sizeof(struct uart_config)));
    2af4:	2201      	movs	r2, #1
    2af6:	2108      	movs	r1, #8
    2af8:	4628      	mov	r0, r5
    2afa:	f002 ffcc 	bl	5a96 <arch_buffer_validate>
    2afe:	2800      	cmp	r0, #0
    2b00:	d0ed      	beq.n	2ade <z_mrsh_uart_config_get+0x3e>
    2b02:	f003 f8ab 	bl	5c5c <arch_is_user_context>
    2b06:	68b3      	ldr	r3, [r6, #8]
    2b08:	e7dd      	b.n	2ac6 <z_mrsh_uart_config_get+0x26>
    2b0a:	bf00      	nop
    2b0c:	20000524 	.word	0x20000524

00002b10 <z_mrsh_uart_configure>:
#include <syscalls/uart.h>

extern int z_vrfy_uart_configure(struct device * dev, const struct uart_config * cfg);
uintptr_t z_mrsh_uart_configure(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2b10:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    2b12:	4e1a      	ldr	r6, [pc, #104]	; (2b7c <z_mrsh_uart_configure+0x6c>)
    2b14:	9a08      	ldr	r2, [sp, #32]
    2b16:	68b3      	ldr	r3, [r6, #8]
    2b18:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2b1c:	460d      	mov	r5, r1
    2b1e:	4604      	mov	r4, r0
#include <syscalls/uart_config_get_mrsh.c>

static inline int z_vrfy_uart_configure(struct device *dev,
		const struct uart_config *cfg)
{
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2b20:	f7fd fadc 	bl	dc <z_object_find>
    2b24:	2200      	movs	r2, #0
    2b26:	2126      	movs	r1, #38	; 0x26
    2b28:	f002 f99e 	bl	4e68 <z_object_validate>
    2b2c:	4637      	mov	r7, r6
    2b2e:	4602      	mov	r2, r0
    2b30:	b1a8      	cbz	r0, 2b5e <z_mrsh_uart_configure+0x4e>
    2b32:	f003 f893 	bl	5c5c <arch_is_user_context>
    2b36:	68bb      	ldr	r3, [r7, #8]
	Z_OOPS(Z_SYSCALL_MEMORY_READ(cfg, sizeof(struct uart_config)));
    2b38:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    2b3c:	f002 ff7d 	bl	5a3a <arch_syscall_oops>
		return api->configure(dev, cfg);
    2b40:	4629      	mov	r1, r5
    2b42:	4620      	mov	r0, r4
    2b44:	4798      	blx	r3
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_uart_configure(*(struct device **)&arg0, *(const struct uart_config **)&arg1)
;
	_current->syscall_frame = NULL;
    2b46:	68bb      	ldr	r3, [r7, #8]
    2b48:	2200      	movs	r2, #0
    2b4a:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2b4e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (api->configure != NULL) {
    2b50:	68a3      	ldr	r3, [r4, #8]
    2b52:	68db      	ldr	r3, [r3, #12]
    2b54:	2b00      	cmp	r3, #0
    2b56:	d1f3      	bne.n	2b40 <z_mrsh_uart_configure+0x30>
	return -ENOTSUP;
    2b58:	f06f 0022 	mvn.w	r0, #34	; 0x22
    2b5c:	e7f3      	b.n	2b46 <z_mrsh_uart_configure+0x36>
	Z_OOPS(Z_SYSCALL_DRIVER_UART(dev, config_get));
    2b5e:	68a3      	ldr	r3, [r4, #8]
    2b60:	691b      	ldr	r3, [r3, #16]
    2b62:	2b00      	cmp	r3, #0
    2b64:	d0e5      	beq.n	2b32 <z_mrsh_uart_configure+0x22>
	Z_OOPS(Z_SYSCALL_MEMORY_READ(cfg, sizeof(struct uart_config)));
    2b66:	2108      	movs	r1, #8
    2b68:	4628      	mov	r0, r5
    2b6a:	f002 ff94 	bl	5a96 <arch_buffer_validate>
    2b6e:	2800      	cmp	r0, #0
    2b70:	d0ee      	beq.n	2b50 <z_mrsh_uart_configure+0x40>
    2b72:	f003 f873 	bl	5c5c <arch_is_user_context>
    2b76:	68b3      	ldr	r3, [r6, #8]
    2b78:	e7de      	b.n	2b38 <z_mrsh_uart_configure+0x28>
    2b7a:	bf00      	nop
    2b7c:	20000524 	.word	0x20000524

00002b80 <nrf52_errata_108>:
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1;
            uint32_t var2;

            if (*(uint32_t *)0x10000130ul == 0xFFFFFFFF)
    2b80:	4b0b      	ldr	r3, [pc, #44]	; (2bb0 <nrf52_errata_108+0x30>)
    2b82:	681b      	ldr	r3, [r3, #0]
    2b84:	1c5a      	adds	r2, r3, #1
            {
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2b86:	bf05      	ittet	eq
    2b88:	4b0a      	ldreq	r3, [pc, #40]	; (2bb4 <nrf52_errata_108+0x34>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2b8a:	4a0b      	ldreq	r2, [pc, #44]	; (2bb8 <nrf52_errata_108+0x38>)
            }
            else
            {
                var1 = *(uint32_t *)0x10000130ul;
                var2 = *(uint32_t *)0x10000134ul;
    2b8c:	4a0b      	ldrne	r2, [pc, #44]	; (2bbc <nrf52_errata_108+0x3c>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2b8e:	6810      	ldreq	r0, [r2, #0]
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2b90:	bf0a      	itet	eq
    2b92:	781b      	ldrbeq	r3, [r3, #0]
                var2 = *(uint32_t *)0x10000134ul;
    2b94:	6810      	ldrne	r0, [r2, #0]
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2b96:	f3c0 1003 	ubfxeq	r0, r0, #4, #4
            }
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2b9a:	2b06      	cmp	r3, #6
    2b9c:	d105      	bne.n	2baa <nrf52_errata_108+0x2a>
            {
                switch(var2)
    2b9e:	3803      	subs	r0, #3
    2ba0:	2803      	cmp	r0, #3
    2ba2:	bf8c      	ite	hi
    2ba4:	2000      	movhi	r0, #0
    2ba6:	2001      	movls	r0, #1
    2ba8:	4770      	bx	lr
                    case 0x06ul:
                        return true;
                }
            }
        #endif
        return false;
    2baa:	2000      	movs	r0, #0
    #endif
}
    2bac:	4770      	bx	lr
    2bae:	bf00      	nop
    2bb0:	10000130 	.word	0x10000130
    2bb4:	f0000fe0 	.word	0xf0000fe0
    2bb8:	f0000fe8 	.word	0xf0000fe8
    2bbc:	10000134 	.word	0x10000134

00002bc0 <nrf52_errata_16>:
    #ifndef NRF52_SERIES
        return false;
    #else
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2bc0:	4b07      	ldr	r3, [pc, #28]	; (2be0 <nrf52_errata_16+0x20>)
    2bc2:	781b      	ldrb	r3, [r3, #0]
            uint32_t var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2bc4:	2b06      	cmp	r3, #6
    2bc6:	d109      	bne.n	2bdc <nrf52_errata_16+0x1c>
            uint32_t var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2bc8:	4b06      	ldr	r3, [pc, #24]	; (2be4 <nrf52_errata_16+0x24>)
    2bca:	681b      	ldr	r3, [r3, #0]
    2bcc:	f3c3 1303 	ubfx	r3, r3, #4, #4
    2bd0:	3b03      	subs	r3, #3
    2bd2:	2b03      	cmp	r3, #3
    2bd4:	d802      	bhi.n	2bdc <nrf52_errata_16+0x1c>
    2bd6:	4a04      	ldr	r2, [pc, #16]	; (2be8 <nrf52_errata_16+0x28>)
    2bd8:	5cd0      	ldrb	r0, [r2, r3]
    2bda:	4770      	bx	lr
                    case 0x06ul:
                        return false;
                }
            }
        #endif
        return false;
    2bdc:	2000      	movs	r0, #0
    #endif
}
    2bde:	4770      	bx	lr
    2be0:	f0000fe0 	.word	0xf0000fe0
    2be4:	f0000fe8 	.word	0xf0000fe8
    2be8:	00007116 	.word	0x00007116

00002bec <SystemInit>:
{
    SystemCoreClock = __SYSTEM_CLOCK_64M;
}

void SystemInit(void)
{
    2bec:	b508      	push	{r3, lr}
        NRF_P0->PIN_CNF[20] = (GPIO_PIN_CNF_DRIVE_H0H1 << GPIO_PIN_CNF_DRIVE_Pos) | (GPIO_PIN_CNF_INPUT_Connect << GPIO_PIN_CNF_INPUT_Pos) | (GPIO_PIN_CNF_DIR_Output << GPIO_PIN_CNF_DIR_Pos);
    #endif
    
    /* Workaround for Errata 12 "COMP: Reference ladder not correctly calibrated" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_12()){
    2bee:	f7ff ffc7 	bl	2b80 <nrf52_errata_108>
    2bf2:	b128      	cbz	r0, 2c00 <SystemInit+0x14>
        *(volatile uint32_t *)0x40013540 = (*(uint32_t *)0x10000324 & 0x00001F00) >> 8;
    2bf4:	4b7e      	ldr	r3, [pc, #504]	; (2df0 <SystemInit+0x204>)
    2bf6:	4a7f      	ldr	r2, [pc, #508]	; (2df4 <SystemInit+0x208>)
    2bf8:	681b      	ldr	r3, [r3, #0]
    2bfa:	f3c3 2304 	ubfx	r3, r3, #8, #5
    2bfe:	6013      	str	r3, [r2, #0]
    }
    
    /* Workaround for Errata 16 "System: RAM may be corrupt on wakeup from CPU IDLE" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_16()){
    2c00:	f7ff ffde 	bl	2bc0 <nrf52_errata_16>
    2c04:	b110      	cbz	r0, 2c0c <SystemInit+0x20>
        *(volatile uint32_t *)0x4007C074 = 3131961357ul;
    2c06:	4b7c      	ldr	r3, [pc, #496]	; (2df8 <SystemInit+0x20c>)
    2c08:	4a7c      	ldr	r2, [pc, #496]	; (2dfc <SystemInit+0x210>)
    2c0a:	601a      	str	r2, [r3, #0]
    }

    /* Workaround for Errata 31 "CLOCK: Calibration values are not correctly loaded from FICR at reset" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_31()){
    2c0c:	f7ff ffb8 	bl	2b80 <nrf52_errata_108>
    2c10:	b128      	cbz	r0, 2c1e <SystemInit+0x32>
        *(volatile uint32_t *)0x4000053C = ((*(volatile uint32_t *)0x10000244) & 0x0000E000) >> 13;
    2c12:	4b7b      	ldr	r3, [pc, #492]	; (2e00 <SystemInit+0x214>)
    2c14:	4a7b      	ldr	r2, [pc, #492]	; (2e04 <SystemInit+0x218>)
    2c16:	681b      	ldr	r3, [r3, #0]
    2c18:	f3c3 3342 	ubfx	r3, r3, #13, #3
    2c1c:	6013      	str	r3, [r2, #0]
    }

    /* Workaround for Errata 32 "DIF: Debug session automatically enables TracePort pins" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp */
    if (nrf52_errata_32()){
    2c1e:	f7ff ffcf 	bl	2bc0 <nrf52_errata_16>
    2c22:	b120      	cbz	r0, 2c2e <SystemInit+0x42>
        CoreDebug->DEMCR &= ~CoreDebug_DEMCR_TRCENA_Msk;
    2c24:	4a78      	ldr	r2, [pc, #480]	; (2e08 <SystemInit+0x21c>)
    2c26:	68d3      	ldr	r3, [r2, #12]
    2c28:	f023 7380 	bic.w	r3, r3, #16777216	; 0x1000000
    2c2c:	60d3      	str	r3, [r2, #12]
    }

    /* Workaround for Errata 36 "CLOCK: Some registers are not reset when expected" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_36()){
    2c2e:	f7ff ffa7 	bl	2b80 <nrf52_errata_108>
    2c32:	b140      	cbz	r0, 2c46 <SystemInit+0x5a>
        NRF_CLOCK->EVENTS_DONE = 0;
    2c34:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    2c38:	2200      	movs	r2, #0
    2c3a:	f8c3 210c 	str.w	r2, [r3, #268]	; 0x10c
        NRF_CLOCK->EVENTS_CTTO = 0;
    2c3e:	f8c3 2110 	str.w	r2, [r3, #272]	; 0x110
        NRF_CLOCK->CTIV = 0;
    2c42:	f8c3 2538 	str.w	r2, [r3, #1336]	; 0x538
    }

    /* Workaround for Errata 37 "RADIO: Encryption engine is slow by default" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_37()){
    2c46:	f7ff ffbb 	bl	2bc0 <nrf52_errata_16>
    2c4a:	b110      	cbz	r0, 2c52 <SystemInit+0x66>
        *(volatile uint32_t *)0x400005A0 = 0x3;
    2c4c:	4b6f      	ldr	r3, [pc, #444]	; (2e0c <SystemInit+0x220>)
    2c4e:	2203      	movs	r2, #3
    2c50:	601a      	str	r2, [r3, #0]
    }

    /* Workaround for Errata 57 "NFCT: NFC Modulation amplitude" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_57()){
    2c52:	f7ff ffb5 	bl	2bc0 <nrf52_errata_16>
    2c56:	b140      	cbz	r0, 2c6a <SystemInit+0x7e>
        *(volatile uint32_t *)0x40005610 = 0x00000005;
    2c58:	4b6d      	ldr	r3, [pc, #436]	; (2e10 <SystemInit+0x224>)
    2c5a:	2205      	movs	r2, #5
    2c5c:	601a      	str	r2, [r3, #0]
        *(volatile uint32_t *)0x40005688 = 0x00000001;
    2c5e:	2201      	movs	r2, #1
    2c60:	679a      	str	r2, [r3, #120]	; 0x78
        *(volatile uint32_t *)0x40005618 = 0x00000000;
    2c62:	2200      	movs	r2, #0
    2c64:	609a      	str	r2, [r3, #8]
        *(volatile uint32_t *)0x40005614 = 0x0000003F;
    2c66:	223f      	movs	r2, #63	; 0x3f
    2c68:	605a      	str	r2, [r3, #4]
         || defined (NRF52833_XXAA) || defined (DEVELOP_IN_NRF52833)\
         || defined (NRF52840_XXAA) || defined (DEVELOP_IN_NRF52840)
            uint32_t var1;
            uint32_t var2;

            if (*(uint32_t *)0x10000130ul == 0xFFFFFFFF)
    2c6a:	4b6a      	ldr	r3, [pc, #424]	; (2e14 <SystemInit+0x228>)
    2c6c:	681a      	ldr	r2, [r3, #0]
    2c6e:	1c51      	adds	r1, r2, #1
            {
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2c70:	bf0b      	itete	eq
    2c72:	4b69      	ldreq	r3, [pc, #420]	; (2e18 <SystemInit+0x22c>)
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
            }
            else
            {
                var1 = *(uint32_t *)0x10000130ul;
                var2 = *(uint32_t *)0x10000134ul;
    2c74:	4b69      	ldrne	r3, [pc, #420]	; (2e1c <SystemInit+0x230>)
                var1 = ((*(uint32_t *)0xF0000FE0ul) & 0x000000FFul);
    2c76:	781a      	ldrbeq	r2, [r3, #0]
                var2 = *(uint32_t *)0x10000134ul;
    2c78:	681b      	ldrne	r3, [r3, #0]
                var2 = ((*(uint32_t *)0xF0000FE8ul) & 0x000000F0ul) >> 4;
    2c7a:	bf02      	ittt	eq
    2c7c:	3308      	addeq	r3, #8
    2c7e:	681b      	ldreq	r3, [r3, #0]
    2c80:	f3c3 1303 	ubfxeq	r3, r3, #4, #4
            }
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2c84:	2a06      	cmp	r2, #6
    2c86:	d14d      	bne.n	2d24 <SystemInit+0x138>
            {
                switch(var2)
    2c88:	3b03      	subs	r3, #3
    2c8a:	2b03      	cmp	r3, #3
    2c8c:	d84a      	bhi.n	2d24 <SystemInit+0x138>
    }

    /* Workaround for Errata 66 "TEMP: Linearity specification not met with default settings" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_66()){
    2c8e:	4a64      	ldr	r2, [pc, #400]	; (2e20 <SystemInit+0x234>)
    2c90:	5cd3      	ldrb	r3, [r2, r3]
    2c92:	2b00      	cmp	r3, #0
    2c94:	d046      	beq.n	2d24 <SystemInit+0x138>
        NRF_TEMP->A0 = NRF_FICR->TEMP.A0;
    2c96:	f04f 5280 	mov.w	r2, #268435456	; 0x10000000
    2c9a:	4b62      	ldr	r3, [pc, #392]	; (2e24 <SystemInit+0x238>)
    2c9c:	f8d2 1404 	ldr.w	r1, [r2, #1028]	; 0x404
    2ca0:	f8c3 1520 	str.w	r1, [r3, #1312]	; 0x520
        NRF_TEMP->A1 = NRF_FICR->TEMP.A1;
    2ca4:	f8d2 1408 	ldr.w	r1, [r2, #1032]	; 0x408
    2ca8:	f8c3 1524 	str.w	r1, [r3, #1316]	; 0x524
        NRF_TEMP->A2 = NRF_FICR->TEMP.A2;
    2cac:	f8d2 140c 	ldr.w	r1, [r2, #1036]	; 0x40c
    2cb0:	f8c3 1528 	str.w	r1, [r3, #1320]	; 0x528
        NRF_TEMP->A3 = NRF_FICR->TEMP.A3;
    2cb4:	f8d2 1410 	ldr.w	r1, [r2, #1040]	; 0x410
    2cb8:	f8c3 152c 	str.w	r1, [r3, #1324]	; 0x52c
        NRF_TEMP->A4 = NRF_FICR->TEMP.A4;
    2cbc:	f8d2 1414 	ldr.w	r1, [r2, #1044]	; 0x414
    2cc0:	f8c3 1530 	str.w	r1, [r3, #1328]	; 0x530
        NRF_TEMP->A5 = NRF_FICR->TEMP.A5;
    2cc4:	f8d2 1418 	ldr.w	r1, [r2, #1048]	; 0x418
    2cc8:	f8c3 1534 	str.w	r1, [r3, #1332]	; 0x534
        NRF_TEMP->B0 = NRF_FICR->TEMP.B0;
    2ccc:	f8d2 141c 	ldr.w	r1, [r2, #1052]	; 0x41c
    2cd0:	f8c3 1540 	str.w	r1, [r3, #1344]	; 0x540
        NRF_TEMP->B1 = NRF_FICR->TEMP.B1;
    2cd4:	f8d2 1420 	ldr.w	r1, [r2, #1056]	; 0x420
    2cd8:	f8c3 1544 	str.w	r1, [r3, #1348]	; 0x544
        NRF_TEMP->B2 = NRF_FICR->TEMP.B2;
    2cdc:	f8d2 1424 	ldr.w	r1, [r2, #1060]	; 0x424
    2ce0:	f8c3 1548 	str.w	r1, [r3, #1352]	; 0x548
        NRF_TEMP->B3 = NRF_FICR->TEMP.B3;
    2ce4:	f8d2 1428 	ldr.w	r1, [r2, #1064]	; 0x428
    2ce8:	f8c3 154c 	str.w	r1, [r3, #1356]	; 0x54c
        NRF_TEMP->B4 = NRF_FICR->TEMP.B4;
    2cec:	f8d2 142c 	ldr.w	r1, [r2, #1068]	; 0x42c
    2cf0:	f8c3 1550 	str.w	r1, [r3, #1360]	; 0x550
        NRF_TEMP->B5 = NRF_FICR->TEMP.B5;
    2cf4:	f8d2 1430 	ldr.w	r1, [r2, #1072]	; 0x430
    2cf8:	f8c3 1554 	str.w	r1, [r3, #1364]	; 0x554
        NRF_TEMP->T0 = NRF_FICR->TEMP.T0;
    2cfc:	f8d2 1434 	ldr.w	r1, [r2, #1076]	; 0x434
    2d00:	f8c3 1560 	str.w	r1, [r3, #1376]	; 0x560
        NRF_TEMP->T1 = NRF_FICR->TEMP.T1;
    2d04:	f8d2 1438 	ldr.w	r1, [r2, #1080]	; 0x438
    2d08:	f8c3 1564 	str.w	r1, [r3, #1380]	; 0x564
        NRF_TEMP->T2 = NRF_FICR->TEMP.T2;
    2d0c:	f8d2 143c 	ldr.w	r1, [r2, #1084]	; 0x43c
    2d10:	f8c3 1568 	str.w	r1, [r3, #1384]	; 0x568
        NRF_TEMP->T3 = NRF_FICR->TEMP.T3;
    2d14:	f8d2 1440 	ldr.w	r1, [r2, #1088]	; 0x440
    2d18:	f8c3 156c 	str.w	r1, [r3, #1388]	; 0x56c
        NRF_TEMP->T4 = NRF_FICR->TEMP.T4;
    2d1c:	f8d2 2444 	ldr.w	r2, [r2, #1092]	; 0x444
    2d20:	f8c3 2570 	str.w	r2, [r3, #1392]	; 0x570
    }

    /* Workaround for Errata 108 "RAM: RAM content cannot be trusted upon waking up from System ON Idle or System OFF mode" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_108()){
    2d24:	f7ff ff2c 	bl	2b80 <nrf52_errata_108>
    2d28:	b128      	cbz	r0, 2d36 <SystemInit+0x14a>
        *(volatile uint32_t *)0x40000EE4ul = *(volatile uint32_t *)0x10000258ul & 0x0000004Ful;
    2d2a:	4b3f      	ldr	r3, [pc, #252]	; (2e28 <SystemInit+0x23c>)
    2d2c:	4a3f      	ldr	r2, [pc, #252]	; (2e2c <SystemInit+0x240>)
    2d2e:	681b      	ldr	r3, [r3, #0]
    2d30:	f003 034f 	and.w	r3, r3, #79	; 0x4f
    2d34:	6013      	str	r3, [r2, #0]
    }
    
    /* Workaround for Errata 136 "System: Bits in RESETREAS are set when they should not be" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_136()){
    2d36:	f7ff ff23 	bl	2b80 <nrf52_errata_108>
    2d3a:	b148      	cbz	r0, 2d50 <SystemInit+0x164>
        if (NRF_POWER->RESETREAS & POWER_RESETREAS_RESETPIN_Msk){
    2d3c:	f04f 4380 	mov.w	r3, #1073741824	; 0x40000000
    2d40:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2d44:	07d2      	lsls	r2, r2, #31
            NRF_POWER->RESETREAS =  ~POWER_RESETREAS_RESETPIN_Msk;
    2d46:	bf44      	itt	mi
    2d48:	f06f 0201 	mvnmi.w	r2, #1
    2d4c:	f8c3 2400 	strmi.w	r2, [r3, #1024]	; 0x400
    #ifndef NRF52_SERIES
        return false;
    #else
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            uint32_t var1 = *(uint32_t *)0x10000130ul;
    2d50:	4b30      	ldr	r3, [pc, #192]	; (2e14 <SystemInit+0x228>)
            uint32_t var2 = *(uint32_t *)0x10000134ul;
        #endif
        #if defined (NRF52832_XXAA) || defined (DEVELOP_IN_NRF52832)\
         || defined (NRF52832_XXAB) || defined (DEVELOP_IN_NRF52832)
            if (var1 == 0x06)
    2d52:	681b      	ldr	r3, [r3, #0]
    2d54:	2b06      	cmp	r3, #6
    2d56:	d10c      	bne.n	2d72 <SystemInit+0x186>
            uint32_t var2 = *(uint32_t *)0x10000134ul;
    2d58:	4b30      	ldr	r3, [pc, #192]	; (2e1c <SystemInit+0x230>)
    2d5a:	681b      	ldr	r3, [r3, #0]
    2d5c:	3b03      	subs	r3, #3
    2d5e:	2b03      	cmp	r3, #3
    2d60:	d807      	bhi.n	2d72 <SystemInit+0x186>
        }
    }
    
    /* Workaround for Errata 182 "RADIO: Fixes for anomalies #102, #106, and #107 do not take effect" found at the Errata document
       for your device located at https://infocenter.nordicsemi.com/index.jsp  */
    if (nrf52_errata_182()){
    2d62:	4a33      	ldr	r2, [pc, #204]	; (2e30 <SystemInit+0x244>)
    2d64:	5cd3      	ldrb	r3, [r2, r3]
    2d66:	b123      	cbz	r3, 2d72 <SystemInit+0x186>
        *(volatile uint32_t *) 0x4000173C |= (0x1 << 10);
    2d68:	4a32      	ldr	r2, [pc, #200]	; (2e34 <SystemInit+0x248>)
    2d6a:	6813      	ldr	r3, [r2, #0]
    2d6c:	f443 6380 	orr.w	r3, r3, #1024	; 0x400
    2d70:	6013      	str	r3, [r2, #0]

    /* Configure GPIO pads as pPin Reset pin if Pin Reset capabilities desired. If CONFIG_GPIO_AS_PINRESET is not
      defined, pin reset will not be available. One GPIO (see Product Specification to see which one) will then be
      reserved for PinReset and not available as normal GPIO. */
    #if defined (CONFIG_GPIO_AS_PINRESET)
        if (((NRF_UICR->PSELRESET[0] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos)) ||
    2d72:	f04f 2310 	mov.w	r3, #268439552	; 0x10001000
    2d76:	f8d3 2200 	ldr.w	r2, [r3, #512]	; 0x200
    2d7a:	2a00      	cmp	r2, #0
    2d7c:	db03      	blt.n	2d86 <SystemInit+0x19a>
            ((NRF_UICR->PSELRESET[1] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos))){
    2d7e:	f8d3 3204 	ldr.w	r3, [r3, #516]	; 0x204
        if (((NRF_UICR->PSELRESET[0] & UICR_PSELRESET_CONNECT_Msk) != (UICR_PSELRESET_CONNECT_Connected << UICR_PSELRESET_CONNECT_Pos)) ||
    2d82:	2b00      	cmp	r3, #0
    2d84:	da2f      	bge.n	2de6 <SystemInit+0x1fa>
            NRF_NVMC->CONFIG = NVMC_CONFIG_WEN_Wen << NVMC_CONFIG_WEN_Pos;
    2d86:	4b2c      	ldr	r3, [pc, #176]	; (2e38 <SystemInit+0x24c>)
    2d88:	2201      	movs	r2, #1
    2d8a:	f8c3 2504 	str.w	r2, [r3, #1284]	; 0x504
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2d8e:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2d92:	2a00      	cmp	r2, #0
    2d94:	d0fb      	beq.n	2d8e <SystemInit+0x1a2>
            NRF_UICR->PSELRESET[0] = 21;
    2d96:	f04f 2210 	mov.w	r2, #268439552	; 0x10001000
    2d9a:	2115      	movs	r1, #21
    2d9c:	f8c2 1200 	str.w	r1, [r2, #512]	; 0x200
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2da0:	f8d3 2400 	ldr.w	r2, [r3, #1024]	; 0x400
    2da4:	2a00      	cmp	r2, #0
    2da6:	d0fb      	beq.n	2da0 <SystemInit+0x1b4>
            NRF_UICR->PSELRESET[1] = 21;
    2da8:	f04f 2310 	mov.w	r3, #268439552	; 0x10001000
    2dac:	2215      	movs	r2, #21
    2dae:	f8c3 2204 	str.w	r2, [r3, #516]	; 0x204
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2db2:	4b21      	ldr	r3, [pc, #132]	; (2e38 <SystemInit+0x24c>)
    2db4:	461a      	mov	r2, r3
    2db6:	f8d3 1400 	ldr.w	r1, [r3, #1024]	; 0x400
    2dba:	2900      	cmp	r1, #0
    2dbc:	d0fb      	beq.n	2db6 <SystemInit+0x1ca>
            NRF_NVMC->CONFIG = NVMC_CONFIG_WEN_Ren << NVMC_CONFIG_WEN_Pos;
    2dbe:	2100      	movs	r1, #0
    2dc0:	f8c3 1504 	str.w	r1, [r3, #1284]	; 0x504
            while (NRF_NVMC->READY == NVMC_READY_READY_Busy){}
    2dc4:	f8d2 3400 	ldr.w	r3, [r2, #1024]	; 0x400
    2dc8:	2b00      	cmp	r3, #0
    2dca:	d0fb      	beq.n	2dc4 <SystemInit+0x1d8>
  __ASM volatile ("dsb 0xF":::"memory");
    2dcc:	f3bf 8f4f 	dsb	sy
__NO_RETURN __STATIC_INLINE void __NVIC_SystemReset(void)
{
  __DSB();                                                          /* Ensure all outstanding memory accesses included
                                                                       buffered write are completed before reset */
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
                           (SCB->AIRCR & SCB_AIRCR_PRIGROUP_Msk) |
    2dd0:	491a      	ldr	r1, [pc, #104]	; (2e3c <SystemInit+0x250>)
    2dd2:	4b1b      	ldr	r3, [pc, #108]	; (2e40 <SystemInit+0x254>)
    2dd4:	68ca      	ldr	r2, [r1, #12]
    2dd6:	f402 62e0 	and.w	r2, r2, #1792	; 0x700
    2dda:	4313      	orrs	r3, r2
  SCB->AIRCR  = (uint32_t)((0x5FAUL << SCB_AIRCR_VECTKEY_Pos)    |
    2ddc:	60cb      	str	r3, [r1, #12]
    2dde:	f3bf 8f4f 	dsb	sy
                            SCB_AIRCR_SYSRESETREQ_Msk    );         /* Keep priority group unchanged */
  __DSB();                                                          /* Ensure completion of memory access */

  for(;;)                                                           /* wait until reset */
  {
    __NOP();
    2de2:	bf00      	nop
  for(;;)                                                           /* wait until reset */
    2de4:	e7fd      	b.n	2de2 <SystemInit+0x1f6>
    SystemCoreClock = __SYSTEM_CLOCK_64M;
    2de6:	4b17      	ldr	r3, [pc, #92]	; (2e44 <SystemInit+0x258>)
    2de8:	4a17      	ldr	r2, [pc, #92]	; (2e48 <SystemInit+0x25c>)
    2dea:	601a      	str	r2, [r3, #0]
            NVIC_SystemReset();
        }
    #endif

    SystemCoreClockUpdate();
}
    2dec:	bd08      	pop	{r3, pc}
    2dee:	bf00      	nop
    2df0:	10000324 	.word	0x10000324
    2df4:	40013540 	.word	0x40013540
    2df8:	4007c074 	.word	0x4007c074
    2dfc:	baadf00d 	.word	0xbaadf00d
    2e00:	10000244 	.word	0x10000244
    2e04:	4000053c 	.word	0x4000053c
    2e08:	e000edf0 	.word	0xe000edf0
    2e0c:	400005a0 	.word	0x400005a0
    2e10:	40005610 	.word	0x40005610
    2e14:	10000130 	.word	0x10000130
    2e18:	f0000fe0 	.word	0xf0000fe0
    2e1c:	10000134 	.word	0x10000134
    2e20:	0000710e 	.word	0x0000710e
    2e24:	4000c000 	.word	0x4000c000
    2e28:	10000258 	.word	0x10000258
    2e2c:	40000ee4 	.word	0x40000ee4
    2e30:	00007112 	.word	0x00007112
    2e34:	4000173c 	.word	0x4000173c
    2e38:	4001e000 	.word	0x4001e000
    2e3c:	e000ed00 	.word	0xe000ed00
    2e40:	05fa0004 	.word	0x05fa0004
    2e44:	20002c38 	.word	0x20002c38
    2e48:	03d09000 	.word	0x03d09000

00002e4c <z_sys_init_run_level>:
 * off and the next one begins.
 *
 * @param level init level to run.
 */
void z_sys_init_run_level(int32_t level)
{
    2e4c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2e4e:	4b0b      	ldr	r3, [pc, #44]	; (2e7c <z_sys_init_run_level+0x30>)
    2e50:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
    2e54:	3001      	adds	r0, #1
			if (dev) {
				/* Initialization failed. Clear the API struct
				 * so that device_get_binding() will not succeed
				 * for it.
				 */
				dev->driver_api = NULL;
    2e56:	2700      	movs	r7, #0
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2e58:	f853 6020 	ldr.w	r6, [r3, r0, lsl #2]
    2e5c:	42a6      	cmp	r6, r4
    2e5e:	d800      	bhi.n	2e62 <z_sys_init_run_level+0x16>
			}
		}
	}
}
    2e60:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		struct device *dev = entry->dev;
    2e62:	6865      	ldr	r5, [r4, #4]
		if (dev != NULL) {
    2e64:	b115      	cbz	r5, 2e6c <z_sys_init_run_level+0x20>
			z_object_init(dev);
    2e66:	4628      	mov	r0, r5
    2e68:	f003 fc88 	bl	677c <z_object_init>
		retval = entry->init(dev);
    2e6c:	6823      	ldr	r3, [r4, #0]
    2e6e:	4628      	mov	r0, r5
    2e70:	4798      	blx	r3
		if (retval != 0) {
    2e72:	b108      	cbz	r0, 2e78 <z_sys_init_run_level+0x2c>
			if (dev) {
    2e74:	b105      	cbz	r5, 2e78 <z_sys_init_run_level+0x2c>
				dev->driver_api = NULL;
    2e76:	60af      	str	r7, [r5, #8]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
    2e78:	3408      	adds	r4, #8
    2e7a:	e7ef      	b.n	2e5c <z_sys_init_run_level+0x10>
    2e7c:	00006bbc 	.word	0x00006bbc

00002e80 <z_impl_device_get_binding>:
	/* Split the search into two loops: in the common scenario, where
	 * device names are stored in ROM (and are referenced by the user
	 * with CONFIG_* macros), only cheap pointer comparisons will be
	 * performed. Reserve string comparisons for a fallback.
	 */
	for (dev = __device_start; dev != __device_end; dev++) {
    2e80:	4b0f      	ldr	r3, [pc, #60]	; (2ec0 <z_impl_device_get_binding+0x40>)
{
    2e82:	b570      	push	{r4, r5, r6, lr}
	for (dev = __device_start; dev != __device_end; dev++) {
    2e84:	4c0f      	ldr	r4, [pc, #60]	; (2ec4 <z_impl_device_get_binding+0x44>)
{
    2e86:	4605      	mov	r5, r0
    2e88:	461e      	mov	r6, r3
	for (dev = __device_start; dev != __device_end; dev++) {
    2e8a:	429c      	cmp	r4, r3
    2e8c:	d104      	bne.n	2e98 <z_impl_device_get_binding+0x18>
		if (z_device_ready(dev) && (dev->name == name)) {
			return dev;
		}
	}

	for (dev = __device_start; dev != __device_end; dev++) {
    2e8e:	4c0d      	ldr	r4, [pc, #52]	; (2ec4 <z_impl_device_get_binding+0x44>)
    2e90:	42b4      	cmp	r4, r6
    2e92:	d108      	bne.n	2ea6 <z_impl_device_get_binding+0x26>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
			return dev;
		}
	}

	return NULL;
    2e94:	2400      	movs	r4, #0
    2e96:	e010      	b.n	2eba <z_impl_device_get_binding+0x3a>
		if (z_device_ready(dev) && (dev->name == name)) {
    2e98:	68a2      	ldr	r2, [r4, #8]
    2e9a:	b112      	cbz	r2, 2ea2 <z_impl_device_get_binding+0x22>
    2e9c:	6822      	ldr	r2, [r4, #0]
    2e9e:	42aa      	cmp	r2, r5
    2ea0:	d00b      	beq.n	2eba <z_impl_device_get_binding+0x3a>
	for (dev = __device_start; dev != __device_end; dev++) {
    2ea2:	3410      	adds	r4, #16
    2ea4:	e7f1      	b.n	2e8a <z_impl_device_get_binding+0xa>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    2ea6:	68a3      	ldr	r3, [r4, #8]
    2ea8:	b90b      	cbnz	r3, 2eae <z_impl_device_get_binding+0x2e>
	for (dev = __device_start; dev != __device_end; dev++) {
    2eaa:	3410      	adds	r4, #16
    2eac:	e7f0      	b.n	2e90 <z_impl_device_get_binding+0x10>
		if (z_device_ready(dev) && (strcmp(name, dev->name) == 0)) {
    2eae:	6821      	ldr	r1, [r4, #0]
    2eb0:	4628      	mov	r0, r5
    2eb2:	f002 fe06 	bl	5ac2 <strcmp>
    2eb6:	2800      	cmp	r0, #0
    2eb8:	d1f7      	bne.n	2eaa <z_impl_device_get_binding+0x2a>
}
    2eba:	4620      	mov	r0, r4
    2ebc:	bd70      	pop	{r4, r5, r6, pc}
    2ebe:	bf00      	nop
    2ec0:	20002c88 	.word	0x20002c88
    2ec4:	20002c48 	.word	0x20002c48

00002ec8 <z_mrsh_device_get_binding>:
#include <syscalls/device.h>

extern struct device * z_vrfy_device_get_binding(const char * name);
uintptr_t z_mrsh_device_get_binding(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    2ec8:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    2eca:	4c0b      	ldr	r4, [pc, #44]	; (2ef8 <z_mrsh_device_get_binding+0x30>)
{
    2ecc:	b08c      	sub	sp, #48	; 0x30
	_current->syscall_frame = ssf;
    2ece:	68a3      	ldr	r3, [r4, #8]
    2ed0:	9a10      	ldr	r2, [sp, #64]	; 0x40
    2ed2:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    2ed6:	4601      	mov	r1, r0
#ifdef CONFIG_USERSPACE
static inline struct device *z_vrfy_device_get_binding(const char *name)
{
	char name_copy[Z_DEVICE_MAX_NAME_LEN];

	if (z_user_string_copy(name_copy, (char *)name, sizeof(name_copy))
    2ed8:	2230      	movs	r2, #48	; 0x30
    2eda:	4668      	mov	r0, sp
    2edc:	f003 fc76 	bl	67cc <z_user_string_copy>
    2ee0:	b940      	cbnz	r0, 2ef4 <z_mrsh_device_get_binding+0x2c>
	    != 0) {
		return 0;
	}

	return z_impl_device_get_binding(name_copy);
    2ee2:	4668      	mov	r0, sp
    2ee4:	f7ff ffcc 	bl	2e80 <z_impl_device_get_binding>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	struct device * ret = z_vrfy_device_get_binding(*(const char **)&arg0)
;
	_current->syscall_frame = NULL;
    2ee8:	68a3      	ldr	r3, [r4, #8]
    2eea:	2200      	movs	r2, #0
    2eec:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    2ef0:	b00c      	add	sp, #48	; 0x30
    2ef2:	bd10      	pop	{r4, pc}
		return 0;
    2ef4:	2000      	movs	r0, #0
    2ef6:	e7f7      	b.n	2ee8 <z_mrsh_device_get_binding+0x20>
    2ef8:	20000524 	.word	0x20000524

00002efc <z_mrsh_z_errno>:

extern int * z_vrfy_z_errno();
uintptr_t z_mrsh_z_errno(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    2efc:	4b03      	ldr	r3, [pc, #12]	; (2f0c <z_mrsh_z_errno+0x10>)
    2efe:	689b      	ldr	r3, [r3, #8]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int * ret = z_vrfy_z_errno()
;
	_current->syscall_frame = NULL;
    2f00:	2200      	movs	r2, #0
	return (uintptr_t) ret;
}
    2f02:	6e58      	ldr	r0, [r3, #100]	; 0x64
	_current->syscall_frame = NULL;
    2f04:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
}
    2f08:	4770      	bx	lr
    2f0a:	bf00      	nop
    2f0c:	20000524 	.word	0x20000524

00002f10 <idle>:
#else
#define IDLE_YIELD_IF_COOP() do { } while (false)
#endif

void idle(void *unused1, void *unused2, void *unused3)
{
    2f10:	b508      	push	{r3, lr}
	_kernel.idle = ticks;
    2f12:	4d0b      	ldr	r5, [pc, #44]	; (2f40 <idle+0x30>)
	__asm__ volatile(
    2f14:	f04f 0220 	mov.w	r2, #32
    2f18:	f3ef 8311 	mrs	r3, BASEPRI
    2f1c:	f382 8811 	msr	BASEPRI, r2
    2f20:	f3bf 8f6f 	isb	sy
	int32_t ticks = z_get_next_timeout_expiry();
    2f24:	f003 f983 	bl	622e <z_get_next_timeout_expiry>
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    2f28:	2101      	movs	r1, #1
    2f2a:	2802      	cmp	r0, #2
	int32_t ticks = z_get_next_timeout_expiry();
    2f2c:	4604      	mov	r4, r0
	z_set_timeout_expiry((ticks < IDLE_THRESH) ? 1 : ticks, true);
    2f2e:	bfd8      	it	le
    2f30:	4608      	movle	r0, r1
    2f32:	f003 f98c 	bl	624e <z_set_timeout_expiry>
	_kernel.idle = ticks;
    2f36:	622c      	str	r4, [r5, #32]
 *
 * @return N/A
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
    2f38:	f7fe fba8 	bl	168c <arch_cpu_idle>
}
    2f3c:	e7ea      	b.n	2f14 <idle+0x4>
    2f3e:	bf00      	nop
    2f40:	20000524 	.word	0x20000524

00002f44 <z_bss_zero>:
 *
 * @return N/A
 */
void z_bss_zero(void)
{
	(void)memset(__bss_start, 0, __bss_end - __bss_start);
    2f44:	4802      	ldr	r0, [pc, #8]	; (2f50 <z_bss_zero+0xc>)
    2f46:	4a03      	ldr	r2, [pc, #12]	; (2f54 <z_bss_zero+0x10>)
    2f48:	2100      	movs	r1, #0
    2f4a:	1a12      	subs	r2, r2, r0
    2f4c:	f002 bdf0 	b.w	5b30 <memset>
    2f50:	20000000 	.word	0x20000000
    2f54:	200012b8 	.word	0x200012b8

00002f58 <z_data_copy>:
 * @return N/A
 */
void z_data_copy(void)
{
	(void)memcpy(&__data_ram_start, &__data_rom_start,
		 __data_ram_end - __data_ram_start);
    2f58:	4809      	ldr	r0, [pc, #36]	; (2f80 <z_data_copy+0x28>)
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    2f5a:	4a0a      	ldr	r2, [pc, #40]	; (2f84 <z_data_copy+0x2c>)
    2f5c:	490a      	ldr	r1, [pc, #40]	; (2f88 <z_data_copy+0x30>)
{
    2f5e:	b508      	push	{r3, lr}
	(void)memcpy(&__data_ram_start, &__data_rom_start,
    2f60:	1a12      	subs	r2, r2, r0
    2f62:	f002 fdba 	bl	5ada <memcpy>
#ifdef CONFIG_ARCH_HAS_RAMFUNC_SUPPORT
	(void)memcpy(&_ramfunc_ram_start, &_ramfunc_rom_start,
    2f66:	4a09      	ldr	r2, [pc, #36]	; (2f8c <z_data_copy+0x34>)
    2f68:	4909      	ldr	r1, [pc, #36]	; (2f90 <z_data_copy+0x38>)
    2f6a:	480a      	ldr	r0, [pc, #40]	; (2f94 <z_data_copy+0x3c>)
    2f6c:	f002 fdb5 	bl	5ada <memcpy>
		count--;
	}
	__stack_chk_guard = guard_copy;
#else
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
		 _app_smem_end - _app_smem_start);
    2f70:	4809      	ldr	r0, [pc, #36]	; (2f98 <z_data_copy+0x40>)
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
    2f72:	4a0a      	ldr	r2, [pc, #40]	; (2f9c <z_data_copy+0x44>)
    2f74:	490a      	ldr	r1, [pc, #40]	; (2fa0 <z_data_copy+0x48>)
#endif /* CONFIG_STACK_CANARIES */
#endif /* CONFIG_USERSPACE */
}
    2f76:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	(void)memcpy(&_app_smem_start, &_app_smem_rom_start,
    2f7a:	1a12      	subs	r2, r2, r0
    2f7c:	f002 bdad 	b.w	5ada <memcpy>
    2f80:	20002c00 	.word	0x20002c00
    2f84:	200043a8 	.word	0x200043a8
    2f88:	00007268 	.word	0x00007268
    2f8c:	00000000 	.word	0x00000000
    2f90:	00007268 	.word	0x00007268
    2f94:	20000000 	.word	0x20000000
    2f98:	20000000 	.word	0x20000000
    2f9c:	20000000 	.word	0x20000000
    2fa0:	00007268 	.word	0x00007268

00002fa4 <bg_thread_main>:
 * init functions, then invokes application's main() routine.
 *
 * @return N/A
 */
static void bg_thread_main(void *unused1, void *unused2, void *unused3)
{
    2fa4:	b508      	push	{r3, lr}
	static const unsigned int boot_delay = CONFIG_BOOT_DELAY;
#else
	static const unsigned int boot_delay;
#endif

	z_sys_post_kernel = true;
    2fa6:	4b0c      	ldr	r3, [pc, #48]	; (2fd8 <bg_thread_main+0x34>)
    2fa8:	2201      	movs	r2, #1

	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    2faa:	2002      	movs	r0, #2
	z_sys_post_kernel = true;
    2fac:	701a      	strb	r2, [r3, #0]
	z_sys_init_run_level(_SYS_INIT_LEVEL_POST_KERNEL);
    2fae:	f7ff ff4d 	bl	2e4c <z_sys_init_run_level>
		k_busy_wait(CONFIG_BOOT_DELAY * USEC_PER_MSEC);
	}

#if defined(CONFIG_BOOT_BANNER)
#ifdef BUILD_VERSION
	printk("*** Booting Zephyr OS build %s %s ***\n",
    2fb2:	4a0a      	ldr	r2, [pc, #40]	; (2fdc <bg_thread_main+0x38>)
    2fb4:	490a      	ldr	r1, [pc, #40]	; (2fe0 <bg_thread_main+0x3c>)
    2fb6:	480b      	ldr	r0, [pc, #44]	; (2fe4 <bg_thread_main+0x40>)
    2fb8:	f002 f91b 	bl	51f2 <printk>
	__do_global_ctors_aux();
	__do_init_array_aux();
#endif

	/* Final init level before app starts */
	z_sys_init_run_level(_SYS_INIT_LEVEL_APPLICATION);
    2fbc:	2003      	movs	r0, #3
    2fbe:	f7ff ff45 	bl	2e4c <z_sys_init_run_level>

	z_init_static_threads();
    2fc2:	f001 fa8d 	bl	44e0 <z_init_static_threads>
	z_timestamp_main = k_cycle_get_32();
#endif

	extern void main(void);

	main();
    2fc6:	f7fd fb17 	bl	5f8 <main>

	/* Mark nonessenrial since main() has no more work to do */
	z_main_thread.base.user_options &= ~K_ESSENTIAL;
    2fca:	4a07      	ldr	r2, [pc, #28]	; (2fe8 <bg_thread_main+0x44>)
    2fcc:	7b13      	ldrb	r3, [r2, #12]
    2fce:	f023 0301 	bic.w	r3, r3, #1
    2fd2:	7313      	strb	r3, [r2, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
    2fd4:	bd08      	pop	{r3, pc}
    2fd6:	bf00      	nop
    2fd8:	200012b3 	.word	0x200012b3
    2fdc:	00007161 	.word	0x00007161
    2fe0:	0000711a 	.word	0x0000711a
    2fe4:	0000713b 	.word	0x0000713b
    2fe8:	20000320 	.word	0x20000320

00002fec <z_cstart>:
 * cleared/zeroed.
 *
 * @return Does not return
 */
FUNC_NORETURN void z_cstart(void)
{
    2fec:	e92d 4880 	stmdb	sp!, {r7, fp, lr}
 *
 * @return N/A
 */
static ALWAYS_INLINE void z_arm_interrupt_stack_setup(void)
{
	uint32_t msp =
    2ff0:	f8df 90f4 	ldr.w	r9, [pc, #244]	; 30e8 <z_cstart+0xfc>
    2ff4:	b0af      	sub	sp, #188	; 0xbc
  __ASM volatile ("MSR msp, %0" : : "r" (topOfMainStack) : );
    2ff6:	f389 8808 	msr	MSP, r9
	 * for Cortex-M3 and Cortex-M4 (ARMv7-M) MCUs. For the rest
	 * of ARM Cortex-M processors this setting is enforced by
	 * default and it is not configurable.
	 */
#if defined(CONFIG_CPU_CORTEX_M3) || defined(CONFIG_CPU_CORTEX_M4)
	SCB->CCR |= SCB_CCR_STKALIGN_Msk;
    2ffa:	4d33      	ldr	r5, [pc, #204]	; (30c8 <z_cstart+0xdc>)
	_kernel.ready_q.cache = &z_main_thread;
    2ffc:	4e33      	ldr	r6, [pc, #204]	; (30cc <z_cstart+0xe0>)
    2ffe:	696b      	ldr	r3, [r5, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    3000:	f8df a0e8 	ldr.w	sl, [pc, #232]	; 30ec <z_cstart+0x100>
	z_setup_new_thread(thread, stack,
    3004:	4f32      	ldr	r7, [pc, #200]	; (30d0 <z_cstart+0xe4>)
    3006:	f443 7300 	orr.w	r3, r3, #512	; 0x200
    SCB->SHP[(((uint32_t)IRQn) & 0xFUL)-4UL] = (uint8_t)((priority << (8U - __NVIC_PRIO_BITS)) & (uint32_t)0xFFUL);
    300a:	2400      	movs	r4, #0
    300c:	616b      	str	r3, [r5, #20]
    300e:	23e0      	movs	r3, #224	; 0xe0
    3010:	f885 3022 	strb.w	r3, [r5, #34]	; 0x22
    3014:	77ec      	strb	r4, [r5, #31]
    3016:	762c      	strb	r4, [r5, #24]
    3018:	766c      	strb	r4, [r5, #25]
    301a:	76ac      	strb	r4, [r5, #26]
#if defined(CONFIG_ARM_SECURE_FIRMWARE)
	NVIC_SetPriority(SecureFault_IRQn, _EXC_FAULT_PRIO);
#endif /* CONFIG_ARM_SECURE_FIRMWARE */

	/* Enable Usage, Mem, & Bus Faults */
	SCB->SHCSR |= SCB_SHCSR_USGFAULTENA_Msk | SCB_SHCSR_MEMFAULTENA_Msk |
    301c:	6a6b      	ldr	r3, [r5, #36]	; 0x24
    301e:	f443 23e0 	orr.w	r3, r3, #458752	; 0x70000
    3022:	626b      	str	r3, [r5, #36]	; 0x24

static ALWAYS_INLINE void arch_kernel_init(void)
{
	z_arm_interrupt_stack_setup();
	z_arm_exc_setup();
	z_arm_fault_init();
    3024:	f7fe fda2 	bl	1b6c <z_arm_fault_init>
	z_arm_cpu_idle_init();
    3028:	f7fe fb2a 	bl	1680 <z_arm_cpu_idle_init>
static ALWAYS_INLINE void z_arm_clear_faults(void)
{
#if defined(CONFIG_ARMV6_M_ARMV8_M_BASELINE)
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	/* Reset all faults */
	SCB->CFSR = SCB_CFSR_USGFAULTSR_Msk |
    302c:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
    3030:	62ab      	str	r3, [r5, #40]	; 0x28
		    SCB_CFSR_MEMFAULTSR_Msk |
		    SCB_CFSR_BUSFAULTSR_Msk;

	/* Clear all Hard Faults - HFSR is write-one-to-clear */
	SCB->HFSR = 0xffffffff;
    3032:	62eb      	str	r3, [r5, #44]	; 0x2c
#endif
#ifdef CONFIG_USERSPACE
	dummy_thread->mem_domain_info.mem_domain = 0;
#endif

	_current_cpu->current = dummy_thread;
    3034:	4d27      	ldr	r5, [pc, #156]	; (30d4 <z_cstart+0xe8>)
	dummy_thread->mem_domain_info.mem_domain = 0;
    3036:	9425      	str	r4, [sp, #148]	; 0x94
	dummy_thread->base.user_options = K_ESSENTIAL;
    3038:	f240 1301 	movw	r3, #257	; 0x101
    303c:	f8ad 3024 	strh.w	r3, [sp, #36]	; 0x24
	_current_cpu->current = dummy_thread;
    3040:	ab06      	add	r3, sp, #24
    3042:	60ab      	str	r3, [r5, #8]

	z_dummy_thread_init(&dummy_thread);
#endif

	/* perform basic hardware initialization */
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_1);
    3044:	4620      	mov	r0, r4
	dummy_thread->stack_info.size = 0U;
    3046:	e9cd 4420 	strd	r4, r4, [sp, #128]	; 0x80
    304a:	f7ff feff 	bl	2e4c <z_sys_init_run_level>
	z_sys_init_run_level(_SYS_INIT_LEVEL_PRE_KERNEL_2);
    304e:	2001      	movs	r0, #1
    3050:	f7ff fefc 	bl	2e4c <z_sys_init_run_level>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    3054:	f04f 0b01 	mov.w	fp, #1
	z_sched_init();
    3058:	f000 fe06 	bl	3c68 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    305c:	4b1e      	ldr	r3, [pc, #120]	; (30d8 <z_cstart+0xec>)
	_kernel.ready_q.cache = &z_main_thread;
    305e:	626e      	str	r6, [r5, #36]	; 0x24
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
    3060:	491e      	ldr	r1, [pc, #120]	; (30dc <z_cstart+0xf0>)
    3062:	9305      	str	r3, [sp, #20]
    3064:	f44f 6280 	mov.w	r2, #1024	; 0x400
    3068:	4653      	mov	r3, sl
    306a:	e9cd 4b03 	strd	r4, fp, [sp, #12]
    306e:	e9cd 4401 	strd	r4, r4, [sp, #4]
    3072:	9400      	str	r4, [sp, #0]
    3074:	4630      	mov	r0, r6
    3076:	f001 f935 	bl	42e4 <z_setup_new_thread>
	sys_trace_thread_resume(thread);
}

static inline void z_mark_thread_as_started(struct k_thread *thread)
{
	thread->base.thread_state &= ~_THREAD_PRESTART;
    307a:	7b73      	ldrb	r3, [r6, #13]
    307c:	4680      	mov	r8, r0
    307e:	f023 0304 	bic.w	r3, r3, #4
	z_ready_thread(&z_main_thread);
    3082:	4630      	mov	r0, r6
    3084:	7373      	strb	r3, [r6, #13]
    3086:	f002 ff84 	bl	5f92 <z_ready_thread>
	z_setup_new_thread(thread, stack,
    308a:	230f      	movs	r3, #15
    308c:	e9cd 4302 	strd	r4, r3, [sp, #8]
    3090:	4913      	ldr	r1, [pc, #76]	; (30e0 <z_cstart+0xf4>)
    3092:	4b14      	ldr	r3, [pc, #80]	; (30e4 <z_cstart+0xf8>)
    3094:	f44f 72a0 	mov.w	r2, #320	; 0x140
    3098:	e9cd b404 	strd	fp, r4, [sp, #16]
    309c:	e9cd 4400 	strd	r4, r4, [sp]
    30a0:	4638      	mov	r0, r7
    30a2:	f001 f91f 	bl	42e4 <z_setup_new_thread>
    30a6:	7b7b      	ldrb	r3, [r7, #13]
		_kernel.cpus[i].idle_thread = &z_idle_threads[i];
    30a8:	60ef      	str	r7, [r5, #12]
    30aa:	f023 0304 	bic.w	r3, r3, #4
    30ae:	737b      	strb	r3, [r7, #13]
 * @return N/A
 */

static inline void sys_dlist_init(sys_dlist_t *list)
{
	list->head = (sys_dnode_t *)list;
    30b0:	f105 0318 	add.w	r3, r5, #24
	list->tail = (sys_dnode_t *)list;
    30b4:	e9c5 3306 	strd	r3, r3, [r5, #24]
		_kernel.cpus[i].id = i;
    30b8:	752c      	strb	r4, [r5, #20]
		_kernel.cpus[i].irq_stack =
    30ba:	f8c5 9004 	str.w	r9, [r5, #4]
	arch_switch_to_main_thread(&z_main_thread, stack_ptr, bg_thread_main);
    30be:	4652      	mov	r2, sl
    30c0:	4641      	mov	r1, r8
    30c2:	4630      	mov	r0, r6
    30c4:	f7fe fac2 	bl	164c <arch_switch_to_main_thread>
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
    30c8:	e000ed00 	.word	0xe000ed00
    30cc:	20000320 	.word	0x20000320
    30d0:	20000280 	.word	0x20000280
    30d4:	20000524 	.word	0x20000524
    30d8:	00007162 	.word	0x00007162
    30dc:	20002000 	.word	0x20002000
    30e0:	20001400 	.word	0x20001400
    30e4:	00002f11 	.word	0x00002f11
    30e8:	20001d40 	.word	0x20001d40
    30ec:	00002fa5 	.word	0x00002fa5

000030f0 <z_mrsh_k_mutex_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_init(struct k_mutex * mutex);
uintptr_t z_mrsh_k_mutex_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    30f0:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    30f2:	4d0e      	ldr	r5, [pc, #56]	; (312c <z_mrsh_k_mutex_init+0x3c>)
    30f4:	9a06      	ldr	r2, [sp, #24]
    30f6:	68ab      	ldr	r3, [r5, #8]
    30f8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    30fc:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_init(struct k_mutex *mutex)
{
	Z_OOPS(Z_SYSCALL_OBJ_INIT(mutex, K_OBJ_MUTEX));
    30fe:	f7fc ffed 	bl	dc <z_object_find>
    3102:	2201      	movs	r2, #1
    3104:	2103      	movs	r1, #3
    3106:	f001 feaf 	bl	4e68 <z_object_validate>
    310a:	4604      	mov	r4, r0
    310c:	b130      	cbz	r0, 311c <z_mrsh_k_mutex_init+0x2c>
    310e:	f002 fe05 	bl	5d1c <arch_is_user_context>
    3112:	68ab      	ldr	r3, [r5, #8]
    3114:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3118:	f002 fc8f 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_mutex_init(mutex);
    311c:	4630      	mov	r0, r6
    311e:	f002 fe17 	bl	5d50 <z_impl_k_mutex_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_mutex_init(*(struct k_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
    3122:	68ab      	ldr	r3, [r5, #8]
    3124:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3128:	bd70      	pop	{r4, r5, r6, pc}
    312a:	bf00      	nop
    312c:	20000524 	.word	0x20000524

00003130 <z_impl_k_mutex_lock>:
	}
	return false;
}

int z_impl_k_mutex_lock(struct k_mutex *mutex, k_timeout_t timeout)
{
    3130:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
    3134:	4604      	mov	r4, r0
    3136:	4616      	mov	r6, r2
    3138:	461f      	mov	r7, r3
    313a:	f04f 0320 	mov.w	r3, #32
    313e:	f3ef 8811 	mrs	r8, BASEPRI
    3142:	f383 8811 	msr	BASEPRI, r3
    3146:	f3bf 8f6f 	isb	sy
	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");

	sys_trace_void(SYS_TRACE_ID_MUTEX_LOCK);
	key = k_spin_lock(&lock);

	if (likely((mutex->lock_count == 0U) || (mutex->owner == _current))) {
    314a:	68c3      	ldr	r3, [r0, #12]
    314c:	4a39      	ldr	r2, [pc, #228]	; (3234 <z_impl_k_mutex_lock+0x104>)
    314e:	b16b      	cbz	r3, 316c <z_impl_k_mutex_lock+0x3c>
    3150:	6880      	ldr	r0, [r0, #8]
    3152:	6891      	ldr	r1, [r2, #8]
    3154:	4288      	cmp	r0, r1
    3156:	d01c      	beq.n	3192 <z_impl_k_mutex_lock+0x62>
		sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);

		return 0;
	}

	if (unlikely(K_TIMEOUT_EQ(timeout, K_NO_WAIT))) {
    3158:	ea56 0307 	orrs.w	r3, r6, r7
    315c:	d11b      	bne.n	3196 <z_impl_k_mutex_lock+0x66>
	__asm__ volatile(
    315e:	f388 8811 	msr	BASEPRI, r8
    3162:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);
		return -EBUSY;
    3166:	f06f 020f 	mvn.w	r2, #15
    316a:	e00e      	b.n	318a <z_impl_k_mutex_lock+0x5a>
					_current->base.prio :
    316c:	6891      	ldr	r1, [r2, #8]
    316e:	f991 100e 	ldrsb.w	r1, [r1, #14]
		mutex->owner_orig_prio = (mutex->lock_count == 0U) ?
    3172:	6121      	str	r1, [r4, #16]
		mutex->lock_count++;
    3174:	3301      	adds	r3, #1
    3176:	60e3      	str	r3, [r4, #12]
		mutex->owner = _current;
    3178:	6893      	ldr	r3, [r2, #8]
    317a:	60a3      	str	r3, [r4, #8]
    317c:	f002 fdce 	bl	5d1c <arch_is_user_context>
    3180:	f388 8811 	msr	BASEPRI, r8
    3184:	f3bf 8f6f 	isb	sy
		return 0;
    3188:	2200      	movs	r2, #0
		k_spin_unlock(&lock, key);
	}

	sys_trace_end_call(SYS_TRACE_ID_MUTEX_LOCK);
	return -EAGAIN;
}
    318a:	4610      	mov	r0, r2
    318c:	b002      	add	sp, #8
    318e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
					_current->base.prio :
    3192:	6921      	ldr	r1, [r4, #16]
    3194:	e7ed      	b.n	3172 <z_impl_k_mutex_lock+0x42>
	new_prio = new_prio_for_inheritance(_current->base.prio,
    3196:	f991 100e 	ldrsb.w	r1, [r1, #14]
    319a:	f990 300e 	ldrsb.w	r3, [r0, #14]
    319e:	4299      	cmp	r1, r3
    31a0:	bfa8      	it	ge
    31a2:	4619      	movge	r1, r3
    31a4:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    31a8:	f002 fdb8 	bl	5d1c <arch_is_user_context>
	if (z_is_prio_higher(new_prio, mutex->owner->base.prio)) {
    31ac:	68a3      	ldr	r3, [r4, #8]
    31ae:	f993 300e 	ldrsb.w	r3, [r3, #14]
    31b2:	4299      	cmp	r1, r3
    31b4:	da37      	bge.n	3226 <z_impl_k_mutex_lock+0xf6>
		resched = adjust_owner_prio(mutex, new_prio);
    31b6:	f104 0008 	add.w	r0, r4, #8
    31ba:	f002 fdb9 	bl	5d30 <adjust_owner_prio.isra.0>
    31be:	4605      	mov	r5, r0
	int got_mutex = z_pend_curr(&lock, key, &mutex->wait_q, timeout);
    31c0:	4622      	mov	r2, r4
    31c2:	4641      	mov	r1, r8
    31c4:	e9cd 6700 	strd	r6, r7, [sp]
    31c8:	481b      	ldr	r0, [pc, #108]	; (3238 <z_impl_k_mutex_lock+0x108>)
    31ca:	f000 fce5 	bl	3b98 <z_pend_curr>
    31ce:	4602      	mov	r2, r0
    31d0:	f002 fda4 	bl	5d1c <arch_is_user_context>
    31d4:	f002 fda2 	bl	5d1c <arch_is_user_context>
	if (got_mutex == 0) {
    31d8:	2a00      	cmp	r2, #0
    31da:	d0d6      	beq.n	318a <z_impl_k_mutex_lock+0x5a>
    31dc:	f002 fd9e 	bl	5d1c <arch_is_user_context>
	__asm__ volatile(
    31e0:	f04f 0320 	mov.w	r3, #32
    31e4:	f3ef 8611 	mrs	r6, BASEPRI
    31e8:	f383 8811 	msr	BASEPRI, r3
    31ec:	f3bf 8f6f 	isb	sy
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
    31f0:	6823      	ldr	r3, [r4, #0]
    31f2:	6921      	ldr	r1, [r4, #16]
 * @return a pointer to the head element, NULL if list is empty
 */

static inline sys_dnode_t *sys_dlist_peek_head(sys_dlist_t *list)
{
	return sys_dlist_is_empty(list) ? NULL : list->head;
    31f4:	42a3      	cmp	r3, r4
    31f6:	d007      	beq.n	3208 <z_impl_k_mutex_lock+0xd8>
		new_prio_for_inheritance(waiter->base.prio, mutex->owner_orig_prio) :
    31f8:	b133      	cbz	r3, 3208 <z_impl_k_mutex_lock+0xd8>
    31fa:	f993 300e 	ldrsb.w	r3, [r3, #14]
    31fe:	4299      	cmp	r1, r3
    3200:	bfa8      	it	ge
    3202:	4619      	movge	r1, r3
    3204:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    3208:	f002 fd88 	bl	5d1c <arch_is_user_context>
	resched = adjust_owner_prio(mutex, new_prio) || resched;
    320c:	f104 0008 	add.w	r0, r4, #8
    3210:	f002 fd8e 	bl	5d30 <adjust_owner_prio.isra.0>
    3214:	b900      	cbnz	r0, 3218 <z_impl_k_mutex_lock+0xe8>
	if (resched) {
    3216:	b145      	cbz	r5, 322a <z_impl_k_mutex_lock+0xfa>
		z_reschedule(&lock, key);
    3218:	4807      	ldr	r0, [pc, #28]	; (3238 <z_impl_k_mutex_lock+0x108>)
    321a:	4631      	mov	r1, r6
    321c:	f002 fe71 	bl	5f02 <z_reschedule>
	return -EAGAIN;
    3220:	f06f 020a 	mvn.w	r2, #10
    3224:	e7b1      	b.n	318a <z_impl_k_mutex_lock+0x5a>
	bool resched = false;
    3226:	2500      	movs	r5, #0
    3228:	e7ca      	b.n	31c0 <z_impl_k_mutex_lock+0x90>
	__asm__ volatile(
    322a:	f386 8811 	msr	BASEPRI, r6
    322e:	f3bf 8f6f 	isb	sy
    3232:	e7f5      	b.n	3220 <z_impl_k_mutex_lock+0xf0>
    3234:	20000524 	.word	0x20000524
    3238:	200012b4 	.word	0x200012b4

0000323c <z_mrsh_k_mutex_lock>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_lock(struct k_mutex * mutex, k_timeout_t timeout);
uintptr_t z_mrsh_k_mutex_lock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    323c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    3240:	4d10      	ldr	r5, [pc, #64]	; (3284 <z_mrsh_k_mutex_lock+0x48>)
    3242:	68ab      	ldr	r3, [r5, #8]
{
    3244:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    3246:	9a08      	ldr	r2, [sp, #32]
    3248:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    324c:	4688      	mov	r8, r1
    324e:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_lock(struct k_mutex *mutex,
				      k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(mutex, K_OBJ_MUTEX));
    3250:	f7fc ff44 	bl	dc <z_object_find>
    3254:	2200      	movs	r2, #0
    3256:	2103      	movs	r1, #3
    3258:	f001 fe06 	bl	4e68 <z_object_validate>
    325c:	4604      	mov	r4, r0
    325e:	b130      	cbz	r0, 326e <z_mrsh_k_mutex_lock+0x32>
    3260:	f002 fd5c 	bl	5d1c <arch_is_user_context>
    3264:	68ab      	ldr	r3, [r5, #8]
    3266:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    326a:	f002 fbe6 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_mutex_lock(mutex, timeout);
    326e:	463b      	mov	r3, r7
    3270:	4642      	mov	r2, r8
    3272:	4630      	mov	r0, r6
    3274:	f7ff ff5c 	bl	3130 <z_impl_k_mutex_lock>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_mutex_lock(*(struct k_mutex **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    3278:	68ab      	ldr	r3, [r5, #8]
    327a:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    327e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    3282:	bf00      	nop
    3284:	20000524 	.word	0x20000524

00003288 <z_impl_k_mutex_unlock>:
}
#include <syscalls/k_mutex_lock_mrsh.c>
#endif

int z_impl_k_mutex_unlock(struct k_mutex *mutex)
{
    3288:	b538      	push	{r3, r4, r5, lr}
	struct k_thread *new_owner;

	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");

	CHECKIF(mutex->owner == NULL) {
    328a:	6883      	ldr	r3, [r0, #8]
{
    328c:	4604      	mov	r4, r0
	CHECKIF(mutex->owner == NULL) {
    328e:	2b00      	cmp	r3, #0
    3290:	d03a      	beq.n	3308 <z_impl_k_mutex_unlock+0x80>
		return -EINVAL;
	}
	/*
	 * The current thread does not own the mutex.
	 */
	CHECKIF(mutex->owner != _current) {
    3292:	4a20      	ldr	r2, [pc, #128]	; (3314 <z_impl_k_mutex_unlock+0x8c>)
    3294:	6892      	ldr	r2, [r2, #8]
    3296:	4293      	cmp	r3, r2
    3298:	d139      	bne.n	330e <z_impl_k_mutex_unlock+0x86>
{
#ifdef CONFIG_PREEMPT_ENABLED
	__ASSERT(!arch_is_in_isr(), "");
	__ASSERT(_current->base.sched_locked != 1, "");

	--_current->base.sched_locked;
    329a:	7bda      	ldrb	r2, [r3, #15]
    329c:	3a01      	subs	r2, #1
    329e:	73da      	strb	r2, [r3, #15]
    32a0:	f002 fd3c 	bl	5d1c <arch_is_user_context>

	/*
	 * If we are the owner and count is greater than 1, then decrement
	 * the count and return and keep current thread as the owner.
	 */
	if (mutex->lock_count - 1U != 0U) {
    32a4:	68e3      	ldr	r3, [r4, #12]
    32a6:	2b01      	cmp	r3, #1
    32a8:	d005      	beq.n	32b6 <z_impl_k_mutex_unlock+0x2e>
		mutex->lock_count--;
    32aa:	3b01      	subs	r3, #1
    32ac:	60e3      	str	r3, [r4, #12]
		k_spin_unlock(&lock, key);
	}


k_mutex_unlock_return:
	k_sched_unlock();
    32ae:	f000 fa25 	bl	36fc <k_sched_unlock>
	sys_trace_end_call(SYS_TRACE_ID_MUTEX_UNLOCK);

	return 0;
    32b2:	2000      	movs	r0, #0
}
    32b4:	bd38      	pop	{r3, r4, r5, pc}
	__asm__ volatile(
    32b6:	f04f 0320 	mov.w	r3, #32
    32ba:	f3ef 8511 	mrs	r5, BASEPRI
    32be:	f383 8811 	msr	BASEPRI, r3
    32c2:	f3bf 8f6f 	isb	sy
	adjust_owner_prio(mutex, mutex->owner_orig_prio);
    32c6:	6921      	ldr	r1, [r4, #16]
    32c8:	f104 0008 	add.w	r0, r4, #8
    32cc:	f002 fd30 	bl	5d30 <adjust_owner_prio.isra.0>
	new_owner = z_unpend_first_thread(&mutex->wait_q);
    32d0:	4620      	mov	r0, r4
    32d2:	f002 fed4 	bl	607e <z_unpend_first_thread>
	mutex->owner = new_owner;
    32d6:	60a0      	str	r0, [r4, #8]
	new_owner = z_unpend_first_thread(&mutex->wait_q);
    32d8:	4602      	mov	r2, r0
    32da:	f002 fd1f 	bl	5d1c <arch_is_user_context>
	if (new_owner != NULL) {
    32de:	b16a      	cbz	r2, 32fc <z_impl_k_mutex_unlock+0x74>
		mutex->owner_orig_prio = new_owner->base.prio;
    32e0:	f992 300e 	ldrsb.w	r3, [r2, #14]
    32e4:	6123      	str	r3, [r4, #16]
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
    32e6:	2300      	movs	r3, #0
		z_ready_thread(new_owner);
    32e8:	4610      	mov	r0, r2
    32ea:	f8c2 3090 	str.w	r3, [r2, #144]	; 0x90
    32ee:	f002 fe50 	bl	5f92 <z_ready_thread>
		z_reschedule(&lock, key);
    32f2:	4809      	ldr	r0, [pc, #36]	; (3318 <z_impl_k_mutex_unlock+0x90>)
    32f4:	4629      	mov	r1, r5
    32f6:	f002 fe04 	bl	5f02 <z_reschedule>
    32fa:	e7d8      	b.n	32ae <z_impl_k_mutex_unlock+0x26>
		mutex->lock_count = 0U;
    32fc:	60e2      	str	r2, [r4, #12]
	__asm__ volatile(
    32fe:	f385 8811 	msr	BASEPRI, r5
    3302:	f3bf 8f6f 	isb	sy
    3306:	e7d2      	b.n	32ae <z_impl_k_mutex_unlock+0x26>
		return -EINVAL;
    3308:	f06f 0015 	mvn.w	r0, #21
    330c:	e7d2      	b.n	32b4 <z_impl_k_mutex_unlock+0x2c>
		return -EPERM;
    330e:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    3312:	e7cf      	b.n	32b4 <z_impl_k_mutex_unlock+0x2c>
    3314:	20000524 	.word	0x20000524
    3318:	200012b4 	.word	0x200012b4

0000331c <z_mrsh_k_mutex_unlock>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_mutex_unlock(struct k_mutex * mutex);
uintptr_t z_mrsh_k_mutex_unlock(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    331c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    331e:	4d0e      	ldr	r5, [pc, #56]	; (3358 <z_mrsh_k_mutex_unlock+0x3c>)
    3320:	9a06      	ldr	r2, [sp, #24]
    3322:	68ab      	ldr	r3, [r5, #8]
    3324:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3328:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_mutex_unlock(struct k_mutex *mutex)
{
	Z_OOPS(Z_SYSCALL_OBJ(mutex, K_OBJ_MUTEX));
    332a:	f7fc fed7 	bl	dc <z_object_find>
    332e:	2200      	movs	r2, #0
    3330:	2103      	movs	r1, #3
    3332:	f001 fd99 	bl	4e68 <z_object_validate>
    3336:	4604      	mov	r4, r0
    3338:	b130      	cbz	r0, 3348 <z_mrsh_k_mutex_unlock+0x2c>
    333a:	f002 fcef 	bl	5d1c <arch_is_user_context>
    333e:	68ab      	ldr	r3, [r5, #8]
    3340:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3344:	f002 fb79 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_mutex_unlock(mutex);
    3348:	4630      	mov	r0, r6
    334a:	f7ff ff9d 	bl	3288 <z_impl_k_mutex_unlock>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_mutex_unlock(*(struct k_mutex **)&arg0)
;
	_current->syscall_frame = NULL;
    334e:	68ab      	ldr	r3, [r5, #8]
    3350:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3354:	bd70      	pop	{r4, r5, r6, pc}
    3356:	bf00      	nop
    3358:	20000524 	.word	0x20000524

0000335c <z_mrsh_k_queue_init>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_queue_init(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    335c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    335e:	4d0f      	ldr	r5, [pc, #60]	; (339c <z_mrsh_k_queue_init+0x40>)
    3360:	9a06      	ldr	r2, [sp, #24]
    3362:	68ab      	ldr	r3, [r5, #8]
    3364:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3368:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_queue_init(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(queue, K_OBJ_QUEUE));
    336a:	f7fc feb7 	bl	dc <z_object_find>
    336e:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    3372:	2105      	movs	r1, #5
    3374:	f001 fd78 	bl	4e68 <z_object_validate>
    3378:	4604      	mov	r4, r0
    337a:	b130      	cbz	r0, 338a <z_mrsh_k_queue_init+0x2e>
    337c:	f002 fcf2 	bl	5d64 <arch_is_user_context>
    3380:	68ab      	ldr	r3, [r5, #8]
    3382:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3386:	f002 fb58 	bl	5a3a <arch_syscall_oops>
	z_impl_k_queue_init(queue);
    338a:	4630      	mov	r0, r6
    338c:	f002 fd61 	bl	5e52 <z_impl_k_queue_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_queue_init(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3390:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3392:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3394:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3398:	bd70      	pop	{r4, r5, r6, pc}
    339a:	bf00      	nop
    339c:	20000524 	.word	0x20000524

000033a0 <z_mrsh_k_queue_cancel_wait>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_queue_cancel_wait(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_cancel_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    33a0:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    33a2:	4d0e      	ldr	r5, [pc, #56]	; (33dc <z_mrsh_k_queue_cancel_wait+0x3c>)
    33a4:	9a06      	ldr	r2, [sp, #24]
    33a6:	68ab      	ldr	r3, [r5, #8]
    33a8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    33ac:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_queue_cancel_wait(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    33ae:	f7fc fe95 	bl	dc <z_object_find>
    33b2:	2200      	movs	r2, #0
    33b4:	2105      	movs	r1, #5
    33b6:	f001 fd57 	bl	4e68 <z_object_validate>
    33ba:	4604      	mov	r4, r0
    33bc:	b130      	cbz	r0, 33cc <z_mrsh_k_queue_cancel_wait+0x2c>
    33be:	f002 fcd1 	bl	5d64 <arch_is_user_context>
    33c2:	68ab      	ldr	r3, [r5, #8]
    33c4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    33c8:	f002 fb37 	bl	5a3a <arch_syscall_oops>
	z_impl_k_queue_cancel_wait(queue);
    33cc:	4630      	mov	r0, r6
    33ce:	f002 fd4d 	bl	5e6c <z_impl_k_queue_cancel_wait>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_queue_cancel_wait(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    33d2:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    33d4:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    33d6:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    33da:	bd70      	pop	{r4, r5, r6, pc}
    33dc:	20000524 	.word	0x20000524

000033e0 <z_mrsh_k_queue_alloc_append>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_queue_alloc_append(struct k_queue * queue, void * data);
uintptr_t z_mrsh_k_queue_alloc_append(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    33e0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    33e2:	4d0f      	ldr	r5, [pc, #60]	; (3420 <z_mrsh_k_queue_alloc_append+0x40>)
    33e4:	9a08      	ldr	r2, [sp, #32]
    33e6:	68ab      	ldr	r3, [r5, #8]
    33e8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    33ec:	460f      	mov	r7, r1
    33ee:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_queue_alloc_append(struct k_queue *queue,
						void *data)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    33f0:	f7fc fe74 	bl	dc <z_object_find>
    33f4:	2200      	movs	r2, #0
    33f6:	2105      	movs	r1, #5
    33f8:	f001 fd36 	bl	4e68 <z_object_validate>
    33fc:	4604      	mov	r4, r0
    33fe:	b130      	cbz	r0, 340e <z_mrsh_k_queue_alloc_append+0x2e>
    3400:	f002 fcb0 	bl	5d64 <arch_is_user_context>
    3404:	68ab      	ldr	r3, [r5, #8]
    3406:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    340a:	f002 fb16 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_queue_alloc_append(queue, data);
    340e:	4639      	mov	r1, r7
    3410:	4630      	mov	r0, r6
    3412:	f002 fd4c 	bl	5eae <z_impl_k_queue_alloc_append>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_queue_alloc_append(*(struct k_queue **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    3416:	68ab      	ldr	r3, [r5, #8]
    3418:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    341c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    341e:	bf00      	nop
    3420:	20000524 	.word	0x20000524

00003424 <z_mrsh_k_queue_alloc_prepend>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_queue_alloc_prepend(struct k_queue * queue, void * data);
uintptr_t z_mrsh_k_queue_alloc_prepend(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3424:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    3426:	4d0f      	ldr	r5, [pc, #60]	; (3464 <z_mrsh_k_queue_alloc_prepend+0x40>)
    3428:	9a08      	ldr	r2, [sp, #32]
    342a:	68ab      	ldr	r3, [r5, #8]
    342c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3430:	460f      	mov	r7, r1
    3432:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_queue_alloc_prepend(struct k_queue *queue,
						 void *data)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    3434:	f7fc fe52 	bl	dc <z_object_find>
    3438:	2200      	movs	r2, #0
    343a:	2105      	movs	r1, #5
    343c:	f001 fd14 	bl	4e68 <z_object_validate>
    3440:	4604      	mov	r4, r0
    3442:	b130      	cbz	r0, 3452 <z_mrsh_k_queue_alloc_prepend+0x2e>
    3444:	f002 fc8e 	bl	5d64 <arch_is_user_context>
    3448:	68ab      	ldr	r3, [r5, #8]
    344a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    344e:	f002 faf4 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_queue_alloc_prepend(queue, data);
    3452:	4639      	mov	r1, r7
    3454:	4630      	mov	r0, r6
    3456:	f002 fd2f 	bl	5eb8 <z_impl_k_queue_alloc_prepend>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_queue_alloc_prepend(*(struct k_queue **)&arg0, *(void **)&arg1)
;
	_current->syscall_frame = NULL;
    345a:	68ab      	ldr	r3, [r5, #8]
    345c:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3460:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3462:	bf00      	nop
    3464:	20000524 	.word	0x20000524

00003468 <z_impl_k_queue_get>:

	return 0;
}

void *z_impl_k_queue_get(struct k_queue *queue, k_timeout_t timeout)
{
    3468:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    346a:	4616      	mov	r6, r2
    346c:	461f      	mov	r7, r3
	__asm__ volatile(
    346e:	f04f 0320 	mov.w	r3, #32
    3472:	f3ef 8511 	mrs	r5, BASEPRI
    3476:	f383 8811 	msr	BASEPRI, r3
    347a:	f3bf 8f6f 	isb	sy
 *
 * @return a boolean, true if it's empty, false otherwise
 */
static inline bool sys_sflist_is_empty(sys_sflist_t *list);

Z_GENLIST_IS_EMPTY(sflist)
    347e:	6804      	ldr	r4, [r0, #0]
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
	void *data;

	if (likely(!sys_sflist_is_empty(&queue->data_q))) {
    3480:	b19c      	cbz	r4, 34aa <z_impl_k_queue_get+0x42>
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    3482:	6823      	ldr	r3, [r4, #0]
 *
 * @return A pointer to the first node of the list
 */
static inline sys_sfnode_t *sys_sflist_get_not_empty(sys_sflist_t *list);

Z_GENLIST_GET_NOT_EMPTY(sflist, sfnode)
    3484:	6842      	ldr	r2, [r0, #4]
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    3486:	f023 0303 	bic.w	r3, r3, #3
Z_GENLIST_GET_NOT_EMPTY(sflist, sfnode)
    348a:	4294      	cmp	r4, r2
	list->head = node;
    348c:	6003      	str	r3, [r0, #0]
	list->tail = node;
    348e:	bf08      	it	eq
    3490:	6043      	streq	r3, [r0, #4]
		sys_sfnode_t *node;

		node = sys_sflist_get_not_empty(&queue->data_q);
		data = z_queue_node_peek(node, true);
    3492:	2101      	movs	r1, #1
    3494:	4620      	mov	r0, r4
    3496:	f002 fcd0 	bl	5e3a <z_queue_node_peek>
    349a:	4604      	mov	r4, r0
	__asm__ volatile(
    349c:	f385 8811 	msr	BASEPRI, r5
    34a0:	f3bf 8f6f 	isb	sy
	}

	int ret = z_pend_curr(&queue->lock, key, &queue->wait_q, timeout);

	return (ret != 0) ? NULL : _current->base.swap_data;
}
    34a4:	4620      	mov	r0, r4
    34a6:	b003      	add	sp, #12
    34a8:	bdf0      	pop	{r4, r5, r6, r7, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    34aa:	ea56 0307 	orrs.w	r3, r6, r7
    34ae:	d0f5      	beq.n	349c <z_impl_k_queue_get+0x34>
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    34b0:	f100 0208 	add.w	r2, r0, #8
	int ret = z_pend_curr(&queue->lock, key, &queue->wait_q, timeout);
    34b4:	e9cd 6700 	strd	r6, r7, [sp]
    34b8:	4629      	mov	r1, r5
    34ba:	4610      	mov	r0, r2
    34bc:	f000 fb6c 	bl	3b98 <z_pend_curr>
	return (ret != 0) ? NULL : _current->base.swap_data;
    34c0:	2800      	cmp	r0, #0
    34c2:	d1ef      	bne.n	34a4 <z_impl_k_queue_get+0x3c>
    34c4:	4b01      	ldr	r3, [pc, #4]	; (34cc <z_impl_k_queue_get+0x64>)
    34c6:	689b      	ldr	r3, [r3, #8]
    34c8:	695c      	ldr	r4, [r3, #20]
    34ca:	e7eb      	b.n	34a4 <z_impl_k_queue_get+0x3c>
    34cc:	20000524 	.word	0x20000524

000034d0 <z_mrsh_k_queue_get>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_get(struct k_queue * queue, k_timeout_t timeout);
uintptr_t z_mrsh_k_queue_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    34d0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    34d4:	4d10      	ldr	r5, [pc, #64]	; (3518 <z_mrsh_k_queue_get+0x48>)
    34d6:	68ab      	ldr	r3, [r5, #8]
{
    34d8:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    34da:	9a08      	ldr	r2, [sp, #32]
    34dc:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    34e0:	4688      	mov	r8, r1
    34e2:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline void *z_vrfy_k_queue_get(struct k_queue *queue,
				       k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    34e4:	f7fc fdfa 	bl	dc <z_object_find>
    34e8:	2200      	movs	r2, #0
    34ea:	2105      	movs	r1, #5
    34ec:	f001 fcbc 	bl	4e68 <z_object_validate>
    34f0:	4604      	mov	r4, r0
    34f2:	b130      	cbz	r0, 3502 <z_mrsh_k_queue_get+0x32>
    34f4:	f002 fc36 	bl	5d64 <arch_is_user_context>
    34f8:	68ab      	ldr	r3, [r5, #8]
    34fa:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    34fe:	f002 fa9c 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_queue_get(queue, timeout);
    3502:	463b      	mov	r3, r7
    3504:	4642      	mov	r2, r8
    3506:	4630      	mov	r0, r6
    3508:	f7ff ffae 	bl	3468 <z_impl_k_queue_get>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	void * ret = z_vrfy_k_queue_get(*(struct k_queue **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    350c:	68ab      	ldr	r3, [r5, #8]
    350e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3512:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    3516:	bf00      	nop
    3518:	20000524 	.word	0x20000524

0000351c <z_mrsh_k_queue_is_empty>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_queue_is_empty(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_is_empty(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    351c:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    351e:	4c0e      	ldr	r4, [pc, #56]	; (3558 <z_mrsh_k_queue_is_empty+0x3c>)
    3520:	9a06      	ldr	r2, [sp, #24]
    3522:	68a3      	ldr	r3, [r4, #8]
    3524:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3528:	4605      	mov	r5, r0
}
#include <syscalls/k_queue_get_mrsh.c>

static inline int z_vrfy_k_queue_is_empty(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    352a:	f7fc fdd7 	bl	dc <z_object_find>
    352e:	2200      	movs	r2, #0
    3530:	2105      	movs	r1, #5
    3532:	f001 fc99 	bl	4e68 <z_object_validate>
    3536:	b130      	cbz	r0, 3546 <z_mrsh_k_queue_is_empty+0x2a>
    3538:	f002 fc14 	bl	5d64 <arch_is_user_context>
    353c:	68a3      	ldr	r3, [r4, #8]
    353e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3542:	f002 fa7a 	bl	5a3a <arch_syscall_oops>
Z_GENLIST_IS_EMPTY(sflist)
    3546:	682b      	ldr	r3, [r5, #0]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_queue_is_empty(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3548:	68a2      	ldr	r2, [r4, #8]
    354a:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    354e:	fab3 f083 	clz	r0, r3
    3552:	0940      	lsrs	r0, r0, #5
    3554:	bd38      	pop	{r3, r4, r5, pc}
    3556:	bf00      	nop
    3558:	20000524 	.word	0x20000524

0000355c <z_mrsh_k_queue_peek_head>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_peek_head(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_peek_head(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    355c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    355e:	4d0e      	ldr	r5, [pc, #56]	; (3598 <z_mrsh_k_queue_peek_head+0x3c>)
    3560:	9a06      	ldr	r2, [sp, #24]
    3562:	68ab      	ldr	r3, [r5, #8]
    3564:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3568:	4606      	mov	r6, r0
}
#include <syscalls/k_queue_is_empty_mrsh.c>

static inline void *z_vrfy_k_queue_peek_head(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    356a:	f7fc fdb7 	bl	dc <z_object_find>
    356e:	2200      	movs	r2, #0
    3570:	2105      	movs	r1, #5
    3572:	f001 fc79 	bl	4e68 <z_object_validate>
    3576:	4604      	mov	r4, r0
    3578:	b130      	cbz	r0, 3588 <z_mrsh_k_queue_peek_head+0x2c>
    357a:	f002 fbf3 	bl	5d64 <arch_is_user_context>
    357e:	68ab      	ldr	r3, [r5, #8]
    3580:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3584:	f002 fa59 	bl	5a3a <arch_syscall_oops>
	return z_queue_node_peek(sys_sflist_peek_head(&queue->data_q), false);
    3588:	4601      	mov	r1, r0
    358a:	6830      	ldr	r0, [r6, #0]
    358c:	f002 fc55 	bl	5e3a <z_queue_node_peek>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_queue_peek_head(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    3590:	68ab      	ldr	r3, [r5, #8]
    3592:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3596:	bd70      	pop	{r4, r5, r6, pc}
    3598:	20000524 	.word	0x20000524

0000359c <z_mrsh_k_queue_peek_tail>:
#include <syscalls/kernel.h>

extern void * z_vrfy_k_queue_peek_tail(struct k_queue * queue);
uintptr_t z_mrsh_k_queue_peek_tail(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    359c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    359e:	4d0e      	ldr	r5, [pc, #56]	; (35d8 <z_mrsh_k_queue_peek_tail+0x3c>)
    35a0:	9a06      	ldr	r2, [sp, #24]
    35a2:	68ab      	ldr	r3, [r5, #8]
    35a4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    35a8:	4606      	mov	r6, r0
}
#include <syscalls/k_queue_peek_head_mrsh.c>

static inline void *z_vrfy_k_queue_peek_tail(struct k_queue *queue)
{
	Z_OOPS(Z_SYSCALL_OBJ(queue, K_OBJ_QUEUE));
    35aa:	f7fc fd97 	bl	dc <z_object_find>
    35ae:	2200      	movs	r2, #0
    35b0:	2105      	movs	r1, #5
    35b2:	f001 fc59 	bl	4e68 <z_object_validate>
    35b6:	4604      	mov	r4, r0
    35b8:	b130      	cbz	r0, 35c8 <z_mrsh_k_queue_peek_tail+0x2c>
    35ba:	f002 fbd3 	bl	5d64 <arch_is_user_context>
    35be:	68ab      	ldr	r3, [r5, #8]
    35c0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    35c4:	f002 fa39 	bl	5a3a <arch_syscall_oops>
	return z_queue_node_peek(sys_sflist_peek_tail(&queue->data_q), false);
    35c8:	4601      	mov	r1, r0
    35ca:	6870      	ldr	r0, [r6, #4]
    35cc:	f002 fc35 	bl	5e3a <z_queue_node_peek>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_queue_peek_tail(*(struct k_queue **)&arg0)
;
	_current->syscall_frame = NULL;
    35d0:	68ab      	ldr	r3, [r5, #8]
    35d2:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    35d6:	bd70      	pop	{r4, r5, r6, pc}
    35d8:	20000524 	.word	0x20000524

000035dc <z_reset_time_slice>:
 */
static struct k_thread *pending_current;
#endif

void z_reset_time_slice(void)
{
    35dc:	b510      	push	{r4, lr}
	/* Add the elapsed time since the last announced tick to the
	 * slice count, as we'll see those "expired" ticks arrive in a
	 * FUTURE z_time_slice() call.
	 */
	if (slice_time != 0) {
    35de:	4c08      	ldr	r4, [pc, #32]	; (3600 <z_reset_time_slice+0x24>)
    35e0:	6823      	ldr	r3, [r4, #0]
    35e2:	b15b      	cbz	r3, 35fc <z_reset_time_slice+0x20>
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    35e4:	f7fd fecc 	bl	1380 <z_clock_elapsed>
    35e8:	4603      	mov	r3, r0
    35ea:	6820      	ldr	r0, [r4, #0]
    35ec:	4a05      	ldr	r2, [pc, #20]	; (3604 <z_reset_time_slice+0x28>)
    35ee:	4403      	add	r3, r0
		z_set_timeout_expiry(slice_time, false);
	}
}
    35f0:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		_current_cpu->slice_ticks = slice_time + z_clock_elapsed();
    35f4:	6113      	str	r3, [r2, #16]
		z_set_timeout_expiry(slice_time, false);
    35f6:	2100      	movs	r1, #0
    35f8:	f002 be29 	b.w	624e <z_set_timeout_expiry>
}
    35fc:	bd10      	pop	{r4, pc}
    35fe:	bf00      	nop
    3600:	2000055c 	.word	0x2000055c
    3604:	20000524 	.word	0x20000524

00003608 <k_sched_time_slice_set>:

void k_sched_time_slice_set(int32_t slice, int prio)
{
    3608:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    360a:	4605      	mov	r5, r0
    360c:	460c      	mov	r4, r1
	__asm__ volatile(
    360e:	f04f 0320 	mov.w	r3, #32
    3612:	f3ef 8611 	mrs	r6, BASEPRI
    3616:	f383 8811 	msr	BASEPRI, r3
    361a:	f3bf 8f6f 	isb	sy
	LOCKED(&sched_spinlock) {
		_current_cpu->slice_ticks = 0;
    361e:	4b0d      	ldr	r3, [pc, #52]	; (3654 <k_sched_time_slice_set+0x4c>)
    3620:	2200      	movs	r2, #0
		} else {
			return t * (to_hz / from_hz);
		}
	} else {
		if (result32) {
			return (uint32_t)((t * to_hz + off) / from_hz);
    3622:	f44f 4700 	mov.w	r7, #32768	; 0x8000
    3626:	f240 30e7 	movw	r0, #999	; 0x3e7
    362a:	2100      	movs	r1, #0
    362c:	611a      	str	r2, [r3, #16]
    362e:	fbe7 0105 	umlal	r0, r1, r7, r5
    3632:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    3636:	2300      	movs	r3, #0
    3638:	f7fc fdd0 	bl	1dc <__aeabi_uldivmod>
		slice_time = k_ms_to_ticks_ceil32(slice);
    363c:	4b06      	ldr	r3, [pc, #24]	; (3658 <k_sched_time_slice_set+0x50>)
    363e:	6018      	str	r0, [r3, #0]
		slice_max_prio = prio;
    3640:	4b06      	ldr	r3, [pc, #24]	; (365c <k_sched_time_slice_set+0x54>)
    3642:	601c      	str	r4, [r3, #0]
		z_reset_time_slice();
    3644:	f7ff ffca 	bl	35dc <z_reset_time_slice>
	__asm__ volatile(
    3648:	f386 8811 	msr	BASEPRI, r6
    364c:	f3bf 8f6f 	isb	sy
	}
}
    3650:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3652:	bf00      	nop
    3654:	20000524 	.word	0x20000524
    3658:	2000055c 	.word	0x2000055c
    365c:	20000558 	.word	0x20000558

00003660 <k_sched_lock>:
	__asm__ volatile(
    3660:	f04f 0320 	mov.w	r3, #32
    3664:	f3ef 8111 	mrs	r1, BASEPRI
    3668:	f383 8811 	msr	BASEPRI, r3
    366c:	f3bf 8f6f 	isb	sy
    3670:	4b04      	ldr	r3, [pc, #16]	; (3684 <k_sched_lock+0x24>)
    3672:	689a      	ldr	r2, [r3, #8]
    3674:	7bd3      	ldrb	r3, [r2, #15]
    3676:	3b01      	subs	r3, #1
    3678:	73d3      	strb	r3, [r2, #15]
	__asm__ volatile(
    367a:	f381 8811 	msr	BASEPRI, r1
    367e:	f3bf 8f6f 	isb	sy
void k_sched_lock(void)
{
	LOCKED(&sched_spinlock) {
		z_sched_lock();
	}
}
    3682:	4770      	bx	lr
    3684:	20000524 	.word	0x20000524

00003688 <z_priq_dumb_remove>:
}

void z_priq_dumb_remove(sys_dlist_t *pq, struct k_thread *thread)
{
#if defined(CONFIG_SWAP_NONATOMIC) && defined(CONFIG_SCHED_DUMB)
	if (pq == &_kernel.ready_q.runq && thread == _current &&
    3688:	4b09      	ldr	r3, [pc, #36]	; (36b0 <z_priq_dumb_remove+0x28>)
    368a:	f103 0228 	add.w	r2, r3, #40	; 0x28
    368e:	4282      	cmp	r2, r0
    3690:	d105      	bne.n	369e <z_priq_dumb_remove+0x16>
    3692:	689b      	ldr	r3, [r3, #8]
    3694:	428b      	cmp	r3, r1
    3696:	d102      	bne.n	369e <z_priq_dumb_remove+0x16>
    3698:	7b4b      	ldrb	r3, [r1, #13]
    369a:	06db      	lsls	r3, r3, #27
    369c:	d106      	bne.n	36ac <z_priq_dumb_remove+0x24>
 * @return N/A
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	node->prev->next = node->next;
    369e:	e9d1 3200 	ldrd	r3, r2, [r1]
    36a2:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    36a4:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    36a6:	2300      	movs	r3, #0
	node->prev = NULL;
    36a8:	e9c1 3300 	strd	r3, r3, [r1]
#endif

	__ASSERT_NO_MSG(!z_is_idle_thread_object(thread));

	sys_dlist_remove(&thread->base.qnode_dlist);
}
    36ac:	4770      	bx	lr
    36ae:	bf00      	nop
    36b0:	20000524 	.word	0x20000524

000036b4 <update_cache>:
{
    36b4:	b570      	push	{r4, r5, r6, lr}
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    36b6:	4c10      	ldr	r4, [pc, #64]	; (36f8 <update_cache+0x44>)
{
    36b8:	4606      	mov	r6, r0
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    36ba:	f104 0028 	add.w	r0, r4, #40	; 0x28
    36be:	f002 fc5e 	bl	5f7e <z_priq_dumb_best>
	if (_current->base.thread_state & _THREAD_ABORTING) {
    36c2:	68a3      	ldr	r3, [r4, #8]
    36c4:	7b59      	ldrb	r1, [r3, #13]
	struct k_thread *thread = _priq_run_best(&_kernel.ready_q.runq);
    36c6:	4605      	mov	r5, r0
	if (_current->base.thread_state & _THREAD_ABORTING) {
    36c8:	0688      	lsls	r0, r1, #26
		_current->base.thread_state |= _THREAD_DEAD;
    36ca:	bf44      	itt	mi
    36cc:	f041 0108 	orrmi.w	r1, r1, #8
    36d0:	7359      	strbmi	r1, [r3, #13]
	return thread ? thread : _current_cpu->idle_thread;
    36d2:	b905      	cbnz	r5, 36d6 <update_cache+0x22>
    36d4:	68e5      	ldr	r5, [r4, #12]
	if (preempt_ok != 0) {
    36d6:	b94e      	cbnz	r6, 36ec <update_cache+0x38>
	if (z_is_thread_prevented_from_running(_current)) {
    36d8:	7b5a      	ldrb	r2, [r3, #13]
    36da:	06d2      	lsls	r2, r2, #27
    36dc:	d106      	bne.n	36ec <update_cache+0x38>
	if (IS_ENABLED(CONFIG_SWAP_NONATOMIC)
    36de:	69aa      	ldr	r2, [r5, #24]
    36e0:	b922      	cbnz	r2, 36ec <update_cache+0x38>
	if (is_preempt(_current) || is_metairq(thread)) {
    36e2:	89da      	ldrh	r2, [r3, #14]
    36e4:	2a7f      	cmp	r2, #127	; 0x7f
    36e6:	d901      	bls.n	36ec <update_cache+0x38>
		_kernel.ready_q.cache = _current;
    36e8:	6263      	str	r3, [r4, #36]	; 0x24
}
    36ea:	bd70      	pop	{r4, r5, r6, pc}
		if (thread != _current) {
    36ec:	42ab      	cmp	r3, r5
    36ee:	d001      	beq.n	36f4 <update_cache+0x40>
			z_reset_time_slice();
    36f0:	f7ff ff74 	bl	35dc <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
    36f4:	6265      	str	r5, [r4, #36]	; 0x24
}
    36f6:	e7f8      	b.n	36ea <update_cache+0x36>
    36f8:	20000524 	.word	0x20000524

000036fc <k_sched_unlock>:
{
    36fc:	b510      	push	{r4, lr}
	__asm__ volatile(
    36fe:	f04f 0320 	mov.w	r3, #32
    3702:	f3ef 8411 	mrs	r4, BASEPRI
    3706:	f383 8811 	msr	BASEPRI, r3
    370a:	f3bf 8f6f 	isb	sy
		++_current->base.sched_locked;
    370e:	4b09      	ldr	r3, [pc, #36]	; (3734 <k_sched_unlock+0x38>)
    3710:	689a      	ldr	r2, [r3, #8]
    3712:	7bd3      	ldrb	r3, [r2, #15]
    3714:	3301      	adds	r3, #1
    3716:	73d3      	strb	r3, [r2, #15]
		update_cache(0);
    3718:	2000      	movs	r0, #0
    371a:	f7ff ffcb 	bl	36b4 <update_cache>
	__asm__ volatile(
    371e:	f384 8811 	msr	BASEPRI, r4
    3722:	f3bf 8f6f 	isb	sy
    3726:	f002 fbcc 	bl	5ec2 <arch_is_user_context>
}
    372a:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule_unlocked();
    372e:	f002 bbff 	b.w	5f30 <z_reschedule_unlocked>
    3732:	bf00      	nop
    3734:	20000524 	.word	0x20000524

00003738 <ready_thread>:
{
    3738:	b470      	push	{r4, r5, r6}
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    373a:	7b43      	ldrb	r3, [r0, #13]
    373c:	06db      	lsls	r3, r3, #27
    373e:	d12a      	bne.n	3796 <ready_thread+0x5e>

int z_abort_timeout(struct _timeout *to);

static inline bool z_is_inactive_timeout(struct _timeout *t)
{
	return !sys_dnode_is_linked(&t->node);
    3740:	6983      	ldr	r3, [r0, #24]
	if (z_is_thread_ready(thread)) {
    3742:	bb43      	cbnz	r3, 3796 <ready_thread+0x5e>
	return list->head == list;
    3744:	4a15      	ldr	r2, [pc, #84]	; (379c <ready_thread+0x64>)
    3746:	4611      	mov	r1, r2
    3748:	f851 4f28 	ldr.w	r4, [r1, #40]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    374c:	428c      	cmp	r4, r1
    374e:	bf18      	it	ne
    3750:	4623      	movne	r3, r4
    3752:	2b00      	cmp	r3, #0
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    3754:	6ad4      	ldr	r4, [r2, #44]	; 0x2c
    3756:	bf38      	it	cc
    3758:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    375a:	b1b3      	cbz	r3, 378a <ready_thread+0x52>
	if (thread_1->base.prio < thread_2->base.prio) {
    375c:	f990 600e 	ldrsb.w	r6, [r0, #14]
    3760:	f993 500e 	ldrsb.w	r5, [r3, #14]
    3764:	42ae      	cmp	r6, r5
    3766:	db03      	blt.n	3770 <ready_thread+0x38>
	return (node == list->tail) ? NULL : node->next;
    3768:	42a3      	cmp	r3, r4
    376a:	d00e      	beq.n	378a <ready_thread+0x52>
    376c:	681b      	ldr	r3, [r3, #0]
    376e:	e7f4      	b.n	375a <ready_thread+0x22>
	node->prev = successor->prev;
    3770:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    3772:	e9c0 3200 	strd	r3, r2, [r0]
	successor->prev->next = node;
    3776:	6010      	str	r0, [r2, #0]
	successor->prev = node;
    3778:	6058      	str	r0, [r3, #4]
	thread->base.thread_state |= states;
    377a:	7b43      	ldrb	r3, [r0, #13]
    377c:	f063 037f 	orn	r3, r3, #127	; 0x7f
    3780:	7343      	strb	r3, [r0, #13]
}
    3782:	bc70      	pop	{r4, r5, r6}
		update_cache(0);
    3784:	2000      	movs	r0, #0
    3786:	f7ff bf95 	b.w	36b4 <update_cache>
	node->prev = list->tail;
    378a:	e9c0 1400 	strd	r1, r4, [r0]
	list->tail->next = node;
    378e:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    3790:	6018      	str	r0, [r3, #0]
	list->tail = node;
    3792:	62d0      	str	r0, [r2, #44]	; 0x2c
}
    3794:	e7f1      	b.n	377a <ready_thread+0x42>
}
    3796:	bc70      	pop	{r4, r5, r6}
    3798:	4770      	bx	lr
    379a:	bf00      	nop
    379c:	20000524 	.word	0x20000524

000037a0 <z_sched_start>:
{
    37a0:	b510      	push	{r4, lr}
	__asm__ volatile(
    37a2:	f04f 0220 	mov.w	r2, #32
    37a6:	f3ef 8411 	mrs	r4, BASEPRI
    37aa:	f382 8811 	msr	BASEPRI, r2
    37ae:	f3bf 8f6f 	isb	sy
	if (z_has_thread_started(thread)) {
    37b2:	7b42      	ldrb	r2, [r0, #13]
    37b4:	0751      	lsls	r1, r2, #29
    37b6:	d404      	bmi.n	37c2 <z_sched_start+0x22>
	__asm__ volatile(
    37b8:	f384 8811 	msr	BASEPRI, r4
    37bc:	f3bf 8f6f 	isb	sy
}
    37c0:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_PRESTART;
    37c2:	f022 0204 	bic.w	r2, r2, #4
    37c6:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
    37c8:	f7ff ffb6 	bl	3738 <ready_thread>
	z_reschedule(&sched_spinlock, key);
    37cc:	4621      	mov	r1, r4
    37ce:	4802      	ldr	r0, [pc, #8]	; (37d8 <z_sched_start+0x38>)
}
    37d0:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    37d4:	f002 bb95 	b.w	5f02 <z_reschedule>
    37d8:	200012b4 	.word	0x200012b4

000037dc <z_impl_k_thread_resume>:
{
    37dc:	b510      	push	{r4, lr}
	__asm__ volatile(
    37de:	f04f 0220 	mov.w	r2, #32
    37e2:	f3ef 8411 	mrs	r4, BASEPRI
    37e6:	f382 8811 	msr	BASEPRI, r2
    37ea:	f3bf 8f6f 	isb	sy
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    37ee:	7b42      	ldrb	r2, [r0, #13]
    37f0:	f022 0210 	bic.w	r2, r2, #16
    37f4:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
    37f6:	f7ff ff9f 	bl	3738 <ready_thread>
	z_reschedule(&sched_spinlock, key);
    37fa:	4621      	mov	r1, r4
    37fc:	4802      	ldr	r0, [pc, #8]	; (3808 <z_impl_k_thread_resume+0x2c>)
}
    37fe:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&sched_spinlock, key);
    3802:	f002 bb7e 	b.w	5f02 <z_reschedule>
    3806:	bf00      	nop
    3808:	200012b4 	.word	0x200012b4

0000380c <z_mrsh_k_thread_resume>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_resume(k_tid_t thread);
uintptr_t z_mrsh_k_thread_resume(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    380c:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    380e:	4d0e      	ldr	r5, [pc, #56]	; (3848 <z_mrsh_k_thread_resume+0x3c>)
    3810:	9a06      	ldr	r2, [sp, #24]
    3812:	68ab      	ldr	r3, [r5, #8]
    3814:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3818:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    381a:	f7fc fc5f 	bl	dc <z_object_find>
    381e:	2200      	movs	r2, #0
    3820:	2109      	movs	r1, #9
    3822:	f001 fb21 	bl	4e68 <z_object_validate>
    3826:	4604      	mov	r4, r0
    3828:	b130      	cbz	r0, 3838 <z_mrsh_k_thread_resume+0x2c>
    382a:	f002 fb4a 	bl	5ec2 <arch_is_user_context>
    382e:	68ab      	ldr	r3, [r5, #8]
    3830:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3834:	f002 f901 	bl	5a3a <arch_syscall_oops>
	z_impl_k_thread_resume(thread);
    3838:	4630      	mov	r0, r6
    383a:	f7ff ffcf 	bl	37dc <z_impl_k_thread_resume>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_resume(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    383e:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3840:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3842:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3846:	bd70      	pop	{r4, r5, r6, pc}
    3848:	20000524 	.word	0x20000524

0000384c <z_move_thread_to_end_of_prio_q>:
{
    384c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    384e:	4601      	mov	r1, r0
    3850:	f04f 0320 	mov.w	r3, #32
    3854:	f3ef 8411 	mrs	r4, BASEPRI
    3858:	f383 8811 	msr	BASEPRI, r3
    385c:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    3860:	f990 300d 	ldrsb.w	r3, [r0, #13]
    3864:	2b00      	cmp	r3, #0
    3866:	da02      	bge.n	386e <z_move_thread_to_end_of_prio_q+0x22>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    3868:	4819      	ldr	r0, [pc, #100]	; (38d0 <z_move_thread_to_end_of_prio_q+0x84>)
    386a:	f7ff ff0d 	bl	3688 <z_priq_dumb_remove>
	return list->head == list;
    386e:	4a19      	ldr	r2, [pc, #100]	; (38d4 <z_move_thread_to_end_of_prio_q+0x88>)
    3870:	4610      	mov	r0, r2
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    3872:	6ad5      	ldr	r5, [r2, #44]	; 0x2c
	return list->head == list;
    3874:	f850 3f28 	ldr.w	r3, [r0, #40]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3878:	4283      	cmp	r3, r0
    387a:	bf08      	it	eq
    387c:	2300      	moveq	r3, #0
    387e:	2b00      	cmp	r3, #0
    3880:	bf38      	it	cc
    3882:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    3884:	b1eb      	cbz	r3, 38c2 <z_move_thread_to_end_of_prio_q+0x76>
	if (thread_1->base.prio < thread_2->base.prio) {
    3886:	f991 700e 	ldrsb.w	r7, [r1, #14]
    388a:	f993 600e 	ldrsb.w	r6, [r3, #14]
    388e:	42b7      	cmp	r7, r6
    3890:	db03      	blt.n	389a <z_move_thread_to_end_of_prio_q+0x4e>
	return (node == list->tail) ? NULL : node->next;
    3892:	429d      	cmp	r5, r3
    3894:	d015      	beq.n	38c2 <z_move_thread_to_end_of_prio_q+0x76>
    3896:	681b      	ldr	r3, [r3, #0]
    3898:	e7f4      	b.n	3884 <z_move_thread_to_end_of_prio_q+0x38>
	node->prev = successor->prev;
    389a:	6858      	ldr	r0, [r3, #4]
	node->next = successor;
    389c:	e9c1 3000 	strd	r3, r0, [r1]
	successor->prev->next = node;
    38a0:	6001      	str	r1, [r0, #0]
	successor->prev = node;
    38a2:	6059      	str	r1, [r3, #4]
	thread->base.thread_state |= states;
    38a4:	7b4b      	ldrb	r3, [r1, #13]
		update_cache(thread == _current);
    38a6:	6890      	ldr	r0, [r2, #8]
    38a8:	f063 037f 	orn	r3, r3, #127	; 0x7f
    38ac:	734b      	strb	r3, [r1, #13]
    38ae:	1a43      	subs	r3, r0, r1
    38b0:	4258      	negs	r0, r3
    38b2:	4158      	adcs	r0, r3
    38b4:	f7ff fefe 	bl	36b4 <update_cache>
	__asm__ volatile(
    38b8:	f384 8811 	msr	BASEPRI, r4
    38bc:	f3bf 8f6f 	isb	sy
}
    38c0:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	node->prev = list->tail;
    38c2:	e9c1 0500 	strd	r0, r5, [r1]
	list->tail->next = node;
    38c6:	6ad3      	ldr	r3, [r2, #44]	; 0x2c
    38c8:	6019      	str	r1, [r3, #0]
	list->tail = node;
    38ca:	62d1      	str	r1, [r2, #44]	; 0x2c
}
    38cc:	e7ea      	b.n	38a4 <z_move_thread_to_end_of_prio_q+0x58>
    38ce:	bf00      	nop
    38d0:	2000054c 	.word	0x2000054c
    38d4:	20000524 	.word	0x20000524

000038d8 <z_time_slice>:
{
    38d8:	b538      	push	{r3, r4, r5, lr}
	if (pending_current == _current) {
    38da:	4a15      	ldr	r2, [pc, #84]	; (3930 <z_time_slice+0x58>)
    38dc:	4b15      	ldr	r3, [pc, #84]	; (3934 <z_time_slice+0x5c>)
    38de:	6814      	ldr	r4, [r2, #0]
{
    38e0:	4601      	mov	r1, r0
	if (pending_current == _current) {
    38e2:	6898      	ldr	r0, [r3, #8]
    38e4:	42a0      	cmp	r0, r4
    38e6:	461c      	mov	r4, r3
    38e8:	d103      	bne.n	38f2 <z_time_slice+0x1a>
}
    38ea:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
			z_reset_time_slice();
    38ee:	f7ff be75 	b.w	35dc <z_reset_time_slice>
	pending_current = NULL;
    38f2:	2500      	movs	r5, #0
    38f4:	6015      	str	r5, [r2, #0]
	if (slice_time && sliceable(_current)) {
    38f6:	4a10      	ldr	r2, [pc, #64]	; (3938 <z_time_slice+0x60>)
    38f8:	6812      	ldr	r2, [r2, #0]
    38fa:	b1b2      	cbz	r2, 392a <z_time_slice+0x52>
		&& !z_is_thread_timeout_active(thread);
    38fc:	89c2      	ldrh	r2, [r0, #14]
    38fe:	2a7f      	cmp	r2, #127	; 0x7f
    3900:	d813      	bhi.n	392a <z_time_slice+0x52>
		&& !z_is_prio_higher(thread->base.prio, slice_max_prio)
    3902:	4a0e      	ldr	r2, [pc, #56]	; (393c <z_time_slice+0x64>)
    3904:	f990 500e 	ldrsb.w	r5, [r0, #14]
    3908:	6812      	ldr	r2, [r2, #0]
    390a:	4295      	cmp	r5, r2
    390c:	db0d      	blt.n	392a <z_time_slice+0x52>
		&& !z_is_idle_thread_object(thread)
    390e:	4a0c      	ldr	r2, [pc, #48]	; (3940 <z_time_slice+0x68>)
    3910:	4290      	cmp	r0, r2
    3912:	d00a      	beq.n	392a <z_time_slice+0x52>
		&& !z_is_thread_timeout_active(thread);
    3914:	6982      	ldr	r2, [r0, #24]
    3916:	b942      	cbnz	r2, 392a <z_time_slice+0x52>
		if (ticks >= _current_cpu->slice_ticks) {
    3918:	691a      	ldr	r2, [r3, #16]
    391a:	428a      	cmp	r2, r1
    391c:	dc02      	bgt.n	3924 <z_time_slice+0x4c>
			z_move_thread_to_end_of_prio_q(_current);
    391e:	f7ff ff95 	bl	384c <z_move_thread_to_end_of_prio_q>
    3922:	e7e2      	b.n	38ea <z_time_slice+0x12>
			_current_cpu->slice_ticks -= ticks;
    3924:	1a52      	subs	r2, r2, r1
    3926:	611a      	str	r2, [r3, #16]
}
    3928:	bd38      	pop	{r3, r4, r5, pc}
		_current_cpu->slice_ticks = 0;
    392a:	2300      	movs	r3, #0
    392c:	6123      	str	r3, [r4, #16]
    392e:	e7fb      	b.n	3928 <z_time_slice+0x50>
    3930:	20000554 	.word	0x20000554
    3934:	20000524 	.word	0x20000524
    3938:	2000055c 	.word	0x2000055c
    393c:	20000558 	.word	0x20000558
    3940:	20000280 	.word	0x20000280

00003944 <z_impl_k_thread_suspend>:
{
    3944:	b570      	push	{r4, r5, r6, lr}
    3946:	4604      	mov	r4, r0
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
    3948:	3018      	adds	r0, #24
    394a:	f002 fc4a 	bl	61e2 <z_abort_timeout>
	__asm__ volatile(
    394e:	f04f 0320 	mov.w	r3, #32
    3952:	f3ef 8611 	mrs	r6, BASEPRI
    3956:	f383 8811 	msr	BASEPRI, r3
    395a:	f3bf 8f6f 	isb	sy
		if (z_is_thread_queued(thread)) {
    395e:	f994 300d 	ldrsb.w	r3, [r4, #13]
    3962:	2b00      	cmp	r3, #0
    3964:	da07      	bge.n	3976 <z_impl_k_thread_suspend+0x32>
			_priq_run_remove(&_kernel.ready_q.runq, thread);
    3966:	480f      	ldr	r0, [pc, #60]	; (39a4 <z_impl_k_thread_suspend+0x60>)
    3968:	4621      	mov	r1, r4
    396a:	f7ff fe8d 	bl	3688 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    396e:	7b63      	ldrb	r3, [r4, #13]
    3970:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    3974:	7363      	strb	r3, [r4, #13]
		update_cache(thread == _current);
    3976:	4d0c      	ldr	r5, [pc, #48]	; (39a8 <z_impl_k_thread_suspend+0x64>)
	thread->base.thread_state |= _THREAD_SUSPENDED;
    3978:	7b63      	ldrb	r3, [r4, #13]
    397a:	68a8      	ldr	r0, [r5, #8]
    397c:	f043 0310 	orr.w	r3, r3, #16
    3980:	7363      	strb	r3, [r4, #13]
    3982:	1b03      	subs	r3, r0, r4
    3984:	4258      	negs	r0, r3
    3986:	4158      	adcs	r0, r3
    3988:	f7ff fe94 	bl	36b4 <update_cache>
	__asm__ volatile(
    398c:	f386 8811 	msr	BASEPRI, r6
    3990:	f3bf 8f6f 	isb	sy
	if (thread == _current) {
    3994:	68ab      	ldr	r3, [r5, #8]
    3996:	42a3      	cmp	r3, r4
    3998:	d103      	bne.n	39a2 <z_impl_k_thread_suspend+0x5e>
}
    399a:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule_unlocked();
    399e:	f002 bac7 	b.w	5f30 <z_reschedule_unlocked>
}
    39a2:	bd70      	pop	{r4, r5, r6, pc}
    39a4:	2000054c 	.word	0x2000054c
    39a8:	20000524 	.word	0x20000524

000039ac <z_mrsh_k_thread_suspend>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_suspend(k_tid_t thread);
uintptr_t z_mrsh_k_thread_suspend(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    39ac:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    39ae:	4d0e      	ldr	r5, [pc, #56]	; (39e8 <z_mrsh_k_thread_suspend+0x3c>)
    39b0:	9a06      	ldr	r2, [sp, #24]
    39b2:	68ab      	ldr	r3, [r5, #8]
    39b4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    39b8:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    39ba:	f7fc fb8f 	bl	dc <z_object_find>
    39be:	2200      	movs	r2, #0
    39c0:	2109      	movs	r1, #9
    39c2:	f001 fa51 	bl	4e68 <z_object_validate>
    39c6:	4604      	mov	r4, r0
    39c8:	b130      	cbz	r0, 39d8 <z_mrsh_k_thread_suspend+0x2c>
    39ca:	f002 fa7a 	bl	5ec2 <arch_is_user_context>
    39ce:	68ab      	ldr	r3, [r5, #8]
    39d0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    39d4:	f002 f831 	bl	5a3a <arch_syscall_oops>
	z_impl_k_thread_suspend(thread);
    39d8:	4630      	mov	r0, r6
    39da:	f7ff ffb3 	bl	3944 <z_impl_k_thread_suspend>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_suspend(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    39de:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    39e0:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    39e2:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    39e6:	bd70      	pop	{r4, r5, r6, pc}
    39e8:	20000524 	.word	0x20000524

000039ec <z_thread_single_abort>:
	if (thread->fn_abort != NULL) {
    39ec:	6e03      	ldr	r3, [r0, #96]	; 0x60
{
    39ee:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    39f2:	4604      	mov	r4, r0
	if (thread->fn_abort != NULL) {
    39f4:	b103      	cbz	r3, 39f8 <z_thread_single_abort+0xc>
		thread->fn_abort();
    39f6:	4798      	blx	r3
    39f8:	f104 0018 	add.w	r0, r4, #24
    39fc:	f002 fbf1 	bl	61e2 <z_abort_timeout>
	__asm__ volatile(
    3a00:	f04f 0320 	mov.w	r3, #32
    3a04:	f3ef 8611 	mrs	r6, BASEPRI
    3a08:	f383 8811 	msr	BASEPRI, r3
    3a0c:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    3a10:	7b63      	ldrb	r3, [r4, #13]
    3a12:	06d8      	lsls	r0, r3, #27
    3a14:	d12d      	bne.n	3a72 <z_thread_single_abort+0x86>
		if (z_is_thread_ready(thread)) {
    3a16:	69a2      	ldr	r2, [r4, #24]
    3a18:	bb5a      	cbnz	r2, 3a72 <z_thread_single_abort+0x86>
			if (z_is_thread_queued(thread)) {
    3a1a:	0619      	lsls	r1, r3, #24
    3a1c:	d507      	bpl.n	3a2e <z_thread_single_abort+0x42>
				_priq_run_remove(&_kernel.ready_q.runq,
    3a1e:	4825      	ldr	r0, [pc, #148]	; (3ab4 <z_thread_single_abort+0xc8>)
    3a20:	4621      	mov	r1, r4
    3a22:	f7ff fe31 	bl	3688 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    3a26:	7b63      	ldrb	r3, [r4, #13]
    3a28:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    3a2c:	7363      	strb	r3, [r4, #13]
			update_cache(thread == _current);
    3a2e:	4b22      	ldr	r3, [pc, #136]	; (3ab8 <z_thread_single_abort+0xcc>)
    3a30:	6898      	ldr	r0, [r3, #8]
    3a32:	1b02      	subs	r2, r0, r4
    3a34:	4250      	negs	r0, r2
    3a36:	4150      	adcs	r0, r2
    3a38:	f7ff fe3c 	bl	36b4 <update_cache>
		thread->base.thread_state |= mask;
    3a3c:	7b63      	ldrb	r3, [r4, #13]
		z_object_uninit(thread->stack_obj);
    3a3e:	f8d4 0080 	ldr.w	r0, [r4, #128]	; 0x80
		thread->base.thread_state |= mask;
    3a42:	f043 0308 	orr.w	r3, r3, #8
    3a46:	7363      	strb	r3, [r4, #13]
		z_object_uninit(thread->stack_obj);
    3a48:	f002 fea1 	bl	678e <z_object_uninit>
		z_object_uninit(thread);
    3a4c:	4620      	mov	r0, r4
    3a4e:	f002 fe9e 	bl	678e <z_object_uninit>
		z_thread_perms_all_clear(thread);
    3a52:	4620      	mov	r0, r4
    3a54:	f001 f9fa 	bl	4e4c <z_thread_perms_all_clear>
	sys_dlist_init(&w->waitq);
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
    3a58:	f104 0830 	add.w	r8, r4, #48	; 0x30
			waiter->base.pended_on = NULL;
    3a5c:	2700      	movs	r7, #0
	return list->head == list;
    3a5e:	6b25      	ldr	r5, [r4, #48]	; 0x30
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3a60:	4545      	cmp	r5, r8
    3a62:	d000      	beq.n	3a66 <z_thread_single_abort+0x7a>
		while ((waiter = z_waitq_head(&thread->base.join_waiters)) !=
    3a64:	b995      	cbnz	r5, 3a8c <z_thread_single_abort+0xa0>
	__asm__ volatile(
    3a66:	f386 8811 	msr	BASEPRI, r6
    3a6a:	f3bf 8f6f 	isb	sy
}
    3a6e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			if (z_is_thread_pending(thread)) {
    3a72:	079b      	lsls	r3, r3, #30
    3a74:	d5e2      	bpl.n	3a3c <z_thread_single_abort+0x50>
				_priq_wait_remove(&pended_on(thread)->waitq,
    3a76:	68a0      	ldr	r0, [r4, #8]
    3a78:	4621      	mov	r1, r4
    3a7a:	f7ff fe05 	bl	3688 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    3a7e:	7b63      	ldrb	r3, [r4, #13]
    3a80:	f023 0302 	bic.w	r3, r3, #2
    3a84:	7363      	strb	r3, [r4, #13]
				thread->base.pended_on = NULL;
    3a86:	2300      	movs	r3, #0
    3a88:	60a3      	str	r3, [r4, #8]
    3a8a:	e7d7      	b.n	3a3c <z_thread_single_abort+0x50>
    3a8c:	f105 0018 	add.w	r0, r5, #24
    3a90:	f002 fba7 	bl	61e2 <z_abort_timeout>
			_priq_wait_remove(&pended_on(waiter)->waitq, waiter);
    3a94:	68a8      	ldr	r0, [r5, #8]
    3a96:	4629      	mov	r1, r5
    3a98:	f7ff fdf6 	bl	3688 <z_priq_dumb_remove>
    3a9c:	7b6b      	ldrb	r3, [r5, #13]
			waiter->base.pended_on = NULL;
    3a9e:	60af      	str	r7, [r5, #8]
    3aa0:	f023 0302 	bic.w	r3, r3, #2
    3aa4:	736b      	strb	r3, [r5, #13]
    3aa6:	f8c5 7090 	str.w	r7, [r5, #144]	; 0x90
			ready_thread(waiter);
    3aaa:	4628      	mov	r0, r5
    3aac:	f7ff fe44 	bl	3738 <ready_thread>
    3ab0:	e7d5      	b.n	3a5e <z_thread_single_abort+0x72>
    3ab2:	bf00      	nop
    3ab4:	2000054c 	.word	0x2000054c
    3ab8:	20000524 	.word	0x20000524

00003abc <unready_thread>:
{
    3abc:	b508      	push	{r3, lr}
	if (z_is_thread_queued(thread)) {
    3abe:	f990 300d 	ldrsb.w	r3, [r0, #13]
    3ac2:	2b00      	cmp	r3, #0
{
    3ac4:	4601      	mov	r1, r0
	if (z_is_thread_queued(thread)) {
    3ac6:	da06      	bge.n	3ad6 <unready_thread+0x1a>
		_priq_run_remove(&_kernel.ready_q.runq, thread);
    3ac8:	4807      	ldr	r0, [pc, #28]	; (3ae8 <unready_thread+0x2c>)
    3aca:	f7ff fddd 	bl	3688 <z_priq_dumb_remove>
	thread->base.thread_state &= ~states;
    3ace:	7b4b      	ldrb	r3, [r1, #13]
    3ad0:	f003 037f 	and.w	r3, r3, #127	; 0x7f
    3ad4:	734b      	strb	r3, [r1, #13]
	update_cache(thread == _current);
    3ad6:	4b05      	ldr	r3, [pc, #20]	; (3aec <unready_thread+0x30>)
    3ad8:	6898      	ldr	r0, [r3, #8]
    3ada:	1a43      	subs	r3, r0, r1
    3adc:	4258      	negs	r0, r3
    3ade:	4158      	adcs	r0, r3
}
    3ae0:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	update_cache(thread == _current);
    3ae4:	f7ff bde6 	b.w	36b4 <update_cache>
    3ae8:	2000054c 	.word	0x2000054c
    3aec:	20000524 	.word	0x20000524

00003af0 <z_tick_sleep.part.0>:
	z_impl_k_yield();
}
#include <syscalls/k_yield_mrsh.c>
#endif

static int32_t z_tick_sleep(int32_t ticks)
    3af0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    3af2:	4605      	mov	r5, r0
#else
	ticks += _TICK_ALIGN;
	timeout = (k_ticks_t) ticks;
#endif

	expected_wakeup_time = ticks + z_tick_get_32();
    3af4:	f002 fbc5 	bl	6282 <z_tick_get_32>
    3af8:	182c      	adds	r4, r5, r0
	__asm__ volatile(
    3afa:	f04f 0320 	mov.w	r3, #32
    3afe:	f3ef 8711 	mrs	r7, BASEPRI
    3b02:	f383 8811 	msr	BASEPRI, r3
    3b06:	f3bf 8f6f 	isb	sy
	 */
	struct k_spinlock local_lock = {};
	k_spinlock_key_t key = k_spin_lock(&local_lock);

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    3b0a:	4e0d      	ldr	r6, [pc, #52]	; (3b40 <z_tick_sleep.part.0+0x50>)
    3b0c:	4b0d      	ldr	r3, [pc, #52]	; (3b44 <z_tick_sleep.part.0+0x54>)
    3b0e:	68b0      	ldr	r0, [r6, #8]
    3b10:	6018      	str	r0, [r3, #0]
#endif
	z_remove_thread_from_ready_q(_current);
    3b12:	f002 fa79 	bl	6008 <z_remove_thread_from_ready_q>
	z_add_thread_timeout(_current, timeout);
    3b16:	68b0      	ldr	r0, [r6, #8]
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    3b18:	490b      	ldr	r1, [pc, #44]	; (3b48 <z_tick_sleep.part.0+0x58>)
    3b1a:	462a      	mov	r2, r5
    3b1c:	17eb      	asrs	r3, r5, #31
    3b1e:	3018      	adds	r0, #24
    3b20:	f000 fe06 	bl	4730 <z_add_timeout>
	z_mark_thread_as_suspended(_current);
    3b24:	68b2      	ldr	r2, [r6, #8]
	thread->base.thread_state |= _THREAD_SUSPENDED;
    3b26:	7b53      	ldrb	r3, [r2, #13]
    3b28:	f043 0310 	orr.w	r3, r3, #16
    3b2c:	7353      	strb	r3, [r2, #13]
	ret = arch_swap(key);
    3b2e:	4638      	mov	r0, r7
    3b30:	f7fd fc70 	bl	1414 <arch_swap>

	(void)z_swap(&local_lock, key);

	__ASSERT(!z_is_thread_state_set(_current, _THREAD_SUSPENDED), "");

	ticks = expected_wakeup_time - z_tick_get_32();
    3b34:	f002 fba5 	bl	6282 <z_tick_get_32>
    3b38:	1a20      	subs	r0, r4, r0
		return ticks;
	}
#endif

	return 0;
}
    3b3a:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
    3b3e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    3b40:	20000524 	.word	0x20000524
    3b44:	20000554 	.word	0x20000554
    3b48:	00005fb3 	.word	0x00005fb3

00003b4c <pend>:
{
    3b4c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    3b50:	4606      	mov	r6, r0
    3b52:	4614      	mov	r4, r2
    3b54:	461d      	mov	r5, r3
    3b56:	f04f 0320 	mov.w	r3, #32
    3b5a:	f3ef 8711 	mrs	r7, BASEPRI
    3b5e:	f383 8811 	msr	BASEPRI, r3
    3b62:	f3bf 8f6f 	isb	sy
		add_to_waitq_locked(thread, wait_q);
    3b66:	f002 fa5f 	bl	6028 <add_to_waitq_locked>
	__asm__ volatile(
    3b6a:	f387 8811 	msr	BASEPRI, r7
    3b6e:	f3bf 8f6f 	isb	sy
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    3b72:	1c6b      	adds	r3, r5, #1
    3b74:	bf08      	it	eq
    3b76:	f1b4 3fff 	cmpeq.w	r4, #4294967295	; 0xffffffff
    3b7a:	d008      	beq.n	3b8e <pend+0x42>
    3b7c:	4622      	mov	r2, r4
    3b7e:	462b      	mov	r3, r5
    3b80:	f106 0018 	add.w	r0, r6, #24
    3b84:	4903      	ldr	r1, [pc, #12]	; (3b94 <pend+0x48>)
}
    3b86:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    3b8a:	f000 bdd1 	b.w	4730 <z_add_timeout>
    3b8e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    3b92:	bf00      	nop
    3b94:	00005fb3 	.word	0x00005fb3

00003b98 <z_pend_curr>:
{
    3b98:	b510      	push	{r4, lr}
	pending_current = _current;
    3b9a:	4b07      	ldr	r3, [pc, #28]	; (3bb8 <z_pend_curr+0x20>)
    3b9c:	6898      	ldr	r0, [r3, #8]
    3b9e:	4b07      	ldr	r3, [pc, #28]	; (3bbc <z_pend_curr+0x24>)
{
    3ba0:	460c      	mov	r4, r1
	pending_current = _current;
    3ba2:	6018      	str	r0, [r3, #0]
{
    3ba4:	4611      	mov	r1, r2
	pend(_current, wait_q, timeout);
    3ba6:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    3baa:	f7ff ffcf 	bl	3b4c <pend>
    3bae:	4620      	mov	r0, r4
}
    3bb0:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
    3bb4:	f7fd bc2e 	b.w	1414 <arch_swap>
    3bb8:	20000524 	.word	0x20000524
    3bbc:	20000554 	.word	0x20000554

00003bc0 <z_set_prio>:
{
    3bc0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    3bc4:	4604      	mov	r4, r0
	__asm__ volatile(
    3bc6:	f04f 0320 	mov.w	r3, #32
    3bca:	f3ef 8811 	mrs	r8, BASEPRI
    3bce:	f383 8811 	msr	BASEPRI, r3
    3bd2:	f3bf 8f6f 	isb	sy
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    3bd6:	7b43      	ldrb	r3, [r0, #13]
    3bd8:	06db      	lsls	r3, r3, #27
    3bda:	b24e      	sxtb	r6, r1
    3bdc:	d12e      	bne.n	3c3c <z_set_prio+0x7c>
	return !sys_dnode_is_linked(&t->node);
    3bde:	6985      	ldr	r5, [r0, #24]
		if (need_sched) {
    3be0:	bb65      	cbnz	r5, 3c3c <z_set_prio+0x7c>
				_priq_run_remove(&_kernel.ready_q.runq, thread);
    3be2:	4f18      	ldr	r7, [pc, #96]	; (3c44 <z_set_prio+0x84>)
    3be4:	4621      	mov	r1, r4
    3be6:	f107 0028 	add.w	r0, r7, #40	; 0x28
    3bea:	f7ff fd4d 	bl	3688 <z_priq_dumb_remove>
	return list->head == list;
    3bee:	6abb      	ldr	r3, [r7, #40]	; 0x28
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    3bf0:	6afa      	ldr	r2, [r7, #44]	; 0x2c
				thread->base.prio = prio;
    3bf2:	73a6      	strb	r6, [r4, #14]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3bf4:	4283      	cmp	r3, r0
    3bf6:	bf18      	it	ne
    3bf8:	461d      	movne	r5, r3
    3bfa:	2d00      	cmp	r5, #0
    3bfc:	bf38      	it	cc
    3bfe:	2500      	movcc	r5, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    3c00:	b1b5      	cbz	r5, 3c30 <z_set_prio+0x70>
	if (thread_1->base.prio < thread_2->base.prio) {
    3c02:	f995 100e 	ldrsb.w	r1, [r5, #14]
    3c06:	42b1      	cmp	r1, r6
    3c08:	dc03      	bgt.n	3c12 <z_set_prio+0x52>
	return (node == list->tail) ? NULL : node->next;
    3c0a:	42aa      	cmp	r2, r5
    3c0c:	d010      	beq.n	3c30 <z_set_prio+0x70>
    3c0e:	682d      	ldr	r5, [r5, #0]
    3c10:	e7f6      	b.n	3c00 <z_set_prio+0x40>
	node->prev = successor->prev;
    3c12:	686a      	ldr	r2, [r5, #4]
	node->next = successor;
    3c14:	e9c4 5200 	strd	r5, r2, [r4]
	successor->prev->next = node;
    3c18:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    3c1a:	606c      	str	r4, [r5, #4]
			update_cache(1);
    3c1c:	2001      	movs	r0, #1
    3c1e:	f7ff fd49 	bl	36b4 <update_cache>
    3c22:	2001      	movs	r0, #1
	__asm__ volatile(
    3c24:	f388 8811 	msr	BASEPRI, r8
    3c28:	f3bf 8f6f 	isb	sy
}
    3c2c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	node->prev = list->tail;
    3c30:	e9c4 0200 	strd	r0, r2, [r4]
	list->tail->next = node;
    3c34:	6afb      	ldr	r3, [r7, #44]	; 0x2c
    3c36:	601c      	str	r4, [r3, #0]
	list->tail = node;
    3c38:	62fc      	str	r4, [r7, #44]	; 0x2c
}
    3c3a:	e7ef      	b.n	3c1c <z_set_prio+0x5c>
			thread->base.prio = prio;
    3c3c:	73a6      	strb	r6, [r4, #14]
    3c3e:	2000      	movs	r0, #0
    3c40:	e7f0      	b.n	3c24 <z_set_prio+0x64>
    3c42:	bf00      	nop
    3c44:	20000524 	.word	0x20000524

00003c48 <z_thread_priority_set>:
{
    3c48:	b508      	push	{r3, lr}
	bool need_sched = z_set_prio(thread, prio);
    3c4a:	f7ff ffb9 	bl	3bc0 <z_set_prio>
	if (need_sched && _current->base.sched_locked == 0) {
    3c4e:	b138      	cbz	r0, 3c60 <z_thread_priority_set+0x18>
    3c50:	4b04      	ldr	r3, [pc, #16]	; (3c64 <z_thread_priority_set+0x1c>)
    3c52:	689b      	ldr	r3, [r3, #8]
    3c54:	7bdb      	ldrb	r3, [r3, #15]
    3c56:	b91b      	cbnz	r3, 3c60 <z_thread_priority_set+0x18>
}
    3c58:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		z_reschedule_unlocked();
    3c5c:	f002 b968 	b.w	5f30 <z_reschedule_unlocked>
}
    3c60:	bd08      	pop	{r3, pc}
    3c62:	bf00      	nop
    3c64:	20000524 	.word	0x20000524

00003c68 <z_sched_init>:
	list->head = (sys_dnode_t *)list;
    3c68:	4b04      	ldr	r3, [pc, #16]	; (3c7c <z_sched_init+0x14>)
	k_sched_time_slice_set(CONFIG_TIMESLICE_SIZE,
    3c6a:	2100      	movs	r1, #0
    3c6c:	f103 0228 	add.w	r2, r3, #40	; 0x28
	list->tail = (sys_dnode_t *)list;
    3c70:	e9c3 220a 	strd	r2, r2, [r3, #40]	; 0x28
    3c74:	4608      	mov	r0, r1
    3c76:	f7ff bcc7 	b.w	3608 <k_sched_time_slice_set>
    3c7a:	bf00      	nop
    3c7c:	20000524 	.word	0x20000524

00003c80 <z_mrsh_k_thread_priority_get>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_thread_priority_get(k_tid_t thread);
uintptr_t z_mrsh_k_thread_priority_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3c80:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    3c82:	4c0d      	ldr	r4, [pc, #52]	; (3cb8 <z_mrsh_k_thread_priority_get+0x38>)
    3c84:	9a06      	ldr	r2, [sp, #24]
    3c86:	68a3      	ldr	r3, [r4, #8]
    3c88:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3c8c:	4605      	mov	r5, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    3c8e:	f7fc fa25 	bl	dc <z_object_find>
    3c92:	2200      	movs	r2, #0
    3c94:	2109      	movs	r1, #9
    3c96:	f001 f8e7 	bl	4e68 <z_object_validate>
    3c9a:	4603      	mov	r3, r0
    3c9c:	b130      	cbz	r0, 3cac <z_mrsh_k_thread_priority_get+0x2c>
    3c9e:	f002 f910 	bl	5ec2 <arch_is_user_context>
    3ca2:	68a3      	ldr	r3, [r4, #8]
    3ca4:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3ca8:	f001 fec7 	bl	5a3a <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_thread_priority_get(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    3cac:	68a2      	ldr	r2, [r4, #8]
	return thread->base.prio;
    3cae:	f995 000e 	ldrsb.w	r0, [r5, #14]
    3cb2:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    3cb6:	bd38      	pop	{r3, r4, r5, pc}
    3cb8:	20000524 	.word	0x20000524

00003cbc <z_mrsh_k_thread_priority_set>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_priority_set(k_tid_t thread, int prio);
uintptr_t z_mrsh_k_thread_priority_set(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3cbc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    3cbe:	4e17      	ldr	r6, [pc, #92]	; (3d1c <z_mrsh_k_thread_priority_set+0x60>)
    3cc0:	9a08      	ldr	r2, [sp, #32]
    3cc2:	68b3      	ldr	r3, [r6, #8]
    3cc4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3cc8:	460c      	mov	r4, r1
    3cca:	4607      	mov	r7, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    3ccc:	f7fc fa06 	bl	dc <z_object_find>
    3cd0:	2200      	movs	r2, #0
    3cd2:	2109      	movs	r1, #9
    3cd4:	f001 f8c8 	bl	4e68 <z_object_validate>
    3cd8:	4632      	mov	r2, r6
    3cda:	4605      	mov	r5, r0
    3cdc:	b188      	cbz	r0, 3d02 <z_mrsh_k_thread_priority_set+0x46>
    3cde:	f002 f8f0 	bl	5ec2 <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG((int8_t)prio >= thread->base.prio,
    3ce2:	68b3      	ldr	r3, [r6, #8]
    3ce4:	e015      	b.n	3d12 <z_mrsh_k_thread_priority_set+0x56>
    3ce6:	f997 200e 	ldrsb.w	r2, [r7, #14]
    3cea:	b263      	sxtb	r3, r4
    3cec:	429a      	cmp	r2, r3
    3cee:	dcf6      	bgt.n	3cde <z_mrsh_k_thread_priority_set+0x22>
	z_thread_priority_set(thread, prio);
    3cf0:	4638      	mov	r0, r7
    3cf2:	4621      	mov	r1, r4
    3cf4:	f7ff ffa8 	bl	3c48 <z_thread_priority_set>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_priority_set(*(k_tid_t*)&arg0, *(int*)&arg1)
;
	_current->syscall_frame = NULL;
    3cf8:	68b3      	ldr	r3, [r6, #8]
	return 0;
}
    3cfa:	4628      	mov	r0, r5
	_current->syscall_frame = NULL;
    3cfc:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
}
    3d00:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if (!z_is_prio_higher_or_equal(prio,
    3d02:	2c0e      	cmp	r4, #14
    3d04:	dc02      	bgt.n	3d0c <z_mrsh_k_thread_priority_set+0x50>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(_is_valid_prio(prio, NULL),
    3d06:	f114 0f10 	cmn.w	r4, #16
    3d0a:	daec      	bge.n	3ce6 <z_mrsh_k_thread_priority_set+0x2a>
    3d0c:	f002 f8d9 	bl	5ec2 <arch_is_user_context>
    3d10:	6893      	ldr	r3, [r2, #8]
    3d12:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3d16:	f001 fe90 	bl	5a3a <arch_syscall_oops>
    3d1a:	bf00      	nop
    3d1c:	20000524 	.word	0x20000524

00003d20 <z_impl_k_yield>:
{
    3d20:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (!z_is_idle_thread_object(_current)) {
    3d22:	4c24      	ldr	r4, [pc, #144]	; (3db4 <z_impl_k_yield+0x94>)
    3d24:	4b24      	ldr	r3, [pc, #144]	; (3db8 <z_impl_k_yield+0x98>)
    3d26:	68a2      	ldr	r2, [r4, #8]
    3d28:	429a      	cmp	r2, r3
    3d2a:	d030      	beq.n	3d8e <z_impl_k_yield+0x6e>
	__asm__ volatile(
    3d2c:	f04f 0320 	mov.w	r3, #32
    3d30:	f3ef 8511 	mrs	r5, BASEPRI
    3d34:	f383 8811 	msr	BASEPRI, r3
    3d38:	f3bf 8f6f 	isb	sy
				_priq_run_remove(&_kernel.ready_q.runq,
    3d3c:	68a1      	ldr	r1, [r4, #8]
    3d3e:	f104 0028 	add.w	r0, r4, #40	; 0x28
    3d42:	f7ff fca1 	bl	3688 <z_priq_dumb_remove>
	return list->head == list;
    3d46:	6aa3      	ldr	r3, [r4, #40]	; 0x28
			_priq_run_add(&_kernel.ready_q.runq, _current);
    3d48:	68a2      	ldr	r2, [r4, #8]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    3d4a:	6ae1      	ldr	r1, [r4, #44]	; 0x2c
	return sys_dlist_is_empty(list) ? NULL : list->head;
    3d4c:	4283      	cmp	r3, r0
    3d4e:	bf08      	it	eq
    3d50:	2300      	moveq	r3, #0
    3d52:	2b00      	cmp	r3, #0
    3d54:	bf38      	it	cc
    3d56:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    3d58:	b32b      	cbz	r3, 3da6 <z_impl_k_yield+0x86>
	if (thread_1->base.prio < thread_2->base.prio) {
    3d5a:	f992 700e 	ldrsb.w	r7, [r2, #14]
    3d5e:	f993 600e 	ldrsb.w	r6, [r3, #14]
    3d62:	42b7      	cmp	r7, r6
    3d64:	db03      	blt.n	3d6e <z_impl_k_yield+0x4e>
	return (node == list->tail) ? NULL : node->next;
    3d66:	428b      	cmp	r3, r1
    3d68:	d01d      	beq.n	3da6 <z_impl_k_yield+0x86>
    3d6a:	681b      	ldr	r3, [r3, #0]
    3d6c:	e7f4      	b.n	3d58 <z_impl_k_yield+0x38>
	node->prev = successor->prev;
    3d6e:	6859      	ldr	r1, [r3, #4]
	node->next = successor;
    3d70:	e9c2 3100 	strd	r3, r1, [r2]
	successor->prev->next = node;
    3d74:	600a      	str	r2, [r1, #0]
	successor->prev = node;
    3d76:	605a      	str	r2, [r3, #4]
	thread->base.thread_state |= states;
    3d78:	7b53      	ldrb	r3, [r2, #13]
    3d7a:	f063 037f 	orn	r3, r3, #127	; 0x7f
    3d7e:	7353      	strb	r3, [r2, #13]
			update_cache(1);
    3d80:	2001      	movs	r0, #1
    3d82:	f7ff fc97 	bl	36b4 <update_cache>
	__asm__ volatile(
    3d86:	f385 8811 	msr	BASEPRI, r5
    3d8a:	f3bf 8f6f 	isb	sy
	__asm__ volatile(
    3d8e:	f04f 0320 	mov.w	r3, #32
    3d92:	f3ef 8011 	mrs	r0, BASEPRI
    3d96:	f383 8811 	msr	BASEPRI, r3
    3d9a:	f3bf 8f6f 	isb	sy
}
    3d9e:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    3da2:	f7fd bb37 	b.w	1414 <arch_swap>
	node->prev = list->tail;
    3da6:	e9c2 0100 	strd	r0, r1, [r2]
	list->tail->next = node;
    3daa:	6ae3      	ldr	r3, [r4, #44]	; 0x2c
    3dac:	601a      	str	r2, [r3, #0]
	list->tail = node;
    3dae:	62e2      	str	r2, [r4, #44]	; 0x2c
}
    3db0:	e7e2      	b.n	3d78 <z_impl_k_yield+0x58>
    3db2:	bf00      	nop
    3db4:	20000524 	.word	0x20000524
    3db8:	20000280 	.word	0x20000280

00003dbc <z_mrsh_k_yield>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_yield();
uintptr_t z_mrsh_k_yield(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3dbc:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    3dbe:	4c06      	ldr	r4, [pc, #24]	; (3dd8 <z_mrsh_k_yield+0x1c>)
    3dc0:	9a04      	ldr	r2, [sp, #16]
    3dc2:	68a3      	ldr	r3, [r4, #8]
    3dc4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	z_impl_k_yield();
    3dc8:	f7ff ffaa 	bl	3d20 <z_impl_k_yield>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_yield()
;
	_current->syscall_frame = NULL;
    3dcc:	68a3      	ldr	r3, [r4, #8]
    3dce:	2000      	movs	r0, #0
    3dd0:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    3dd4:	bd10      	pop	{r4, pc}
    3dd6:	bf00      	nop
    3dd8:	20000524 	.word	0x20000524

00003ddc <z_impl_k_sleep>:

int32_t z_impl_k_sleep(k_timeout_t timeout)
{
    3ddc:	b5d0      	push	{r4, r6, r7, lr}
    3dde:	460f      	mov	r7, r1
	k_ticks_t ticks;

	__ASSERT(!arch_is_in_isr(), "");

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    3de0:	3701      	adds	r7, #1
    3de2:	bf08      	it	eq
    3de4:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    3de8:	4606      	mov	r6, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    3dea:	d106      	bne.n	3dfa <z_impl_k_sleep+0x1e>
		k_thread_suspend(_current);
    3dec:	4b0c      	ldr	r3, [pc, #48]	; (3e20 <z_impl_k_sleep+0x44>)
    3dee:	6898      	ldr	r0, [r3, #8]
	z_impl_k_thread_suspend(thread);
    3df0:	f7ff fda8 	bl	3944 <z_impl_k_thread_suspend>
    3df4:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
	ticks = timeout.ticks;
#endif

	ticks = z_tick_sleep(ticks);
	return k_ticks_to_ms_floor64(ticks);
}
    3df8:	bdd0      	pop	{r4, r6, r7, pc}
	ticks = z_tick_sleep(ticks);
    3dfa:	4604      	mov	r4, r0
    3dfc:	f002 f861 	bl	5ec2 <arch_is_user_context>
	if (ticks == 0) {
    3e00:	b94e      	cbnz	r6, 3e16 <z_impl_k_sleep+0x3a>
	z_impl_k_yield();
    3e02:	f7ff ff8d 	bl	3d20 <z_impl_k_yield>
		} else {
			return (t * to_hz + off) / from_hz;
    3e06:	f44f 707a 	mov.w	r0, #1000	; 0x3e8
    3e0a:	fb84 3400 	smull	r3, r4, r4, r0
    3e0e:	0bd8      	lsrs	r0, r3, #15
    3e10:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
	return k_ticks_to_ms_floor64(ticks);
    3e14:	e7f0      	b.n	3df8 <z_impl_k_sleep+0x1c>
    3e16:	4630      	mov	r0, r6
    3e18:	f7ff fe6a 	bl	3af0 <z_tick_sleep.part.0>
    3e1c:	4604      	mov	r4, r0
    3e1e:	e7f2      	b.n	3e06 <z_impl_k_sleep+0x2a>
    3e20:	20000524 	.word	0x20000524

00003e24 <z_mrsh_k_sleep>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_sleep(k_timeout_t timeout);
uintptr_t z_mrsh_k_sleep(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3e24:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    3e26:	4c06      	ldr	r4, [pc, #24]	; (3e40 <z_mrsh_k_sleep+0x1c>)
    3e28:	9a04      	ldr	r2, [sp, #16]
    3e2a:	68a3      	ldr	r3, [r4, #8]
    3e2c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_sleep(k_timeout_t timeout)
{
	return z_impl_k_sleep(timeout);
    3e30:	f7ff ffd4 	bl	3ddc <z_impl_k_sleep>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg0;
	parm0.split.hi = arg1;
	int32_t ret = z_vrfy_k_sleep(parm0.val)
;
	_current->syscall_frame = NULL;
    3e34:	68a3      	ldr	r3, [r4, #8]
    3e36:	2200      	movs	r2, #0
    3e38:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3e3c:	bd10      	pop	{r4, pc}
    3e3e:	bf00      	nop
    3e40:	20000524 	.word	0x20000524

00003e44 <z_impl_k_usleep>:
}
#include <syscalls/k_sleep_mrsh.c>
#endif

int32_t z_impl_k_usleep(int us)
{
    3e44:	b538      	push	{r3, r4, r5, lr}
    3e46:	4c0f      	ldr	r4, [pc, #60]	; (3e84 <z_impl_k_usleep+0x40>)
    3e48:	4a0f      	ldr	r2, [pc, #60]	; (3e88 <z_impl_k_usleep+0x44>)
    3e4a:	f44f 4100 	mov.w	r1, #32768	; 0x8000
    3e4e:	2500      	movs	r5, #0
    3e50:	fbc1 4500 	smlal	r4, r5, r1, r0
    3e54:	4620      	mov	r0, r4
    3e56:	2300      	movs	r3, #0
    3e58:	4629      	mov	r1, r5
    3e5a:	f7fc f9bf 	bl	1dc <__aeabi_uldivmod>
    3e5e:	4604      	mov	r4, r0
    3e60:	f002 f82f 	bl	5ec2 <arch_is_user_context>
	if (ticks == 0) {
    3e64:	b944      	cbnz	r4, 3e78 <z_impl_k_usleep+0x34>
    3e66:	f7ff ff5b 	bl	3d20 <z_impl_k_yield>
    3e6a:	4807      	ldr	r0, [pc, #28]	; (3e88 <z_impl_k_usleep+0x44>)
    3e6c:	fb84 3400 	smull	r3, r4, r4, r0
    3e70:	0bd8      	lsrs	r0, r3, #15
	int32_t ticks;

	ticks = k_us_to_ticks_ceil64(us);
	ticks = z_tick_sleep(ticks);
	return k_ticks_to_us_floor64(ticks);
}
    3e72:	ea40 4044 	orr.w	r0, r0, r4, lsl #17
    3e76:	bd38      	pop	{r3, r4, r5, pc}
    3e78:	4620      	mov	r0, r4
    3e7a:	f7ff fe39 	bl	3af0 <z_tick_sleep.part.0>
    3e7e:	4604      	mov	r4, r0
    3e80:	e7f3      	b.n	3e6a <z_impl_k_usleep+0x26>
    3e82:	bf00      	nop
    3e84:	000f423f 	.word	0x000f423f
    3e88:	000f4240 	.word	0x000f4240

00003e8c <z_mrsh_k_usleep>:
#include <syscalls/kernel.h>

extern int32_t z_vrfy_k_usleep(int32_t us);
uintptr_t z_mrsh_k_usleep(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3e8c:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    3e8e:	4c06      	ldr	r4, [pc, #24]	; (3ea8 <z_mrsh_k_usleep+0x1c>)
    3e90:	9a04      	ldr	r2, [sp, #16]
    3e92:	68a3      	ldr	r3, [r4, #8]
    3e94:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int32_t z_vrfy_k_usleep(int us)
{
	return z_impl_k_usleep(us);
    3e98:	f7ff ffd4 	bl	3e44 <z_impl_k_usleep>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int32_t ret = z_vrfy_k_usleep(*(int32_t*)&arg0)
;
	_current->syscall_frame = NULL;
    3e9c:	68a3      	ldr	r3, [r4, #8]
    3e9e:	2200      	movs	r2, #0
    3ea0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3ea4:	bd10      	pop	{r4, pc}
    3ea6:	bf00      	nop
    3ea8:	20000524 	.word	0x20000524

00003eac <z_mrsh_k_wakeup>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_wakeup(k_tid_t thread);
uintptr_t z_mrsh_k_wakeup(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3eac:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    3eae:	4d0e      	ldr	r5, [pc, #56]	; (3ee8 <z_mrsh_k_wakeup+0x3c>)
    3eb0:	9a06      	ldr	r2, [sp, #24]
    3eb2:	68ab      	ldr	r3, [r5, #8]
    3eb4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3eb8:	4606      	mov	r6, r0
#endif

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_wakeup(k_tid_t thread)
{
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    3eba:	f7fc f90f 	bl	dc <z_object_find>
    3ebe:	2200      	movs	r2, #0
    3ec0:	2109      	movs	r1, #9
    3ec2:	f000 ffd1 	bl	4e68 <z_object_validate>
    3ec6:	4604      	mov	r4, r0
    3ec8:	b130      	cbz	r0, 3ed8 <z_mrsh_k_wakeup+0x2c>
    3eca:	f001 fffa 	bl	5ec2 <arch_is_user_context>
    3ece:	68ab      	ldr	r3, [r5, #8]
    3ed0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    3ed4:	f001 fdb1 	bl	5a3a <arch_syscall_oops>
	z_impl_k_wakeup(thread);
    3ed8:	4630      	mov	r0, r6
    3eda:	f002 f90d 	bl	60f8 <z_impl_k_wakeup>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_wakeup(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    3ede:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    3ee0:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    3ee2:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    3ee6:	bd70      	pop	{r4, r5, r6, pc}
    3ee8:	20000524 	.word	0x20000524

00003eec <z_impl_k_current_get>:

#ifdef CONFIG_SMP
	arch_irq_unlock(k);
#endif
	return ret;
}
    3eec:	4b01      	ldr	r3, [pc, #4]	; (3ef4 <z_impl_k_current_get+0x8>)
    3eee:	6898      	ldr	r0, [r3, #8]
    3ef0:	4770      	bx	lr
    3ef2:	bf00      	nop
    3ef4:	20000524 	.word	0x20000524

00003ef8 <z_mrsh_k_current_get>:

extern k_tid_t z_vrfy_k_current_get();
uintptr_t z_mrsh_k_current_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    3ef8:	4b02      	ldr	r3, [pc, #8]	; (3f04 <z_mrsh_k_current_get+0xc>)
    3efa:	6898      	ldr	r0, [r3, #8]
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_tid_t ret = z_vrfy_k_current_get()
;
	_current->syscall_frame = NULL;
    3efc:	2300      	movs	r3, #0
    3efe:	f8c0 3084 	str.w	r3, [r0, #132]	; 0x84
	return (uintptr_t) ret;
}
    3f02:	4770      	bx	lr
    3f04:	20000524 	.word	0x20000524

00003f08 <z_impl_k_is_preempt_thread>:
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    3f08:	f3ef 8305 	mrs	r3, IPSR
#include <syscalls/k_current_get_mrsh.c>
#endif

int z_impl_k_is_preempt_thread(void)
{
	return !arch_is_in_isr() && is_preempt(_current);
    3f0c:	b93b      	cbnz	r3, 3f1e <z_impl_k_is_preempt_thread+0x16>
    3f0e:	4b05      	ldr	r3, [pc, #20]	; (3f24 <z_impl_k_is_preempt_thread+0x1c>)
    3f10:	689b      	ldr	r3, [r3, #8]
    3f12:	89d8      	ldrh	r0, [r3, #14]
    3f14:	287f      	cmp	r0, #127	; 0x7f
    3f16:	bf8c      	ite	hi
    3f18:	2000      	movhi	r0, #0
    3f1a:	2001      	movls	r0, #1
    3f1c:	4770      	bx	lr
    3f1e:	2000      	movs	r0, #0
}
    3f20:	4770      	bx	lr
    3f22:	bf00      	nop
    3f24:	20000524 	.word	0x20000524

00003f28 <z_mrsh_k_is_preempt_thread>:

extern int z_vrfy_k_is_preempt_thread();
uintptr_t z_mrsh_k_is_preempt_thread(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    3f28:	4a06      	ldr	r2, [pc, #24]	; (3f44 <z_mrsh_k_is_preempt_thread+0x1c>)
{
    3f2a:	b508      	push	{r3, lr}
	_current->syscall_frame = ssf;
    3f2c:	6893      	ldr	r3, [r2, #8]
    3f2e:	9904      	ldr	r1, [sp, #16]
    3f30:	f8c3 1084 	str.w	r1, [r3, #132]	; 0x84

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_is_preempt_thread(void)
{
	return z_impl_k_is_preempt_thread();
    3f34:	f7ff ffe8 	bl	3f08 <z_impl_k_is_preempt_thread>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_is_preempt_thread()
;
	_current->syscall_frame = NULL;
    3f38:	6893      	ldr	r3, [r2, #8]
    3f3a:	2200      	movs	r2, #0
    3f3c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3f40:	bd08      	pop	{r3, pc}
    3f42:	bf00      	nop
    3f44:	20000524 	.word	0x20000524

00003f48 <z_impl_k_thread_join>:
}

#endif /* CONFIG_SCHED_CPU_MASK */

int z_impl_k_thread_join(struct k_thread *thread, k_timeout_t timeout)
{
    3f48:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    3f4a:	4601      	mov	r1, r0
    3f4c:	4614      	mov	r4, r2
    3f4e:	461d      	mov	r5, r3
    3f50:	f04f 0320 	mov.w	r3, #32
    3f54:	f3ef 8611 	mrs	r6, BASEPRI
    3f58:	f383 8811 	msr	BASEPRI, r3
    3f5c:	f3bf 8f6f 	isb	sy
	__ASSERT(((arch_is_in_isr() == false) ||
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	key = k_spin_lock(&sched_spinlock);

	if ((thread->base.pended_on == &_current->base.join_waiters) ||
    3f60:	4f18      	ldr	r7, [pc, #96]	; (3fc4 <z_impl_k_thread_join+0x7c>)
    3f62:	688a      	ldr	r2, [r1, #8]
    3f64:	68b8      	ldr	r0, [r7, #8]
    3f66:	f100 0330 	add.w	r3, r0, #48	; 0x30
    3f6a:	429a      	cmp	r2, r3
    3f6c:	d01d      	beq.n	3faa <z_impl_k_thread_join+0x62>
    3f6e:	4288      	cmp	r0, r1
    3f70:	d01b      	beq.n	3faa <z_impl_k_thread_join+0x62>
	    (thread == _current)) {
		ret = -EDEADLK;
		goto out;
	}

	if ((thread->base.thread_state & _THREAD_DEAD) != 0) {
    3f72:	7b4b      	ldrb	r3, [r1, #13]
    3f74:	071a      	lsls	r2, r3, #28
    3f76:	d41f      	bmi.n	3fb8 <z_impl_k_thread_join+0x70>
		ret = 0;
		goto out;
	}

	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    3f78:	ea54 0305 	orrs.w	r3, r4, r5
    3f7c:	d01e      	beq.n	3fbc <z_impl_k_thread_join+0x74>
		ret = -EBUSY;
		goto out;
	}

#if defined(CONFIG_TIMESLICING) && defined(CONFIG_SWAP_NONATOMIC)
	pending_current = _current;
    3f7e:	4b12      	ldr	r3, [pc, #72]	; (3fc8 <z_impl_k_thread_join+0x80>)
#endif
	add_to_waitq_locked(_current, &thread->base.join_waiters);
    3f80:	3130      	adds	r1, #48	; 0x30
	pending_current = _current;
    3f82:	6018      	str	r0, [r3, #0]
	add_to_waitq_locked(_current, &thread->base.join_waiters);
    3f84:	f002 f850 	bl	6028 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    3f88:	1c6b      	adds	r3, r5, #1
    3f8a:	bf08      	it	eq
    3f8c:	f1b4 3fff 	cmpeq.w	r4, #4294967295	; 0xffffffff
    3f90:	d006      	beq.n	3fa0 <z_impl_k_thread_join+0x58>
	add_thread_timeout(_current, timeout);
    3f92:	68b8      	ldr	r0, [r7, #8]
	z_add_timeout(&th->base.timeout, z_thread_timeout, ticks);
    3f94:	490d      	ldr	r1, [pc, #52]	; (3fcc <z_impl_k_thread_join+0x84>)
    3f96:	4622      	mov	r2, r4
    3f98:	462b      	mov	r3, r5
    3f9a:	3018      	adds	r0, #24
    3f9c:	f000 fbc8 	bl	4730 <z_add_timeout>
    3fa0:	4630      	mov	r0, r6

	return z_swap(&sched_spinlock, key);
out:
	k_spin_unlock(&sched_spinlock, key);
	return ret;
}
    3fa2:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    3fa6:	f7fd ba35 	b.w	1414 <arch_swap>
		ret = -EDEADLK;
    3faa:	f06f 0020 	mvn.w	r0, #32
	__asm__ volatile(
    3fae:	f386 8811 	msr	BASEPRI, r6
    3fb2:	f3bf 8f6f 	isb	sy
}
    3fb6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		ret = 0;
    3fb8:	2000      	movs	r0, #0
    3fba:	e7f8      	b.n	3fae <z_impl_k_thread_join+0x66>
		ret = -EBUSY;
    3fbc:	f06f 000f 	mvn.w	r0, #15
    3fc0:	e7f5      	b.n	3fae <z_impl_k_thread_join+0x66>
    3fc2:	bf00      	nop
    3fc4:	20000524 	.word	0x20000524
    3fc8:	20000554 	.word	0x20000554
    3fcc:	00005fb3 	.word	0x00005fb3

00003fd0 <z_mrsh_k_thread_join>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_thread_join(struct k_thread * thread, k_timeout_t timeout);
uintptr_t z_mrsh_k_thread_join(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    3fd0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    3fd2:	4c0b      	ldr	r4, [pc, #44]	; (4000 <z_mrsh_k_thread_join+0x30>)
    3fd4:	68a3      	ldr	r3, [r4, #8]
{
    3fd6:	4616      	mov	r6, r2
	_current->syscall_frame = ssf;
    3fd8:	9a08      	ldr	r2, [sp, #32]
    3fda:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    3fde:	4605      	mov	r5, r0
    3fe0:	460f      	mov	r7, r1
}

static inline int z_vrfy_k_thread_join(struct k_thread *thread,
				       k_timeout_t timeout)
{
	if (thread_obj_validate(thread)) {
    3fe2:	f001 ff78 	bl	5ed6 <thread_obj_validate>
    3fe6:	b948      	cbnz	r0, 3ffc <z_mrsh_k_thread_join+0x2c>
		return 0;
	}

	return z_impl_k_thread_join(thread, timeout);
    3fe8:	463a      	mov	r2, r7
    3fea:	4633      	mov	r3, r6
    3fec:	4628      	mov	r0, r5
    3fee:	f7ff ffab 	bl	3f48 <z_impl_k_thread_join>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_thread_join(*(struct k_thread **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    3ff2:	68a3      	ldr	r3, [r4, #8]
    3ff4:	2200      	movs	r2, #0
    3ff6:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    3ffa:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		return 0;
    3ffc:	2000      	movs	r0, #0
    3ffe:	e7f8      	b.n	3ff2 <z_mrsh_k_thread_join+0x22>
    4000:	20000524 	.word	0x20000524

00004004 <z_mrsh_k_thread_abort>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_abort(k_tid_t thread);
uintptr_t z_mrsh_k_thread_abort(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4004:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4006:	4d0e      	ldr	r5, [pc, #56]	; (4040 <z_mrsh_k_thread_abort+0x3c>)
    4008:	9a06      	ldr	r2, [sp, #24]
    400a:	68ab      	ldr	r3, [r5, #8]
    400c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4010:	4604      	mov	r4, r0
}
#include <syscalls/k_thread_join_mrsh.c>

static inline void z_vrfy_k_thread_abort(k_tid_t thread)
{
	if (thread_obj_validate(thread)) {
    4012:	f001 ff60 	bl	5ed6 <thread_obj_validate>
    4016:	462e      	mov	r6, r5
    4018:	b960      	cbnz	r0, 4034 <z_mrsh_k_thread_abort+0x30>
		return;
	}

	Z_OOPS(Z_SYSCALL_VERIFY_MSG(!(thread->base.user_options & K_ESSENTIAL),
    401a:	7b23      	ldrb	r3, [r4, #12]
    401c:	07db      	lsls	r3, r3, #31
    401e:	d506      	bpl.n	402e <z_mrsh_k_thread_abort+0x2a>
    4020:	f001 ff4f 	bl	5ec2 <arch_is_user_context>
    4024:	68ab      	ldr	r3, [r5, #8]
    4026:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    402a:	f001 fd06 	bl	5a3a <arch_syscall_oops>
				    "aborting essential thread %p", thread));

	z_impl_k_thread_abort((struct k_thread *)thread);
    402e:	4620      	mov	r0, r4
    4030:	f7fd fdbe 	bl	1bb0 <z_impl_k_thread_abort>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_abort(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    4034:	68b3      	ldr	r3, [r6, #8]
    4036:	2000      	movs	r0, #0
    4038:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    403c:	bd70      	pop	{r4, r5, r6, pc}
    403e:	bf00      	nop
    4040:	20000524 	.word	0x20000524

00004044 <z_vrfy_k_sem_init>:
}

#ifdef CONFIG_USERSPACE
int z_vrfy_k_sem_init(struct k_sem *sem, unsigned int initial_count,
		      unsigned int limit)
{
    4044:	b570      	push	{r4, r5, r6, lr}
    4046:	460d      	mov	r5, r1
    4048:	4616      	mov	r6, r2
    404a:	4604      	mov	r4, r0
	Z_OOPS(Z_SYSCALL_OBJ_INIT(sem, K_OBJ_SEM));
    404c:	f7fc f846 	bl	dc <z_object_find>
    4050:	2201      	movs	r2, #1
    4052:	2107      	movs	r1, #7
    4054:	f000 ff08 	bl	4e68 <z_object_validate>
    4058:	b138      	cbz	r0, 406a <z_vrfy_k_sem_init+0x26>
    405a:	f002 f869 	bl	6130 <arch_is_user_context>
    405e:	4b06      	ldr	r3, [pc, #24]	; (4078 <z_vrfy_k_sem_init+0x34>)
    4060:	689b      	ldr	r3, [r3, #8]
    4062:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4066:	f001 fce8 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_sem_init(sem, initial_count, limit);
    406a:	4632      	mov	r2, r6
    406c:	4629      	mov	r1, r5
    406e:	4620      	mov	r0, r4
}
    4070:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	return z_impl_k_sem_init(sem, initial_count, limit);
    4074:	f002 b866 	b.w	6144 <z_impl_k_sem_init>
    4078:	20000524 	.word	0x20000524

0000407c <z_mrsh_k_sem_init>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_sem_init(struct k_sem * sem, unsigned int initial_count, unsigned int limit);
uintptr_t z_mrsh_k_sem_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    407c:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    407e:	4c06      	ldr	r4, [pc, #24]	; (4098 <z_mrsh_k_sem_init+0x1c>)
    4080:	9d06      	ldr	r5, [sp, #24]
    4082:	68a3      	ldr	r3, [r4, #8]
    4084:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_sem_init(*(struct k_sem **)&arg0, *(unsigned int*)&arg1, *(unsigned int*)&arg2)
    4088:	f7ff ffdc 	bl	4044 <z_vrfy_k_sem_init>
;
	_current->syscall_frame = NULL;
    408c:	68a3      	ldr	r3, [r4, #8]
    408e:	2200      	movs	r2, #0
    4090:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4094:	bd38      	pop	{r3, r4, r5, pc}
    4096:	bf00      	nop
    4098:	20000524 	.word	0x20000524

0000409c <z_impl_k_sem_give>:
	ARG_UNUSED(sem);
#endif
}

void z_impl_k_sem_give(struct k_sem *sem)
{
    409c:	b538      	push	{r3, r4, r5, lr}
    409e:	4604      	mov	r4, r0
	__asm__ volatile(
    40a0:	f04f 0320 	mov.w	r3, #32
    40a4:	f3ef 8511 	mrs	r5, BASEPRI
    40a8:	f383 8811 	msr	BASEPRI, r3
    40ac:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&lock);
	struct k_thread *thread = z_unpend_first_thread(&sem->wait_q);
    40b0:	f001 ffe5 	bl	607e <z_unpend_first_thread>

	sys_trace_void(SYS_TRACE_ID_SEMA_GIVE);

	if (thread != NULL) {
    40b4:	b150      	cbz	r0, 40cc <z_impl_k_sem_give+0x30>
    40b6:	2200      	movs	r2, #0
    40b8:	f8c0 2090 	str.w	r2, [r0, #144]	; 0x90
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
    40bc:	f001 ff69 	bl	5f92 <z_ready_thread>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
		handle_poll_events(sem);
	}

	sys_trace_end_call(SYS_TRACE_ID_SEMA_GIVE);
	z_reschedule(&lock, key);
    40c0:	4629      	mov	r1, r5
    40c2:	4808      	ldr	r0, [pc, #32]	; (40e4 <z_impl_k_sem_give+0x48>)
}
    40c4:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_reschedule(&lock, key);
    40c8:	f001 bf1b 	b.w	5f02 <z_reschedule>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
    40cc:	e9d4 3202 	ldrd	r3, r2, [r4, #8]
    40d0:	429a      	cmp	r2, r3
    40d2:	bf18      	it	ne
    40d4:	3301      	addne	r3, #1
    40d6:	60a3      	str	r3, [r4, #8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
    40d8:	2102      	movs	r1, #2
    40da:	f104 0010 	add.w	r0, r4, #16
    40de:	f002 fa18 	bl	6512 <z_handle_obj_poll_events>
}
    40e2:	e7ed      	b.n	40c0 <z_impl_k_sem_give+0x24>
    40e4:	200012b4 	.word	0x200012b4

000040e8 <z_mrsh_k_sem_give>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_sem_give(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_give(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    40e8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    40ea:	4d0e      	ldr	r5, [pc, #56]	; (4124 <z_mrsh_k_sem_give+0x3c>)
    40ec:	9a06      	ldr	r2, [sp, #24]
    40ee:	68ab      	ldr	r3, [r5, #8]
    40f0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    40f4:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_sem_give(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    40f6:	f7fb fff1 	bl	dc <z_object_find>
    40fa:	2200      	movs	r2, #0
    40fc:	2107      	movs	r1, #7
    40fe:	f000 feb3 	bl	4e68 <z_object_validate>
    4102:	4604      	mov	r4, r0
    4104:	b130      	cbz	r0, 4114 <z_mrsh_k_sem_give+0x2c>
    4106:	f002 f813 	bl	6130 <arch_is_user_context>
    410a:	68ab      	ldr	r3, [r5, #8]
    410c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4110:	f001 fc93 	bl	5a3a <arch_syscall_oops>
	z_impl_k_sem_give(sem);
    4114:	4630      	mov	r0, r6
    4116:	f7ff ffc1 	bl	409c <z_impl_k_sem_give>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_sem_give(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    411a:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    411c:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    411e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4122:	bd70      	pop	{r4, r5, r6, pc}
    4124:	20000524 	.word	0x20000524

00004128 <z_impl_k_sem_take>:
}
#include <syscalls/k_sem_give_mrsh.c>
#endif

int z_impl_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
    4128:	b537      	push	{r0, r1, r2, r4, r5, lr}
    412a:	4614      	mov	r4, r2
    412c:	461d      	mov	r5, r3
    412e:	f04f 0320 	mov.w	r3, #32
    4132:	f3ef 8111 	mrs	r1, BASEPRI
    4136:	f383 8811 	msr	BASEPRI, r3
    413a:	f3bf 8f6f 	isb	sy
		  K_TIMEOUT_EQ(timeout, K_NO_WAIT)), "");

	sys_trace_void(SYS_TRACE_ID_SEMA_TAKE);
	k_spinlock_key_t key = k_spin_lock(&lock);

	if (likely(sem->count > 0U)) {
    413e:	6883      	ldr	r3, [r0, #8]
    4140:	b143      	cbz	r3, 4154 <z_impl_k_sem_take+0x2c>
		sem->count--;
    4142:	3b01      	subs	r3, #1
    4144:	6083      	str	r3, [r0, #8]
	__asm__ volatile(
    4146:	f381 8811 	msr	BASEPRI, r1
    414a:	f3bf 8f6f 	isb	sy
		k_spin_unlock(&lock, key);
		ret = 0;
    414e:	2000      	movs	r0, #0
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);

out:
	sys_trace_end_call(SYS_TRACE_ID_SEMA_TAKE);
	return ret;
}
    4150:	b003      	add	sp, #12
    4152:	bd30      	pop	{r4, r5, pc}
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    4154:	ea54 0305 	orrs.w	r3, r4, r5
    4158:	d106      	bne.n	4168 <z_impl_k_sem_take+0x40>
    415a:	f381 8811 	msr	BASEPRI, r1
    415e:	f3bf 8f6f 	isb	sy
		ret = -EBUSY;
    4162:	f06f 000f 	mvn.w	r0, #15
    4166:	e7f3      	b.n	4150 <z_impl_k_sem_take+0x28>
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);
    4168:	4602      	mov	r2, r0
    416a:	e9cd 4500 	strd	r4, r5, [sp]
    416e:	4802      	ldr	r0, [pc, #8]	; (4178 <z_impl_k_sem_take+0x50>)
    4170:	f7ff fd12 	bl	3b98 <z_pend_curr>
	return ret;
    4174:	e7ec      	b.n	4150 <z_impl_k_sem_take+0x28>
    4176:	bf00      	nop
    4178:	200012b4 	.word	0x200012b4

0000417c <z_mrsh_k_sem_take>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_sem_take(struct k_sem * sem, k_timeout_t timeout);
uintptr_t z_mrsh_k_sem_take(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    417c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    4180:	4d10      	ldr	r5, [pc, #64]	; (41c4 <z_mrsh_k_sem_take+0x48>)
    4182:	68ab      	ldr	r3, [r5, #8]
{
    4184:	4617      	mov	r7, r2
	_current->syscall_frame = ssf;
    4186:	9a08      	ldr	r2, [sp, #32]
    4188:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    418c:	4688      	mov	r8, r1
    418e:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    4190:	f7fb ffa4 	bl	dc <z_object_find>
    4194:	2200      	movs	r2, #0
    4196:	2107      	movs	r1, #7
    4198:	f000 fe66 	bl	4e68 <z_object_validate>
    419c:	4604      	mov	r4, r0
    419e:	b130      	cbz	r0, 41ae <z_mrsh_k_sem_take+0x32>
    41a0:	f001 ffc6 	bl	6130 <arch_is_user_context>
    41a4:	68ab      	ldr	r3, [r5, #8]
    41a6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    41aa:	f001 fc46 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_sem_take((struct k_sem *)sem, timeout);
    41ae:	463b      	mov	r3, r7
    41b0:	4642      	mov	r2, r8
    41b2:	4630      	mov	r0, r6
    41b4:	f7ff ffb8 	bl	4128 <z_impl_k_sem_take>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg1;
	parm0.split.hi = arg2;
	int ret = z_vrfy_k_sem_take(*(struct k_sem **)&arg0, parm0.val)
;
	_current->syscall_frame = NULL;
    41b8:	68ab      	ldr	r3, [r5, #8]
    41ba:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    41be:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    41c2:	bf00      	nop
    41c4:	20000524 	.word	0x20000524

000041c8 <z_mrsh_k_sem_reset>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_sem_reset(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_reset(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    41c8:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    41ca:	4c0c      	ldr	r4, [pc, #48]	; (41fc <z_mrsh_k_sem_reset+0x34>)
    41cc:	9a06      	ldr	r2, [sp, #24]
    41ce:	68a3      	ldr	r3, [r4, #8]
    41d0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    41d4:	4605      	mov	r5, r0
}
#include <syscalls/k_sem_take_mrsh.c>

static inline void z_vrfy_k_sem_reset(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    41d6:	f7fb ff81 	bl	dc <z_object_find>
    41da:	2200      	movs	r2, #0
    41dc:	2107      	movs	r1, #7
    41de:	f000 fe43 	bl	4e68 <z_object_validate>
    41e2:	b130      	cbz	r0, 41f2 <z_mrsh_k_sem_reset+0x2a>
    41e4:	f001 ffa4 	bl	6130 <arch_is_user_context>
    41e8:	68a3      	ldr	r3, [r4, #8]
    41ea:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    41ee:	f001 fc24 	bl	5a3a <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_sem_reset(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    41f2:	68a2      	ldr	r2, [r4, #8]
	sem->count = 0U;
    41f4:	60a8      	str	r0, [r5, #8]
    41f6:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    41fa:	bd38      	pop	{r3, r4, r5, pc}
    41fc:	20000524 	.word	0x20000524

00004200 <z_mrsh_k_sem_count_get>:
#include <syscalls/kernel.h>

extern unsigned int z_vrfy_k_sem_count_get(struct k_sem * sem);
uintptr_t z_mrsh_k_sem_count_get(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4200:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    4202:	4c0d      	ldr	r4, [pc, #52]	; (4238 <z_mrsh_k_sem_count_get+0x38>)
    4204:	9a06      	ldr	r2, [sp, #24]
    4206:	68a3      	ldr	r3, [r4, #8]
    4208:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    420c:	4605      	mov	r5, r0
}
#include <syscalls/k_sem_reset_mrsh.c>

static inline unsigned int z_vrfy_k_sem_count_get(struct k_sem *sem)
{
	Z_OOPS(Z_SYSCALL_OBJ(sem, K_OBJ_SEM));
    420e:	f7fb ff65 	bl	dc <z_object_find>
    4212:	2200      	movs	r2, #0
    4214:	2107      	movs	r1, #7
    4216:	f000 fe27 	bl	4e68 <z_object_validate>
    421a:	4603      	mov	r3, r0
    421c:	b130      	cbz	r0, 422c <z_mrsh_k_sem_count_get+0x2c>
    421e:	f001 ff87 	bl	6130 <arch_is_user_context>
    4222:	68a3      	ldr	r3, [r4, #8]
    4224:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4228:	f001 fc07 	bl	5a3a <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	unsigned int ret = z_vrfy_k_sem_count_get(*(struct k_sem **)&arg0)
;
	_current->syscall_frame = NULL;
    422c:	68a2      	ldr	r2, [r4, #8]
	return z_impl_k_sem_count_get(sem);
    422e:	68a8      	ldr	r0, [r5, #8]
    4230:	f8c2 3084 	str.w	r3, [r2, #132]	; 0x84
	return (uintptr_t) ret;
}
    4234:	bd38      	pop	{r3, r4, r5, pc}
    4236:	bf00      	nop
    4238:	20000524 	.word	0x20000524

0000423c <schedule_new_thread>:
#endif
#endif

#ifdef CONFIG_MULTITHREADING
static void schedule_new_thread(struct k_thread *thread, k_timeout_t delay)
{
    423c:	b4d0      	push	{r4, r6, r7}
    423e:	4616      	mov	r6, r2
    4240:	461f      	mov	r7, r3
#ifdef CONFIG_SYS_CLOCK_EXISTS
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
    4242:	ea56 0107 	orrs.w	r1, r6, r7
    4246:	d102      	bne.n	424e <schedule_new_thread+0x12>
	}
#else
	ARG_UNUSED(delay);
	k_thread_start(thread);
#endif
}
    4248:	bcd0      	pop	{r4, r6, r7}
	z_sched_start(thread);
    424a:	f7ff baa9 	b.w	37a0 <z_sched_start>
}
    424e:	bcd0      	pop	{r4, r6, r7}
    4250:	4901      	ldr	r1, [pc, #4]	; (4258 <schedule_new_thread+0x1c>)
    4252:	3018      	adds	r0, #24
    4254:	f000 ba6c 	b.w	4730 <z_add_timeout>
    4258:	00005fb3 	.word	0x00005fb3

0000425c <z_mrsh_k_busy_wait>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_busy_wait(uint32_t usec_to_wait);
uintptr_t z_mrsh_k_busy_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    425c:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    425e:	4c06      	ldr	r4, [pc, #24]	; (4278 <z_mrsh_k_busy_wait+0x1c>)
    4260:	9a04      	ldr	r2, [sp, #16]
    4262:	68a3      	ldr	r3, [r4, #8]
    4264:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	arch_busy_wait(usec_to_wait);
    4268:	f7fd fee6 	bl	2038 <arch_busy_wait>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_busy_wait(*(uint32_t*)&arg0)
;
	_current->syscall_frame = NULL;
    426c:	68a3      	ldr	r3, [r4, #8]
    426e:	2000      	movs	r0, #0
    4270:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4274:	bd10      	pop	{r4, pc}
    4276:	bf00      	nop
    4278:	20000524 	.word	0x20000524

0000427c <z_mrsh_k_thread_name_set>:

extern int z_vrfy_k_thread_name_set(k_tid_t thread_id, const char * value);
uintptr_t z_mrsh_k_thread_name_set(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    427c:	4b03      	ldr	r3, [pc, #12]	; (428c <z_mrsh_k_thread_name_set+0x10>)
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_thread_name_set(*(k_tid_t*)&arg0, *(const char **)&arg1)
;
	_current->syscall_frame = NULL;
    427e:	689b      	ldr	r3, [r3, #8]
    4280:	2200      	movs	r2, #0
    4282:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4286:	f06f 0046 	mvn.w	r0, #70	; 0x46
    428a:	4770      	bx	lr
    428c:	20000524 	.word	0x20000524

00004290 <z_mrsh_k_thread_name_copy>:
    4290:	4b03      	ldr	r3, [pc, #12]	; (42a0 <z_mrsh_k_thread_name_copy+0x10>)
    4292:	689b      	ldr	r3, [r3, #8]
    4294:	2200      	movs	r2, #0
    4296:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
    429a:	f06f 0046 	mvn.w	r0, #70	; 0x46
    429e:	4770      	bx	lr
    42a0:	20000524 	.word	0x20000524

000042a4 <z_mrsh_k_thread_start>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_thread_start(k_tid_t thread);
uintptr_t z_mrsh_k_thread_start(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    42a4:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    42a6:	4d0e      	ldr	r5, [pc, #56]	; (42e0 <z_mrsh_k_thread_start+0x3c>)
    42a8:	9a06      	ldr	r2, [sp, #24]
    42aa:	68ab      	ldr	r3, [r5, #8]
    42ac:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    42b0:	4606      	mov	r6, r0
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    42b2:	f7fb ff13 	bl	dc <z_object_find>
    42b6:	2200      	movs	r2, #0
    42b8:	2109      	movs	r1, #9
    42ba:	f000 fdd5 	bl	4e68 <z_object_validate>
    42be:	4604      	mov	r4, r0
    42c0:	b130      	cbz	r0, 42d0 <z_mrsh_k_thread_start+0x2c>
    42c2:	f001 ff52 	bl	616a <arch_is_user_context>
    42c6:	68ab      	ldr	r3, [r5, #8]
    42c8:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    42cc:	f001 fbb5 	bl	5a3a <arch_syscall_oops>
	z_sched_start(thread);
    42d0:	4630      	mov	r0, r6
    42d2:	f7ff fa65 	bl	37a0 <z_sched_start>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_thread_start(*(k_tid_t*)&arg0)
;
	_current->syscall_frame = NULL;
    42d6:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    42d8:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    42da:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    42de:	bd70      	pop	{r4, r5, r6, pc}
    42e0:	20000524 	.word	0x20000524

000042e4 <z_setup_new_thread>:
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
    42e4:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    42e8:	b085      	sub	sp, #20
    42ea:	4604      	mov	r4, r0
    42ec:	460e      	mov	r6, r1
    42ee:	4617      	mov	r7, r2
    42f0:	4699      	mov	r9, r3
		 "user thread %p with kernel-only stack %p",
		 new_thread, stack);
	z_object_init(new_thread);
	z_object_init(stack);
	new_thread->stack_obj = stack;
	new_thread->mem_domain_info.mem_domain = NULL;
    42f2:	2500      	movs	r5, #0
{
    42f4:	f8dd 8040 	ldr.w	r8, [sp, #64]	; 0x40
	z_object_init(new_thread);
    42f8:	f002 fa40 	bl	677c <z_object_init>
	z_object_init(stack);
    42fc:	4630      	mov	r0, r6
    42fe:	f002 fa3d 	bl	677c <z_object_init>
	new_thread->stack_obj = stack;
    4302:	f8c4 6080 	str.w	r6, [r4, #128]	; 0x80
	new_thread->mem_domain_info.mem_domain = NULL;
    4306:	67e5      	str	r5, [r4, #124]	; 0x7c
	new_thread->syscall_frame = NULL;
    4308:	f8c4 5084 	str.w	r5, [r4, #132]	; 0x84
	z_impl_k_object_access_grant(object, thread);
    430c:	4620      	mov	r0, r4
    430e:	4621      	mov	r1, r4
    4310:	f002 fa29 	bl	6766 <z_impl_k_object_access_grant>
	sys_dlist_init(&w->waitq);
    4314:	f104 0330 	add.w	r3, r4, #48	; 0x30
	list->tail = (sys_dnode_t *)list;
    4318:	e9c4 330c 	strd	r3, r3, [r4, #48]	; 0x30
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */

	thread_base->user_options = (uint8_t)options;
	thread_base->thread_state = (uint8_t)initial_state;
    431c:	2304      	movs	r3, #4
    431e:	7363      	strb	r3, [r4, #13]

	thread_base->prio = priority;
    4320:	9b0f      	ldr	r3, [sp, #60]	; 0x3c
	thread_base->user_options = (uint8_t)options;
    4322:	f884 800c 	strb.w	r8, [r4, #12]
	node->prev = NULL;
    4326:	e9c4 5506 	strd	r5, r5, [r4, #24]
	thread_base->prio = priority;
    432a:	73a3      	strb	r3, [r4, #14]

	thread_base->sched_locked = 0U;
    432c:	73e5      	strb	r5, [r4, #15]
	if (z_stack_is_user_capable(stack)) {
    432e:	4630      	mov	r0, r6
    4330:	f001 ff30 	bl	6194 <z_stack_is_user_capable>
    4334:	b360      	cbz	r0, 4390 <z_setup_new_thread+0xac>
		stack_obj_size = Z_THREAD_STACK_SIZE_ADJUST(stack_size);
    4336:	fab7 f387 	clz	r3, r7
    433a:	f04f 4500 	mov.w	r5, #2147483648	; 0x80000000
    433e:	40dd      	lsrs	r5, r3
    4340:	42af      	cmp	r7, r5
    4342:	d903      	bls.n	434c <z_setup_new_thread+0x68>
    4344:	f1c3 0320 	rsb	r3, r3, #32
    4348:	2501      	movs	r5, #1
    434a:	409d      	lsls	r5, r3
	stack_ptr = (char *)stack + stack_obj_size;
    434c:	1977      	adds	r7, r6, r5
    434e:	f001 ff0c 	bl	616a <arch_is_user_context>
		(struct _thread_userspace_local_data *)(stack_ptr - delta);
    4352:	1f3b      	subs	r3, r7, #4
	new_thread->stack_info.start = (uintptr_t)stack_buf_start;
    4354:	e9c4 3619 	strd	r3, r6, [r4, #100]	; 0x64
	new_thread->stack_info.delta = delta;
    4358:	2308      	movs	r3, #8
    435a:	6723      	str	r3, [r4, #112]	; 0x70
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    435c:	9b0e      	ldr	r3, [sp, #56]	; 0x38
    435e:	9302      	str	r3, [sp, #8]
    4360:	9b0d      	ldr	r3, [sp, #52]	; 0x34
    4362:	9301      	str	r3, [sp, #4]
	stack_ptr -= delta;
    4364:	3f08      	subs	r7, #8
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    4366:	9b0c      	ldr	r3, [sp, #48]	; 0x30
	new_thread->stack_info.size = stack_buf_size;
    4368:	66e5      	str	r5, [r4, #108]	; 0x6c
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    436a:	9300      	str	r3, [sp, #0]
	if (!_current) {
    436c:	4d12      	ldr	r5, [pc, #72]	; (43b8 <z_setup_new_thread+0xd4>)
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
    436e:	464b      	mov	r3, r9
    4370:	463a      	mov	r2, r7
    4372:	4631      	mov	r1, r6
    4374:	4620      	mov	r0, r4
    4376:	f7fd f91d 	bl	15b4 <arch_new_thread>
	new_thread->init_data = NULL;
    437a:	2300      	movs	r3, #0
	new_thread->fn_abort = NULL;
    437c:	e9c4 3317 	strd	r3, r3, [r4, #92]	; 0x5c
	if (!_current) {
    4380:	68ab      	ldr	r3, [r5, #8]
    4382:	b94b      	cbnz	r3, 4398 <z_setup_new_thread+0xb4>
}
    4384:	4638      	mov	r0, r7
	new_thread->resource_pool = _current->resource_pool;
    4386:	f8c4 3088 	str.w	r3, [r4, #136]	; 0x88
}
    438a:	b005      	add	sp, #20
    438c:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
		stack_obj_size = Z_KERNEL_STACK_SIZE_ADJUST(stack_size);
    4390:	1dfd      	adds	r5, r7, #7
    4392:	f025 0507 	bic.w	r5, r5, #7
		stack_buf_size = stack_obj_size - K_KERNEL_STACK_RESERVED;
    4396:	e7d9      	b.n	434c <z_setup_new_thread+0x68>
	if (_current->mem_domain_info.mem_domain != NULL) {
    4398:	6fd8      	ldr	r0, [r3, #124]	; 0x7c
    439a:	b110      	cbz	r0, 43a2 <z_setup_new_thread+0xbe>
		k_mem_domain_add_thread(_current->mem_domain_info.mem_domain,
    439c:	4621      	mov	r1, r4
    439e:	f002 f936 	bl	660e <k_mem_domain_add_thread>
	if ((options & K_INHERIT_PERMS) != 0U) {
    43a2:	f018 0f08 	tst.w	r8, #8
    43a6:	d003      	beq.n	43b0 <z_setup_new_thread+0xcc>
		z_thread_perms_inherit(_current, new_thread);
    43a8:	68a8      	ldr	r0, [r5, #8]
    43aa:	4621      	mov	r1, r4
    43ac:	f000 fd34 	bl	4e18 <z_thread_perms_inherit>
	new_thread->resource_pool = _current->resource_pool;
    43b0:	68ab      	ldr	r3, [r5, #8]
    43b2:	f8d3 3088 	ldr.w	r3, [r3, #136]	; 0x88
    43b6:	e7e5      	b.n	4384 <z_setup_new_thread+0xa0>
    43b8:	20000524 	.word	0x20000524

000043bc <z_vrfy_k_thread_create>:
{
    43bc:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    43c0:	b087      	sub	sp, #28
    43c2:	460e      	mov	r6, r1
    43c4:	4617      	mov	r7, r2
    43c6:	4699      	mov	r9, r3
    43c8:	e9dd a813 	ldrd	sl, r8, [sp, #76]	; 0x4c
    43cc:	4605      	mov	r5, r0
	Z_OOPS(Z_SYSCALL_OBJ_NEVER_INIT(new_thread, K_OBJ_THREAD));
    43ce:	f7fb fe85 	bl	dc <z_object_find>
    43d2:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    43d6:	2109      	movs	r1, #9
    43d8:	f000 fd46 	bl	4e68 <z_object_validate>
    43dc:	4c23      	ldr	r4, [pc, #140]	; (446c <z_vrfy_k_thread_create+0xb0>)
    43de:	b130      	cbz	r0, 43ee <z_vrfy_k_thread_create+0x32>
    43e0:	f001 fec3 	bl	616a <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_VERIFY(z_is_prio_lower_or_equal(prio,
    43e4:	68a3      	ldr	r3, [r4, #8]
    43e6:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    43ea:	f001 fb26 	bl	5a3a <arch_syscall_oops>
	stack_object = z_object_find(stack);
    43ee:	4630      	mov	r0, r6
    43f0:	f7fb fe74 	bl	dc <z_object_find>
    43f4:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    43f8:	210b      	movs	r1, #11
    43fa:	4683      	mov	fp, r0
    43fc:	f000 fd34 	bl	4e68 <z_object_validate>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(z_obj_validation_check(stack_object, stack,
    4400:	2800      	cmp	r0, #0
    4402:	d1ed      	bne.n	43e0 <z_vrfy_k_thread_create+0x24>
	stack_obj_size = stack_object->data.stack_data->size;
    4404:	f8db 3008 	ldr.w	r3, [fp, #8]
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(total_size <= stack_obj_size,
    4408:	681b      	ldr	r3, [r3, #0]
    440a:	42bb      	cmp	r3, r7
    440c:	d3e8      	bcc.n	43e0 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(options & K_USER));
    440e:	f018 0f04 	tst.w	r8, #4
    4412:	d0e5      	beq.n	43e0 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(!(options & K_ESSENTIAL)));
    4414:	f018 0301 	ands.w	r3, r8, #1
    4418:	d1e2      	bne.n	43e0 <z_vrfy_k_thread_create+0x24>
	if (!z_is_prio_higher_or_equal(prio,
    441a:	f10a 0210 	add.w	r2, sl, #16
    441e:	2a1e      	cmp	r2, #30
    4420:	d8de      	bhi.n	43e0 <z_vrfy_k_thread_create+0x24>
	Z_OOPS(Z_SYSCALL_VERIFY(z_is_prio_lower_or_equal(prio,
    4422:	68a2      	ldr	r2, [r4, #8]
    4424:	f992 200e 	ldrsb.w	r2, [r2, #14]
    4428:	4592      	cmp	sl, r2
    442a:	dbd9      	blt.n	43e0 <z_vrfy_k_thread_create+0x24>
	z_setup_new_thread(new_thread, stack, stack_size,
    442c:	e9cd 8304 	strd	r8, r3, [sp, #16]
    4430:	9b12      	ldr	r3, [sp, #72]	; 0x48
    4432:	9302      	str	r3, [sp, #8]
    4434:	9b11      	ldr	r3, [sp, #68]	; 0x44
    4436:	9301      	str	r3, [sp, #4]
    4438:	9b10      	ldr	r3, [sp, #64]	; 0x40
    443a:	9300      	str	r3, [sp, #0]
    443c:	f8cd a00c 	str.w	sl, [sp, #12]
    4440:	464b      	mov	r3, r9
    4442:	463a      	mov	r2, r7
    4444:	4631      	mov	r1, r6
    4446:	4628      	mov	r0, r5
    4448:	f7ff ff4c 	bl	42e4 <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
    444c:	e9dd 3416 	ldrd	r3, r4, [sp, #88]	; 0x58
    4450:	3401      	adds	r4, #1
    4452:	bf08      	it	eq
    4454:	f1b3 3fff 	cmpeq.w	r3, #4294967295	; 0xffffffff
    4458:	d004      	beq.n	4464 <z_vrfy_k_thread_create+0xa8>
		schedule_new_thread(new_thread, delay);
    445a:	e9dd 2316 	ldrd	r2, r3, [sp, #88]	; 0x58
    445e:	4628      	mov	r0, r5
    4460:	f7ff feec 	bl	423c <schedule_new_thread>
}
    4464:	4628      	mov	r0, r5
    4466:	b007      	add	sp, #28
    4468:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    446c:	20000524 	.word	0x20000524

00004470 <z_mrsh_k_thread_create>:
#include <syscalls/kernel.h>

extern k_tid_t z_vrfy_k_thread_create(struct k_thread * new_thread, k_thread_stack_t * stack, size_t stack_size, k_thread_entry_t entry, void * p1, void * p2, void * p3, int prio, uint32_t options, k_timeout_t delay);
uintptr_t z_mrsh_k_thread_create(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, void *more, void *ssf)
{
    4470:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	_current->syscall_frame = ssf;
    4474:	4e19      	ldr	r6, [pc, #100]	; (44dc <z_mrsh_k_thread_create+0x6c>)
{
    4476:	b088      	sub	sp, #32
    4478:	469a      	mov	sl, r3
    447a:	9c11      	ldr	r4, [sp, #68]	; 0x44
	_current->syscall_frame = ssf;
    447c:	68b3      	ldr	r3, [r6, #8]
{
    447e:	4691      	mov	r9, r2
	_current->syscall_frame = ssf;
    4480:	9a12      	ldr	r2, [sp, #72]	; 0x48
    4482:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4486:	4607      	mov	r7, r0
    4488:	4688      	mov	r8, r1
	Z_OOPS(Z_SYSCALL_MEMORY_READ(more, 5 * sizeof(uintptr_t)));
    448a:	2200      	movs	r2, #0
    448c:	2114      	movs	r1, #20
    448e:	4620      	mov	r0, r4
    4490:	f001 fb01 	bl	5a96 <arch_buffer_validate>
    4494:	4605      	mov	r5, r0
    4496:	b130      	cbz	r0, 44a6 <z_mrsh_k_thread_create+0x36>
    4498:	f001 fe67 	bl	616a <arch_is_user_context>
    449c:	68b3      	ldr	r3, [r6, #8]
    449e:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    44a2:	f001 faca 	bl	5a3a <arch_syscall_oops>
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = (((uintptr_t *)more)[4]);
	parm0.split.hi = (((uintptr_t *)more)[5]);
    44a6:	e9d4 2304 	ldrd	r2, r3, [r4, #16]
	k_tid_t ret = z_vrfy_k_thread_create(*(struct k_thread **)&arg0, *(k_thread_stack_t **)&arg1, *(size_t*)&arg2, *(k_thread_entry_t*)&arg3, *(void **)&arg4, *(void **)&(((uintptr_t *)more)[0]), *(void **)&(((uintptr_t *)more)[1]), *(int*)&(((uintptr_t *)more)[2]), *(uint32_t*)&(((uintptr_t *)more)[3]), parm0.val)
    44aa:	e9cd 2306 	strd	r2, r3, [sp, #24]
    44ae:	68e3      	ldr	r3, [r4, #12]
    44b0:	9304      	str	r3, [sp, #16]
    44b2:	68a3      	ldr	r3, [r4, #8]
    44b4:	9303      	str	r3, [sp, #12]
    44b6:	6863      	ldr	r3, [r4, #4]
    44b8:	9302      	str	r3, [sp, #8]
    44ba:	6823      	ldr	r3, [r4, #0]
    44bc:	9301      	str	r3, [sp, #4]
    44be:	9b10      	ldr	r3, [sp, #64]	; 0x40
    44c0:	9300      	str	r3, [sp, #0]
    44c2:	464a      	mov	r2, r9
    44c4:	4653      	mov	r3, sl
    44c6:	4641      	mov	r1, r8
    44c8:	4638      	mov	r0, r7
    44ca:	f7ff ff77 	bl	43bc <z_vrfy_k_thread_create>
;
	_current->syscall_frame = NULL;
    44ce:	68b3      	ldr	r3, [r6, #8]
    44d0:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    44d4:	b008      	add	sp, #32
    44d6:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    44da:	bf00      	nop
    44dc:	20000524 	.word	0x20000524

000044e0 <z_init_static_threads>:
{
    44e0:	e92d 4bf0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, fp, lr}
	_FOREACH_STATIC_THREAD(thread_data) {
    44e4:	4f2e      	ldr	r7, [pc, #184]	; (45a0 <z_init_static_threads+0xc0>)
    44e6:	4e2f      	ldr	r6, [pc, #188]	; (45a4 <z_init_static_threads+0xc4>)
{
    44e8:	b086      	sub	sp, #24
    44ea:	463d      	mov	r5, r7
	_FOREACH_STATIC_THREAD(thread_data) {
    44ec:	42be      	cmp	r6, r7
    44ee:	f106 0430 	add.w	r4, r6, #48	; 0x30
    44f2:	d312      	bcc.n	451a <z_init_static_threads+0x3a>
	Z_STRUCT_SECTION_FOREACH(z_object_assignment, pos) {
    44f4:	4c2c      	ldr	r4, [pc, #176]	; (45a8 <z_init_static_threads+0xc8>)
    44f6:	4f2d      	ldr	r7, [pc, #180]	; (45ac <z_init_static_threads+0xcc>)
    44f8:	42bc      	cmp	r4, r7
    44fa:	d335      	bcc.n	4568 <z_init_static_threads+0x88>
	k_sched_lock();
    44fc:	f7ff f8b0 	bl	3660 <k_sched_lock>
	_FOREACH_STATIC_THREAD(thread_data) {
    4500:	4c28      	ldr	r4, [pc, #160]	; (45a4 <z_init_static_threads+0xc4>)
    4502:	f44f 4800 	mov.w	r8, #32768	; 0x8000
    4506:	f240 36e7 	movw	r6, #999	; 0x3e7
    450a:	2700      	movs	r7, #0
    450c:	42ac      	cmp	r4, r5
    450e:	d32d      	bcc.n	456c <z_init_static_threads+0x8c>
}
    4510:	b006      	add	sp, #24
    4512:	e8bd 4bf0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, fp, lr}
	k_sched_unlock();
    4516:	f7ff b8f1 	b.w	36fc <k_sched_unlock>
		z_setup_new_thread(
    451a:	f854 3c04 	ldr.w	r3, [r4, #-4]
    451e:	9305      	str	r3, [sp, #20]
    4520:	f854 3c10 	ldr.w	r3, [r4, #-16]
    4524:	9304      	str	r3, [sp, #16]
    4526:	f854 3c14 	ldr.w	r3, [r4, #-20]
    452a:	9303      	str	r3, [sp, #12]
    452c:	f854 3c18 	ldr.w	r3, [r4, #-24]
    4530:	9302      	str	r3, [sp, #8]
    4532:	f854 3c1c 	ldr.w	r3, [r4, #-28]
    4536:	9301      	str	r3, [sp, #4]
    4538:	f854 3c20 	ldr.w	r3, [r4, #-32]
    453c:	9300      	str	r3, [sp, #0]
    453e:	e954 230a 	ldrd	r2, r3, [r4, #-40]	; 0x28
    4542:	e954 010c 	ldrd	r0, r1, [r4, #-48]	; 0x30
    4546:	f7ff fecd 	bl	42e4 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
    454a:	f854 3c30 	ldr.w	r3, [r4, #-48]
    454e:	65de      	str	r6, [r3, #92]	; 0x5c
    4550:	4626      	mov	r6, r4
    4552:	e7cb      	b.n	44ec <z_init_static_threads+0xc>
			k_object_access_grant(pos->objects[i],
    4554:	6821      	ldr	r1, [r4, #0]
    4556:	f002 f906 	bl	6766 <z_impl_k_object_access_grant>
		for (int i = 0; pos->objects[i] != NULL; i++) {
    455a:	6863      	ldr	r3, [r4, #4]
    455c:	5998      	ldr	r0, [r3, r6]
    455e:	3604      	adds	r6, #4
    4560:	2800      	cmp	r0, #0
    4562:	d1f7      	bne.n	4554 <z_init_static_threads+0x74>
	Z_STRUCT_SECTION_FOREACH(z_object_assignment, pos) {
    4564:	3408      	adds	r4, #8
    4566:	e7c7      	b.n	44f8 <z_init_static_threads+0x18>
    4568:	2600      	movs	r6, #0
    456a:	e7f6      	b.n	455a <z_init_static_threads+0x7a>
		if (thread_data->init_delay != K_TICKS_FOREVER) {
    456c:	6a61      	ldr	r1, [r4, #36]	; 0x24
    456e:	1c4b      	adds	r3, r1, #1
    4570:	d013      	beq.n	459a <z_init_static_threads+0xba>
					    K_MSEC(thread_data->init_delay));
    4572:	ea21 71e1 	bic.w	r1, r1, r1, asr #31
    4576:	46b3      	mov	fp, r6
    4578:	46bc      	mov	ip, r7
    457a:	fbc8 bc01 	smlal	fp, ip, r8, r1
    457e:	f44f 727a 	mov.w	r2, #1000	; 0x3e8
    4582:	2300      	movs	r3, #0
    4584:	4658      	mov	r0, fp
    4586:	4661      	mov	r1, ip
    4588:	f7fb fe28 	bl	1dc <__aeabi_uldivmod>
			schedule_new_thread(thread_data->init_thread,
    458c:	f8d4 9000 	ldr.w	r9, [r4]
    4590:	4602      	mov	r2, r0
    4592:	460b      	mov	r3, r1
    4594:	4648      	mov	r0, r9
    4596:	f7ff fe51 	bl	423c <schedule_new_thread>
	_FOREACH_STATIC_THREAD(thread_data) {
    459a:	3430      	adds	r4, #48	; 0x30
    459c:	e7b6      	b.n	450c <z_init_static_threads+0x2c>
    459e:	bf00      	nop
    45a0:	20002c88 	.word	0x20002c88
    45a4:	20002c88 	.word	0x20002c88
    45a8:	00006b18 	.word	0x00006b18
    45ac:	00006b18 	.word	0x00006b18

000045b0 <z_mrsh_k_float_disable>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_float_disable(struct k_thread * thread);
uintptr_t z_mrsh_k_float_disable(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    45b0:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    45b2:	4c0c      	ldr	r4, [pc, #48]	; (45e4 <z_mrsh_k_float_disable+0x34>)
    45b4:	9a04      	ldr	r2, [sp, #16]
    45b6:	68a3      	ldr	r3, [r4, #8]
    45b8:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
}

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_float_disable(struct k_thread *thread)
{
	Z_OOPS(Z_SYSCALL_OBJ(thread, K_OBJ_THREAD));
    45bc:	f7fb fd8e 	bl	dc <z_object_find>
    45c0:	2200      	movs	r2, #0
    45c2:	2109      	movs	r1, #9
    45c4:	f000 fc50 	bl	4e68 <z_object_validate>
    45c8:	b130      	cbz	r0, 45d8 <z_mrsh_k_float_disable+0x28>
    45ca:	f001 fdce 	bl	616a <arch_is_user_context>
    45ce:	68a3      	ldr	r3, [r4, #8]
    45d0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    45d4:	f001 fa31 	bl	5a3a <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_float_disable(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    45d8:	68a3      	ldr	r3, [r4, #8]
    45da:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    45de:	f06f 0046 	mvn.w	r0, #70	; 0x46
    45e2:	bd10      	pop	{r4, pc}
    45e4:	20000524 	.word	0x20000524

000045e8 <z_mrsh_k_thread_timeout_remaining_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_thread_timeout_remaining_ticks(struct k_thread * t);
uintptr_t z_mrsh_k_thread_timeout_remaining_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    45e8:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    45ea:	4d0e      	ldr	r5, [pc, #56]	; (4624 <z_mrsh_k_thread_timeout_remaining_ticks+0x3c>)
    45ec:	9a06      	ldr	r2, [sp, #24]
    45ee:	68ab      	ldr	r3, [r5, #8]
    45f0:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    45f4:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline k_ticks_t z_vrfy_k_thread_timeout_remaining_ticks(
						    struct k_thread *t)
{
	Z_OOPS(Z_SYSCALL_OBJ(t, K_OBJ_THREAD));
    45f6:	f7fb fd71 	bl	dc <z_object_find>
    45fa:	2200      	movs	r2, #0
    45fc:	2109      	movs	r1, #9
    45fe:	f000 fc33 	bl	4e68 <z_object_validate>
    4602:	4604      	mov	r4, r0
    4604:	b130      	cbz	r0, 4614 <z_mrsh_k_thread_timeout_remaining_ticks+0x2c>
    4606:	f001 fdb0 	bl	616a <arch_is_user_context>
    460a:	68ab      	ldr	r3, [r5, #8]
    460c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4610:	f001 fa13 	bl	5a3a <arch_syscall_oops>
	return z_timeout_remaining(&t->base.timeout);
    4614:	f106 0018 	add.w	r0, r6, #24
    4618:	f001 fdf9 	bl	620e <z_timeout_remaining>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_thread_timeout_remaining_ticks(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    461c:	68ab      	ldr	r3, [r5, #8]
    461e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4622:	bd70      	pop	{r4, r5, r6, pc}
    4624:	20000524 	.word	0x20000524

00004628 <z_mrsh_k_thread_timeout_expires_ticks>:
#include <syscalls/kernel.h>

extern k_ticks_t z_vrfy_k_thread_timeout_expires_ticks(struct k_thread * t);
uintptr_t z_mrsh_k_thread_timeout_expires_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4628:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    462a:	4d0e      	ldr	r5, [pc, #56]	; (4664 <z_mrsh_k_thread_timeout_expires_ticks+0x3c>)
    462c:	9a06      	ldr	r2, [sp, #24]
    462e:	68ab      	ldr	r3, [r5, #8]
    4630:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4634:	4606      	mov	r6, r0
#include <syscalls/k_thread_timeout_remaining_ticks_mrsh.c>

static inline k_ticks_t z_vrfy_k_thread_timeout_expires_ticks(
						  struct k_thread *t)
{
	Z_OOPS(Z_SYSCALL_OBJ(t, K_OBJ_THREAD));
    4636:	f7fb fd51 	bl	dc <z_object_find>
    463a:	2200      	movs	r2, #0
    463c:	2109      	movs	r1, #9
    463e:	f000 fc13 	bl	4e68 <z_object_validate>
    4642:	4604      	mov	r4, r0
    4644:	b130      	cbz	r0, 4654 <z_mrsh_k_thread_timeout_expires_ticks+0x2c>
    4646:	f001 fd90 	bl	616a <arch_is_user_context>
    464a:	68ab      	ldr	r3, [r5, #8]
    464c:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4650:	f001 f9f3 	bl	5a3a <arch_syscall_oops>
	return z_timeout_expires(&t->base.timeout);
    4654:	f106 0018 	add.w	r0, r6, #24
    4658:	f000 f8f2 	bl	4840 <z_timeout_expires>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	k_ticks_t ret = z_vrfy_k_thread_timeout_expires_ticks(*(struct k_thread **)&arg0)
;
	_current->syscall_frame = NULL;
    465c:	68ab      	ldr	r3, [r5, #8]
    465e:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4662:	bd70      	pop	{r4, r5, r6, pc}
    4664:	20000524 	.word	0x20000524

00004668 <elapsed>:
	sys_dlist_remove(&t->node);
}

static int32_t elapsed(void)
{
	return announce_remaining == 0 ? z_clock_elapsed() : 0;
    4668:	4b03      	ldr	r3, [pc, #12]	; (4678 <elapsed+0x10>)
    466a:	681b      	ldr	r3, [r3, #0]
    466c:	b90b      	cbnz	r3, 4672 <elapsed+0xa>
    466e:	f7fc be87 	b.w	1380 <z_clock_elapsed>
}
    4672:	2000      	movs	r0, #0
    4674:	4770      	bx	lr
    4676:	bf00      	nop
    4678:	20000560 	.word	0x20000560

0000467c <remove_timeout>:
{
    467c:	b530      	push	{r4, r5, lr}
    467e:	6803      	ldr	r3, [r0, #0]
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    4680:	b168      	cbz	r0, 469e <remove_timeout+0x22>
    4682:	4a0a      	ldr	r2, [pc, #40]	; (46ac <remove_timeout+0x30>)
	return (node == list->tail) ? NULL : node->next;
    4684:	6852      	ldr	r2, [r2, #4]
    4686:	4290      	cmp	r0, r2
    4688:	d009      	beq.n	469e <remove_timeout+0x22>
	if (next(t) != NULL) {
    468a:	b143      	cbz	r3, 469e <remove_timeout+0x22>
		next(t)->dticks += t->dticks;
    468c:	e9d3 2104 	ldrd	r2, r1, [r3, #16]
    4690:	e9d0 4504 	ldrd	r4, r5, [r0, #16]
    4694:	1912      	adds	r2, r2, r4
    4696:	eb45 0101 	adc.w	r1, r5, r1
    469a:	e9c3 2104 	strd	r2, r1, [r3, #16]
	node->prev->next = node->next;
    469e:	6842      	ldr	r2, [r0, #4]
    46a0:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    46a2:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    46a4:	2300      	movs	r3, #0
	node->prev = NULL;
    46a6:	e9c0 3300 	strd	r3, r3, [r0]
}
    46aa:	bd30      	pop	{r4, r5, pc}
    46ac:	20002c3c 	.word	0x20002c3c

000046b0 <next_timeout>:
	return list->head == list;
    46b0:	4b0a      	ldr	r3, [pc, #40]	; (46dc <next_timeout+0x2c>)

static int32_t next_timeout(void)
{
    46b2:	b510      	push	{r4, lr}
    46b4:	681c      	ldr	r4, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    46b6:	429c      	cmp	r4, r3
    46b8:	bf08      	it	eq
    46ba:	2400      	moveq	r4, #0
	struct _timeout *to = first();
	int32_t ticks_elapsed = elapsed();
    46bc:	f7ff ffd4 	bl	4668 <elapsed>
	int32_t ret = to == NULL ? MAX_WAIT : MAX(0, to->dticks - ticks_elapsed);
    46c0:	b144      	cbz	r4, 46d4 <next_timeout+0x24>
    46c2:	6923      	ldr	r3, [r4, #16]
    46c4:	1a18      	subs	r0, r3, r0

#ifdef CONFIG_TIMESLICING
	if (_current_cpu->slice_ticks && _current_cpu->slice_ticks < ret) {
    46c6:	4b06      	ldr	r3, [pc, #24]	; (46e0 <next_timeout+0x30>)
    46c8:	691b      	ldr	r3, [r3, #16]
    46ca:	b113      	cbz	r3, 46d2 <next_timeout+0x22>
    46cc:	4298      	cmp	r0, r3
    46ce:	bfa8      	it	ge
    46d0:	4618      	movge	r0, r3
		ret = _current_cpu->slice_ticks;
	}
#endif
	return ret;
}
    46d2:	bd10      	pop	{r4, pc}
	int32_t ret = to == NULL ? MAX_WAIT : MAX(0, to->dticks - ticks_elapsed);
    46d4:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
    46d8:	e7f5      	b.n	46c6 <next_timeout+0x16>
    46da:	bf00      	nop
    46dc:	20002c3c 	.word	0x20002c3c
    46e0:	20000524 	.word	0x20000524

000046e4 <timeout_rem>:
/* must be locked */
static k_ticks_t timeout_rem(struct _timeout *timeout)
{
	k_ticks_t ticks = 0;

	if (z_is_inactive_timeout(timeout)) {
    46e4:	6803      	ldr	r3, [r0, #0]
{
    46e6:	b570      	push	{r4, r5, r6, lr}
	if (z_is_inactive_timeout(timeout)) {
    46e8:	b1eb      	cbz	r3, 4726 <timeout_rem+0x42>
	return list->head == list;
    46ea:	4a10      	ldr	r2, [pc, #64]	; (472c <timeout_rem+0x48>)
    46ec:	6813      	ldr	r3, [r2, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    46ee:	4293      	cmp	r3, r2
    46f0:	d016      	beq.n	4720 <timeout_rem+0x3c>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    46f2:	6851      	ldr	r1, [r2, #4]
    46f4:	2400      	movs	r4, #0
    46f6:	2500      	movs	r5, #0
		return 0;
	}

	for (struct _timeout *t = first(); t != NULL; t = next(t)) {
    46f8:	b93b      	cbnz	r3, 470a <timeout_rem+0x26>
		if (timeout == t) {
			break;
		}
	}

	return ticks - elapsed();
    46fa:	f7ff ffb5 	bl	4668 <elapsed>
    46fe:	1a24      	subs	r4, r4, r0
    4700:	eb65 75e0 	sbc.w	r5, r5, r0, asr #31
}
    4704:	4620      	mov	r0, r4
    4706:	4629      	mov	r1, r5
    4708:	bd70      	pop	{r4, r5, r6, pc}
		ticks += t->dticks;
    470a:	e9d3 2604 	ldrd	r2, r6, [r3, #16]
    470e:	18a4      	adds	r4, r4, r2
    4710:	eb46 0505 	adc.w	r5, r6, r5
		if (timeout == t) {
    4714:	4283      	cmp	r3, r0
    4716:	d0f0      	beq.n	46fa <timeout_rem+0x16>
	return (node == list->tail) ? NULL : node->next;
    4718:	428b      	cmp	r3, r1
    471a:	d0ee      	beq.n	46fa <timeout_rem+0x16>
    471c:	681b      	ldr	r3, [r3, #0]
    471e:	e7eb      	b.n	46f8 <timeout_rem+0x14>
    4720:	2400      	movs	r4, #0
    4722:	2500      	movs	r5, #0
    4724:	e7e9      	b.n	46fa <timeout_rem+0x16>
		return 0;
    4726:	2400      	movs	r4, #0
    4728:	2500      	movs	r5, #0
    472a:	e7eb      	b.n	4704 <timeout_rem+0x20>
    472c:	20002c3c 	.word	0x20002c3c

00004730 <z_add_timeout>:
{
    4730:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    4734:	9101      	str	r1, [sp, #4]
    4736:	4619      	mov	r1, r3
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    4738:	1c4b      	adds	r3, r1, #1
    473a:	bf08      	it	eq
    473c:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
{
    4740:	4682      	mov	sl, r0
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    4742:	d06c      	beq.n	481e <z_add_timeout+0xee>
	k_ticks_t ticks = timeout.ticks + 1;
    4744:	1c54      	adds	r4, r2, #1
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    4746:	f06f 0301 	mvn.w	r3, #1
	k_ticks_t ticks = timeout.ticks + 1;
    474a:	f141 0500 	adc.w	r5, r1, #0
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(ticks) >= 0) {
    474e:	f04f 3bff 	mov.w	fp, #4294967295	; 0xffffffff
    4752:	ebb3 0804 	subs.w	r8, r3, r4
    4756:	eb6b 0905 	sbc.w	r9, fp, r5
    475a:	f1b8 0f00 	cmp.w	r8, #0
    475e:	f179 0300 	sbcs.w	r3, r9, #0
    4762:	db0f      	blt.n	4784 <z_add_timeout+0x54>
		ticks = Z_TICK_ABS(ticks) - (curr_tick + elapsed());
    4764:	f7ff ff80 	bl	4668 <elapsed>
    4768:	4a33      	ldr	r2, [pc, #204]	; (4838 <z_add_timeout+0x108>)
    476a:	e9d2 1c00 	ldrd	r1, ip, [r2]
    476e:	f06f 0301 	mvn.w	r3, #1
    4772:	1a5b      	subs	r3, r3, r1
    4774:	eb6b 020c 	sbc.w	r2, fp, ip
    4778:	1b1e      	subs	r6, r3, r4
    477a:	eb62 0705 	sbc.w	r7, r2, r5
    477e:	1a34      	subs	r4, r6, r0
    4780:	eb67 75e0 	sbc.w	r5, r7, r0, asr #31
	to->fn = fn;
    4784:	9b01      	ldr	r3, [sp, #4]
    4786:	f8ca 3008 	str.w	r3, [sl, #8]
	__asm__ volatile(
    478a:	f04f 0320 	mov.w	r3, #32
    478e:	f3ef 8611 	mrs	r6, BASEPRI
    4792:	f383 8811 	msr	BASEPRI, r3
    4796:	f3bf 8f6f 	isb	sy
		to->dticks = ticks + elapsed();
    479a:	f7ff ff65 	bl	4668 <elapsed>
	ticks = MAX(1, ticks);
    479e:	2c01      	cmp	r4, #1
    47a0:	f175 0300 	sbcs.w	r3, r5, #0
	return list->head == list;
    47a4:	4b25      	ldr	r3, [pc, #148]	; (483c <z_add_timeout+0x10c>)
    47a6:	bfb8      	it	lt
    47a8:	2401      	movlt	r4, #1
    47aa:	681a      	ldr	r2, [r3, #0]
    47ac:	bfb8      	it	lt
    47ae:	2500      	movlt	r5, #0
		to->dticks = ticks + elapsed();
    47b0:	1824      	adds	r4, r4, r0
    47b2:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    47b6:	429a      	cmp	r2, r3
    47b8:	e9ca 4504 	strd	r4, r5, [sl, #16]
    47bc:	d001      	beq.n	47c2 <z_add_timeout+0x92>
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
    47be:	685f      	ldr	r7, [r3, #4]
		for (t = first(); t != NULL; t = next(t)) {
    47c0:	b952      	cbnz	r2, 47d8 <z_add_timeout+0xa8>
	node->prev = list->tail;
    47c2:	685a      	ldr	r2, [r3, #4]
    47c4:	f8ca 2004 	str.w	r2, [sl, #4]
	list->tail->next = node;
    47c8:	685a      	ldr	r2, [r3, #4]
	node->next = list;
    47ca:	f8ca 3000 	str.w	r3, [sl]
	list->tail->next = node;
    47ce:	f8c2 a000 	str.w	sl, [r2]
	list->tail = node;
    47d2:	f8c3 a004 	str.w	sl, [r3, #4]
}
    47d6:	e014      	b.n	4802 <z_add_timeout+0xd2>
			if (t->dticks > to->dticks) {
    47d8:	e9d2 8904 	ldrd	r8, r9, [r2, #16]
    47dc:	e9da 4504 	ldrd	r4, r5, [sl, #16]
    47e0:	454d      	cmp	r5, r9
    47e2:	bf08      	it	eq
    47e4:	4544      	cmpeq	r4, r8
    47e6:	d21d      	bcs.n	4824 <z_add_timeout+0xf4>
				t->dticks -= to->dticks;
    47e8:	ebb8 0004 	subs.w	r0, r8, r4
    47ec:	eb69 0105 	sbc.w	r1, r9, r5
    47f0:	e9c2 0104 	strd	r0, r1, [r2, #16]
	node->prev = successor->prev;
    47f4:	6851      	ldr	r1, [r2, #4]
	node->next = successor;
    47f6:	e9ca 2100 	strd	r2, r1, [sl]
	successor->prev->next = node;
    47fa:	f8c1 a000 	str.w	sl, [r1]
	successor->prev = node;
    47fe:	f8c2 a004 	str.w	sl, [r2, #4]
	return list->head == list;
    4802:	681a      	ldr	r2, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    4804:	429a      	cmp	r2, r3
    4806:	d006      	beq.n	4816 <z_add_timeout+0xe6>
		if (to == first()) {
    4808:	4592      	cmp	sl, r2
    480a:	d104      	bne.n	4816 <z_add_timeout+0xe6>
			z_clock_set_timeout(next_timeout(), false);
    480c:	f7ff ff50 	bl	46b0 <next_timeout>
    4810:	2100      	movs	r1, #0
    4812:	f7fc fd49 	bl	12a8 <z_clock_set_timeout>
	__asm__ volatile(
    4816:	f386 8811 	msr	BASEPRI, r6
    481a:	f3bf 8f6f 	isb	sy
}
    481e:	b003      	add	sp, #12
    4820:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			to->dticks -= t->dticks;
    4824:	ebb4 0008 	subs.w	r0, r4, r8
    4828:	eb65 0109 	sbc.w	r1, r5, r9
	return (node == list->tail) ? NULL : node->next;
    482c:	42ba      	cmp	r2, r7
    482e:	e9ca 0104 	strd	r0, r1, [sl, #16]
    4832:	d0c6      	beq.n	47c2 <z_add_timeout+0x92>
    4834:	6812      	ldr	r2, [r2, #0]
    4836:	e7c3      	b.n	47c0 <z_add_timeout+0x90>
    4838:	200003c0 	.word	0x200003c0
    483c:	20002c3c 	.word	0x20002c3c

00004840 <z_timeout_expires>:

	return ticks;
}

k_ticks_t z_timeout_expires(struct _timeout *timeout)
{
    4840:	b510      	push	{r4, lr}
	__asm__ volatile(
    4842:	f04f 0320 	mov.w	r3, #32
    4846:	f3ef 8411 	mrs	r4, BASEPRI
    484a:	f383 8811 	msr	BASEPRI, r3
    484e:	f3bf 8f6f 	isb	sy
	k_ticks_t ticks = 0;

	LOCKED(&timeout_lock) {
		ticks = curr_tick + timeout_rem(timeout);
    4852:	f7ff ff47 	bl	46e4 <timeout_rem>
    4856:	4a05      	ldr	r2, [pc, #20]	; (486c <z_timeout_expires+0x2c>)
    4858:	e9d2 3200 	ldrd	r3, r2, [r2]
    485c:	18c0      	adds	r0, r0, r3
    485e:	eb42 0101 	adc.w	r1, r2, r1
	__asm__ volatile(
    4862:	f384 8811 	msr	BASEPRI, r4
    4866:	f3bf 8f6f 	isb	sy
	}

	return ticks;
}
    486a:	bd10      	pop	{r4, pc}
    486c:	200003c0 	.word	0x200003c0

00004870 <z_clock_announce>:
		}
	}
}

void z_clock_announce(int32_t ticks)
{
    4870:	e92d 4ff7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, sl, fp, lr}
    4874:	4606      	mov	r6, r0
#ifdef CONFIG_TIMESLICING
	z_time_slice(ticks);
    4876:	f7ff f82f 	bl	38d8 <z_time_slice>
	__asm__ volatile(
    487a:	f04f 0320 	mov.w	r3, #32
    487e:	f3ef 8411 	mrs	r4, BASEPRI
    4882:	f383 8811 	msr	BASEPRI, r3
    4886:	f3bf 8f6f 	isb	sy
#endif

	k_spinlock_key_t key = k_spin_lock(&timeout_lock);

	announce_remaining = ticks;
    488a:	4d2d      	ldr	r5, [pc, #180]	; (4940 <z_clock_announce+0xd0>)
    488c:	f8df a0b4 	ldr.w	sl, [pc, #180]	; 4944 <z_clock_announce+0xd4>
	return list->head == list;
    4890:	f8df b0b4 	ldr.w	fp, [pc, #180]	; 4948 <z_clock_announce+0xd8>
    4894:	602e      	str	r6, [r5, #0]

	while (first() != NULL && first()->dticks <= announce_remaining) {
    4896:	4651      	mov	r1, sl
    4898:	f8d5 c000 	ldr.w	ip, [r5]
    489c:	f8db 0000 	ldr.w	r0, [fp]
    48a0:	4662      	mov	r2, ip
    48a2:	17d3      	asrs	r3, r2, #31
	return sys_dlist_is_empty(list) ? NULL : list->head;
    48a4:	4558      	cmp	r0, fp
    48a6:	e9cd 2300 	strd	r2, r3, [sp]
    48aa:	e9da 8900 	ldrd	r8, r9, [sl]
    48ae:	d00e      	beq.n	48ce <z_clock_announce+0x5e>
    48b0:	b168      	cbz	r0, 48ce <z_clock_announce+0x5e>
    48b2:	e9d0 6704 	ldrd	r6, r7, [r0, #16]
    48b6:	42bb      	cmp	r3, r7
    48b8:	bf08      	it	eq
    48ba:	45b4      	cmpeq	ip, r6
    48bc:	d21e      	bcs.n	48fc <z_clock_announce+0x8c>
		t->fn(t);
		key = k_spin_lock(&timeout_lock);
	}

	if (first() != NULL) {
		first()->dticks -= announce_remaining;
    48be:	9b00      	ldr	r3, [sp, #0]
    48c0:	ebb6 0c03 	subs.w	ip, r6, r3
    48c4:	9b01      	ldr	r3, [sp, #4]
    48c6:	eb67 0603 	sbc.w	r6, r7, r3
    48ca:	e9c0 c604 	strd	ip, r6, [r0, #16]
	}

	curr_tick += announce_remaining;
    48ce:	9b00      	ldr	r3, [sp, #0]
    48d0:	eb13 0208 	adds.w	r2, r3, r8
    48d4:	9b01      	ldr	r3, [sp, #4]
	announce_remaining = 0;
    48d6:	f04f 0600 	mov.w	r6, #0
	curr_tick += announce_remaining;
    48da:	eb43 0309 	adc.w	r3, r3, r9
    48de:	e9c1 2300 	strd	r2, r3, [r1]
	announce_remaining = 0;
    48e2:	602e      	str	r6, [r5, #0]

	z_clock_set_timeout(next_timeout(), false);
    48e4:	f7ff fee4 	bl	46b0 <next_timeout>
    48e8:	4631      	mov	r1, r6
    48ea:	f7fc fcdd 	bl	12a8 <z_clock_set_timeout>
	__asm__ volatile(
    48ee:	f384 8811 	msr	BASEPRI, r4
    48f2:	f3bf 8f6f 	isb	sy

	k_spin_unlock(&timeout_lock, key);
}
    48f6:	b003      	add	sp, #12
    48f8:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		curr_tick += dt;
    48fc:	eb18 0806 	adds.w	r8, r8, r6
		t->dticks = 0;
    4900:	f04f 0200 	mov.w	r2, #0
    4904:	f04f 0300 	mov.w	r3, #0
		curr_tick += dt;
    4908:	eb49 79e6 	adc.w	r9, r9, r6, asr #31
		t->dticks = 0;
    490c:	e9c0 2304 	strd	r2, r3, [r0, #16]
		announce_remaining -= dt;
    4910:	ebac 0606 	sub.w	r6, ip, r6
		curr_tick += dt;
    4914:	e9ca 8900 	strd	r8, r9, [sl]
		announce_remaining -= dt;
    4918:	602e      	str	r6, [r5, #0]
		remove_timeout(t);
    491a:	f7ff feaf 	bl	467c <remove_timeout>
    491e:	f384 8811 	msr	BASEPRI, r4
    4922:	f3bf 8f6f 	isb	sy
		t->fn(t);
    4926:	6883      	ldr	r3, [r0, #8]
    4928:	4798      	blx	r3
	__asm__ volatile(
    492a:	f04f 0320 	mov.w	r3, #32
    492e:	f3ef 8411 	mrs	r4, BASEPRI
    4932:	f383 8811 	msr	BASEPRI, r3
    4936:	f3bf 8f6f 	isb	sy

	/* Note that we need to use the underlying arch-specific lock
	 * implementation.  The "irq_lock()" API in SMP context is
	 * actually a wrapper for a global spinlock!
	 */
	k.key = arch_irq_lock();
    493a:	4902      	ldr	r1, [pc, #8]	; (4944 <z_clock_announce+0xd4>)
#endif

#ifdef CONFIG_SPIN_VALIDATE
	z_spin_lock_set_owner(l);
#endif
	return k;
    493c:	e7ac      	b.n	4898 <z_clock_announce+0x28>
    493e:	bf00      	nop
    4940:	20000560 	.word	0x20000560
    4944:	200003c0 	.word	0x200003c0
    4948:	20002c3c 	.word	0x20002c3c

0000494c <z_tick_get>:

int64_t z_tick_get(void)
{
    494c:	b510      	push	{r4, lr}
    494e:	f04f 0320 	mov.w	r3, #32
    4952:	f3ef 8411 	mrs	r4, BASEPRI
    4956:	f383 8811 	msr	BASEPRI, r3
    495a:	f3bf 8f6f 	isb	sy
	uint64_t t = 0U;

	LOCKED(&timeout_lock) {
		t = curr_tick + z_clock_elapsed();
    495e:	f7fc fd0f 	bl	1380 <z_clock_elapsed>
    4962:	4b06      	ldr	r3, [pc, #24]	; (497c <z_tick_get+0x30>)
    4964:	e9d3 2300 	ldrd	r2, r3, [r3]
    4968:	1812      	adds	r2, r2, r0
    496a:	f143 0300 	adc.w	r3, r3, #0
	__asm__ volatile(
    496e:	f384 8811 	msr	BASEPRI, r4
    4972:	f3bf 8f6f 	isb	sy
	}
	return t;
}
    4976:	4610      	mov	r0, r2
    4978:	4619      	mov	r1, r3
    497a:	bd10      	pop	{r4, pc}
    497c:	200003c0 	.word	0x200003c0

00004980 <z_mrsh_k_uptime_ticks>:
#include <syscalls/kernel.h>

extern int64_t z_vrfy_k_uptime_ticks();
uintptr_t z_mrsh_k_uptime_ticks(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4980:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    4982:	4d10      	ldr	r5, [pc, #64]	; (49c4 <z_mrsh_k_uptime_ticks+0x44>)
    4984:	9a08      	ldr	r2, [sp, #32]
    4986:	68ab      	ldr	r3, [r5, #8]
    4988:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    498c:	4604      	mov	r4, r0
#endif
}

int64_t z_impl_k_uptime_ticks(void)
{
	return z_tick_get();
    498e:	f7ff ffdd 	bl	494c <z_tick_get>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int64_t ret = z_vrfy_k_uptime_ticks()
;
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(((uint64_t *)arg0), 8));
    4992:	2201      	movs	r2, #1
    4994:	4607      	mov	r7, r0
    4996:	460e      	mov	r6, r1
    4998:	4620      	mov	r0, r4
    499a:	2108      	movs	r1, #8
    499c:	f001 f87b 	bl	5a96 <arch_buffer_validate>
    49a0:	462a      	mov	r2, r5
    49a2:	b148      	cbz	r0, 49b8 <z_mrsh_k_uptime_ticks+0x38>
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    49a4:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    49a8:	b90b      	cbnz	r3, 49ae <z_mrsh_k_uptime_ticks+0x2e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    49aa:	f3ef 8314 	mrs	r3, CONTROL
    49ae:	6893      	ldr	r3, [r2, #8]
    49b0:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    49b4:	f001 f841 	bl	5a3a <arch_syscall_oops>
	*((uint64_t *)arg0) = ret;
	_current->syscall_frame = NULL;
    49b8:	68aa      	ldr	r2, [r5, #8]
	*((uint64_t *)arg0) = ret;
    49ba:	e9c4 7600 	strd	r7, r6, [r4]
	_current->syscall_frame = NULL;
    49be:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    49c2:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    49c4:	20000524 	.word	0x20000524

000049c8 <z_impl_k_poll>:
	return 0;
}

int z_impl_k_poll(struct k_poll_event *events, int num_events,
		  k_timeout_t timeout)
{
    49c8:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    49cc:	b089      	sub	sp, #36	; 0x24
    49ce:	461f      	mov	r7, r3
	int events_registered;
	k_spinlock_key_t key;
	struct _poller poller = { .is_polling = true,
    49d0:	2301      	movs	r3, #1
    49d2:	f88d 3014 	strb.w	r3, [sp, #20]
				  .thread     = _current,
    49d6:	4b29      	ldr	r3, [pc, #164]	; (4a7c <z_impl_k_poll+0xb4>)
	struct _poller poller = { .is_polling = true,
    49d8:	689b      	ldr	r3, [r3, #8]
    49da:	9306      	str	r3, [sp, #24]
    49dc:	4b28      	ldr	r3, [pc, #160]	; (4a80 <z_impl_k_poll+0xb8>)
    49de:	9307      	str	r3, [sp, #28]

	__ASSERT(!arch_is_in_isr(), "");
	__ASSERT(events != NULL, "NULL events\n");
	__ASSERT(num_events >= 0, "<0 events\n");

	events_registered = register_events(events, num_events, &poller,
    49e0:	ea52 0307 	orrs.w	r3, r2, r7
{
    49e4:	4616      	mov	r6, r2
	events_registered = register_events(events, num_events, &poller,
    49e6:	bf0c      	ite	eq
    49e8:	2301      	moveq	r3, #1
    49ea:	2300      	movne	r3, #0
    49ec:	aa05      	add	r2, sp, #20
{
    49ee:	4605      	mov	r5, r0
	events_registered = register_events(events, num_events, &poller,
    49f0:	f001 fd1f 	bl	6432 <register_events>
    49f4:	4680      	mov	r8, r0
	__asm__ volatile(
    49f6:	f04f 0320 	mov.w	r3, #32
    49fa:	f3ef 8911 	mrs	r9, BASEPRI
    49fe:	f383 8811 	msr	BASEPRI, r3
    4a02:	f3bf 8f6f 	isb	sy
	/*
	 * If we're not polling anymore, it means that at least one event
	 * condition is met, either when looping through the events here or
	 * because one of the events registered has had its state changed.
	 */
	if (!poller.is_polling) {
    4a06:	f89d 3014 	ldrb.w	r3, [sp, #20]
    4a0a:	f003 04ff 	and.w	r4, r3, #255	; 0xff
    4a0e:	b963      	cbnz	r3, 4a2a <z_impl_k_poll+0x62>
		clear_event_registrations(events, events_registered, key);
    4a10:	4601      	mov	r1, r0
    4a12:	464a      	mov	r2, r9
    4a14:	4628      	mov	r0, r5
    4a16:	f001 fc6b 	bl	62f0 <clear_event_registrations>
	__asm__ volatile(
    4a1a:	f389 8811 	msr	BASEPRI, r9
    4a1e:	f3bf 8f6f 	isb	sy
	key = k_spin_lock(&lock);
	clear_event_registrations(events, events_registered, key);
	k_spin_unlock(&lock, key);

	return swap_rc;
}
    4a22:	4620      	mov	r0, r4
    4a24:	b009      	add	sp, #36	; 0x24
    4a26:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	poller.is_polling = false;
    4a2a:	2300      	movs	r3, #0
    4a2c:	f88d 3014 	strb.w	r3, [sp, #20]
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    4a30:	ea56 0307 	orrs.w	r3, r6, r7
    4a34:	d106      	bne.n	4a44 <z_impl_k_poll+0x7c>
    4a36:	f389 8811 	msr	BASEPRI, r9
    4a3a:	f3bf 8f6f 	isb	sy
		return -EAGAIN;
    4a3e:	f06f 040a 	mvn.w	r4, #10
    4a42:	e7ee      	b.n	4a22 <z_impl_k_poll+0x5a>
	_wait_q_t wait_q = Z_WAIT_Q_INIT(&wait_q);
    4a44:	aa03      	add	r2, sp, #12
	int swap_rc = z_pend_curr(&lock, key, &wait_q, timeout);
    4a46:	e9cd 6700 	strd	r6, r7, [sp]
    4a4a:	4649      	mov	r1, r9
    4a4c:	480d      	ldr	r0, [pc, #52]	; (4a84 <z_impl_k_poll+0xbc>)
	_wait_q_t wait_q = Z_WAIT_Q_INIT(&wait_q);
    4a4e:	e9cd 2203 	strd	r2, r2, [sp, #12]
	int swap_rc = z_pend_curr(&lock, key, &wait_q, timeout);
    4a52:	f7ff f8a1 	bl	3b98 <z_pend_curr>
    4a56:	4604      	mov	r4, r0
	__asm__ volatile(
    4a58:	f04f 0320 	mov.w	r3, #32
    4a5c:	f3ef 8611 	mrs	r6, BASEPRI
    4a60:	f383 8811 	msr	BASEPRI, r3
    4a64:	f3bf 8f6f 	isb	sy
	clear_event_registrations(events, events_registered, key);
    4a68:	4632      	mov	r2, r6
    4a6a:	4641      	mov	r1, r8
    4a6c:	4628      	mov	r0, r5
    4a6e:	f001 fc3f 	bl	62f0 <clear_event_registrations>
	__asm__ volatile(
    4a72:	f386 8811 	msr	BASEPRI, r6
    4a76:	f3bf 8f6f 	isb	sy
	return swap_rc;
    4a7a:	e7d2      	b.n	4a22 <z_impl_k_poll+0x5a>
    4a7c:	20000524 	.word	0x20000524
    4a80:	0000637d 	.word	0x0000637d
    4a84:	200012b4 	.word	0x200012b4

00004a88 <z_mrsh_k_poll>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_poll(struct k_poll_event * events, int num_events, k_timeout_t timeout);
uintptr_t z_mrsh_k_poll(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4a88:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	_current->syscall_frame = ssf;
    4a8c:	f8df a148 	ldr.w	sl, [pc, #328]	; 4bd8 <z_mrsh_k_poll+0x150>
{
    4a90:	b085      	sub	sp, #20
    4a92:	4691      	mov	r9, r2
    4a94:	9303      	str	r3, [sp, #12]
	_current->syscall_frame = ssf;
    4a96:	f8da 3008 	ldr.w	r3, [sl, #8]
    4a9a:	9a10      	ldr	r2, [sp, #64]	; 0x40
    4a9c:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	uint32_t bounds;

	/* Validate the events buffer and make a copy of it in an
	 * allocated kernel-side buffer.
	 */
	if (Z_SYSCALL_VERIFY(num_events >= 0)) {
    4aa0:	1e0d      	subs	r5, r1, #0
{
    4aa2:	4607      	mov	r7, r0
    4aa4:	46d0      	mov	r8, sl
    4aa6:	f280 8084 	bge.w	4bb2 <z_mrsh_k_poll+0x12a>
    4aaa:	f001 fc17 	bl	62dc <arch_is_user_context>
		ret = -EINVAL;
    4aae:	f06f 0515 	mvn.w	r5, #21
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_poll(*(struct k_poll_event **)&arg0, *(int*)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    4ab2:	f8d8 3008 	ldr.w	r3, [r8, #8]
    4ab6:	2200      	movs	r2, #0
	return (uintptr_t) ret;
}
    4ab8:	4628      	mov	r0, r5
	_current->syscall_frame = NULL;
    4aba:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
}
    4abe:	b005      	add	sp, #20
    4ac0:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	__asm__ volatile(
    4ac4:	f04f 0320 	mov.w	r3, #32
    4ac8:	f3ef 8b11 	mrs	fp, BASEPRI
    4acc:	f383 8811 	msr	BASEPRI, r3
    4ad0:	f3bf 8f6f 	isb	sy
		ret = -ENOMEM;
		goto out;
	}

	key = k_spin_lock(&lock);
	if (Z_SYSCALL_MEMORY_WRITE(events, bounds)) {
    4ad4:	2201      	movs	r2, #1
    4ad6:	9900      	ldr	r1, [sp, #0]
    4ad8:	4638      	mov	r0, r7
    4ada:	f000 ffdc 	bl	5a96 <arch_buffer_validate>
    4ade:	4606      	mov	r6, r0
    4ae0:	2800      	cmp	r0, #0
    4ae2:	d05b      	beq.n	4b9c <z_mrsh_k_poll+0x114>
    4ae4:	f001 fbfa 	bl	62dc <arch_is_user_context>
	__asm__ volatile(
    4ae8:	f38b 8811 	msr	BASEPRI, fp
    4aec:	f3bf 8f6f 	isb	sy
out_free:
	k_free(events_copy);
out:
	return ret;
oops_free:
	k_free(events_copy);
    4af0:	4620      	mov	r0, r4
    4af2:	f001 fea3 	bl	683c <k_free>
	Z_OOPS(1);
    4af6:	f8da 3008 	ldr.w	r3, [sl, #8]
			Z_OOPS(Z_SYSCALL_OBJ(e->signal, K_OBJ_POLL_SIGNAL));
    4afa:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4afe:	f000 ff9c 	bl	5a3a <arch_syscall_oops>
		if (Z_SYSCALL_VERIFY(e->mode == K_POLL_MODE_NOTIFY_ONLY)) {
    4b02:	f89a 300e 	ldrb.w	r3, [sl, #14]
    4b06:	079b      	lsls	r3, r3, #30
    4b08:	d535      	bpl.n	4b76 <z_mrsh_k_poll+0xee>
    4b0a:	f001 fbe7 	bl	62dc <arch_is_user_context>
		switch (e->type) {
    4b0e:	f06f 0515 	mvn.w	r5, #21
    4b12:	e02c      	b.n	4b6e <z_mrsh_k_poll+0xe6>
			Z_OOPS(Z_SYSCALL_OBJ(e->signal, K_OBJ_POLL_SIGNAL));
    4b14:	f8da 0010 	ldr.w	r0, [sl, #16]
    4b18:	f7fb fae0 	bl	dc <z_object_find>
    4b1c:	2200      	movs	r2, #0
    4b1e:	2106      	movs	r1, #6
    4b20:	f000 f9a2 	bl	4e68 <z_object_validate>
    4b24:	b190      	cbz	r0, 4b4c <z_mrsh_k_poll+0xc4>
    4b26:	f001 fbd9 	bl	62dc <arch_is_user_context>
    4b2a:	f8d8 3008 	ldr.w	r3, [r8, #8]
    4b2e:	e7e4      	b.n	4afa <z_mrsh_k_poll+0x72>
			Z_OOPS(Z_SYSCALL_OBJ(e->sem, K_OBJ_SEM));
    4b30:	f8da 0010 	ldr.w	r0, [sl, #16]
    4b34:	f7fb fad2 	bl	dc <z_object_find>
    4b38:	2200      	movs	r2, #0
    4b3a:	2107      	movs	r1, #7
    4b3c:	e7f0      	b.n	4b20 <z_mrsh_k_poll+0x98>
			Z_OOPS(Z_SYSCALL_OBJ(e->queue, K_OBJ_QUEUE));
    4b3e:	f8da 0010 	ldr.w	r0, [sl, #16]
    4b42:	f7fb facb 	bl	dc <z_object_find>
    4b46:	2200      	movs	r2, #0
    4b48:	2105      	movs	r1, #5
    4b4a:	e7e9      	b.n	4b20 <z_mrsh_k_poll+0x98>
	for (int i = 0; i < num_events; i++) {
    4b4c:	3601      	adds	r6, #1
    4b4e:	f10a 0a14 	add.w	sl, sl, #20
    4b52:	42b5      	cmp	r5, r6
    4b54:	dcd5      	bgt.n	4b02 <z_mrsh_k_poll+0x7a>
	return z_impl_k_poll(events, num_events, timeout);
    4b56:	4629      	mov	r1, r5
    4b58:	464a      	mov	r2, r9
    4b5a:	9b03      	ldr	r3, [sp, #12]
    4b5c:	4620      	mov	r0, r4
    4b5e:	f7ff ff33 	bl	49c8 <z_impl_k_poll>
	(void)memcpy((void *)events, events_copy, bounds);
    4b62:	9a00      	ldr	r2, [sp, #0]
    4b64:	4605      	mov	r5, r0
    4b66:	4621      	mov	r1, r4
    4b68:	4638      	mov	r0, r7
    4b6a:	f000 ffb6 	bl	5ada <memcpy>
	k_free(events_copy);
    4b6e:	4620      	mov	r0, r4
    4b70:	f001 fe64 	bl	683c <k_free>
    4b74:	e79d      	b.n	4ab2 <z_mrsh_k_poll+0x2a>
		switch (e->type) {
    4b76:	f89a 300d 	ldrb.w	r3, [sl, #13]
    4b7a:	f003 030f 	and.w	r3, r3, #15
    4b7e:	2b04      	cmp	r3, #4
    4b80:	d8c5      	bhi.n	4b0e <z_mrsh_k_poll+0x86>
    4b82:	a201      	add	r2, pc, #4	; (adr r2, 4b88 <z_mrsh_k_poll+0x100>)
    4b84:	f852 f023 	ldr.w	pc, [r2, r3, lsl #2]
    4b88:	00004b4d 	.word	0x00004b4d
    4b8c:	00004b15 	.word	0x00004b15
    4b90:	00004b31 	.word	0x00004b31
    4b94:	00004b0f 	.word	0x00004b0f
    4b98:	00004b3f 	.word	0x00004b3f
	(void)memcpy(events_copy, events, bounds);
    4b9c:	9a00      	ldr	r2, [sp, #0]
    4b9e:	4639      	mov	r1, r7
    4ba0:	4620      	mov	r0, r4
    4ba2:	f000 ff9a 	bl	5ada <memcpy>
    4ba6:	f38b 8811 	msr	BASEPRI, fp
    4baa:	f3bf 8f6f 	isb	sy
	for (int i = 0; i < num_events; i++) {
    4bae:	46a2      	mov	sl, r4
    4bb0:	e7cf      	b.n	4b52 <z_mrsh_k_poll+0xca>
	return __builtin_mul_overflow(a, b, result);
    4bb2:	2314      	movs	r3, #20
    4bb4:	fba5 3403 	umull	r3, r4, r5, r3
    4bb8:	e9cd 3400 	strd	r3, r4, [sp]
    4bbc:	9b01      	ldr	r3, [sp, #4]
    4bbe:	2b00      	cmp	r3, #0
    4bc0:	f47f af73 	bne.w	4aaa <z_mrsh_k_poll+0x22>
	events_copy = z_thread_malloc(bounds);
    4bc4:	9800      	ldr	r0, [sp, #0]
    4bc6:	f000 f989 	bl	4edc <z_thread_malloc>
	if (!events_copy) {
    4bca:	4604      	mov	r4, r0
    4bcc:	2800      	cmp	r0, #0
    4bce:	f47f af79 	bne.w	4ac4 <z_mrsh_k_poll+0x3c>
		ret = -ENOMEM;
    4bd2:	f06f 050b 	mvn.w	r5, #11
    4bd6:	e76c      	b.n	4ab2 <z_mrsh_k_poll+0x2a>
    4bd8:	20000524 	.word	0x20000524

00004bdc <z_mrsh_k_poll_signal_init>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_poll_signal_init(struct k_poll_signal * signal);
uintptr_t z_mrsh_k_poll_signal_init(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4bdc:	b570      	push	{r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4bde:	4d0e      	ldr	r5, [pc, #56]	; (4c18 <z_mrsh_k_poll_signal_init+0x3c>)
    4be0:	9a06      	ldr	r2, [sp, #24]
    4be2:	68ab      	ldr	r3, [r5, #8]
    4be4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4be8:	4606      	mov	r6, r0
}

#ifdef CONFIG_USERSPACE
static inline void z_vrfy_k_poll_signal_init(struct k_poll_signal *signal)
{
	Z_OOPS(Z_SYSCALL_OBJ_INIT(signal, K_OBJ_POLL_SIGNAL));
    4bea:	f7fb fa77 	bl	dc <z_object_find>
    4bee:	2201      	movs	r2, #1
    4bf0:	2106      	movs	r1, #6
    4bf2:	f000 f939 	bl	4e68 <z_object_validate>
    4bf6:	4604      	mov	r4, r0
    4bf8:	b130      	cbz	r0, 4c08 <z_mrsh_k_poll_signal_init+0x2c>
    4bfa:	f001 fb6f 	bl	62dc <arch_is_user_context>
    4bfe:	68ab      	ldr	r3, [r5, #8]
    4c00:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4c04:	f000 ff19 	bl	5a3a <arch_syscall_oops>
	z_impl_k_poll_signal_init(signal);
    4c08:	4630      	mov	r0, r6
    4c0a:	f001 fc90 	bl	652e <z_impl_k_poll_signal_init>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_poll_signal_init(*(struct k_poll_signal **)&arg0)
;
	_current->syscall_frame = NULL;
    4c0e:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    4c10:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    4c12:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4c16:	bd70      	pop	{r4, r5, r6, pc}
    4c18:	20000524 	.word	0x20000524

00004c1c <z_vrfy_k_poll_signal_check>:
}

#ifdef CONFIG_USERSPACE
void z_vrfy_k_poll_signal_check(struct k_poll_signal *signal,
			       unsigned int *signaled, int *result)
{
    4c1c:	b570      	push	{r4, r5, r6, lr}
    4c1e:	460c      	mov	r4, r1
    4c20:	4616      	mov	r6, r2
    4c22:	4605      	mov	r5, r0
	Z_OOPS(Z_SYSCALL_OBJ(signal, K_OBJ_POLL_SIGNAL));
    4c24:	f7fb fa5a 	bl	dc <z_object_find>
    4c28:	2200      	movs	r2, #0
    4c2a:	2106      	movs	r1, #6
    4c2c:	f000 f91c 	bl	4e68 <z_object_validate>
    4c30:	b138      	cbz	r0, 4c42 <z_vrfy_k_poll_signal_check+0x26>
    4c32:	f001 fb53 	bl	62dc <arch_is_user_context>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(signaled, sizeof(unsigned int)));
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(result, sizeof(int)));
    4c36:	4b0c      	ldr	r3, [pc, #48]	; (4c68 <z_vrfy_k_poll_signal_check+0x4c>)
    4c38:	689b      	ldr	r3, [r3, #8]
    4c3a:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4c3e:	f000 fefc 	bl	5a3a <arch_syscall_oops>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(signaled, sizeof(unsigned int)));
    4c42:	2201      	movs	r2, #1
    4c44:	2104      	movs	r1, #4
    4c46:	4620      	mov	r0, r4
    4c48:	f000 ff25 	bl	5a96 <arch_buffer_validate>
    4c4c:	2800      	cmp	r0, #0
    4c4e:	d1f0      	bne.n	4c32 <z_vrfy_k_poll_signal_check+0x16>
	Z_OOPS(Z_SYSCALL_MEMORY_WRITE(result, sizeof(int)));
    4c50:	2201      	movs	r2, #1
    4c52:	2104      	movs	r1, #4
    4c54:	4630      	mov	r0, r6
    4c56:	f000 ff1e 	bl	5a96 <arch_buffer_validate>
    4c5a:	2800      	cmp	r0, #0
    4c5c:	d1e9      	bne.n	4c32 <z_vrfy_k_poll_signal_check+0x16>
	*signaled = signal->signaled;
    4c5e:	68ab      	ldr	r3, [r5, #8]
    4c60:	6023      	str	r3, [r4, #0]
	*result = signal->result;
    4c62:	68eb      	ldr	r3, [r5, #12]
    4c64:	6033      	str	r3, [r6, #0]
	z_impl_k_poll_signal_check(signal, signaled, result);
}
    4c66:	bd70      	pop	{r4, r5, r6, pc}
    4c68:	20000524 	.word	0x20000524

00004c6c <z_mrsh_k_poll_signal_check>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_poll_signal_check(struct k_poll_signal * signal, unsigned int * signaled, int * result);
uintptr_t z_mrsh_k_poll_signal_check(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4c6c:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    4c6e:	4c06      	ldr	r4, [pc, #24]	; (4c88 <z_mrsh_k_poll_signal_check+0x1c>)
    4c70:	9d06      	ldr	r5, [sp, #24]
    4c72:	68a3      	ldr	r3, [r4, #8]
    4c74:	f8c3 5084 	str.w	r5, [r3, #132]	; 0x84
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_poll_signal_check(*(struct k_poll_signal **)&arg0, *(unsigned int **)&arg1, *(int **)&arg2)
    4c78:	f7ff ffd0 	bl	4c1c <z_vrfy_k_poll_signal_check>
;
	_current->syscall_frame = NULL;
    4c7c:	68a3      	ldr	r3, [r4, #8]
    4c7e:	2000      	movs	r0, #0
    4c80:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4c84:	bd38      	pop	{r3, r4, r5, pc}
    4c86:	bf00      	nop
    4c88:	20000524 	.word	0x20000524

00004c8c <z_impl_k_poll_signal_raise>:
#include <syscalls/k_poll_signal_check_mrsh.c>
#endif

int z_impl_k_poll_signal_raise(struct k_poll_signal *signal, int result)
{
    4c8c:	b538      	push	{r3, r4, r5, lr}
    4c8e:	4603      	mov	r3, r0
	__asm__ volatile(
    4c90:	f04f 0220 	mov.w	r2, #32
    4c94:	f3ef 8511 	mrs	r5, BASEPRI
    4c98:	f382 8811 	msr	BASEPRI, r2
    4c9c:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&lock);
	struct k_poll_event *poll_event;

	signal->result = result;
    4ca0:	60c1      	str	r1, [r0, #12]
	signal->signaled = 1U;
    4ca2:	2101      	movs	r1, #1
    4ca4:	6081      	str	r1, [r0, #8]
	return list->head == list;
    4ca6:	6800      	ldr	r0, [r0, #0]

static inline sys_dnode_t *sys_dlist_get(sys_dlist_t *list)
{
	sys_dnode_t *node = NULL;

	if (!sys_dlist_is_empty(list)) {
    4ca8:	4283      	cmp	r3, r0
    4caa:	d106      	bne.n	4cba <z_impl_k_poll_signal_raise+0x2e>
	__asm__ volatile(
    4cac:	f385 8811 	msr	BASEPRI, r5
    4cb0:	f3bf 8f6f 	isb	sy

	poll_event = (struct k_poll_event *)sys_dlist_get(&signal->poll_events);
	if (poll_event == NULL) {
		k_spin_unlock(&lock, key);
		return 0;
    4cb4:	2400      	movs	r4, #0

	int rc = signal_poll_event(poll_event, K_POLL_STATE_SIGNALED);

	z_reschedule(&lock, key);
	return rc;
}
    4cb6:	4620      	mov	r0, r4
    4cb8:	bd38      	pop	{r3, r4, r5, pc}
	node->prev->next = node->next;
    4cba:	e9d0 3200 	ldrd	r3, r2, [r0]
    4cbe:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    4cc0:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    4cc2:	2300      	movs	r3, #0
	node->prev = NULL;
    4cc4:	e9c0 3300 	strd	r3, r3, [r0]
	int rc = signal_poll_event(poll_event, K_POLL_STATE_SIGNALED);
    4cc8:	f001 fb3d 	bl	6346 <signal_poll_event>
	z_reschedule(&lock, key);
    4ccc:	4629      	mov	r1, r5
	int rc = signal_poll_event(poll_event, K_POLL_STATE_SIGNALED);
    4cce:	4604      	mov	r4, r0
	z_reschedule(&lock, key);
    4cd0:	4801      	ldr	r0, [pc, #4]	; (4cd8 <z_impl_k_poll_signal_raise+0x4c>)
    4cd2:	f001 f916 	bl	5f02 <z_reschedule>
	return rc;
    4cd6:	e7ee      	b.n	4cb6 <z_impl_k_poll_signal_raise+0x2a>
    4cd8:	200012b4 	.word	0x200012b4

00004cdc <z_mrsh_k_poll_signal_raise>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_poll_signal_raise(struct k_poll_signal * signal, int result);
uintptr_t z_mrsh_k_poll_signal_raise(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4cdc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    4cde:	4d0f      	ldr	r5, [pc, #60]	; (4d1c <z_mrsh_k_poll_signal_raise+0x40>)
    4ce0:	9a08      	ldr	r2, [sp, #32]
    4ce2:	68ab      	ldr	r3, [r5, #8]
    4ce4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4ce8:	460f      	mov	r7, r1
    4cea:	4606      	mov	r6, r0

#ifdef CONFIG_USERSPACE
static inline int z_vrfy_k_poll_signal_raise(struct k_poll_signal *signal,
					     int result)
{
	Z_OOPS(Z_SYSCALL_OBJ(signal, K_OBJ_POLL_SIGNAL));
    4cec:	f7fb f9f6 	bl	dc <z_object_find>
    4cf0:	2200      	movs	r2, #0
    4cf2:	2106      	movs	r1, #6
    4cf4:	f000 f8b8 	bl	4e68 <z_object_validate>
    4cf8:	4604      	mov	r4, r0
    4cfa:	b130      	cbz	r0, 4d0a <z_mrsh_k_poll_signal_raise+0x2e>
    4cfc:	f001 faee 	bl	62dc <arch_is_user_context>
    4d00:	68ab      	ldr	r3, [r5, #8]
    4d02:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4d06:	f000 fe98 	bl	5a3a <arch_syscall_oops>
	return z_impl_k_poll_signal_raise(signal, result);
    4d0a:	4639      	mov	r1, r7
    4d0c:	4630      	mov	r0, r6
    4d0e:	f7ff ffbd 	bl	4c8c <z_impl_k_poll_signal_raise>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_poll_signal_raise(*(struct k_poll_signal **)&arg0, *(int*)&arg1)
;
	_current->syscall_frame = NULL;
    4d12:	68ab      	ldr	r3, [r5, #8]
    4d14:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4d18:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    4d1a:	bf00      	nop
    4d1c:	20000524 	.word	0x20000524

00004d20 <z_mrsh_k_poll_signal_reset>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_poll_signal_reset(struct k_poll_signal * signal);
uintptr_t z_mrsh_k_poll_signal_reset(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4d20:	b538      	push	{r3, r4, r5, lr}
	_current->syscall_frame = ssf;
    4d22:	4c0c      	ldr	r4, [pc, #48]	; (4d54 <z_mrsh_k_poll_signal_reset+0x34>)
    4d24:	9a06      	ldr	r2, [sp, #24]
    4d26:	68a3      	ldr	r3, [r4, #8]
    4d28:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4d2c:	4605      	mov	r5, r0
}
#include <syscalls/k_poll_signal_raise_mrsh.c>

static inline void z_vrfy_k_poll_signal_reset(struct k_poll_signal *signal)
{
	Z_OOPS(Z_SYSCALL_OBJ(signal, K_OBJ_POLL_SIGNAL));
    4d2e:	f7fb f9d5 	bl	dc <z_object_find>
    4d32:	2200      	movs	r2, #0
    4d34:	2106      	movs	r1, #6
    4d36:	f000 f897 	bl	4e68 <z_object_validate>
    4d3a:	b130      	cbz	r0, 4d4a <z_mrsh_k_poll_signal_reset+0x2a>
    4d3c:	f001 face 	bl	62dc <arch_is_user_context>
    4d40:	68a3      	ldr	r3, [r4, #8]
    4d42:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4d46:	f000 fe78 	bl	5a3a <arch_syscall_oops>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_poll_signal_reset(*(struct k_poll_signal **)&arg0)
;
	_current->syscall_frame = NULL;
    4d4a:	68a2      	ldr	r2, [r4, #8]
	signal->signaled = 0U;
    4d4c:	60a8      	str	r0, [r5, #8]
    4d4e:	f8c2 0084 	str.w	r0, [r2, #132]	; 0x84
	return 0;
}
    4d52:	bd38      	pop	{r3, r4, r5, pc}
    4d54:	20000524 	.word	0x20000524

00004d58 <z_mrsh_k_futex_wake>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_futex_wake(struct k_futex * futex, bool wake_all);
uintptr_t z_mrsh_k_futex_wake(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4d58:	b573      	push	{r0, r1, r4, r5, r6, lr}
	_current->syscall_frame = ssf;
    4d5a:	4c0e      	ldr	r4, [pc, #56]	; (4d94 <z_mrsh_k_futex_wake+0x3c>)
    4d5c:	9a08      	ldr	r2, [sp, #32]
    4d5e:	68a3      	ldr	r3, [r4, #8]
{
    4d60:	9101      	str	r1, [sp, #4]
	_current->syscall_frame = ssf;
    4d62:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	(void) arg2;	/* unused */
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	int ret = z_vrfy_k_futex_wake(*(struct k_futex **)&arg0, *(bool*)&arg1)
    4d66:	b2ce      	uxtb	r6, r1
	return woken;
}

static inline int z_vrfy_k_futex_wake(struct k_futex *futex, bool wake_all)
{
	if (Z_SYSCALL_MEMORY_WRITE(futex, sizeof(struct k_futex)) != 0) {
    4d68:	2201      	movs	r2, #1
    4d6a:	2104      	movs	r1, #4
{
    4d6c:	4605      	mov	r5, r0
    4d6e:	f000 fe92 	bl	5a96 <arch_buffer_validate>
    4d72:	b148      	cbz	r0, 4d88 <z_mrsh_k_futex_wake+0x30>
    4d74:	f001 fbe1 	bl	653a <arch_is_user_context>
		return -EACCES;
    4d78:	f06f 000c 	mvn.w	r0, #12
;
	_current->syscall_frame = NULL;
    4d7c:	68a3      	ldr	r3, [r4, #8]
    4d7e:	2200      	movs	r2, #0
    4d80:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4d84:	b002      	add	sp, #8
    4d86:	bd70      	pop	{r4, r5, r6, pc}
	}

	return z_impl_k_futex_wake(futex, wake_all);
    4d88:	4631      	mov	r1, r6
    4d8a:	4628      	mov	r0, r5
    4d8c:	f001 fbdf 	bl	654e <z_impl_k_futex_wake>
    4d90:	e7f4      	b.n	4d7c <z_mrsh_k_futex_wake+0x24>
    4d92:	bf00      	nop
    4d94:	20000524 	.word	0x20000524

00004d98 <z_mrsh_k_futex_wait>:
#include <syscalls/kernel.h>

extern int z_vrfy_k_futex_wait(struct k_futex * futex, int expected, k_timeout_t timeout);
uintptr_t z_mrsh_k_futex_wait(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4d98:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	_current->syscall_frame = ssf;
    4d9c:	4c0f      	ldr	r4, [pc, #60]	; (4ddc <z_mrsh_k_futex_wait+0x44>)
{
    4d9e:	461f      	mov	r7, r3
	_current->syscall_frame = ssf;
    4da0:	68a3      	ldr	r3, [r4, #8]
{
    4da2:	4690      	mov	r8, r2
	_current->syscall_frame = ssf;
    4da4:	9a08      	ldr	r2, [sp, #32]
    4da6:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
{
    4daa:	460e      	mov	r6, r1
}

static inline int z_vrfy_k_futex_wait(struct k_futex *futex, int expected,
				      k_timeout_t timeout)
{
	if (Z_SYSCALL_MEMORY_WRITE(futex, sizeof(struct k_futex)) != 0) {
    4dac:	2201      	movs	r2, #1
    4dae:	2104      	movs	r1, #4
    4db0:	4605      	mov	r5, r0
    4db2:	f000 fe70 	bl	5a96 <arch_buffer_validate>
    4db6:	b148      	cbz	r0, 4dcc <z_mrsh_k_futex_wait+0x34>
    4db8:	f001 fbbf 	bl	653a <arch_is_user_context>
		return -EACCES;
    4dbc:	f06f 000c 	mvn.w	r0, #12
	union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm0;
	parm0.split.lo = arg2;
	parm0.split.hi = arg3;
	int ret = z_vrfy_k_futex_wait(*(struct k_futex **)&arg0, *(int*)&arg1, parm0.val)
;
	_current->syscall_frame = NULL;
    4dc0:	68a3      	ldr	r3, [r4, #8]
    4dc2:	2200      	movs	r2, #0
    4dc4:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4dc8:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	}

	return z_impl_k_futex_wait(futex, expected, timeout);
    4dcc:	4642      	mov	r2, r8
    4dce:	463b      	mov	r3, r7
    4dd0:	4631      	mov	r1, r6
    4dd2:	4628      	mov	r0, r5
    4dd4:	f001 fbe8 	bl	65a8 <z_impl_k_futex_wait>
    4dd8:	e7f2      	b.n	4dc0 <z_mrsh_k_futex_wait+0x28>
    4dda:	bf00      	nop
    4ddc:	20000524 	.word	0x20000524

00004de0 <init_mem_domain_module>:
	thread->mem_domain_info.mem_domain = NULL;
	k_spin_unlock(&lock, key);
}

static int init_mem_domain_module(struct device *arg)
{
    4de0:	b508      	push	{r3, lr}
	ARG_UNUSED(arg);

	max_partitions = arch_mem_domain_max_partitions_get();
    4de2:	f000 fe53 	bl	5a8c <arch_mem_domain_max_partitions_get>
    4de6:	4b02      	ldr	r3, [pc, #8]	; (4df0 <init_mem_domain_module+0x10>)
    4de8:	7018      	strb	r0, [r3, #0]
	 * out of bounds error.
	 */
	__ASSERT(max_partitions <= CONFIG_MAX_DOMAIN_PARTITIONS, "");

	return 0;
}
    4dea:	2000      	movs	r0, #0
    4dec:	bd08      	pop	{r3, pc}
    4dee:	bf00      	nop
    4df0:	200012b4 	.word	0x200012b4

00004df4 <app_shmem_bss_zero>:

extern char __app_shmem_regions_start[];
extern char __app_shmem_regions_end[];

static int app_shmem_bss_zero(struct device *unused)
{
    4df4:	b538      	push	{r3, r4, r5, lr}
	struct z_app_region *region, *end;

	ARG_UNUSED(unused);

	end = (struct z_app_region *)&__app_shmem_regions_end;
	region = (struct z_app_region *)&__app_shmem_regions_start;
    4df6:	4c06      	ldr	r4, [pc, #24]	; (4e10 <app_shmem_bss_zero+0x1c>)

	for ( ; region < end; region++) {
    4df8:	4d06      	ldr	r5, [pc, #24]	; (4e14 <app_shmem_bss_zero+0x20>)
    4dfa:	42ac      	cmp	r4, r5
    4dfc:	d301      	bcc.n	4e02 <app_shmem_bss_zero+0xe>
		(void)memset(region->bss_start, 0, region->bss_size);
	}

	return 0;
}
    4dfe:	2000      	movs	r0, #0
    4e00:	bd38      	pop	{r3, r4, r5, pc}
		(void)memset(region->bss_start, 0, region->bss_size);
    4e02:	6862      	ldr	r2, [r4, #4]
    4e04:	f854 0b08 	ldr.w	r0, [r4], #8
    4e08:	2100      	movs	r1, #0
    4e0a:	f000 fe91 	bl	5b30 <memset>
	for ( ; region < end; region++) {
    4e0e:	e7f4      	b.n	4dfa <app_shmem_bss_zero+0x6>
    4e10:	00006b18 	.word	0x00006b18
    4e14:	00006b18 	.word	0x00006b18

00004e18 <z_thread_perms_inherit>:
{
    4e18:	b530      	push	{r4, r5, lr}
    4e1a:	b085      	sub	sp, #20
    4e1c:	460d      	mov	r5, r1
    4e1e:	4604      	mov	r4, r0
		thread_index_get(parent),
    4e20:	f001 fc58 	bl	66d4 <thread_index_get>
	struct perm_ctx ctx = {
    4e24:	9001      	str	r0, [sp, #4]
		thread_index_get(child),
    4e26:	4628      	mov	r0, r5
    4e28:	f001 fc54 	bl	66d4 <thread_index_get>
	if ((ctx.parent_id != -1) && (ctx.child_id != -1)) {
    4e2c:	9b01      	ldr	r3, [sp, #4]
    4e2e:	3301      	adds	r3, #1
	struct perm_ctx ctx = {
    4e30:	e9cd 0402 	strd	r0, r4, [sp, #8]
	if ((ctx.parent_id != -1) && (ctx.child_id != -1)) {
    4e34:	d005      	beq.n	4e42 <z_thread_perms_inherit+0x2a>
    4e36:	3001      	adds	r0, #1
    4e38:	d003      	beq.n	4e42 <z_thread_perms_inherit+0x2a>
		z_object_wordlist_foreach(wordlist_cb, &ctx);
    4e3a:	4803      	ldr	r0, [pc, #12]	; (4e48 <z_thread_perms_inherit+0x30>)
    4e3c:	a901      	add	r1, sp, #4
    4e3e:	f7fb f967 	bl	110 <z_object_gperf_wordlist_foreach>
}
    4e42:	b005      	add	sp, #20
    4e44:	bd30      	pop	{r4, r5, pc}
    4e46:	bf00      	nop
    4e48:	00006699 	.word	0x00006699

00004e4c <z_thread_perms_all_clear>:
{
    4e4c:	b508      	push	{r3, lr}
	uintptr_t index = thread_index_get(thread);
    4e4e:	f001 fc41 	bl	66d4 <thread_index_get>
	if (index != -1) {
    4e52:	1c43      	adds	r3, r0, #1
	uintptr_t index = thread_index_get(thread);
    4e54:	4601      	mov	r1, r0
	if (index != -1) {
    4e56:	d004      	beq.n	4e62 <z_thread_perms_all_clear+0x16>
}
    4e58:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		z_object_wordlist_foreach(clear_perms_cb, (void *)index);
    4e5c:	4801      	ldr	r0, [pc, #4]	; (4e64 <z_thread_perms_all_clear+0x18>)
    4e5e:	f7fb b957 	b.w	110 <z_object_gperf_wordlist_foreach>
}
    4e62:	bd08      	pop	{r3, pc}
    4e64:	000066d1 	.word	0x000066d1

00004e68 <z_object_validate>:
{
    4e68:	b538      	push	{r3, r4, r5, lr}
    4e6a:	4615      	mov	r5, r2
	if (unlikely((ko == NULL) ||
    4e6c:	4604      	mov	r4, r0
    4e6e:	b368      	cbz	r0, 4ecc <z_object_validate+0x64>
    4e70:	b111      	cbz	r1, 4e78 <z_object_validate+0x10>
    4e72:	7983      	ldrb	r3, [r0, #6]
    4e74:	428b      	cmp	r3, r1
    4e76:	d129      	bne.n	4ecc <z_object_validate+0x64>
	if ((ko->flags & K_OBJ_FLAG_PUBLIC) != 0U) {
    4e78:	79e3      	ldrb	r3, [r4, #7]
    4e7a:	079a      	lsls	r2, r3, #30
    4e7c:	d50a      	bpl.n	4e94 <z_object_validate+0x2c>
	if (likely(init == _OBJ_INIT_TRUE)) {
    4e7e:	2d00      	cmp	r5, #0
    4e80:	d01c      	beq.n	4ebc <z_object_validate+0x54>
	} else if (init < _OBJ_INIT_TRUE) { /* _OBJ_INIT_FALSE case */
    4e82:	da26      	bge.n	4ed2 <z_object_validate+0x6a>
		if (unlikely((ko->flags & K_OBJ_FLAG_INITIALIZED) != 0U)) {
    4e84:	79e3      	ldrb	r3, [r4, #7]
			return -EADDRINUSE;
    4e86:	f013 0f01 	tst.w	r3, #1
    4e8a:	bf0c      	ite	eq
    4e8c:	2000      	moveq	r0, #0
    4e8e:	f06f 002f 	mvnne.w	r0, #47	; 0x2f
    4e92:	e01a      	b.n	4eca <z_object_validate+0x62>
	index = thread_index_get(_current);
    4e94:	4b10      	ldr	r3, [pc, #64]	; (4ed8 <z_object_validate+0x70>)
    4e96:	6898      	ldr	r0, [r3, #8]
    4e98:	f001 fc1c 	bl	66d4 <thread_index_get>
	if (index != -1) {
    4e9c:	1c43      	adds	r3, r0, #1
    4e9e:	d014      	beq.n	4eca <z_object_validate+0x62>
}

static ALWAYS_INLINE
	int sys_bitfield_test_bit(mem_addr_t addr, unsigned int bit)
{
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    4ea0:	0942      	lsrs	r2, r0, #5
		return sys_bitfield_test_bit((mem_addr_t)&ko->perms, index);
    4ea2:	1d23      	adds	r3, r4, #4
    4ea4:	f000 001f 	and.w	r0, r0, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    4ea8:	f853 2022 	ldr.w	r2, [r3, r2, lsl #2]
	return temp & (1 << bit);
    4eac:	2301      	movs	r3, #1
    4eae:	fa03 f000 	lsl.w	r0, r3, r0
	if (unlikely(thread_perms_test(ko) == 0)) {
    4eb2:	4210      	tst	r0, r2
    4eb4:	d1e3      	bne.n	4e7e <z_object_validate+0x16>
		return -EPERM;
    4eb6:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    4eba:	e006      	b.n	4eca <z_object_validate+0x62>
		if (unlikely((ko->flags & K_OBJ_FLAG_INITIALIZED) == 0U)) {
    4ebc:	79e3      	ldrb	r3, [r4, #7]
			return -EINVAL;
    4ebe:	f013 0f01 	tst.w	r3, #1
    4ec2:	bf14      	ite	ne
    4ec4:	2000      	movne	r0, #0
    4ec6:	f06f 0015 	mvneq.w	r0, #21
}
    4eca:	bd38      	pop	{r3, r4, r5, pc}
		return -EBADF;
    4ecc:	f06f 0008 	mvn.w	r0, #8
    4ed0:	e7fb      	b.n	4eca <z_object_validate+0x62>
	return 0;
    4ed2:	2000      	movs	r0, #0
    4ed4:	e7f9      	b.n	4eca <z_object_validate+0x62>
    4ed6:	bf00      	nop
    4ed8:	20000524 	.word	0x20000524

00004edc <z_thread_malloc>:
#else
#define _HEAP_MEM_POOL	NULL
#endif

void *z_thread_malloc(size_t size)
{
    4edc:	b510      	push	{r4, lr}
    4ede:	4604      	mov	r4, r0
	void *ret;
	struct k_mem_pool *pool;

	if (k_is_in_isr()) {
    4ee0:	f001 f94d 	bl	617e <k_is_in_isr>
    4ee4:	b950      	cbnz	r0, 4efc <z_thread_malloc+0x20>
		pool = _HEAP_MEM_POOL;
	} else {
		pool = _current->resource_pool;
    4ee6:	4b07      	ldr	r3, [pc, #28]	; (4f04 <z_thread_malloc+0x28>)
    4ee8:	689b      	ldr	r3, [r3, #8]
    4eea:	f8d3 3088 	ldr.w	r3, [r3, #136]	; 0x88
	}

	if (pool) {
    4eee:	b13b      	cbz	r3, 4f00 <z_thread_malloc+0x24>
		ret = k_mem_pool_malloc(pool, size);
    4ef0:	4621      	mov	r1, r4
    4ef2:	4618      	mov	r0, r3
	} else {
		ret = NULL;
	}

	return ret;
}
    4ef4:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		ret = k_mem_pool_malloc(pool, size);
    4ef8:	f001 bc88 	b.w	680c <k_mem_pool_malloc>
		pool = _HEAP_MEM_POOL;
    4efc:	4b02      	ldr	r3, [pc, #8]	; (4f08 <z_thread_malloc+0x2c>)
    4efe:	e7f7      	b.n	4ef0 <z_thread_malloc+0x14>
}
    4f00:	bd10      	pop	{r4, pc}
    4f02:	bf00      	nop
    4f04:	20000524 	.word	0x20000524
    4f08:	20002c44 	.word	0x20002c44

00004f0c <z_mrsh_k_object_access_grant>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_object_access_grant(void * object, struct k_thread * thread);
uintptr_t z_mrsh_k_object_access_grant(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4f0c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	_current->syscall_frame = ssf;
    4f0e:	4d12      	ldr	r5, [pc, #72]	; (4f58 <z_mrsh_k_object_access_grant+0x4c>)
    4f10:	9a08      	ldr	r2, [sp, #32]
    4f12:	68ab      	ldr	r3, [r5, #8]
{
    4f14:	4607      	mov	r7, r0
	_current->syscall_frame = ssf;
    4f16:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84
static inline void z_vrfy_k_object_access_grant(void *object,
						struct k_thread *thread)
{
	struct z_object *ko;

	Z_OOPS(Z_SYSCALL_OBJ_INIT(thread, K_OBJ_THREAD));
    4f1a:	4608      	mov	r0, r1
{
    4f1c:	460e      	mov	r6, r1
    4f1e:	f7fb f8dd 	bl	dc <z_object_find>
    4f22:	2201      	movs	r2, #1
    4f24:	2109      	movs	r1, #9
    4f26:	f7ff ff9f 	bl	4e68 <z_object_validate>
    4f2a:	4604      	mov	r4, r0
    4f2c:	b130      	cbz	r0, 4f3c <z_mrsh_k_object_access_grant+0x30>
    4f2e:	f001 fc8a 	bl	6846 <arch_is_user_context>
	ko = validate_any_object(object);
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    4f32:	68ab      	ldr	r3, [r5, #8]
    4f34:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4f38:	f000 fd7f 	bl	5a3a <arch_syscall_oops>
	ko = validate_any_object(object);
    4f3c:	4638      	mov	r0, r7
    4f3e:	f001 fc8c 	bl	685a <validate_any_object>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    4f42:	2800      	cmp	r0, #0
    4f44:	d0f3      	beq.n	4f2e <z_mrsh_k_object_access_grant+0x22>
				    object));
	z_thread_perms_set(ko, thread);
    4f46:	4631      	mov	r1, r6
    4f48:	f001 fbdf 	bl	670a <z_thread_perms_set>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_object_access_grant(*(void **)&arg0, *(struct k_thread **)&arg1)
;
	_current->syscall_frame = NULL;
    4f4c:	68ab      	ldr	r3, [r5, #8]
	return 0;
}
    4f4e:	4620      	mov	r0, r4
	_current->syscall_frame = NULL;
    4f50:	f8c3 4084 	str.w	r4, [r3, #132]	; 0x84
}
    4f54:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
    4f56:	bf00      	nop
    4f58:	20000524 	.word	0x20000524

00004f5c <z_mrsh_k_object_release>:
#include <syscalls/kernel.h>

extern void z_vrfy_k_object_release(void * object);
uintptr_t z_mrsh_k_object_release(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
    4f5c:	b510      	push	{r4, lr}
	_current->syscall_frame = ssf;
    4f5e:	4c0b      	ldr	r4, [pc, #44]	; (4f8c <z_mrsh_k_object_release+0x30>)
    4f60:	9a04      	ldr	r2, [sp, #16]
    4f62:	68a3      	ldr	r3, [r4, #8]
    4f64:	f8c3 2084 	str.w	r2, [r3, #132]	; 0x84

static inline void z_vrfy_k_object_release(void *object)
{
	struct z_object *ko;

	ko = validate_any_object((void *)object);
    4f68:	f001 fc77 	bl	685a <validate_any_object>
	Z_OOPS(Z_SYSCALL_VERIFY_MSG(ko != NULL, "object %p access denied",
    4f6c:	b930      	cbnz	r0, 4f7c <z_mrsh_k_object_release+0x20>
    4f6e:	f001 fc6a 	bl	6846 <arch_is_user_context>
    4f72:	68a3      	ldr	r3, [r4, #8]
    4f74:	f8d3 0084 	ldr.w	r0, [r3, #132]	; 0x84
    4f78:	f000 fd5f 	bl	5a3a <arch_syscall_oops>
				    (void *)object));
	z_thread_perms_clear(ko, _current);
    4f7c:	68a1      	ldr	r1, [r4, #8]
    4f7e:	f001 fbd8 	bl	6732 <z_thread_perms_clear>
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	z_vrfy_k_object_release(*(void **)&arg0)
;
	_current->syscall_frame = NULL;
    4f82:	68a3      	ldr	r3, [r4, #8]
    4f84:	2000      	movs	r0, #0
    4f86:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return 0;
}
    4f8a:	bd10      	pop	{r4, pc}
    4f8c:	20000524 	.word	0x20000524

00004f90 <z_mrsh_k_object_alloc>:

extern void * z_vrfy_k_object_alloc(enum k_objects otype);
uintptr_t z_mrsh_k_object_alloc(uintptr_t arg0, uintptr_t arg1, uintptr_t arg2,
		uintptr_t arg3, uintptr_t arg4, uintptr_t arg5, void *ssf)
{
	_current->syscall_frame = ssf;
    4f90:	4b02      	ldr	r3, [pc, #8]	; (4f9c <z_mrsh_k_object_alloc+0xc>)
	(void) arg3;	/* unused */
	(void) arg4;	/* unused */
	(void) arg5;	/* unused */
	void * ret = z_vrfy_k_object_alloc(*(enum k_objects*)&arg0)
;
	_current->syscall_frame = NULL;
    4f92:	689b      	ldr	r3, [r3, #8]
    4f94:	2000      	movs	r0, #0
    4f96:	f8c3 0084 	str.w	r0, [r3, #132]	; 0x84
	return (uintptr_t) ret;
}
    4f9a:	4770      	bx	lr
    4f9c:	20000524 	.word	0x20000524

00004fa0 <statics_init>:
	z_waitq_init(&h->wait_q);
	sys_heap_init(&h->heap, mem, bytes);
}

static int statics_init(struct device *unused)
{
    4fa0:	b538      	push	{r3, r4, r5, lr}
	ARG_UNUSED(unused);
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    4fa2:	4c06      	ldr	r4, [pc, #24]	; (4fbc <statics_init+0x1c>)
    4fa4:	4d06      	ldr	r5, [pc, #24]	; (4fc0 <statics_init+0x20>)
    4fa6:	42ac      	cmp	r4, r5
    4fa8:	d301      	bcc.n	4fae <statics_init+0xe>
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
	}
	return 0;
}
    4faa:	2000      	movs	r0, #0
    4fac:	bd38      	pop	{r3, r4, r5, pc}
		k_heap_init(h, h->heap.init_mem, h->heap.init_bytes);
    4fae:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
    4fb2:	4620      	mov	r0, r4
    4fb4:	f001 fc5e 	bl	6874 <k_heap_init>
	Z_STRUCT_SECTION_FOREACH(k_heap, h) {
    4fb8:	3414      	adds	r4, #20
    4fba:	e7f4      	b.n	4fa6 <statics_init+0x6>
    4fbc:	20002c88 	.word	0x20002c88
    4fc0:	20002c9c 	.word	0x20002c9c

00004fc4 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    4fc4:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    4fc8:	b923      	cbnz	r3, 4fd4 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    4fca:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    4fce:	f000 0001 	and.w	r0, r0, #1
    4fd2:	4770      	bx	lr
		return false;
    4fd4:	2000      	movs	r0, #0
}
    4fd6:	4770      	bx	lr

00004fd8 <Thread_send_b>:
	while (1)
    4fd8:	e7fe      	b.n	4fd8 <Thread_send_b>

00004fda <Thread_receive_b>:
	while (1)
    4fda:	e7fe      	b.n	4fda <Thread_receive_b>

00004fdc <k_sleep>:
{
    4fdc:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    4fe0:	4602      	mov	r2, r0
	ret = arch_is_user_context();
    4fe2:	f7ff ffef 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
    4fe6:	b120      	cbz	r0, 4ff2 <k_sleep+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    4fe8:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    4fea:	2688      	movs	r6, #136	; 0x88
	__asm__ volatile("svc %[svid]\n"
    4fec:	df03      	svc	3
}
    4fee:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    4ff2:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_k_sleep(timeout);
    4ff6:	4610      	mov	r0, r2
    4ff8:	f7fe bef0 	b.w	3ddc <z_impl_k_sleep>

00004ffc <gpio_pin_configure.constprop.0>:
static inline int gpio_pin_configure(struct device *port, gpio_pin_t pin,
    4ffc:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
	struct gpio_driver_data *data =
    5000:	68c7      	ldr	r7, [r0, #12]
	ret = gpio_config(port, pin, flags);
    5002:	f88d 1007 	strb.w	r1, [sp, #7]
static inline int gpio_pin_configure(struct device *port, gpio_pin_t pin,
    5006:	4604      	mov	r4, r0
    5008:	460d      	mov	r5, r1
    500a:	f7ff ffdb 	bl	4fc4 <arch_is_user_context>

extern int z_impl_gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags);
static inline int gpio_config(struct device * port, gpio_pin_t pin, gpio_flags_t flags)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    500e:	b180      	cbz	r0, 5032 <gpio_pin_configure.constprop.0+0x36>
	register uint32_t ret __asm__("r0") = arg1;
    5010:	4620      	mov	r0, r4
	register uint32_t r1 __asm__("r1") = arg2;
    5012:	f8dd 1007 	ldr.w	r1, [sp, #7]
	register uint32_t r2 __asm__("r2") = arg3;
    5016:	f240 6201 	movw	r2, #1537	; 0x601
	register uint32_t r6 __asm__("r6") = call_id;
    501a:	2644      	movs	r6, #68	; 0x44
	__asm__ volatile("svc %[svid]\n"
    501c:	df03      	svc	3
	if (ret != 0) {
    501e:	b928      	cbnz	r0, 502c <gpio_pin_configure.constprop.0+0x30>
		data->invert |= (gpio_port_pins_t)BIT(pin);
    5020:	2301      	movs	r3, #1
    5022:	fa03 f505 	lsl.w	r5, r3, r5
    5026:	683b      	ldr	r3, [r7, #0]
    5028:	432b      	orrs	r3, r5
    502a:	603b      	str	r3, [r7, #0]
}
    502c:	b002      	add	sp, #8
    502e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return api->pin_configure(port, pin, flags);
    5032:	68a3      	ldr	r3, [r4, #8]
    5034:	f89d 1007 	ldrb.w	r1, [sp, #7]
    5038:	681b      	ldr	r3, [r3, #0]
    503a:	f240 6201 	movw	r2, #1537	; 0x601
    503e:	4620      	mov	r0, r4
    5040:	4798      	blx	r3
		return (int) arch_syscall_invoke3(*(uintptr_t *)&port, *(uintptr_t *)&pin, *(uintptr_t *)&flags, K_SYSCALL_GPIO_CONFIG);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_config(port, pin, flags);
    5042:	e7ec      	b.n	501e <gpio_pin_configure.constprop.0+0x22>

00005044 <k_thread_create.constprop.0>:
static inline k_tid_t k_thread_create(struct k_thread * new_thread, k_thread_stack_t * stack, size_t stack_size, k_thread_entry_t entry, void * p1, void * p2, void * p3, int prio, uint32_t options, k_timeout_t delay)
    5044:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5048:	b08e      	sub	sp, #56	; 0x38
    504a:	4616      	mov	r6, r2
    504c:	4605      	mov	r5, r0
    504e:	e9dd 7214 	ldrd	r7, r2, [sp, #80]	; 0x50
    5052:	f7ff ffb7 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
    5056:	b188      	cbz	r0, 507c <k_thread_create.constprop.0+0x38>
		uintptr_t more[] = {
    5058:	2400      	movs	r4, #0
    505a:	2305      	movs	r3, #5
    505c:	e9cd 340a 	strd	r3, r4, [sp, #40]	; 0x28
    5060:	e9cd 720c 	strd	r7, r2, [sp, #48]	; 0x30
	register uint32_t ret __asm__("r0") = arg1;
    5064:	4628      	mov	r0, r5
	register uint32_t r3 __asm__("r3") = arg4;
    5066:	4633      	mov	r3, r6
    5068:	e9cd 4408 	strd	r4, r4, [sp, #32]
	register uint32_t r2 __asm__("r2") = arg3;
    506c:	f44f 7200 	mov.w	r2, #512	; 0x200
	register uint32_t r5 __asm__("r5") = arg6;
    5070:	ad08      	add	r5, sp, #32
	register uint32_t r6 __asm__("r6") = call_id;
    5072:	268e      	movs	r6, #142	; 0x8e
	__asm__ volatile("svc %[svid]\n"
    5074:	df03      	svc	3
}
    5076:	b00e      	add	sp, #56	; 0x38
    5078:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
    507c:	2305      	movs	r3, #5
    507e:	e9cd 0302 	strd	r0, r3, [sp, #8]
    5082:	e9cd 7206 	strd	r7, r2, [sp, #24]
    5086:	e9cd 0000 	strd	r0, r0, [sp]
    508a:	9004      	str	r0, [sp, #16]
    508c:	4633      	mov	r3, r6
    508e:	f44f 7200 	mov.w	r2, #512	; 0x200
    5092:	4628      	mov	r0, r5
    5094:	f001 f885 	bl	61a2 <z_impl_k_thread_create>
    5098:	e7ed      	b.n	5076 <k_thread_create.constprop.0+0x32>

0000509a <k_thread_name_set>:
{
    509a:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    509e:	4602      	mov	r2, r0
    50a0:	f7ff ff90 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
    50a4:	b120      	cbz	r0, 50b0 <k_thread_name_set+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    50a6:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    50a8:	2694      	movs	r6, #148	; 0x94
	__asm__ volatile("svc %[svid]\n"
    50aa:	df03      	svc	3
}
    50ac:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    50b0:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	return z_impl_k_thread_name_set(thread_id, value);
    50b4:	4610      	mov	r0, r2
    50b6:	f001 b86a 	b.w	618e <z_impl_k_thread_name_set>

000050ba <gpio_port_clear_bits_raw>:
}


extern int z_impl_gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins);
static inline int gpio_port_clear_bits_raw(struct device * port, gpio_port_pins_t pins)
{
    50ba:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    50be:	4602      	mov	r2, r0
    50c0:	f7ff ff80 	bl	4fc4 <arch_is_user_context>
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    50c4:	b120      	cbz	r0, 50d0 <gpio_port_clear_bits_raw+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    50c6:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    50c8:	2647      	movs	r6, #71	; 0x47
	__asm__ volatile("svc %[svid]\n"
    50ca:	df03      	svc	3
		return (int) arch_syscall_invoke2(*(uintptr_t *)&port, *(uintptr_t *)&pins, K_SYSCALL_GPIO_PORT_CLEAR_BITS_RAW);
	}
#endif
	compiler_barrier();
	return z_impl_gpio_port_clear_bits_raw(port, pins);
}
    50cc:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return api->port_clear_bits_raw(port, pins);
    50d0:	6893      	ldr	r3, [r2, #8]
    50d2:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
    50d6:	691b      	ldr	r3, [r3, #16]
    50d8:	4610      	mov	r0, r2
    50da:	4718      	bx	r3

000050dc <gpio_port_set_bits_raw>:
{
    50dc:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    50e0:	4602      	mov	r2, r0
    50e2:	f7ff ff6f 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
    50e6:	b120      	cbz	r0, 50f2 <gpio_port_set_bits_raw+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    50e8:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    50ea:	2649      	movs	r6, #73	; 0x49
	__asm__ volatile("svc %[svid]\n"
    50ec:	df03      	svc	3
}
    50ee:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
	return api->port_set_bits_raw(port, pins);
    50f2:	6893      	ldr	r3, [r2, #8]
    50f4:	e8bd 4150 	ldmia.w	sp!, {r4, r6, r8, lr}
    50f8:	68db      	ldr	r3, [r3, #12]
    50fa:	4610      	mov	r0, r2
    50fc:	4718      	bx	r3

000050fe <k_thread_suspend>:
{
    50fe:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    5102:	4602      	mov	r2, r0
    5104:	f7ff ff5e 	bl	4fc4 <arch_is_user_context>
	if (z_syscall_trap()) {
    5108:	b120      	cbz	r0, 5114 <k_thread_suspend+0x16>
	register uint32_t ret __asm__("r0") = arg1;
    510a:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    510c:	269a      	movs	r6, #154	; 0x9a
	__asm__ volatile("svc %[svid]\n"
    510e:	df03      	svc	3
}
    5110:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    5114:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_thread_suspend(thread);
    5118:	4610      	mov	r0, r2
    511a:	f7fe bc13 	b.w	3944 <z_impl_k_thread_suspend>

0000511e <sys_notify_validate>:

int sys_notify_validate(struct sys_notify *notify)
{
	int rv = 0;

	if (notify == NULL) {
    511e:	4603      	mov	r3, r0
    5120:	b140      	cbz	r0, 5134 <sys_notify_validate+0x16>
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    5122:	6842      	ldr	r2, [r0, #4]
	return method & SYS_NOTIFY_METHOD_MASK;
    5124:	f002 0203 	and.w	r2, r2, #3
		return -EINVAL;
	}

	/* Validate configuration based on mode */
	switch (sys_notify_get_method(notify)) {
    5128:	2a02      	cmp	r2, #2
    512a:	d006      	beq.n	513a <sys_notify_validate+0x1c>
    512c:	2a03      	cmp	r2, #3
    512e:	d004      	beq.n	513a <sys_notify_validate+0x1c>
    5130:	2a01      	cmp	r2, #1
    5132:	d005      	beq.n	5140 <sys_notify_validate+0x22>
		return -EINVAL;
    5134:	f06f 0015 	mvn.w	r0, #21
	if (rv == 0) {
		notify->result = 0;
	}

	return rv;
}
    5138:	4770      	bx	lr
		if (notify->method.signal == NULL) {
    513a:	681a      	ldr	r2, [r3, #0]
    513c:	2a00      	cmp	r2, #0
    513e:	d0f9      	beq.n	5134 <sys_notify_validate+0x16>
		notify->result = 0;
    5140:	2000      	movs	r0, #0
    5142:	6098      	str	r0, [r3, #8]
    5144:	4770      	bx	lr

00005146 <sys_notify_finalize>:
	uint32_t method = notify->flags >> SYS_NOTIFY_METHOD_POS;
    5146:	6842      	ldr	r2, [r0, #4]
	return method & SYS_NOTIFY_METHOD_MASK;
    5148:	f002 0203 	and.w	r2, r2, #3

	/* Store the result and capture secondary notification
	 * information.
	 */
	notify->result = res;
	switch (method) {
    514c:	2a02      	cmp	r2, #2
{
    514e:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
    5152:	4603      	mov	r3, r0
	notify->result = res;
    5154:	6081      	str	r1, [r0, #8]
	switch (method) {
    5156:	d012      	beq.n	517e <sys_notify_finalize+0x38>
    5158:	2a03      	cmp	r2, #3
    515a:	d113      	bne.n	5184 <sys_notify_finalize+0x3e>
	case SYS_NOTIFY_METHOD_SPINWAIT:
		break;
	case SYS_NOTIFY_METHOD_CALLBACK:
		rv = notify->method.callback;
    515c:	6804      	ldr	r4, [r0, #0]
	struct k_poll_signal *sig = NULL;
    515e:	2000      	movs	r0, #0
	/* Mark completion by clearing the flags field to the
	 * completed state, releasing any spin-waiters, then complete
	 * secondary notification.
	 */
	compiler_barrier();
	notify->flags = SYS_NOTIFY_METHOD_COMPLETED;
    5160:	2200      	movs	r2, #0
    5162:	605a      	str	r2, [r3, #4]

	if (IS_ENABLED(CONFIG_POLL) && (sig != NULL)) {
    5164:	b140      	cbz	r0, 5178 <sys_notify_finalize+0x32>
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5166:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    516a:	b973      	cbnz	r3, 518a <sys_notify_finalize+0x44>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    516c:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    5170:	07db      	lsls	r3, r3, #31
    5172:	d50a      	bpl.n	518a <sys_notify_finalize+0x44>
	register uint32_t r6 __asm__("r6") = call_id;
    5174:	2679      	movs	r6, #121	; 0x79
	__asm__ volatile("svc %[svid]\n"
    5176:	df03      	svc	3
		k_poll_signal_raise(sig, res);
	}

	return rv;
}
    5178:	4620      	mov	r0, r4
    517a:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
		sig = notify->method.signal;
    517e:	6800      	ldr	r0, [r0, #0]
	sys_notify_generic_callback rv = 0;
    5180:	2400      	movs	r4, #0
		break;
    5182:	e7ed      	b.n	5160 <sys_notify_finalize+0x1a>
	switch (method) {
    5184:	2400      	movs	r4, #0
    5186:	4620      	mov	r0, r4
    5188:	e7ea      	b.n	5160 <sys_notify_finalize+0x1a>
	return z_impl_k_poll_signal_raise(signal, result);
    518a:	f7ff fd7f 	bl	4c8c <z_impl_k_poll_signal_raise>
	return rv;
    518e:	e7f3      	b.n	5178 <sys_notify_finalize+0x32>

00005190 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5190:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5194:	b923      	cbnz	r3, 51a0 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5196:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    519a:	f000 0001 	and.w	r0, r0, #1
    519e:	4770      	bx	lr
		return false;
    51a0:	2000      	movs	r0, #0
}
    51a2:	4770      	bx	lr

000051a4 <arch_printk_char_out>:
}
    51a4:	2000      	movs	r0, #0
    51a6:	4770      	bx	lr

000051a8 <buf_flush>:
{
    51a8:	e92d 4150 	stmdb	sp!, {r4, r6, r8, lr}
	k_str_out(ctx->buf, ctx->buf_count);
    51ac:	6841      	ldr	r1, [r0, #4]
{
    51ae:	4604      	mov	r4, r0
	k_str_out(ctx->buf, ctx->buf_count);
    51b0:	f100 0208 	add.w	r2, r0, #8
    51b4:	f7ff ffec 	bl	5190 <arch_is_user_context>

extern void z_impl_k_str_out(char * c, size_t n);
static inline void k_str_out(char * c, size_t n)
{
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    51b8:	b130      	cbz	r0, 51c8 <buf_flush+0x20>
	register uint32_t ret __asm__("r0") = arg1;
    51ba:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    51bc:	268c      	movs	r6, #140	; 0x8c
	__asm__ volatile("svc %[svid]\n"
    51be:	df03      	svc	3
	ctx->buf_count = 0U;
    51c0:	2300      	movs	r3, #0
    51c2:	6063      	str	r3, [r4, #4]
}
    51c4:	e8bd 8150 	ldmia.w	sp!, {r4, r6, r8, pc}
		arch_syscall_invoke2(*(uintptr_t *)&c, *(uintptr_t *)&n, K_SYSCALL_K_STR_OUT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_str_out(c, n);
    51c8:	4610      	mov	r0, r2
    51ca:	f7fb fc8f 	bl	aec <z_impl_k_str_out>
    51ce:	e7f7      	b.n	51c0 <buf_flush+0x18>

000051d0 <buf_char_out>:
	ctx->count++;
    51d0:	680b      	ldr	r3, [r1, #0]
    51d2:	3301      	adds	r3, #1
    51d4:	600b      	str	r3, [r1, #0]
	ctx->buf[ctx->buf_count++] = c;
    51d6:	684b      	ldr	r3, [r1, #4]
    51d8:	1c5a      	adds	r2, r3, #1
    51da:	440b      	add	r3, r1
{
    51dc:	b510      	push	{r4, lr}
	if (ctx->buf_count == CONFIG_PRINTK_BUFFER_SIZE) {
    51de:	2a20      	cmp	r2, #32
{
    51e0:	4604      	mov	r4, r0
	ctx->buf[ctx->buf_count++] = c;
    51e2:	604a      	str	r2, [r1, #4]
{
    51e4:	4608      	mov	r0, r1
	ctx->buf[ctx->buf_count++] = c;
    51e6:	721c      	strb	r4, [r3, #8]
	if (ctx->buf_count == CONFIG_PRINTK_BUFFER_SIZE) {
    51e8:	d101      	bne.n	51ee <buf_char_out+0x1e>
		buf_flush(ctx);
    51ea:	f7ff ffdd 	bl	51a8 <buf_flush>
}
    51ee:	4620      	mov	r0, r4
    51f0:	bd10      	pop	{r4, pc}

000051f2 <printk>:
 * @param fmt formatted string to output
 *
 * @return N/A
 */
void printk(const char *fmt, ...)
{
    51f2:	b40f      	push	{r0, r1, r2, r3}
    51f4:	b507      	push	{r0, r1, r2, lr}
    51f6:	a904      	add	r1, sp, #16
    51f8:	f851 0b04 	ldr.w	r0, [r1], #4
	va_list ap;

	va_start(ap, fmt);
    51fc:	9101      	str	r1, [sp, #4]

	if (IS_ENABLED(CONFIG_LOG_PRINTK)) {
		log_printk(fmt, ap);
	} else {
		vprintk(fmt, ap);
    51fe:	f7fb fc83 	bl	b08 <vprintk>
	}
	va_end(ap);
}
    5202:	b003      	add	sp, #12
    5204:	f85d eb04 	ldr.w	lr, [sp], #4
    5208:	b004      	add	sp, #16
    520a:	4770      	bx	lr

0000520c <process_recheck>:
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    520c:	8b03      	ldrh	r3, [r0, #24]
	if ((state == ONOFF_STATE_OFF)
    520e:	f013 0307 	ands.w	r3, r3, #7
    5212:	d105      	bne.n	5220 <process_recheck+0x14>
	    && !sys_slist_is_empty(&mgr->clients)) {
    5214:	6803      	ldr	r3, [r0, #0]
    5216:	2b00      	cmp	r3, #0
		evt = EVT_START;
    5218:	bf0c      	ite	eq
    521a:	2000      	moveq	r0, #0
    521c:	2003      	movne	r0, #3
    521e:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ON)
    5220:	2b02      	cmp	r3, #2
    5222:	d105      	bne.n	5230 <process_recheck+0x24>
		   && (mgr->refs == 0)) {
    5224:	8b43      	ldrh	r3, [r0, #26]
    5226:	2b00      	cmp	r3, #0
		evt = EVT_STOP;
    5228:	bf14      	ite	ne
    522a:	2000      	movne	r0, #0
    522c:	2004      	moveq	r0, #4
    522e:	4770      	bx	lr
	} else if ((state == ONOFF_STATE_ERROR)
    5230:	2b01      	cmp	r3, #1
    5232:	d105      	bne.n	5240 <process_recheck+0x34>
		   && !sys_slist_is_empty(&mgr->clients)) {
    5234:	6803      	ldr	r3, [r0, #0]
    5236:	2b00      	cmp	r3, #0
		evt = EVT_RESET;
    5238:	bf0c      	ite	eq
    523a:	2000      	moveq	r0, #0
    523c:	2005      	movne	r0, #5
    523e:	4770      	bx	lr
	int evt = EVT_NOP;
    5240:	2000      	movs	r0, #0
}
    5242:	4770      	bx	lr

00005244 <validate_args>:
{
    5244:	b510      	push	{r4, lr}
    5246:	460c      	mov	r4, r1
	if ((mgr == NULL) || (cli == NULL)) {
    5248:	b140      	cbz	r0, 525c <validate_args+0x18>
    524a:	b139      	cbz	r1, 525c <validate_args+0x18>
	int rv = sys_notify_validate(&cli->notify);
    524c:	1d08      	adds	r0, r1, #4
    524e:	f7ff ff66 	bl	511e <sys_notify_validate>
	if ((rv == 0)
    5252:	b928      	cbnz	r0, 5260 <validate_args+0x1c>
	    && ((cli->notify.flags
    5254:	68a3      	ldr	r3, [r4, #8]
    5256:	f033 0303 	bics.w	r3, r3, #3
    525a:	d001      	beq.n	5260 <validate_args+0x1c>
		rv = -EINVAL;
    525c:	f06f 0015 	mvn.w	r0, #21
}
    5260:	bd10      	pop	{r4, pc}

00005262 <transition_complete>:
{
    5262:	b410      	push	{r4}
	__asm__ volatile(
    5264:	f04f 0420 	mov.w	r4, #32
    5268:	f3ef 8211 	mrs	r2, BASEPRI
    526c:	f384 8811 	msr	BASEPRI, r4
    5270:	f3bf 8f6f 	isb	sy
	mgr->last_res = res;
    5274:	6141      	str	r1, [r0, #20]
}
    5276:	bc10      	pop	{r4}
	process_event(mgr, EVT_COMPLETE, key);
    5278:	2101      	movs	r1, #1
    527a:	f7fb bc8b 	b.w	b94 <process_event>

0000527e <onoff_manager_init>:
{
    527e:	b538      	push	{r3, r4, r5, lr}
    5280:	460c      	mov	r4, r1
	if ((mgr == NULL)
    5282:	4605      	mov	r5, r0
    5284:	b158      	cbz	r0, 529e <onoff_manager_init+0x20>
	    || (transitions == NULL)
    5286:	b151      	cbz	r1, 529e <onoff_manager_init+0x20>
	    || (transitions->start == NULL)
    5288:	680b      	ldr	r3, [r1, #0]
    528a:	b143      	cbz	r3, 529e <onoff_manager_init+0x20>
	    || (transitions->stop == NULL)) {
    528c:	684b      	ldr	r3, [r1, #4]
    528e:	b133      	cbz	r3, 529e <onoff_manager_init+0x20>
	*mgr = (struct onoff_manager)ONOFF_MANAGER_INITIALIZER(transitions);
    5290:	221c      	movs	r2, #28
    5292:	2100      	movs	r1, #0
    5294:	f000 fc4c 	bl	5b30 <memset>
    5298:	612c      	str	r4, [r5, #16]
	return 0;
    529a:	2000      	movs	r0, #0
}
    529c:	bd38      	pop	{r3, r4, r5, pc}
		return -EINVAL;
    529e:	f06f 0015 	mvn.w	r0, #21
    52a2:	e7fb      	b.n	529c <onoff_manager_init+0x1e>

000052a4 <onoff_request>:

int onoff_request(struct onoff_manager *mgr,
		  struct onoff_client *cli)
{
    52a4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    52a8:	4604      	mov	r4, r0
    52aa:	460d      	mov	r5, r1
	bool add_client = false;        /* add client to pending list */
	bool start = false;             /* trigger a start transition */
	bool notify = false;            /* do client notification */
	int rv = validate_args(mgr, cli);
    52ac:	f7ff ffca 	bl	5244 <validate_args>

	if (rv < 0) {
    52b0:	1e06      	subs	r6, r0, #0
    52b2:	db36      	blt.n	5322 <onoff_request+0x7e>
    52b4:	f04f 0320 	mov.w	r3, #32
    52b8:	f3ef 8211 	mrs	r2, BASEPRI
    52bc:	f383 8811 	msr	BASEPRI, r3
    52c0:	f3bf 8f6f 	isb	sy

	k_spinlock_key_t key = k_spin_lock(&mgr->lock);
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;

	/* Reject if this would overflow the reference count. */
	if (mgr->refs == SERVICE_REFS_MAX) {
    52c4:	8b63      	ldrh	r3, [r4, #26]
	uint32_t state = mgr->flags & ONOFF_STATE_MASK;
    52c6:	8b21      	ldrh	r1, [r4, #24]
	if (mgr->refs == SERVICE_REFS_MAX) {
    52c8:	f64f 70ff 	movw	r0, #65535	; 0xffff
    52cc:	4283      	cmp	r3, r0
    52ce:	f001 0707 	and.w	r7, r1, #7
    52d2:	d034      	beq.n	533e <onoff_request+0x9a>
		rv = -EAGAIN;
		goto out;
	}

	rv = state;
	if (state == ONOFF_STATE_ON) {
    52d4:	2f02      	cmp	r7, #2
    52d6:	d114      	bne.n	5302 <onoff_request+0x5e>
		/* Increment reference count, notify in exit */
		notify = true;
		mgr->refs += 1U;
    52d8:	3301      	adds	r3, #1
    52da:	8363      	strh	r3, [r4, #26]
	rv = state;
    52dc:	463e      	mov	r6, r7
		notify = true;
    52de:	2301      	movs	r3, #1
	__asm__ volatile(
    52e0:	f382 8811 	msr	BASEPRI, r2
    52e4:	f3bf 8f6f 	isb	sy
	if (start) {
		process_event(mgr, EVT_RECHECK, key);
	} else {
		k_spin_unlock(&mgr->lock, key);

		if (notify) {
    52e8:	b1db      	cbz	r3, 5322 <onoff_request+0x7e>
		(onoff_client_callback)sys_notify_finalize(&cli->notify, res);
    52ea:	2100      	movs	r1, #0
    52ec:	1d28      	adds	r0, r5, #4
    52ee:	f7ff ff2a 	bl	5146 <sys_notify_finalize>
	if (cb) {
    52f2:	4680      	mov	r8, r0
    52f4:	b1a8      	cbz	r0, 5322 <onoff_request+0x7e>
		cb(mgr, cli, state, res);
    52f6:	2300      	movs	r3, #0
    52f8:	463a      	mov	r2, r7
    52fa:	4629      	mov	r1, r5
    52fc:	4620      	mov	r0, r4
    52fe:	47c0      	blx	r8
    5300:	e00f      	b.n	5322 <onoff_request+0x7e>
	} else if ((state == ONOFF_STATE_OFF)
    5302:	078b      	lsls	r3, r1, #30
    5304:	d001      	beq.n	530a <onoff_request+0x66>
		   || (state == ONOFF_STATE_TO_ON)) {
    5306:	2f06      	cmp	r7, #6
    5308:	d10e      	bne.n	5328 <onoff_request+0x84>
	parent->next = child;
    530a:	2300      	movs	r3, #0
    530c:	602b      	str	r3, [r5, #0]
Z_GENLIST_APPEND(slist, snode)
    530e:	6863      	ldr	r3, [r4, #4]
    5310:	b993      	cbnz	r3, 5338 <onoff_request+0x94>
	list->head = node;
    5312:	e9c4 5500 	strd	r5, r5, [r4]
	if (start) {
    5316:	463e      	mov	r6, r7
    5318:	b967      	cbnz	r7, 5334 <onoff_request+0x90>
		process_event(mgr, EVT_RECHECK, key);
    531a:	2102      	movs	r1, #2
    531c:	4620      	mov	r0, r4
    531e:	f7fb fc39 	bl	b94 <process_event>
			notify_one(mgr, cli, state, 0);
		}
	}

	return rv;
}
    5322:	4630      	mov	r0, r6
    5324:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		rv = -EIO;
    5328:	2f05      	cmp	r7, #5
    532a:	bf0c      	ite	eq
    532c:	f06f 0622 	mvneq.w	r6, #34	; 0x22
    5330:	f06f 0604 	mvnne.w	r6, #4
    5334:	2300      	movs	r3, #0
    5336:	e7d3      	b.n	52e0 <onoff_request+0x3c>
	parent->next = child;
    5338:	601d      	str	r5, [r3, #0]
	list->tail = node;
    533a:	6065      	str	r5, [r4, #4]
}
    533c:	e7eb      	b.n	5316 <onoff_request+0x72>
		rv = -EAGAIN;
    533e:	f06f 060a 	mvn.w	r6, #10
    5342:	e7f7      	b.n	5334 <onoff_request+0x90>

00005344 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
    5344:	4604      	mov	r4, r0
    5346:	b508      	push	{r3, lr}
    5348:	4608      	mov	r0, r1
    534a:	4611      	mov	r1, r2
	entry(p1, p2, p3);
    534c:	461a      	mov	r2, r3
    534e:	47a0      	blx	r4
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5350:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5354:	b973      	cbnz	r3, 5374 <z_thread_entry+0x30>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5356:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    535a:	07da      	lsls	r2, r3, #31
    535c:	d50a      	bpl.n	5374 <z_thread_entry+0x30>
	register uint32_t r6 __asm__("r6") = call_id;
    535e:	265e      	movs	r6, #94	; 0x5e
	__asm__ volatile("svc %[svid]\n"
    5360:	df03      	svc	3
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5362:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5366:	b943      	cbnz	r3, 537a <z_thread_entry+0x36>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5368:	f3ef 8314 	mrs	r3, CONTROL
	if (z_syscall_trap()) {
    536c:	07db      	lsls	r3, r3, #31
    536e:	d504      	bpl.n	537a <z_thread_entry+0x36>
	register uint32_t r6 __asm__("r6") = call_id;
    5370:	268d      	movs	r6, #141	; 0x8d
	__asm__ volatile("svc %[svid]\n"
    5372:	df03      	svc	3
	return z_impl_k_current_get();
    5374:	f7fe fdba 	bl	3eec <z_impl_k_current_get>
    5378:	e7f3      	b.n	5362 <z_thread_entry+0x1e>
	z_impl_k_thread_abort(thread);
    537a:	f7fc fc19 	bl	1bb0 <z_impl_k_thread_abort>
    537e:	e7f9      	b.n	5374 <z_thread_entry+0x30>

00005380 <chunk_field>:
				 enum chunk_fields f)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    5380:	6883      	ldr	r3, [r0, #8]
	void *cmem = &buf[c];
    5382:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    5386:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
		return ((uint32_t *)cmem)[f];
    538a:	bf2c      	ite	cs
    538c:	f851 0022 	ldrcs.w	r0, [r1, r2, lsl #2]
	} else {
		return ((uint16_t *)cmem)[f];
    5390:	f831 0012 	ldrhcc.w	r0, [r1, r2, lsl #1]
	}
}
    5394:	4770      	bx	lr

00005396 <chunk_set>:
			     enum chunk_fields f, chunkid_t val)
{
	CHECK(c <= h->len);

	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];
    5396:	eb00 01c1 	add.w	r1, r0, r1, lsl #3

	if (big_heap(h)) {
    539a:	6880      	ldr	r0, [r0, #8]
    539c:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
		CHECK(val == (uint32_t)val);
		((uint32_t *)cmem)[f] = val;
    53a0:	bf2c      	ite	cs
    53a2:	f841 3022 	strcs.w	r3, [r1, r2, lsl #2]
	} else {
		CHECK(val == (uint16_t)val);
		((uint16_t *)cmem)[f] = val;
    53a6:	f821 3012 	strhcc.w	r3, [r1, r2, lsl #1]
	}
}
    53aa:	4770      	bx	lr

000053ac <chunk_size>:
{
	return chunk_field(h, c, SIZE_AND_USED) & 1;
}

static inline size_t chunk_size(struct z_heap *h, chunkid_t c)
{
    53ac:	b508      	push	{r3, lr}
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
    53ae:	2201      	movs	r2, #1
    53b0:	f7ff ffe6 	bl	5380 <chunk_field>
}
    53b4:	0840      	lsrs	r0, r0, #1
    53b6:	bd08      	pop	{r3, pc}

000053b8 <set_chunk_used>:
static inline void set_chunk_used(struct z_heap *h, chunkid_t c, bool used)
{
	chunk_unit_t *buf = chunk_buf(h);
	void *cmem = &buf[c];

	if (big_heap(h)) {
    53b8:	6883      	ldr	r3, [r0, #8]
    53ba:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
	void *cmem = &buf[c];
    53be:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
	if (big_heap(h)) {
    53c2:	d308      	bcc.n	53d6 <set_chunk_used+0x1e>
		if (used) {
    53c4:	684b      	ldr	r3, [r1, #4]
    53c6:	b11a      	cbz	r2, 53d0 <set_chunk_used+0x18>
			((uint32_t *)cmem)[SIZE_AND_USED] |= 1;
    53c8:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint32_t *)cmem)[SIZE_AND_USED] &= ~1;
    53cc:	604b      	str	r3, [r1, #4]
    53ce:	4770      	bx	lr
    53d0:	f023 0301 	bic.w	r3, r3, #1
    53d4:	e7fa      	b.n	53cc <set_chunk_used+0x14>
		}
	} else {
		if (used) {
    53d6:	884b      	ldrh	r3, [r1, #2]
    53d8:	b11a      	cbz	r2, 53e2 <set_chunk_used+0x2a>
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1;
    53da:	f043 0301 	orr.w	r3, r3, #1
		} else {
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    53de:	804b      	strh	r3, [r1, #2]
		}
	}
}
    53e0:	4770      	bx	lr
			((uint16_t *)cmem)[SIZE_AND_USED] &= ~1;
    53e2:	f023 0301 	bic.w	r3, r3, #1
    53e6:	e7fa      	b.n	53de <set_chunk_used+0x26>

000053e8 <set_chunk_size>:
 * when its size is modified, and potential set_chunk_used() is always
 * invoked after set_chunk_size().
 */
static inline void set_chunk_size(struct z_heap *h, chunkid_t c, size_t size)
{
	chunk_set(h, c, SIZE_AND_USED, size << 1);
    53e8:	0053      	lsls	r3, r2, #1
    53ea:	2201      	movs	r2, #1
    53ec:	f7ff bfd3 	b.w	5396 <chunk_set>

000053f0 <bucket_idx>:
	return big_heap(h) && chunk_size(h, c) == 1;
}

static inline size_t chunk_header_bytes(struct z_heap *h)
{
	return big_heap(h) ? 8 : 4;
    53f0:	6880      	ldr	r0, [r0, #8]
	return bytes_to_chunksz(h, 1);
}

static inline int bucket_idx(struct z_heap *h, size_t sz)
{
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    53f2:	3101      	adds	r1, #1
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    53f4:	f5b0 4f00 	cmp.w	r0, #32768	; 0x8000
    53f8:	bf2c      	ite	cs
    53fa:	2002      	movcs	r0, #2
    53fc:	2001      	movcc	r0, #1
	size_t usable_sz = sz - min_chunk_size(h) + 1;
    53fe:	1a08      	subs	r0, r1, r0
	return 31 - __builtin_clz(usable_sz);
    5400:	fab0 f080 	clz	r0, r0
}
    5404:	f1c0 001f 	rsb	r0, r0, #31
    5408:	4770      	bx	lr

0000540a <merge_chunks>:
	set_left_chunk_size(h, right_chunk(h, rc), rsz);
}

/* Does not modify free list */
static void merge_chunks(struct z_heap *h, chunkid_t lc, chunkid_t rc)
{
    540a:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    540e:	4616      	mov	r6, r2
    5410:	4604      	mov	r4, r0
    5412:	460f      	mov	r7, r1
	size_t newsz = chunk_size(h, lc) + chunk_size(h, rc);
    5414:	f7ff ffca 	bl	53ac <chunk_size>
    5418:	4631      	mov	r1, r6
    541a:	4605      	mov	r5, r0
    541c:	4620      	mov	r0, r4
    541e:	f7ff ffc5 	bl	53ac <chunk_size>
    5422:	4405      	add	r5, r0

	set_chunk_size(h, lc, newsz);
    5424:	462a      	mov	r2, r5
    5426:	4639      	mov	r1, r7
    5428:	4620      	mov	r0, r4
    542a:	f7ff ffdd 	bl	53e8 <set_chunk_size>
	return c + chunk_size(h, c);
    542e:	4631      	mov	r1, r6
    5430:	4620      	mov	r0, r4
    5432:	f7ff ffbb 	bl	53ac <chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5436:	462b      	mov	r3, r5
    5438:	1831      	adds	r1, r6, r0
    543a:	2200      	movs	r2, #0
    543c:	4620      	mov	r0, r4
	set_left_chunk_size(h, right_chunk(h, rc), newsz);
}
    543e:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5442:	f7ff bfa8 	b.w	5396 <chunk_set>

00005446 <split_chunks>:
{
    5446:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    544a:	4614      	mov	r4, r2
    544c:	4605      	mov	r5, r0
    544e:	460e      	mov	r6, r1
	size_t sz0 = chunk_size(h, lc);
    5450:	f7ff ffac 	bl	53ac <chunk_size>
	size_t lsz = rc - lc;
    5454:	eba4 0806 	sub.w	r8, r4, r6
	size_t rsz = sz0 - lsz;
    5458:	1b37      	subs	r7, r6, r4
    545a:	4407      	add	r7, r0
	set_chunk_size(h, lc, lsz);
    545c:	4642      	mov	r2, r8
    545e:	4631      	mov	r1, r6
    5460:	4628      	mov	r0, r5
    5462:	f7ff ffc1 	bl	53e8 <set_chunk_size>
	set_chunk_size(h, rc, rsz);
    5466:	463a      	mov	r2, r7
    5468:	4621      	mov	r1, r4
    546a:	4628      	mov	r0, r5
    546c:	f7ff ffbc 	bl	53e8 <set_chunk_size>
    5470:	4643      	mov	r3, r8
    5472:	2200      	movs	r2, #0
    5474:	4621      	mov	r1, r4
    5476:	4628      	mov	r0, r5
    5478:	f7ff ff8d 	bl	5396 <chunk_set>
	return c + chunk_size(h, c);
    547c:	4621      	mov	r1, r4
    547e:	4628      	mov	r0, r5
    5480:	f7ff ff94 	bl	53ac <chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    5484:	463b      	mov	r3, r7
    5486:	1821      	adds	r1, r4, r0
    5488:	2200      	movs	r2, #0
    548a:	4628      	mov	r0, r5
}
    548c:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    5490:	f7ff bf81 	b.w	5396 <chunk_set>

00005494 <free_list_remove_bidx>:
{
    5494:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    5498:	4617      	mov	r7, r2
	return chunk_field(h, c, FREE_NEXT);
    549a:	2203      	movs	r2, #3
    549c:	460e      	mov	r6, r1
    549e:	4604      	mov	r4, r0
    54a0:	f7ff ff6e 	bl	5380 <chunk_field>
	if (next_free_chunk(h, c) == c) {
    54a4:	4286      	cmp	r6, r0
    54a6:	4605      	mov	r5, r0
    54a8:	f107 0804 	add.w	r8, r7, #4
    54ac:	d10b      	bne.n	54c6 <free_list_remove_bidx+0x32>
		h->avail_buckets &= ~(1 << bidx);
    54ae:	2301      	movs	r3, #1
    54b0:	fa03 f707 	lsl.w	r7, r3, r7
    54b4:	68e3      	ldr	r3, [r4, #12]
    54b6:	ea23 0307 	bic.w	r3, r3, r7
    54ba:	60e3      	str	r3, [r4, #12]
		b->next = 0;
    54bc:	2300      	movs	r3, #0
    54be:	f844 3028 	str.w	r3, [r4, r8, lsl #2]
}
    54c2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return chunk_field(h, c, FREE_PREV);
    54c6:	4631      	mov	r1, r6
    54c8:	2202      	movs	r2, #2
    54ca:	4620      	mov	r0, r4
    54cc:	f7ff ff58 	bl	5380 <chunk_field>
	chunk_set(h, c, FREE_NEXT, next);
    54d0:	462b      	mov	r3, r5
	return chunk_field(h, c, FREE_PREV);
    54d2:	4606      	mov	r6, r0
	chunk_set(h, c, FREE_NEXT, next);
    54d4:	4601      	mov	r1, r0
		b->next = second;
    54d6:	f844 5028 	str.w	r5, [r4, r8, lsl #2]
    54da:	4620      	mov	r0, r4
    54dc:	2203      	movs	r2, #3
    54de:	f7ff ff5a 	bl	5396 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    54e2:	4633      	mov	r3, r6
    54e4:	4629      	mov	r1, r5
    54e6:	4620      	mov	r0, r4
    54e8:	2202      	movs	r2, #2
}
    54ea:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    54ee:	f7ff bf52 	b.w	5396 <chunk_set>

000054f2 <free_list_remove>:
{
    54f2:	b538      	push	{r3, r4, r5, lr}
    54f4:	4604      	mov	r4, r0
    54f6:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    54f8:	f7ff ff58 	bl	53ac <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    54fc:	68a3      	ldr	r3, [r4, #8]
    54fe:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5502:	4601      	mov	r1, r0
    5504:	d301      	bcc.n	550a <free_list_remove+0x18>
	if (!solo_free_header(h, c)) {
    5506:	2801      	cmp	r0, #1
    5508:	d009      	beq.n	551e <free_list_remove+0x2c>
		int bidx = bucket_idx(h, chunk_size(h, c));
    550a:	4620      	mov	r0, r4
    550c:	f7ff ff70 	bl	53f0 <bucket_idx>
		free_list_remove_bidx(h, c, bidx);
    5510:	4629      	mov	r1, r5
		int bidx = bucket_idx(h, chunk_size(h, c));
    5512:	4602      	mov	r2, r0
		free_list_remove_bidx(h, c, bidx);
    5514:	4620      	mov	r0, r4
}
    5516:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		free_list_remove_bidx(h, c, bidx);
    551a:	f7ff bfbb 	b.w	5494 <free_list_remove_bidx>
}
    551e:	bd38      	pop	{r3, r4, r5, pc}

00005520 <alloc_chunk>:
	set_chunk_used(h, c, false);
	free_chunk(h, c);
}

static chunkid_t alloc_chunk(struct z_heap *h, size_t sz)
{
    5520:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    5524:	4604      	mov	r4, r0
    5526:	4688      	mov	r8, r1
	int bi = bucket_idx(h, sz);
    5528:	f7ff ff62 	bl	53f0 <bucket_idx>
	struct z_heap_bucket *b = &h->buckets[bi];

	if (bi > bucket_idx(h, h->len)) {
    552c:	68a1      	ldr	r1, [r4, #8]
	int bi = bucket_idx(h, sz);
    552e:	4605      	mov	r5, r0
	if (bi > bucket_idx(h, h->len)) {
    5530:	4620      	mov	r0, r4
    5532:	f7ff ff5d 	bl	53f0 <bucket_idx>
    5536:	42a8      	cmp	r0, r5
    5538:	da03      	bge.n	5542 <alloc_chunk+0x22>
		return 0;
    553a:	2600      	movs	r6, #0
		CHECK(chunk_size(h, c) >= sz);
		return c;
	}

	return 0;
}
    553c:	4630      	mov	r0, r6
    553e:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	if (b->next) {
    5542:	eb04 0a85 	add.w	sl, r4, r5, lsl #2
    5546:	f8da 9010 	ldr.w	r9, [sl, #16]
    554a:	f1b9 0f00 	cmp.w	r9, #0
    554e:	d019      	beq.n	5584 <alloc_chunk+0x64>
    5550:	2703      	movs	r7, #3
			chunkid_t c = b->next;
    5552:	f8da 6010 	ldr.w	r6, [sl, #16]
			if (chunk_size(h, c) >= sz) {
    5556:	4620      	mov	r0, r4
    5558:	4631      	mov	r1, r6
    555a:	f7ff ff27 	bl	53ac <chunk_size>
    555e:	4540      	cmp	r0, r8
    5560:	d305      	bcc.n	556e <alloc_chunk+0x4e>
				free_list_remove_bidx(h, c, bi);
    5562:	462a      	mov	r2, r5
		free_list_remove_bidx(h, c, minbucket);
    5564:	4631      	mov	r1, r6
    5566:	4620      	mov	r0, r4
    5568:	f7ff ff94 	bl	5494 <free_list_remove_bidx>
		return c;
    556c:	e7e6      	b.n	553c <alloc_chunk+0x1c>
	return chunk_field(h, c, FREE_NEXT);
    556e:	2203      	movs	r2, #3
    5570:	4631      	mov	r1, r6
    5572:	4620      	mov	r0, r4
    5574:	f7ff ff04 	bl	5380 <chunk_field>
		} while (--i && b->next != first);
    5578:	3f01      	subs	r7, #1
			b->next = next_free_chunk(h, c);
    557a:	f8ca 0010 	str.w	r0, [sl, #16]
		} while (--i && b->next != first);
    557e:	d001      	beq.n	5584 <alloc_chunk+0x64>
    5580:	4581      	cmp	r9, r0
    5582:	d1e6      	bne.n	5552 <alloc_chunk+0x32>
	size_t bmask = h->avail_buckets & ~((1 << (bi + 1)) - 1);
    5584:	68e3      	ldr	r3, [r4, #12]
    5586:	3501      	adds	r5, #1
    5588:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
    558c:	40aa      	lsls	r2, r5
	if ((bmask & h->avail_buckets) != 0) {
    558e:	401a      	ands	r2, r3
    5590:	d0d3      	beq.n	553a <alloc_chunk+0x1a>
		int minbucket = __builtin_ctz(bmask & h->avail_buckets);
    5592:	fa92 f2a2 	rbit	r2, r2
    5596:	fab2 f282 	clz	r2, r2
		chunkid_t c = h->buckets[minbucket].next;
    559a:	1d13      	adds	r3, r2, #4
    559c:	f854 6023 	ldr.w	r6, [r4, r3, lsl #2]
    55a0:	e7e0      	b.n	5564 <alloc_chunk+0x44>

000055a2 <free_list_add>:
{
    55a2:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    55a6:	4604      	mov	r4, r0
    55a8:	460d      	mov	r5, r1
	return sizeof(void *) > 4 || chunks > 0x7fff;
    55aa:	f7ff feff 	bl	53ac <chunk_size>
	return big_heap(h) && chunk_size(h, c) == 1;
    55ae:	68a3      	ldr	r3, [r4, #8]
    55b0:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    55b4:	4601      	mov	r1, r0
    55b6:	d301      	bcc.n	55bc <free_list_add+0x1a>
	if (!solo_free_header(h, c)) {
    55b8:	2801      	cmp	r0, #1
    55ba:	d035      	beq.n	5628 <free_list_add+0x86>
		int bidx = bucket_idx(h, chunk_size(h, c));
    55bc:	4620      	mov	r0, r4
    55be:	f7ff ff17 	bl	53f0 <bucket_idx>
	if (b->next == 0) {
    55c2:	eb04 0280 	add.w	r2, r4, r0, lsl #2
    55c6:	6916      	ldr	r6, [r2, #16]
    55c8:	b99e      	cbnz	r6, 55f2 <free_list_add+0x50>
		h->avail_buckets |= (1 << bidx);
    55ca:	2301      	movs	r3, #1
    55cc:	fa03 f000 	lsl.w	r0, r3, r0
    55d0:	68e3      	ldr	r3, [r4, #12]
    55d2:	4303      	orrs	r3, r0
    55d4:	60e3      	str	r3, [r4, #12]
	chunk_set(h, c, FREE_PREV, prev);
    55d6:	4629      	mov	r1, r5
		b->next = c;
    55d8:	6115      	str	r5, [r2, #16]
    55da:	462b      	mov	r3, r5
    55dc:	2202      	movs	r2, #2
    55de:	4620      	mov	r0, r4
    55e0:	f7ff fed9 	bl	5396 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    55e4:	2203      	movs	r2, #3
    55e6:	4629      	mov	r1, r5
	chunk_set(h, c, FREE_PREV, prev);
    55e8:	4620      	mov	r0, r4
}
    55ea:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    55ee:	f7ff bed2 	b.w	5396 <chunk_set>
	return chunk_field(h, c, FREE_PREV);
    55f2:	2202      	movs	r2, #2
    55f4:	4631      	mov	r1, r6
    55f6:	4620      	mov	r0, r4
    55f8:	f7ff fec2 	bl	5380 <chunk_field>
	chunk_set(h, c, FREE_PREV, prev);
    55fc:	2202      	movs	r2, #2
    55fe:	4603      	mov	r3, r0
	return chunk_field(h, c, FREE_PREV);
    5600:	4607      	mov	r7, r0
	chunk_set(h, c, FREE_PREV, prev);
    5602:	4629      	mov	r1, r5
    5604:	4620      	mov	r0, r4
    5606:	f7ff fec6 	bl	5396 <chunk_set>
	chunk_set(h, c, FREE_NEXT, next);
    560a:	4633      	mov	r3, r6
    560c:	2203      	movs	r2, #3
    560e:	4629      	mov	r1, r5
    5610:	4620      	mov	r0, r4
    5612:	f7ff fec0 	bl	5396 <chunk_set>
    5616:	2203      	movs	r2, #3
    5618:	4639      	mov	r1, r7
    561a:	462b      	mov	r3, r5
    561c:	4620      	mov	r0, r4
    561e:	f7ff feba 	bl	5396 <chunk_set>
	chunk_set(h, c, FREE_PREV, prev);
    5622:	2202      	movs	r2, #2
    5624:	4631      	mov	r1, r6
    5626:	e7df      	b.n	55e8 <free_list_add+0x46>
    5628:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

0000562c <sys_heap_free>:
{
    562c:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	if (mem == NULL) {
    562e:	2900      	cmp	r1, #0
    5630:	d050      	beq.n	56d4 <sys_heap_free+0xa8>
	struct z_heap *h = heap->heap;
    5632:	6805      	ldr	r5, [r0, #0]
	return big_heap(h) ? 8 : 4;
    5634:	68ab      	ldr	r3, [r5, #8]
    5636:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    563a:	bf2c      	ite	cs
    563c:	2408      	movcs	r4, #8
    563e:	2404      	movcc	r4, #4
	return (mem - chunk_header_bytes(h) - base) / CHUNK_UNIT;
    5640:	1b0c      	subs	r4, r1, r4
    5642:	1b64      	subs	r4, r4, r5
    5644:	bf48      	it	mi
    5646:	3407      	addmi	r4, #7
    5648:	10e4      	asrs	r4, r4, #3
	set_chunk_used(h, c, false);
    564a:	2200      	movs	r2, #0
    564c:	4621      	mov	r1, r4
    564e:	4628      	mov	r0, r5
    5650:	f7ff feb2 	bl	53b8 <set_chunk_used>
	return c + chunk_size(h, c);
    5654:	4621      	mov	r1, r4
    5656:	f7ff fea9 	bl	53ac <chunk_size>
    565a:	1826      	adds	r6, r4, r0
	return chunk_field(h, c, SIZE_AND_USED) & 1;
    565c:	2201      	movs	r2, #1
    565e:	4631      	mov	r1, r6
    5660:	4628      	mov	r0, r5
    5662:	f7ff fe8d 	bl	5380 <chunk_field>
	if (!chunk_used(h, right_chunk(h, c))) {
    5666:	07c3      	lsls	r3, r0, #31
    5668:	d40c      	bmi.n	5684 <sys_heap_free+0x58>
		free_list_remove(h, right_chunk(h, c));
    566a:	4631      	mov	r1, r6
    566c:	4628      	mov	r0, r5
    566e:	f7ff ff40 	bl	54f2 <free_list_remove>
	return c + chunk_size(h, c);
    5672:	4621      	mov	r1, r4
    5674:	4628      	mov	r0, r5
    5676:	f7ff fe99 	bl	53ac <chunk_size>
		merge_chunks(h, c, right_chunk(h, c));
    567a:	4621      	mov	r1, r4
    567c:	1822      	adds	r2, r4, r0
    567e:	4628      	mov	r0, r5
    5680:	f7ff fec3 	bl	540a <merge_chunks>
	return c - chunk_field(h, c, LEFT_SIZE);
    5684:	2200      	movs	r2, #0
    5686:	4621      	mov	r1, r4
    5688:	4628      	mov	r0, r5
    568a:	f7ff fe79 	bl	5380 <chunk_field>
    568e:	1a27      	subs	r7, r4, r0
	return chunk_field(h, c, SIZE_AND_USED) & 1;
    5690:	2201      	movs	r2, #1
    5692:	4639      	mov	r1, r7
    5694:	4628      	mov	r0, r5
    5696:	f7ff fe73 	bl	5380 <chunk_field>
	if (!chunk_used(h, left_chunk(h, c))) {
    569a:	f010 0601 	ands.w	r6, r0, #1
    569e:	d113      	bne.n	56c8 <sys_heap_free+0x9c>
		free_list_remove(h, left_chunk(h, c));
    56a0:	4639      	mov	r1, r7
    56a2:	4628      	mov	r0, r5
    56a4:	f7ff ff25 	bl	54f2 <free_list_remove>
	return c - chunk_field(h, c, LEFT_SIZE);
    56a8:	4621      	mov	r1, r4
    56aa:	4632      	mov	r2, r6
    56ac:	4628      	mov	r0, r5
    56ae:	f7ff fe67 	bl	5380 <chunk_field>
		merge_chunks(h, left_chunk(h, c), c);
    56b2:	4622      	mov	r2, r4
    56b4:	1a21      	subs	r1, r4, r0
    56b6:	4628      	mov	r0, r5
    56b8:	f7ff fea7 	bl	540a <merge_chunks>
    56bc:	4621      	mov	r1, r4
    56be:	4632      	mov	r2, r6
    56c0:	4628      	mov	r0, r5
    56c2:	f7ff fe5d 	bl	5380 <chunk_field>
    56c6:	1a24      	subs	r4, r4, r0
	free_list_add(h, c);
    56c8:	4621      	mov	r1, r4
    56ca:	4628      	mov	r0, r5
}
    56cc:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, c);
    56d0:	f7ff bf67 	b.w	55a2 <free_list_add>
}
    56d4:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

000056d6 <sys_heap_alloc>:

void *sys_heap_alloc(struct sys_heap *heap, size_t bytes)
{
    56d6:	b570      	push	{r4, r5, r6, lr}
	if (bytes == 0) {
    56d8:	b909      	cbnz	r1, 56de <sys_heap_alloc+0x8>
		return NULL;
    56da:	2000      	movs	r0, #0
		free_list_add(h, c + chunk_sz);
	}

	set_chunk_used(h, c, true);
	return chunk_mem(h, c);
}
    56dc:	bd70      	pop	{r4, r5, r6, pc}
	struct z_heap *h = heap->heap;
    56de:	6805      	ldr	r5, [r0, #0]
	return big_heap(h) ? 8 : 4;
    56e0:	68ab      	ldr	r3, [r5, #8]
    56e2:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    56e6:	bf2c      	ite	cs
    56e8:	2208      	movcs	r2, #8
    56ea:	2204      	movcc	r2, #4
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    56ec:	1dcc      	adds	r4, r1, #7
    56ee:	4414      	add	r4, r2
    56f0:	08e4      	lsrs	r4, r4, #3
	chunkid_t c = alloc_chunk(h, chunk_sz);
    56f2:	4621      	mov	r1, r4
    56f4:	4628      	mov	r0, r5
    56f6:	f7ff ff13 	bl	5520 <alloc_chunk>
	if (c == 0) {
    56fa:	4606      	mov	r6, r0
    56fc:	2800      	cmp	r0, #0
    56fe:	d0ec      	beq.n	56da <sys_heap_alloc+0x4>
	if (chunk_size(h, c) > chunk_sz) {
    5700:	4601      	mov	r1, r0
    5702:	4628      	mov	r0, r5
    5704:	f7ff fe52 	bl	53ac <chunk_size>
    5708:	42a0      	cmp	r0, r4
    570a:	d909      	bls.n	5720 <sys_heap_alloc+0x4a>
		split_chunks(h, c, c + chunk_sz);
    570c:	4434      	add	r4, r6
    570e:	4631      	mov	r1, r6
    5710:	4628      	mov	r0, r5
    5712:	4622      	mov	r2, r4
    5714:	f7ff fe97 	bl	5446 <split_chunks>
		free_list_add(h, c + chunk_sz);
    5718:	4621      	mov	r1, r4
    571a:	4628      	mov	r0, r5
    571c:	f7ff ff41 	bl	55a2 <free_list_add>
	set_chunk_used(h, c, true);
    5720:	4628      	mov	r0, r5
    5722:	2201      	movs	r2, #1
    5724:	4631      	mov	r1, r6
    5726:	f7ff fe47 	bl	53b8 <set_chunk_used>
	return big_heap(h) ? 8 : 4;
    572a:	68ab      	ldr	r3, [r5, #8]
    572c:	f5b3 4f00 	cmp.w	r3, #32768	; 0x8000
    5730:	bf2c      	ite	cs
    5732:	2008      	movcs	r0, #8
    5734:	2004      	movcc	r0, #4
	uint8_t *ret = ((uint8_t *)&buf[c]) + chunk_header_bytes(h);
    5736:	eb00 00c6 	add.w	r0, r0, r6, lsl #3
    573a:	4428      	add	r0, r5
	return chunk_mem(h, c);
    573c:	e7ce      	b.n	56dc <sys_heap_alloc+0x6>

0000573e <sys_heap_init>:
	return big_heap_bytes(size) ? 8 : 4;
    573e:	f5b2 2f80 	cmp.w	r2, #262144	; 0x40000
	set_chunk_used(h, c, true);
	return mem;
}

void sys_heap_init(struct sys_heap *heap, void *mem, size_t bytes)
{
    5742:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    5744:	bf2c      	ite	cs
    5746:	2508      	movcs	r5, #8
    5748:	2504      	movcc	r5, #4
	/* Must fit in a 32 bit count of HUNK_UNIT */
	__ASSERT(bytes / CHUNK_UNIT <= 0xffffffffU, "heap size is too big");

	/* Reserve the final marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
    574a:	1b55      	subs	r5, r2, r5

	/* Round the start up, the end down */
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    574c:	1dcc      	adds	r4, r1, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    574e:	440d      	add	r5, r1
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
    5750:	f024 0407 	bic.w	r4, r4, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
    5754:	f025 0507 	bic.w	r5, r5, #7
	CHECK(end > addr);
	__ASSERT(buf_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->chunk0_hdr_area = 0;
    5758:	2200      	movs	r2, #0
    575a:	2300      	movs	r3, #0
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    575c:	1b2d      	subs	r5, r5, r4
	heap->heap = h;
    575e:	6004      	str	r4, [r0, #0]
	size_t buf_sz = (end - addr) / CHUNK_UNIT;
    5760:	08ed      	lsrs	r5, r5, #3
	h->chunk0_hdr_area = 0;
    5762:	e9c4 2300 	strd	r2, r3, [r4]
	h->len = buf_sz;
	h->avail_buckets = 0;
    5766:	2300      	movs	r3, #0

	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5768:	4629      	mov	r1, r5
	h->len = buf_sz;
    576a:	60a5      	str	r5, [r4, #8]
	h->avail_buckets = 0;
    576c:	60e3      	str	r3, [r4, #12]
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    576e:	4620      	mov	r0, r4
    5770:	f7ff fe3e 	bl	53f0 <bucket_idx>
	size_t chunk0_size = chunksz(sizeof(struct z_heap) +
    5774:	0086      	lsls	r6, r0, #2
	return (bytes + CHUNK_UNIT - 1) / CHUNK_UNIT;
    5776:	361b      	adds	r6, #27
	int nb_buckets = bucket_idx(h, buf_sz) + 1;
    5778:	1c41      	adds	r1, r0, #1
    577a:	08f6      	lsrs	r6, r6, #3
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) < buf_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
    577c:	f104 0210 	add.w	r2, r4, #16
		h->buckets[i].next = 0;
    5780:	4618      	mov	r0, r3
	for (int i = 0; i < nb_buckets; i++) {
    5782:	428b      	cmp	r3, r1
    5784:	db29      	blt.n	57da <sys_heap_init+0x9c>
	}

	/* chunk containing our struct z_heap */
	set_chunk_size(h, 0, chunk0_size);
    5786:	4632      	mov	r2, r6
    5788:	4620      	mov	r0, r4
    578a:	2100      	movs	r1, #0
    578c:	f7ff fe2c 	bl	53e8 <set_chunk_size>
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    5790:	1baf      	subs	r7, r5, r6
	set_chunk_used(h, 0, true);
    5792:	4620      	mov	r0, r4
    5794:	2201      	movs	r2, #1
    5796:	2100      	movs	r1, #0
    5798:	f7ff fe0e 	bl	53b8 <set_chunk_used>
	set_chunk_size(h, chunk0_size, buf_sz - chunk0_size);
    579c:	463a      	mov	r2, r7
    579e:	4631      	mov	r1, r6
    57a0:	f7ff fe22 	bl	53e8 <set_chunk_size>
	chunk_set(h, c, LEFT_SIZE, size);
    57a4:	4633      	mov	r3, r6
    57a6:	4631      	mov	r1, r6
    57a8:	4620      	mov	r0, r4
    57aa:	2200      	movs	r2, #0
    57ac:	f7ff fdf3 	bl	5396 <chunk_set>
	set_left_chunk_size(h, chunk0_size, chunk0_size);

	/* the end marker chunk */
	set_chunk_size(h, buf_sz, 0);
    57b0:	4629      	mov	r1, r5
    57b2:	4620      	mov	r0, r4
    57b4:	2200      	movs	r2, #0
    57b6:	f7ff fe17 	bl	53e8 <set_chunk_size>
    57ba:	463b      	mov	r3, r7
    57bc:	4629      	mov	r1, r5
    57be:	4620      	mov	r0, r4
    57c0:	2200      	movs	r2, #0
    57c2:	f7ff fde8 	bl	5396 <chunk_set>
	set_left_chunk_size(h, buf_sz, buf_sz - chunk0_size);
	set_chunk_used(h, buf_sz, true);
    57c6:	4629      	mov	r1, r5
    57c8:	4620      	mov	r0, r4
    57ca:	2201      	movs	r2, #1
    57cc:	f7ff fdf4 	bl	53b8 <set_chunk_used>

	free_list_add(h, chunk0_size);
    57d0:	4631      	mov	r1, r6
}
    57d2:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	free_list_add(h, chunk0_size);
    57d6:	f7ff bee4 	b.w	55a2 <free_list_add>
		h->buckets[i].next = 0;
    57da:	f842 0b04 	str.w	r0, [r2], #4
	for (int i = 0; i < nb_buckets; i++) {
    57de:	3301      	adds	r3, #1
    57e0:	e7cf      	b.n	5782 <sys_heap_init+0x44>

000057e2 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    57e2:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    57e6:	b923      	cbnz	r3, 57f2 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    57e8:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    57ec:	f000 0001 	and.w	r0, r0, #1
    57f0:	4770      	bx	lr
		return false;
    57f2:	2000      	movs	r0, #0
}
    57f4:	4770      	bx	lr

000057f6 <z_impl_z_sys_mutex_kernel_lock>:
{
    57f6:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    57fa:	4615      	mov	r5, r2
    57fc:	461c      	mov	r4, r3
	obj = z_object_find(mutex);
    57fe:	f7fa fc6d 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_SYS_MUTEX) {
    5802:	b1a8      	cbz	r0, 5830 <z_impl_z_sys_mutex_kernel_lock+0x3a>
    5804:	7983      	ldrb	r3, [r0, #6]
    5806:	2b0e      	cmp	r3, #14
    5808:	d112      	bne.n	5830 <z_impl_z_sys_mutex_kernel_lock+0x3a>
	return obj->data.mutex;
    580a:	6881      	ldr	r1, [r0, #8]
	if (kernel_mutex == NULL) {
    580c:	b181      	cbz	r1, 5830 <z_impl_z_sys_mutex_kernel_lock+0x3a>
    580e:	f7ff ffe8 	bl	57e2 <arch_is_user_context>
	if (z_syscall_trap()) {
    5812:	b130      	cbz	r0, 5822 <z_impl_z_sys_mutex_kernel_lock+0x2c>
	register uint32_t ret __asm__("r0") = arg1;
    5814:	4608      	mov	r0, r1
	register uint32_t r2 __asm__("r2") = arg3;
    5816:	4622      	mov	r2, r4
	register uint32_t r1 __asm__("r1") = arg2;
    5818:	4629      	mov	r1, r5
	register uint32_t r6 __asm__("r6") = call_id;
    581a:	266c      	movs	r6, #108	; 0x6c
	__asm__ volatile("svc %[svid]\n"
    581c:	df03      	svc	3
}
    581e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	return z_impl_k_mutex_lock(mutex, timeout);
    5822:	462a      	mov	r2, r5
    5824:	4623      	mov	r3, r4
    5826:	4608      	mov	r0, r1
    5828:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    582c:	f7fd bc80 	b.w	3130 <z_impl_k_mutex_lock>
		return -EINVAL;
    5830:	f06f 0015 	mvn.w	r0, #21
    5834:	e7f3      	b.n	581e <z_impl_z_sys_mutex_kernel_lock+0x28>

00005836 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_DISASSEMBLY, 1);
GEN_ABSOLUTE_SYM(CONFIG_OUTPUT_PRINT_MEMORY_USAGE, 1);
GEN_ABSOLUTE_SYM(CONFIG_BUILD_OUTPUT_BIN, 1);
GEN_ABSOLUTE_SYM(CONFIG_COMPAT_INCLUDES, 1);

GEN_ABS_SYM_END
    5836:	4770      	bx	lr

00005838 <uart_poll_out>:
}


extern void z_impl_uart_poll_out(struct device * dev, unsigned char out_char);
static inline void uart_poll_out(struct device * dev, unsigned char out_char)
{
    5838:	e92d 4147 	stmdb	sp!, {r0, r1, r2, r6, r8, lr}
    583c:	4603      	mov	r3, r0
    583e:	f88d 1007 	strb.w	r1, [sp, #7]
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5842:	f3ef 8205 	mrs	r2, IPSR
	if (value) {
    5846:	b952      	cbnz	r2, 585e <uart_poll_out+0x26>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5848:	f3ef 8214 	mrs	r2, CONTROL
#ifdef CONFIG_USERSPACE
	if (z_syscall_trap()) {
    584c:	07d2      	lsls	r2, r2, #31
    584e:	d506      	bpl.n	585e <uart_poll_out+0x26>
	register uint32_t r1 __asm__("r1") = arg2;
    5850:	f8dd 1007 	ldr.w	r1, [sp, #7]
	register uint32_t r6 __asm__("r6") = call_id;
    5854:	26e5      	movs	r6, #229	; 0xe5
	__asm__ volatile("svc %[svid]\n"
    5856:	df03      	svc	3
		return;
	}
#endif
	compiler_barrier();
	z_impl_uart_poll_out(dev, out_char);
}
    5858:	b003      	add	sp, #12
    585a:	e8bd 8140 	ldmia.w	sp!, {r6, r8, pc}
	api->poll_out(dev, out_char);
    585e:	689a      	ldr	r2, [r3, #8]
    5860:	f89d 1007 	ldrb.w	r1, [sp, #7]
    5864:	6852      	ldr	r2, [r2, #4]
    5866:	4618      	mov	r0, r3
    5868:	4790      	blx	r2
}
    586a:	e7f5      	b.n	5858 <uart_poll_out+0x20>

0000586c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    586c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5870:	b923      	cbnz	r3, 587c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5872:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5876:	f000 0001 	and.w	r0, r0, #1
    587a:	4770      	bx	lr
		return false;
    587c:	2000      	movs	r0, #0
}
    587e:	4770      	bx	lr

00005880 <get_status>:
	return GET_STATUS(get_sub_data(dev, type)->flags);
    5880:	68c2      	ldr	r2, [r0, #12]
    5882:	b2cb      	uxtb	r3, r1
    5884:	210c      	movs	r1, #12
    5886:	fb03 2101 	mla	r1, r3, r1, r2
    588a:	6c08      	ldr	r0, [r1, #64]	; 0x40
}
    588c:	f000 0007 	and.w	r0, r0, #7
    5890:	4770      	bx	lr

00005892 <set_off_state>:
	__asm__ volatile(
    5892:	f04f 0320 	mov.w	r3, #32
    5896:	f3ef 8211 	mrs	r2, BASEPRI
    589a:	f383 8811 	msr	BASEPRI, r3
    589e:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    58a2:	6803      	ldr	r3, [r0, #0]
	if ((current_ctx != 0) && (current_ctx != ctx)) {
    58a4:	f013 03c0 	ands.w	r3, r3, #192	; 0xc0
    58a8:	d001      	beq.n	58ae <set_off_state+0x1c>
    58aa:	428b      	cmp	r3, r1
    58ac:	d107      	bne.n	58be <set_off_state+0x2c>
		*flags = CLOCK_CONTROL_STATUS_OFF;
    58ae:	2301      	movs	r3, #1
    58b0:	6003      	str	r3, [r0, #0]
	int err = 0;
    58b2:	2000      	movs	r0, #0
	__asm__ volatile(
    58b4:	f382 8811 	msr	BASEPRI, r2
    58b8:	f3bf 8f6f 	isb	sy
}
    58bc:	4770      	bx	lr
		err = -EPERM;
    58be:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    58c2:	e7f7      	b.n	58b4 <set_off_state+0x22>

000058c4 <set_starting_state>:
{
    58c4:	b510      	push	{r4, lr}
	__asm__ volatile(
    58c6:	f04f 0320 	mov.w	r3, #32
    58ca:	f3ef 8211 	mrs	r2, BASEPRI
    58ce:	f383 8811 	msr	BASEPRI, r3
    58d2:	f3bf 8f6f 	isb	sy
	uint32_t current_ctx = GET_CTX(*flags);
    58d6:	6803      	ldr	r3, [r0, #0]
	if ((*flags & (STATUS_MASK)) == CLOCK_CONTROL_STATUS_OFF) {
    58d8:	f003 0407 	and.w	r4, r3, #7
    58dc:	2c01      	cmp	r4, #1
    58de:	d106      	bne.n	58ee <set_starting_state+0x2a>
		*flags = CLOCK_CONTROL_STATUS_STARTING | ctx;
    58e0:	6001      	str	r1, [r0, #0]
	int err = 0;
    58e2:	2000      	movs	r0, #0
	__asm__ volatile(
    58e4:	f382 8811 	msr	BASEPRI, r2
    58e8:	f3bf 8f6f 	isb	sy
}
    58ec:	bd10      	pop	{r4, pc}
	uint32_t current_ctx = GET_CTX(*flags);
    58ee:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
	} else if (current_ctx != ctx) {
    58f2:	428b      	cmp	r3, r1
		err = -EBUSY;
    58f4:	bf14      	ite	ne
    58f6:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
    58fa:	f06f 000f 	mvneq.w	r0, #15
    58fe:	e7f1      	b.n	58e4 <set_starting_state+0x20>

00005900 <set_on_state>:
	__asm__ volatile(
    5900:	f04f 0320 	mov.w	r3, #32
    5904:	f3ef 8211 	mrs	r2, BASEPRI
    5908:	f383 8811 	msr	BASEPRI, r3
    590c:	f3bf 8f6f 	isb	sy
	*flags = CLOCK_CONTROL_STATUS_ON | GET_CTX(*flags);
    5910:	6803      	ldr	r3, [r0, #0]
    5912:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
    5916:	f043 0302 	orr.w	r3, r3, #2
    591a:	6003      	str	r3, [r0, #0]
	__asm__ volatile(
    591c:	f382 8811 	msr	BASEPRI, r2
    5920:	f3bf 8f6f 	isb	sy
}
    5924:	4770      	bx	lr

00005926 <onoff_started_callback>:
	return &data->mgr[type];
    5926:	68c0      	ldr	r0, [r0, #12]
{
    5928:	b410      	push	{r4}
	return &data->mgr[type];
    592a:	b2cb      	uxtb	r3, r1
	notify(mgr, 0);
    592c:	241c      	movs	r4, #28
    592e:	fb03 0004 	mla	r0, r3, r4, r0
    5932:	2100      	movs	r1, #0
}
    5934:	bc10      	pop	{r4}
	notify(mgr, 0);
    5936:	4710      	bx	r2

00005938 <blocking_start_callback>:
{
    5938:	e92d 4148 	stmdb	sp!, {r3, r6, r8, lr}
    593c:	f7ff ff96 	bl	586c <arch_is_user_context>
	if (z_syscall_trap()) {
    5940:	b120      	cbz	r0, 594c <blocking_start_callback+0x14>
	register uint32_t ret __asm__("r0") = arg1;
    5942:	4610      	mov	r0, r2
	register uint32_t r6 __asm__("r6") = call_id;
    5944:	2684      	movs	r6, #132	; 0x84
	__asm__ volatile("svc %[svid]\n"
    5946:	df03      	svc	3
}
    5948:	e8bd 8148 	ldmia.w	sp!, {r3, r6, r8, pc}
    594c:	e8bd 4148 	ldmia.w	sp!, {r3, r6, r8, lr}
	z_impl_k_sem_give(sem);
    5950:	4610      	mov	r0, r2
    5952:	f7fe bba3 	b.w	409c <z_impl_k_sem_give>

00005956 <lfclk_spinwait>:
                    (nrf_clock_lfclk_t)((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_SRC_Msk)
    5956:	f04f 4280 	mov.w	r2, #1073741824	; 0x40000000
    595a:	f8d2 3418 	ldr.w	r3, [r2, #1048]	; 0x418
            if ((p_reg->LFCLKSTAT & CLOCK_LFCLKSTAT_STATE_Msk)
    595e:	f8d2 1418 	ldr.w	r1, [r2, #1048]	; 0x418
    5962:	03c9      	lsls	r1, r1, #15
    5964:	d5f9      	bpl.n	595a <lfclk_spinwait+0x4>
                                        >> CLOCK_LFCLKSTAT_SRC_Pos);
    5966:	f003 0303 	and.w	r3, r3, #3
	while (!(nrf_clock_is_running(NRF_CLOCK, d, (void *)&type)
    596a:	4298      	cmp	r0, r3
    596c:	d1f5      	bne.n	595a <lfclk_spinwait+0x4>
}
    596e:	4770      	bx	lr

00005970 <api_stop>:
{
    5970:	b538      	push	{r3, r4, r5, lr}
    5972:	b2cc      	uxtb	r4, r1
	err = set_off_state(&subdata->flags, ctx);
    5974:	230c      	movs	r3, #12
{
    5976:	4605      	mov	r5, r0
	err = set_off_state(&subdata->flags, ctx);
    5978:	4363      	muls	r3, r4
    597a:	68c0      	ldr	r0, [r0, #12]
    597c:	3340      	adds	r3, #64	; 0x40
    597e:	2180      	movs	r1, #128	; 0x80
    5980:	4418      	add	r0, r3
    5982:	f7ff ff86 	bl	5892 <set_off_state>
	if (err < 0) {
    5986:	2800      	cmp	r0, #0
    5988:	db05      	blt.n	5996 <api_stop+0x26>
	get_sub_config(dev, type)->stop();
    598a:	6869      	ldr	r1, [r5, #4]
    598c:	eb01 04c4 	add.w	r4, r1, r4, lsl #3
    5990:	6863      	ldr	r3, [r4, #4]
    5992:	4798      	blx	r3
	return 0;
    5994:	2000      	movs	r0, #0
}
    5996:	bd38      	pop	{r3, r4, r5, pc}

00005998 <api_start>:
{
    5998:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    599c:	b2cd      	uxtb	r5, r1
	err = set_starting_state(&subdata->flags, ctx);
    599e:	f04f 080c 	mov.w	r8, #12
	struct nrf_clock_control_sub_data *subdata = get_sub_data(dev, type);
    59a2:	68c4      	ldr	r4, [r0, #12]
	err = set_starting_state(&subdata->flags, ctx);
    59a4:	fb08 f805 	mul.w	r8, r8, r5
{
    59a8:	4606      	mov	r6, r0
	err = set_starting_state(&subdata->flags, ctx);
    59aa:	f108 0040 	add.w	r0, r8, #64	; 0x40
    59ae:	2180      	movs	r1, #128	; 0x80
    59b0:	4420      	add	r0, r4
{
    59b2:	4617      	mov	r7, r2
	err = set_starting_state(&subdata->flags, ctx);
    59b4:	f7ff ff86 	bl	58c4 <set_starting_state>
	if (err < 0) {
    59b8:	2800      	cmp	r0, #0
    59ba:	db09      	blt.n	59d0 <api_start+0x38>
	subdata->cb = data->cb;
    59bc:	4444      	add	r4, r8
    59be:	687b      	ldr	r3, [r7, #4]
    59c0:	63a3      	str	r3, [r4, #56]	; 0x38
	subdata->user_data = data->user_data;
    59c2:	68bb      	ldr	r3, [r7, #8]
    59c4:	63e3      	str	r3, [r4, #60]	; 0x3c
	 get_sub_config(dev, type)->start();
    59c6:	6873      	ldr	r3, [r6, #4]
    59c8:	f853 3035 	ldr.w	r3, [r3, r5, lsl #3]
    59cc:	4798      	blx	r3
	return 0;
    59ce:	2000      	movs	r0, #0
}
    59d0:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

000059d4 <z_clock_isr>:
/* Weak-linked noop defaults for optional driver interfaces: */

void __weak z_clock_isr(void *arg)
{
	__ASSERT_NO_MSG(false);
}
    59d4:	4770      	bx	lr

000059d6 <z_clock_idle_exit>:
{
}

void __weak z_clock_idle_exit(void)
{
}
    59d6:	4770      	bx	lr

000059d8 <SEGGER_RTT_Init>:
*    Initializes the RTT Control Block.
*    Should be used in RAM targets, at start of the application.
*
*/
void SEGGER_RTT_Init (void) {
  _DoInit();
    59d8:	f7fb bcec 	b.w	13b4 <_DoInit>

000059dc <rtt_init>:
 */

K_MUTEX_DEFINE(rtt_term_mutex);

static int rtt_init(struct device *unused)
{
    59dc:	b508      	push	{r3, lr}
	ARG_UNUSED(unused);

	SEGGER_RTT_Init();
    59de:	f7ff fffb 	bl	59d8 <SEGGER_RTT_Init>

	return 0;
}
    59e2:	2000      	movs	r0, #0
    59e4:	bd08      	pop	{r3, pc}

000059e6 <z_irq_spurious>:
 */
void z_irq_spurious(void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
    59e6:	2100      	movs	r1, #0
    59e8:	2001      	movs	r0, #1
    59ea:	f000 b80a 	b.w	5a02 <z_arm_fatal_error>

000059ee <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    59ee:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    59f2:	b923      	cbnz	r3, 59fe <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    59f4:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    59f8:	f000 0001 	and.w	r0, r0, #1
    59fc:	4770      	bx	lr
		return false;
    59fe:	2000      	movs	r0, #0
}
    5a00:	4770      	bx	lr

00005a02 <z_arm_fatal_error>:
	LOG_ERR("Faulting instruction address (r15/pc): 0x%08x",
		esf->basic.pc);
}

void z_arm_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    5a02:	b508      	push	{r3, lr}
    5a04:	4602      	mov	r2, r0

	if (esf != NULL) {
    5a06:	b139      	cbz	r1, 5a18 <z_arm_fatal_error+0x16>
	return arch_is_user_context();
    5a08:	f7ff fff1 	bl	59ee <arch_is_user_context>
    5a0c:	f7ff ffef 	bl	59ee <arch_is_user_context>
    5a10:	f7ff ffed 	bl	59ee <arch_is_user_context>
    5a14:	f7ff ffeb 	bl	59ee <arch_is_user_context>
		esf_dump(esf);
	}
	z_fatal_error(reason, esf);
}
    5a18:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_fatal_error(reason, esf);
    5a1c:	4610      	mov	r0, r2
    5a1e:	f000 b955 	b.w	5ccc <z_fatal_error>

00005a22 <z_do_kernel_oops>:
 *   fault handler will executed insted of the SVC.
 *
 * @param esf exception frame
 */
void z_do_kernel_oops(const z_arch_esf_t *esf)
{
    5a22:	4601      	mov	r1, r0
	/* Stacked R0 holds the exception reason. */
	unsigned int reason = esf->basic.r0;
    5a24:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("MRS %0, control" : "=r" (result) );
    5a26:	f3ef 8314 	mrs	r3, CONTROL

#if defined(CONFIG_USERSPACE)
	if ((__get_CONTROL() & CONTROL_nPRIV_Msk) == CONTROL_nPRIV_Msk) {
    5a2a:	07db      	lsls	r3, r3, #31
    5a2c:	d503      	bpl.n	5a36 <z_do_kernel_oops+0x14>
		 * Exception triggered from nPRIV mode.
		 *
		 * User mode is only allowed to induce oopses and stack check
		 * failures via software-triggered system fatal exceptions.
		 */
		if (!((esf->basic.r0 == K_ERR_KERNEL_OOPS) ||
    5a2e:	1e83      	subs	r3, r0, #2
			(esf->basic.r0 == K_ERR_STACK_CHK_FAIL))) {

			reason = K_ERR_KERNEL_OOPS;
    5a30:	2b02      	cmp	r3, #2
    5a32:	bf28      	it	cs
    5a34:	2003      	movcs	r0, #3
		}
	}

#endif /* CONFIG_USERSPACE */
	z_arm_fatal_error(reason, esf);
    5a36:	f7ff bfe4 	b.w	5a02 <z_arm_fatal_error>

00005a3a <arch_syscall_oops>:
}

FUNC_NORETURN void arch_syscall_oops(void *ssf_ptr)
{
    5a3a:	b500      	push	{lr}
    5a3c:	4604      	mov	r4, r0
    5a3e:	b089      	sub	sp, #36	; 0x24
	uint32_t *ssf_contents = ssf_ptr;
	z_arch_esf_t oops_esf = { 0 };
    5a40:	2100      	movs	r1, #0
    5a42:	2220      	movs	r2, #32
    5a44:	4668      	mov	r0, sp
    5a46:	f000 f873 	bl	5b30 <memset>

	/* TODO: Copy the rest of the register set out of ssf_ptr */
	oops_esf.basic.pc = ssf_contents[3];
    5a4a:	68e3      	ldr	r3, [r4, #12]
    5a4c:	9306      	str	r3, [sp, #24]

	z_arm_fatal_error(K_ERR_KERNEL_OOPS, &oops_esf);
    5a4e:	4669      	mov	r1, sp
    5a50:	2003      	movs	r0, #3
    5a52:	f7ff ffd6 	bl	5a02 <z_arm_fatal_error>

00005a56 <z_arm_nmi>:
 *
 * @return N/A
 */

void z_arm_nmi(void)
{
    5a56:	b508      	push	{r3, lr}
	handler();
    5a58:	f7fb fe26 	bl	16a8 <z_SysNmiOnReset>
	z_arm_int_exit();
}
    5a5c:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
    5a60:	f7fc b88c 	b.w	1b7c <z_arm_exc_exit>

00005a64 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5a64:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5a68:	b923      	cbnz	r3, 5a74 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5a6a:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5a6e:	f000 0001 	and.w	r0, r0, #1
    5a72:	4770      	bx	lr
		return false;
    5a74:	2000      	movs	r0, #0
}
    5a76:	4770      	bx	lr

00005a78 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5a78:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5a7c:	b923      	cbnz	r3, 5a88 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5a7e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5a82:	f000 0001 	and.w	r0, r0, #1
    5a86:	4770      	bx	lr
		return false;
    5a88:	2000      	movs	r0, #0
}
    5a8a:	4770      	bx	lr

00005a8c <arch_mem_domain_max_partitions_get>:
{
    5a8c:	b508      	push	{r3, lr}
	int available_regions = arm_core_mpu_get_max_available_dyn_regions();
    5a8e:	f7fc f9a5 	bl	1ddc <arm_core_mpu_get_max_available_dyn_regions>
}
    5a92:	3801      	subs	r0, #1
    5a94:	bd08      	pop	{r3, pc}

00005a96 <arch_buffer_validate>:
	arch_mem_domain_destroy(thread->mem_domain_info.mem_domain);
}

int arch_buffer_validate(void *addr, size_t size, int write)
{
	return arm_core_mpu_buffer_validate(addr, size, write);
    5a96:	f7fc b9a9 	b.w	1dec <arm_core_mpu_buffer_validate>

00005a9a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5a9a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5a9e:	b923      	cbnz	r3, 5aaa <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5aa0:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5aa4:	f000 0001 	and.w	r0, r0, #1
    5aa8:	4770      	bx	lr
		return false;
    5aaa:	2000      	movs	r0, #0
}
    5aac:	4770      	bx	lr

00005aae <strcpy>:

char *strcpy(char *_MLIBC_RESTRICT d, const char *_MLIBC_RESTRICT s)
{
	char *dest = d;

	while (*s != '\0') {
    5aae:	3901      	subs	r1, #1
    5ab0:	4603      	mov	r3, r0
    5ab2:	f811 2f01 	ldrb.w	r2, [r1, #1]!
    5ab6:	b90a      	cbnz	r2, 5abc <strcpy+0xe>
		*d = *s;
		d++;
		s++;
	}

	*d = '\0';
    5ab8:	701a      	strb	r2, [r3, #0]

	return dest;
}
    5aba:	4770      	bx	lr
		*d = *s;
    5abc:	f803 2b01 	strb.w	r2, [r3], #1
		s++;
    5ac0:	e7f7      	b.n	5ab2 <strcpy+0x4>

00005ac2 <strcmp>:
 * @return negative # if <s1> < <s2>, 0 if <s1> == <s2>, else positive #
 */

int strcmp(const char *s1, const char *s2)
{
	while ((*s1 == *s2) && (*s1 != '\0')) {
    5ac2:	1e43      	subs	r3, r0, #1
    5ac4:	3901      	subs	r1, #1
    5ac6:	f813 2f01 	ldrb.w	r2, [r3, #1]!
    5aca:	f811 0f01 	ldrb.w	r0, [r1, #1]!
    5ace:	4282      	cmp	r2, r0
    5ad0:	d101      	bne.n	5ad6 <strcmp+0x14>
    5ad2:	2a00      	cmp	r2, #0
    5ad4:	d1f7      	bne.n	5ac6 <strcmp+0x4>
		s1++;
		s2++;
	}

	return *s1 - *s2;
}
    5ad6:	1a10      	subs	r0, r2, r0
    5ad8:	4770      	bx	lr

00005ada <memcpy>:
 *
 * @return pointer to start of destination buffer
 */

void *memcpy(void *_MLIBC_RESTRICT d, const void *_MLIBC_RESTRICT s, size_t n)
{
    5ada:	b5f0      	push	{r4, r5, r6, r7, lr}

	unsigned char *d_byte = (unsigned char *)d;
	const unsigned char *s_byte = (const unsigned char *)s;
	const uintptr_t mask = sizeof(mem_word_t) - 1;

	if ((((uintptr_t)d ^ (uintptr_t)s_byte) & mask) == 0) {
    5adc:	ea81 0400 	eor.w	r4, r1, r0
    5ae0:	07a5      	lsls	r5, r4, #30
    5ae2:	4603      	mov	r3, r0
    5ae4:	d00b      	beq.n	5afe <memcpy+0x24>
    5ae6:	3b01      	subs	r3, #1
    5ae8:	440a      	add	r2, r1
		s_byte = (unsigned char *)s_word;
	}

	/* do byte-sized copying until finished */

	while (n > 0) {
    5aea:	4291      	cmp	r1, r2
    5aec:	d11b      	bne.n	5b26 <memcpy+0x4c>
		*(d_byte++) = *(s_byte++);
		n--;
	}

	return d;
}
    5aee:	bdf0      	pop	{r4, r5, r6, r7, pc}
			if (n == 0) {
    5af0:	2a00      	cmp	r2, #0
    5af2:	d0fc      	beq.n	5aee <memcpy+0x14>
			*(d_byte++) = *(s_byte++);
    5af4:	f811 4b01 	ldrb.w	r4, [r1], #1
    5af8:	f803 4b01 	strb.w	r4, [r3], #1
			n--;
    5afc:	3a01      	subs	r2, #1
		while (((uintptr_t)d_byte) & mask) {
    5afe:	079c      	lsls	r4, r3, #30
    5b00:	d1f6      	bne.n	5af0 <memcpy+0x16>
    5b02:	f022 0403 	bic.w	r4, r2, #3
    5b06:	1f1d      	subs	r5, r3, #4
    5b08:	0896      	lsrs	r6, r2, #2
    5b0a:	190f      	adds	r7, r1, r4
		while (n >= sizeof(mem_word_t)) {
    5b0c:	42b9      	cmp	r1, r7
    5b0e:	d105      	bne.n	5b1c <memcpy+0x42>
    5b10:	f06f 0503 	mvn.w	r5, #3
    5b14:	fb05 2206 	mla	r2, r5, r6, r2
    5b18:	4423      	add	r3, r4
    5b1a:	e7e4      	b.n	5ae6 <memcpy+0xc>
			*(d_word++) = *(s_word++);
    5b1c:	f851 cb04 	ldr.w	ip, [r1], #4
    5b20:	f845 cf04 	str.w	ip, [r5, #4]!
			n -= sizeof(mem_word_t);
    5b24:	e7f2      	b.n	5b0c <memcpy+0x32>
		*(d_byte++) = *(s_byte++);
    5b26:	f811 4b01 	ldrb.w	r4, [r1], #1
    5b2a:	f803 4f01 	strb.w	r4, [r3, #1]!
		n--;
    5b2e:	e7dc      	b.n	5aea <memcpy+0x10>

00005b30 <memset>:
 *
 * @return pointer to start of buffer
 */

void *memset(void *buf, int c, size_t n)
{
    5b30:	b570      	push	{r4, r5, r6, lr}
	/* do byte-sized initialization until word-aligned or finished */

	unsigned char *d_byte = (unsigned char *)buf;
	unsigned char c_byte = (unsigned char)c;
    5b32:	b2c9      	uxtb	r1, r1
	unsigned char *d_byte = (unsigned char *)buf;
    5b34:	4603      	mov	r3, r0

	while (((uintptr_t)d_byte) & (sizeof(mem_word_t) - 1)) {
    5b36:	079c      	lsls	r4, r3, #30
    5b38:	d111      	bne.n	5b5e <memset+0x2e>
	/* do word-sized initialization as long as possible */

	mem_word_t *d_word = (mem_word_t *)d_byte;
	mem_word_t c_word = (mem_word_t)c_byte;

	c_word |= c_word << 8;
    5b3a:	ea41 2401 	orr.w	r4, r1, r1, lsl #8
	c_word |= c_word << 16;
    5b3e:	f022 0603 	bic.w	r6, r2, #3
    5b42:	ea44 4504 	orr.w	r5, r4, r4, lsl #16
#if Z_MEM_WORD_T_WIDTH > 32
	c_word |= c_word << 32;
#endif

	while (n >= sizeof(mem_word_t)) {
    5b46:	441e      	add	r6, r3
    5b48:	0894      	lsrs	r4, r2, #2
    5b4a:	42b3      	cmp	r3, r6
    5b4c:	d10d      	bne.n	5b6a <memset+0x3a>
    5b4e:	f06f 0503 	mvn.w	r5, #3
    5b52:	fb05 2204 	mla	r2, r5, r4, r2
    5b56:	441a      	add	r2, r3

	/* do byte-sized initialization until finished */

	d_byte = (unsigned char *)d_word;

	while (n > 0) {
    5b58:	4293      	cmp	r3, r2
    5b5a:	d109      	bne.n	5b70 <memset+0x40>
		*(d_byte++) = c_byte;
		n--;
	}

	return buf;
}
    5b5c:	bd70      	pop	{r4, r5, r6, pc}
		if (n == 0) {
    5b5e:	2a00      	cmp	r2, #0
    5b60:	d0fc      	beq.n	5b5c <memset+0x2c>
		*(d_byte++) = c_byte;
    5b62:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    5b66:	3a01      	subs	r2, #1
    5b68:	e7e5      	b.n	5b36 <memset+0x6>
		*(d_word++) = c_word;
    5b6a:	f843 5b04 	str.w	r5, [r3], #4
		n -= sizeof(mem_word_t);
    5b6e:	e7ec      	b.n	5b4a <memset+0x1a>
		*(d_byte++) = c_byte;
    5b70:	f803 1b01 	strb.w	r1, [r3], #1
		n--;
    5b74:	e7f0      	b.n	5b58 <memset+0x28>

00005b76 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5b76:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5b7a:	b923      	cbnz	r3, 5b86 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5b7c:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5b80:	f000 0001 	and.w	r0, r0, #1
    5b84:	4770      	bx	lr
		return false;
    5b86:	2000      	movs	r0, #0
}
    5b88:	4770      	bx	lr

00005b8a <_stdout_hook_default>:
}
    5b8a:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    5b8e:	4770      	bx	lr

00005b90 <z_platform_init>:

void z_platform_init(void)
{
	SystemInit();
    5b90:	f7fd b82c 	b.w	2bec <SystemInit>

00005b94 <gpio_nrfx_port_get_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    5b94:	6843      	ldr	r3, [r0, #4]
    5b96:	685b      	ldr	r3, [r3, #4]
    return p_reg->IN;
    5b98:	f8d3 3510 	ldr.w	r3, [r3, #1296]	; 0x510
	*value = nrf_gpio_port_in_read(reg);
    5b9c:	600b      	str	r3, [r1, #0]
}
    5b9e:	2000      	movs	r0, #0
    5ba0:	4770      	bx	lr

00005ba2 <gpio_nrfx_port_set_masked_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    5ba2:	6843      	ldr	r3, [r0, #4]
    5ba4:	685b      	ldr	r3, [r3, #4]
    return p_reg->OUT;
    5ba6:	f8d3 0504 	ldr.w	r0, [r3, #1284]	; 0x504
	nrf_gpio_port_out_write(reg, value_tmp | (mask & value));
    5baa:	4042      	eors	r2, r0
    5bac:	400a      	ands	r2, r1
    5bae:	4042      	eors	r2, r0
    p_reg->OUT = value;
    5bb0:	f8c3 2504 	str.w	r2, [r3, #1284]	; 0x504
}
    5bb4:	2000      	movs	r0, #0
    5bb6:	4770      	bx	lr

00005bb8 <gpio_nrfx_port_set_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    5bb8:	6843      	ldr	r3, [r0, #4]
    5bba:	685b      	ldr	r3, [r3, #4]
}
    5bbc:	2000      	movs	r0, #0
    p_reg->OUTSET = set_mask;
    5bbe:	f8c3 1508 	str.w	r1, [r3, #1288]	; 0x508
    5bc2:	4770      	bx	lr

00005bc4 <gpio_nrfx_port_clear_bits_raw>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    5bc4:	6843      	ldr	r3, [r0, #4]
    5bc6:	685b      	ldr	r3, [r3, #4]
}
    5bc8:	2000      	movs	r0, #0
    p_reg->OUTCLR = clr_mask;
    5bca:	f8c3 150c 	str.w	r1, [r3, #1292]	; 0x50c
    5bce:	4770      	bx	lr

00005bd0 <gpio_nrfx_port_toggle_bits>:
	NRF_GPIO_Type *reg = get_port_cfg(port)->port;
    5bd0:	6843      	ldr	r3, [r0, #4]
    5bd2:	685a      	ldr	r2, [r3, #4]
    return p_reg->OUT;
    5bd4:	f8d2 3504 	ldr.w	r3, [r2, #1284]	; 0x504
	nrf_gpio_port_out_write(reg, value ^ mask);
    5bd8:	404b      	eors	r3, r1
    p_reg->OUT = value;
    5bda:	f8c2 3504 	str.w	r3, [r2, #1284]	; 0x504
}
    5bde:	2000      	movs	r0, #0
    5be0:	4770      	bx	lr

00005be2 <gpio_nrfx_manage_callback>:
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    5be2:	68c3      	ldr	r3, [r0, #12]
Z_GENLIST_IS_EMPTY(slist)
    5be4:	6858      	ldr	r0, [r3, #4]
{
    5be6:	b530      	push	{r4, r5, lr}
	if (!sys_slist_is_empty(callbacks)) {
    5be8:	b158      	cbz	r0, 5c02 <gpio_nrfx_manage_callback+0x20>
 * @return true if node was removed
 */
static inline bool sys_slist_find_and_remove(sys_slist_t *list,
					     sys_snode_t *node);

Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    5bea:	2400      	movs	r4, #0
    5bec:	4281      	cmp	r1, r0
    5bee:	d113      	bne.n	5c18 <gpio_nrfx_manage_callback+0x36>
Z_GENLIST_REMOVE(slist, snode)
    5bf0:	6808      	ldr	r0, [r1, #0]
    5bf2:	b95c      	cbnz	r4, 5c0c <gpio_nrfx_manage_callback+0x2a>
    5bf4:	689c      	ldr	r4, [r3, #8]
	list->head = node;
    5bf6:	6058      	str	r0, [r3, #4]
Z_GENLIST_REMOVE(slist, snode)
    5bf8:	42a1      	cmp	r1, r4
    5bfa:	d100      	bne.n	5bfe <gpio_nrfx_manage_callback+0x1c>
	list->tail = node;
    5bfc:	6098      	str	r0, [r3, #8]
	parent->next = child;
    5bfe:	2000      	movs	r0, #0
    5c00:	6008      	str	r0, [r1, #0]
	if (set) {
    5c02:	b972      	cbnz	r2, 5c22 <gpio_nrfx_manage_callback+0x40>
	return 0;
    5c04:	2000      	movs	r0, #0
}
    5c06:	bd30      	pop	{r4, r5, pc}
    5c08:	4628      	mov	r0, r5
    5c0a:	e7ef      	b.n	5bec <gpio_nrfx_manage_callback+0xa>
    5c0c:	6020      	str	r0, [r4, #0]
Z_GENLIST_REMOVE(slist, snode)
    5c0e:	6898      	ldr	r0, [r3, #8]
    5c10:	4281      	cmp	r1, r0
	list->tail = node;
    5c12:	bf08      	it	eq
    5c14:	609c      	streq	r4, [r3, #8]
}
    5c16:	e7f2      	b.n	5bfe <gpio_nrfx_manage_callback+0x1c>
Z_GENLIST_PEEK_NEXT_NO_CHECK(slist, snode)
    5c18:	6805      	ldr	r5, [r0, #0]
Z_GENLIST_FIND_AND_REMOVE(slist, snode)
    5c1a:	4604      	mov	r4, r0
    5c1c:	2d00      	cmp	r5, #0
    5c1e:	d1f3      	bne.n	5c08 <gpio_nrfx_manage_callback+0x26>
			if (!set) {
    5c20:	b13a      	cbz	r2, 5c32 <gpio_nrfx_manage_callback+0x50>
Z_GENLIST_PREPEND(slist, snode)
    5c22:	685a      	ldr	r2, [r3, #4]
	parent->next = child;
    5c24:	600a      	str	r2, [r1, #0]
Z_GENLIST_PREPEND(slist, snode)
    5c26:	6898      	ldr	r0, [r3, #8]
	list->head = node;
    5c28:	6059      	str	r1, [r3, #4]
Z_GENLIST_PREPEND(slist, snode)
    5c2a:	2800      	cmp	r0, #0
    5c2c:	d1ea      	bne.n	5c04 <gpio_nrfx_manage_callback+0x22>
	list->tail = node;
    5c2e:	6099      	str	r1, [r3, #8]
}
    5c30:	e7e9      	b.n	5c06 <gpio_nrfx_manage_callback+0x24>
				return -EINVAL;
    5c32:	f06f 0015 	mvn.w	r0, #21
	return gpio_manage_callback(&get_port_data(port)->callbacks,
    5c36:	e7e6      	b.n	5c06 <gpio_nrfx_manage_callback+0x24>

00005c38 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5c38:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5c3c:	b923      	cbnz	r3, 5c48 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5c3e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5c42:	f000 0001 	and.w	r0, r0, #1
    5c46:	4770      	bx	lr
		return false;
    5c48:	2000      	movs	r0, #0
}
    5c4a:	4770      	bx	lr

00005c4c <uart_nrfx_config_get>:
	*cfg = get_dev_data(dev)->uart_config;
    5c4c:	68c2      	ldr	r2, [r0, #12]
{
    5c4e:	460b      	mov	r3, r1
	*cfg = get_dev_data(dev)->uart_config;
    5c50:	e892 0003 	ldmia.w	r2, {r0, r1}
    5c54:	e883 0003 	stmia.w	r3, {r0, r1}
}
    5c58:	2000      	movs	r0, #0
    5c5a:	4770      	bx	lr

00005c5c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5c5c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5c60:	b923      	cbnz	r3, 5c6c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5c62:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5c66:	f000 0001 	and.w	r0, r0, #1
    5c6a:	4770      	bx	lr
		return false;
    5c6c:	2000      	movs	r0, #0
}
    5c6e:	4770      	bx	lr

00005c70 <nrfx_busy_wait>:
{
	((nrfx_irq_handler_t)irq_handler)();
}

void nrfx_busy_wait(uint32_t usec_to_wait)
{
    5c70:	e92d 0140 	stmdb	sp!, {r6, r8}
    5c74:	4603      	mov	r3, r0
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5c76:	f3ef 8205 	mrs	r2, IPSR
	if (value) {
    5c7a:	b942      	cbnz	r2, 5c8e <nrfx_busy_wait+0x1e>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5c7c:	f3ef 8214 	mrs	r2, CONTROL
	if (z_syscall_trap()) {
    5c80:	07d2      	lsls	r2, r2, #31
    5c82:	d504      	bpl.n	5c8e <nrfx_busy_wait+0x1e>
	register uint32_t r6 __asm__("r6") = call_id;
    5c84:	265d      	movs	r6, #93	; 0x5d
	__asm__ volatile("svc %[svid]\n"
    5c86:	df03      	svc	3
	k_busy_wait(usec_to_wait);
}
    5c88:	e8bd 0140 	ldmia.w	sp!, {r6, r8}
    5c8c:	4770      	bx	lr
    5c8e:	e8bd 0140 	ldmia.w	sp!, {r6, r8}
	z_impl_k_busy_wait(usec_to_wait);
    5c92:	4618      	mov	r0, r3
    5c94:	f000 ba79 	b.w	618a <z_impl_k_busy_wait>

00005c98 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5c98:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5c9c:	b923      	cbnz	r3, 5ca8 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5c9e:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5ca2:	f000 0001 	and.w	r0, r0, #1
    5ca6:	4770      	bx	lr
		return false;
    5ca8:	2000      	movs	r0, #0
}
    5caa:	4770      	bx	lr

00005cac <arch_system_halt>:
	__asm__ volatile(
    5cac:	f04f 0220 	mov.w	r2, #32
    5cb0:	f3ef 8311 	mrs	r3, BASEPRI
    5cb4:	f382 8811 	msr	BASEPRI, r2
    5cb8:	f3bf 8f6f 	isb	sy
	/* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 */

	(void)arch_irq_lock();
	for (;;) {
    5cbc:	e7fe      	b.n	5cbc <arch_system_halt+0x10>

00005cbe <k_sys_fatal_error_handler>:
/* LCOV_EXCL_STOP */

/* LCOV_EXCL_START */
__weak void k_sys_fatal_error_handler(unsigned int reason,
				      const z_arch_esf_t *esf)
{
    5cbe:	b508      	push	{r3, lr}
    5cc0:	4602      	mov	r2, r0
    5cc2:	f7ff ffe9 	bl	5c98 <arch_is_user_context>
	ARG_UNUSED(esf);

	LOG_PANIC();
	LOG_ERR("Halting system");
	arch_system_halt(reason);
    5cc6:	4610      	mov	r0, r2
    5cc8:	f7ff fff0 	bl	5cac <arch_system_halt>

00005ccc <z_fatal_error>:
	return 0;
#endif
}

void z_fatal_error(unsigned int reason, const z_arch_esf_t *esf)
{
    5ccc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    5cce:	4606      	mov	r6, r0
    5cd0:	460c      	mov	r4, r1
    5cd2:	f04f 0320 	mov.w	r3, #32
    5cd6:	f3ef 8711 	mrs	r7, BASEPRI
    5cda:	f383 8811 	msr	BASEPRI, r3
    5cde:	f3bf 8f6f 	isb	sy
	return z_impl_k_current_get();
    5ce2:	f7fe f903 	bl	3eec <z_impl_k_current_get>
    5ce6:	4605      	mov	r5, r0
    5ce8:	f7ff ffd6 	bl	5c98 <arch_is_user_context>
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
    5cec:	b12c      	cbz	r4, 5cfa <z_fatal_error+0x2e>
	return (esf->basic.xpsr & IPSR_ISR_Msk) ? (true) : (false);
    5cee:	69e3      	ldr	r3, [r4, #28]
    5cf0:	f3c3 0308 	ubfx	r3, r3, #0, #9
    5cf4:	b10b      	cbz	r3, 5cfa <z_fatal_error+0x2e>
    5cf6:	f7ff ffcf 	bl	5c98 <arch_is_user_context>
    5cfa:	f7ff ffcd 	bl	5c98 <arch_is_user_context>
#endif

	LOG_ERR("Current thread: %p (%s)", thread,
		log_strdup(thread_name_get(thread)));

	k_sys_fatal_error_handler(reason, esf);
    5cfe:	4621      	mov	r1, r4
    5d00:	4630      	mov	r0, r6
    5d02:	f7ff ffdc 	bl	5cbe <k_sys_fatal_error_handler>
	__asm__ volatile(
    5d06:	f387 8811 	msr	BASEPRI, r7
    5d0a:	f3bf 8f6f 	isb	sy
	z_impl_k_thread_abort(thread);
    5d0e:	4628      	mov	r0, r5
#endif /*CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION */
	}

	arch_irq_unlock(key);
	k_thread_abort(thread);
}
    5d10:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
    5d14:	f7fb bf4c 	b.w	1bb0 <z_impl_k_thread_abort>

00005d18 <z_sys_power_save_idle_exit>:
	z_clock_idle_exit();
    5d18:	f7ff be5d 	b.w	59d6 <z_clock_idle_exit>

00005d1c <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5d1c:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5d20:	b923      	cbnz	r3, 5d2c <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5d22:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5d26:	f000 0001 	and.w	r0, r0, #1
    5d2a:	4770      	bx	lr
		return false;
    5d2c:	2000      	movs	r0, #0
}
    5d2e:	4770      	bx	lr

00005d30 <adjust_owner_prio.isra.0>:
static bool adjust_owner_prio(struct k_mutex *mutex, int32_t new_prio)
    5d30:	b508      	push	{r3, lr}
	if (mutex->owner->base.prio != new_prio) {
    5d32:	6803      	ldr	r3, [r0, #0]
    5d34:	f993 300e 	ldrsb.w	r3, [r3, #14]
    5d38:	428b      	cmp	r3, r1
static bool adjust_owner_prio(struct k_mutex *mutex, int32_t new_prio)
    5d3a:	4602      	mov	r2, r0
	if (mutex->owner->base.prio != new_prio) {
    5d3c:	d006      	beq.n	5d4c <adjust_owner_prio.isra.0+0x1c>
    5d3e:	f7ff ffed 	bl	5d1c <arch_is_user_context>
}
    5d42:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		return z_set_prio(mutex->owner, new_prio);
    5d46:	6810      	ldr	r0, [r2, #0]
    5d48:	f7fd bf3a 	b.w	3bc0 <z_set_prio>
}
    5d4c:	2000      	movs	r0, #0
    5d4e:	bd08      	pop	{r3, pc}

00005d50 <z_impl_k_mutex_init>:
{
    5d50:	b510      	push	{r4, lr}
	mutex->owner = NULL;
    5d52:	2400      	movs	r4, #0
	mutex->lock_count = 0U;
    5d54:	e9c0 4402 	strd	r4, r4, [r0, #8]
	list->tail = (sys_dnode_t *)list;
    5d58:	e9c0 0000 	strd	r0, r0, [r0]
	z_object_init(mutex);
    5d5c:	f000 fd0e 	bl	677c <z_object_init>
}
    5d60:	4620      	mov	r0, r4
    5d62:	bd10      	pop	{r4, pc}

00005d64 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5d64:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5d68:	b923      	cbnz	r3, 5d74 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5d6a:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5d6e:	f000 0001 	and.w	r0, r0, #1
    5d72:	4770      	bx	lr
		return false;
    5d74:	2000      	movs	r0, #0
}
    5d76:	4770      	bx	lr

00005d78 <queue_insert>:
{
    5d78:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
    5d7c:	4604      	mov	r4, r0
    5d7e:	460d      	mov	r5, r1
    5d80:	4690      	mov	r8, r2
    5d82:	4699      	mov	r9, r3
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    5d84:	f100 0608 	add.w	r6, r0, #8
	__asm__ volatile(
    5d88:	f04f 0320 	mov.w	r3, #32
    5d8c:	f3ef 8711 	mrs	r7, BASEPRI
    5d90:	f383 8811 	msr	BASEPRI, r3
    5d94:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&queue->wait_q);
    5d98:	4630      	mov	r0, r6
    5d9a:	f000 f970 	bl	607e <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    5d9e:	b160      	cbz	r0, 5dba <queue_insert+0x42>
    5da0:	2400      	movs	r4, #0
    5da2:	f8c0 4090 	str.w	r4, [r0, #144]	; 0x90
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
    5da6:	f8c0 8014 	str.w	r8, [r0, #20]
	z_ready_thread(thread);
    5daa:	f000 f8f2 	bl	5f92 <z_ready_thread>
	z_reschedule(&queue->lock, key);
    5dae:	4630      	mov	r0, r6
    5db0:	4639      	mov	r1, r7
    5db2:	f000 f8a6 	bl	5f02 <z_reschedule>
	return 0;
    5db6:	2000      	movs	r0, #0
    5db8:	e00c      	b.n	5dd4 <queue_insert+0x5c>
	if (alloc) {
    5dba:	f1b9 0f00 	cmp.w	r9, #0
    5dbe:	d01b      	beq.n	5df8 <queue_insert+0x80>
		anode = z_thread_malloc(sizeof(*anode));
    5dc0:	2008      	movs	r0, #8
    5dc2:	f7ff f88b 	bl	4edc <z_thread_malloc>
		if (anode == NULL) {
    5dc6:	b938      	cbnz	r0, 5dd8 <queue_insert+0x60>
	__asm__ volatile(
    5dc8:	f387 8811 	msr	BASEPRI, r7
    5dcc:	f3bf 8f6f 	isb	sy
			return -ENOMEM;
    5dd0:	f06f 000b 	mvn.w	r0, #11
}
    5dd4:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
	node->next_and_flags = flags;
    5dd8:	2301      	movs	r3, #1
		anode->data = data;
    5dda:	f8c0 8004 	str.w	r8, [r0, #4]
    5dde:	6003      	str	r3, [r0, #0]
Z_GENLIST_INSERT(sflist, sfnode)
    5de0:	6803      	ldr	r3, [r0, #0]
    5de2:	f003 0203 	and.w	r2, r3, #3
    5de6:	b95d      	cbnz	r5, 5e00 <queue_insert+0x88>
	parent->next_and_flags = cur_flags | (unative_t)child;
    5de8:	6823      	ldr	r3, [r4, #0]
    5dea:	4313      	orrs	r3, r2
    5dec:	6003      	str	r3, [r0, #0]
Z_GENLIST_PREPEND(sflist, sfnode)
    5dee:	6863      	ldr	r3, [r4, #4]
	list->head = node;
    5df0:	6020      	str	r0, [r4, #0]
Z_GENLIST_PREPEND(sflist, sfnode)
    5df2:	b973      	cbnz	r3, 5e12 <queue_insert+0x9a>
	list->tail = node;
    5df4:	6060      	str	r0, [r4, #4]
}
    5df6:	e00c      	b.n	5e12 <queue_insert+0x9a>
	node->next_and_flags = flags;
    5df8:	f8c8 9000 	str.w	r9, [r8]
}
    5dfc:	4640      	mov	r0, r8
    5dfe:	e7ef      	b.n	5de0 <queue_insert+0x68>
	return (sys_sfnode_t *)(node->next_and_flags & ~SYS_SFLIST_FLAGS_MASK);
    5e00:	682b      	ldr	r3, [r5, #0]
Z_GENLIST_INSERT(sflist, sfnode)
    5e02:	f033 0303 	bics.w	r3, r3, #3
    5e06:	d110      	bne.n	5e2a <queue_insert+0xb2>
	parent->next_and_flags = cur_flags | (unative_t)child;
    5e08:	6002      	str	r2, [r0, #0]
Z_GENLIST_APPEND(sflist, sfnode)
    5e0a:	6862      	ldr	r2, [r4, #4]
    5e0c:	b93a      	cbnz	r2, 5e1e <queue_insert+0xa6>
	list->head = node;
    5e0e:	e9c4 0000 	strd	r0, r0, [r4]
	z_handle_obj_poll_events(&queue->poll_events, state);
    5e12:	2104      	movs	r1, #4
    5e14:	f104 0010 	add.w	r0, r4, #16
    5e18:	f000 fb7b 	bl	6512 <z_handle_obj_poll_events>
    5e1c:	e7c7      	b.n	5dae <queue_insert+0x36>
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    5e1e:	6813      	ldr	r3, [r2, #0]
	parent->next_and_flags = cur_flags | (unative_t)child;
    5e20:	f003 0303 	and.w	r3, r3, #3
    5e24:	4303      	orrs	r3, r0
    5e26:	6013      	str	r3, [r2, #0]
    5e28:	e7e4      	b.n	5df4 <queue_insert+0x7c>
    5e2a:	4313      	orrs	r3, r2
    5e2c:	6003      	str	r3, [r0, #0]
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    5e2e:	682b      	ldr	r3, [r5, #0]
	parent->next_and_flags = cur_flags | (unative_t)child;
    5e30:	f003 0303 	and.w	r3, r3, #3
    5e34:	4303      	orrs	r3, r0
    5e36:	602b      	str	r3, [r5, #0]
}
    5e38:	e7eb      	b.n	5e12 <queue_insert+0x9a>

00005e3a <z_queue_node_peek>:
{
    5e3a:	b510      	push	{r4, lr}
	if ((node != NULL) && (sys_sfnode_flags_get(node) != (uint8_t)0)) {
    5e3c:	4604      	mov	r4, r0
    5e3e:	b130      	cbz	r0, 5e4e <z_queue_node_peek+0x14>
	return node->next_and_flags & SYS_SFLIST_FLAGS_MASK;
    5e40:	6802      	ldr	r2, [r0, #0]
    5e42:	0793      	lsls	r3, r2, #30
    5e44:	d003      	beq.n	5e4e <z_queue_node_peek+0x14>
		ret = anode->data;
    5e46:	6844      	ldr	r4, [r0, #4]
		if (needs_free) {
    5e48:	b109      	cbz	r1, 5e4e <z_queue_node_peek+0x14>
			k_free(anode);
    5e4a:	f000 fcf7 	bl	683c <k_free>
}
    5e4e:	4620      	mov	r0, r4
    5e50:	bd10      	pop	{r4, pc}

00005e52 <z_impl_k_queue_init>:
	list->head = NULL;
    5e52:	2200      	movs	r2, #0
	list->tail = NULL;
    5e54:	e9c0 2200 	strd	r2, r2, [r0]
    5e58:	f100 0208 	add.w	r2, r0, #8
    5e5c:	e9c0 2202 	strd	r2, r2, [r0, #8]
	sys_dlist_init(&queue->poll_events);
    5e60:	f100 0210 	add.w	r2, r0, #16
    5e64:	e9c0 2204 	strd	r2, r2, [r0, #16]
	z_object_init(queue);
    5e68:	f000 bc88 	b.w	677c <z_object_init>

00005e6c <z_impl_k_queue_cancel_wait>:
{
    5e6c:	b570      	push	{r4, r5, r6, lr}
    5e6e:	4604      	mov	r4, r0
	k_spinlock_key_t key = k_spin_lock(&queue->lock);
    5e70:	f100 0508 	add.w	r5, r0, #8
	__asm__ volatile(
    5e74:	f04f 0320 	mov.w	r3, #32
    5e78:	f3ef 8611 	mrs	r6, BASEPRI
    5e7c:	f383 8811 	msr	BASEPRI, r3
    5e80:	f3bf 8f6f 	isb	sy
	first_pending_thread = z_unpend_first_thread(&queue->wait_q);
    5e84:	4628      	mov	r0, r5
    5e86:	f000 f8fa 	bl	607e <z_unpend_first_thread>
	if (first_pending_thread != NULL) {
    5e8a:	b128      	cbz	r0, 5e98 <z_impl_k_queue_cancel_wait+0x2c>
    5e8c:	2200      	movs	r2, #0
    5e8e:	f8c0 2090 	str.w	r2, [r0, #144]	; 0x90
    5e92:	6142      	str	r2, [r0, #20]
	z_ready_thread(thread);
    5e94:	f000 f87d 	bl	5f92 <z_ready_thread>
	z_handle_obj_poll_events(&queue->poll_events, state);
    5e98:	f104 0010 	add.w	r0, r4, #16
    5e9c:	2108      	movs	r1, #8
    5e9e:	f000 fb38 	bl	6512 <z_handle_obj_poll_events>
	z_reschedule(&queue->lock, key);
    5ea2:	4631      	mov	r1, r6
    5ea4:	4628      	mov	r0, r5
}
    5ea6:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	z_reschedule(&queue->lock, key);
    5eaa:	f000 b82a 	b.w	5f02 <z_reschedule>

00005eae <z_impl_k_queue_alloc_append>:
{
    5eae:	460a      	mov	r2, r1
	return queue_insert(queue, sys_sflist_peek_tail(&queue->data_q), data,
    5eb0:	2301      	movs	r3, #1
    5eb2:	6841      	ldr	r1, [r0, #4]
    5eb4:	f7ff bf60 	b.w	5d78 <queue_insert>

00005eb8 <z_impl_k_queue_alloc_prepend>:
{
    5eb8:	460a      	mov	r2, r1
	return queue_insert(queue, NULL, data, true);
    5eba:	2301      	movs	r3, #1
    5ebc:	2100      	movs	r1, #0
    5ebe:	f7ff bf5b 	b.w	5d78 <queue_insert>

00005ec2 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    5ec2:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    5ec6:	b923      	cbnz	r3, 5ed2 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    5ec8:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    5ecc:	f000 0001 	and.w	r0, r0, #1
    5ed0:	4770      	bx	lr
		return false;
    5ed2:	2000      	movs	r0, #0
}
    5ed4:	4770      	bx	lr

00005ed6 <thread_obj_validate>:
{
    5ed6:	b508      	push	{r3, lr}
	struct z_object *ko = z_object_find(thread);
    5ed8:	f7fa f900 	bl	dc <z_object_find>
	int ret = z_object_validate(ko, K_OBJ_THREAD, _OBJ_INIT_TRUE);
    5edc:	2200      	movs	r2, #0
    5ede:	2109      	movs	r1, #9
    5ee0:	f7fe ffc2 	bl	4e68 <z_object_validate>
}
    5ee4:	f110 0f16 	cmn.w	r0, #22
    5ee8:	bf14      	ite	ne
    5eea:	2000      	movne	r0, #0
    5eec:	2001      	moveq	r0, #1
    5eee:	bd08      	pop	{r3, pc}

00005ef0 <z_is_t1_higher_prio_than_t2>:
	if (thread_1->base.prio < thread_2->base.prio) {
    5ef0:	f990 000e 	ldrsb.w	r0, [r0, #14]
    5ef4:	f991 300e 	ldrsb.w	r3, [r1, #14]
}
    5ef8:	4298      	cmp	r0, r3
    5efa:	bfac      	ite	ge
    5efc:	2000      	movge	r0, #0
    5efe:	2001      	movlt	r0, #1
    5f00:	4770      	bx	lr

00005f02 <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    5f02:	b921      	cbnz	r1, 5f0e <z_reschedule+0xc>
  __ASM volatile ("MRS %0, ipsr" : "=r" (result) );
    5f04:	f3ef 8005 	mrs	r0, IPSR
    5f08:	b908      	cbnz	r0, 5f0e <z_reschedule+0xc>
    5f0a:	f7fb ba83 	b.w	1414 <arch_swap>
	__asm__ volatile(
    5f0e:	f381 8811 	msr	BASEPRI, r1
    5f12:	f3bf 8f6f 	isb	sy
}
    5f16:	4770      	bx	lr

00005f18 <z_reschedule_irqlock>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
    5f18:	4603      	mov	r3, r0
    5f1a:	b920      	cbnz	r0, 5f26 <z_reschedule_irqlock+0xe>
    5f1c:	f3ef 8205 	mrs	r2, IPSR
    5f20:	b90a      	cbnz	r2, 5f26 <z_reschedule_irqlock+0xe>
    5f22:	f7fb ba77 	b.w	1414 <arch_swap>
    5f26:	f383 8811 	msr	BASEPRI, r3
    5f2a:	f3bf 8f6f 	isb	sy
}
    5f2e:	4770      	bx	lr

00005f30 <z_reschedule_unlocked>:
	__asm__ volatile(
    5f30:	f04f 0320 	mov.w	r3, #32
    5f34:	f3ef 8011 	mrs	r0, BASEPRI
    5f38:	f383 8811 	msr	BASEPRI, r3
    5f3c:	f3bf 8f6f 	isb	sy
	(void) z_reschedule_irqlock(arch_irq_lock());
    5f40:	f7ff bfea 	b.w	5f18 <z_reschedule_irqlock>

00005f44 <z_unpend_thread>:
{
    5f44:	b510      	push	{r4, lr}
    5f46:	4601      	mov	r1, r0
    5f48:	f04f 0320 	mov.w	r3, #32
    5f4c:	f3ef 8411 	mrs	r4, BASEPRI
    5f50:	f383 8811 	msr	BASEPRI, r3
    5f54:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    5f58:	6880      	ldr	r0, [r0, #8]
    5f5a:	f7fd fb95 	bl	3688 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    5f5e:	7b4b      	ldrb	r3, [r1, #13]
    5f60:	f023 0302 	bic.w	r3, r3, #2
    5f64:	734b      	strb	r3, [r1, #13]
		thread->base.pended_on = NULL;
    5f66:	2300      	movs	r3, #0
    5f68:	608b      	str	r3, [r1, #8]
	__asm__ volatile(
    5f6a:	f384 8811 	msr	BASEPRI, r4
    5f6e:	f3bf 8f6f 	isb	sy
}
    5f72:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_abort_timeout(&thread->base.timeout);
    5f76:	f101 0018 	add.w	r0, r1, #24
    5f7a:	f000 b932 	b.w	61e2 <z_abort_timeout>

00005f7e <z_priq_dumb_best>:
{
    5f7e:	4603      	mov	r3, r0
	return list->head == list;
    5f80:	6800      	ldr	r0, [r0, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    5f82:	4283      	cmp	r3, r0
    5f84:	d003      	beq.n	5f8e <z_priq_dumb_best+0x10>
	if (n != NULL) {
    5f86:	2800      	cmp	r0, #0
    5f88:	bf38      	it	cc
    5f8a:	2000      	movcc	r0, #0
    5f8c:	4770      	bx	lr
	struct k_thread *thread = NULL;
    5f8e:	2000      	movs	r0, #0
}
    5f90:	4770      	bx	lr

00005f92 <z_ready_thread>:
{
    5f92:	b510      	push	{r4, lr}
	__asm__ volatile(
    5f94:	f04f 0320 	mov.w	r3, #32
    5f98:	f3ef 8411 	mrs	r4, BASEPRI
    5f9c:	f383 8811 	msr	BASEPRI, r3
    5fa0:	f3bf 8f6f 	isb	sy
		ready_thread(thread);
    5fa4:	f7fd fbc8 	bl	3738 <ready_thread>
	__asm__ volatile(
    5fa8:	f384 8811 	msr	BASEPRI, r4
    5fac:	f3bf 8f6f 	isb	sy
}
    5fb0:	bd10      	pop	{r4, pc}

00005fb2 <z_thread_timeout>:
{
    5fb2:	b538      	push	{r3, r4, r5, lr}
	if (thread->base.pended_on != NULL) {
    5fb4:	f850 3c10 	ldr.w	r3, [r0, #-16]
{
    5fb8:	4604      	mov	r4, r0
	struct k_thread *thread = CONTAINER_OF(timeout,
    5fba:	f1a0 0118 	sub.w	r1, r0, #24
	if (thread->base.pended_on != NULL) {
    5fbe:	b1c3      	cbz	r3, 5ff2 <z_thread_timeout+0x40>
	__asm__ volatile(
    5fc0:	f04f 0320 	mov.w	r3, #32
    5fc4:	f3ef 8511 	mrs	r5, BASEPRI
    5fc8:	f383 8811 	msr	BASEPRI, r3
    5fcc:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    5fd0:	f850 0c10 	ldr.w	r0, [r0, #-16]
    5fd4:	f7fd fb58 	bl	3688 <z_priq_dumb_remove>
    5fd8:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
    5fdc:	f023 0302 	bic.w	r3, r3, #2
    5fe0:	f804 3c0b 	strb.w	r3, [r4, #-11]
		thread->base.pended_on = NULL;
    5fe4:	2300      	movs	r3, #0
    5fe6:	f844 3c10 	str.w	r3, [r4, #-16]
	__asm__ volatile(
    5fea:	f385 8811 	msr	BASEPRI, r5
    5fee:	f3bf 8f6f 	isb	sy
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    5ff2:	f814 3c0b 	ldrb.w	r3, [r4, #-11]
    5ff6:	f023 0314 	bic.w	r3, r3, #20
    5ffa:	f804 3c0b 	strb.w	r3, [r4, #-11]
	z_ready_thread(thread);
    5ffe:	4608      	mov	r0, r1
}
    6000:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
	z_ready_thread(thread);
    6004:	f7ff bfc5 	b.w	5f92 <z_ready_thread>

00006008 <z_remove_thread_from_ready_q>:
{
    6008:	b510      	push	{r4, lr}
	__asm__ volatile(
    600a:	f04f 0320 	mov.w	r3, #32
    600e:	f3ef 8411 	mrs	r4, BASEPRI
    6012:	f383 8811 	msr	BASEPRI, r3
    6016:	f3bf 8f6f 	isb	sy
		unready_thread(thread);
    601a:	f7fd fd4f 	bl	3abc <unready_thread>
	__asm__ volatile(
    601e:	f384 8811 	msr	BASEPRI, r4
    6022:	f3bf 8f6f 	isb	sy
}
    6026:	bd10      	pop	{r4, pc}

00006028 <add_to_waitq_locked>:
{
    6028:	b538      	push	{r3, r4, r5, lr}
    602a:	4604      	mov	r4, r0
    602c:	460d      	mov	r5, r1
	unready_thread(thread);
    602e:	f7fd fd45 	bl	3abc <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
    6032:	7b63      	ldrb	r3, [r4, #13]
    6034:	f043 0302 	orr.w	r3, r3, #2
    6038:	7363      	strb	r3, [r4, #13]
	if (wait_q != NULL) {
    603a:	b1c5      	cbz	r5, 606e <add_to_waitq_locked+0x46>
	return list->head == list;
    603c:	682b      	ldr	r3, [r5, #0]
		thread->base.pended_on = wait_q;
    603e:	60a5      	str	r5, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    6040:	429d      	cmp	r5, r3
    6042:	bf08      	it	eq
    6044:	2300      	moveq	r3, #0
    6046:	2b00      	cmp	r3, #0
    6048:	bf38      	it	cc
    604a:	2300      	movcc	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
    604c:	b183      	cbz	r3, 6070 <add_to_waitq_locked+0x48>
	if (thread_1->base.prio < thread_2->base.prio) {
    604e:	f994 100e 	ldrsb.w	r1, [r4, #14]
    6052:	f993 200e 	ldrsb.w	r2, [r3, #14]
    6056:	4291      	cmp	r1, r2
    6058:	db04      	blt.n	6064 <add_to_waitq_locked+0x3c>
	return (node == list->tail) ? NULL : node->next;
    605a:	686a      	ldr	r2, [r5, #4]
    605c:	429a      	cmp	r2, r3
    605e:	d007      	beq.n	6070 <add_to_waitq_locked+0x48>
    6060:	681b      	ldr	r3, [r3, #0]
    6062:	e7f3      	b.n	604c <add_to_waitq_locked+0x24>
	node->prev = successor->prev;
    6064:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
    6066:	e9c4 3200 	strd	r3, r2, [r4]
	successor->prev->next = node;
    606a:	6014      	str	r4, [r2, #0]
	successor->prev = node;
    606c:	605c      	str	r4, [r3, #4]
}
    606e:	bd38      	pop	{r3, r4, r5, pc}
	node->prev = list->tail;
    6070:	686b      	ldr	r3, [r5, #4]
    6072:	6063      	str	r3, [r4, #4]
	list->tail->next = node;
    6074:	686b      	ldr	r3, [r5, #4]
	node->next = list;
    6076:	6025      	str	r5, [r4, #0]
	list->tail->next = node;
    6078:	601c      	str	r4, [r3, #0]
	list->tail = node;
    607a:	606c      	str	r4, [r5, #4]
    607c:	e7f7      	b.n	606e <add_to_waitq_locked+0x46>

0000607e <z_unpend_first_thread>:
{
    607e:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
    6080:	f04f 0320 	mov.w	r3, #32
    6084:	f3ef 8211 	mrs	r2, BASEPRI
    6088:	f383 8811 	msr	BASEPRI, r3
    608c:	f3bf 8f6f 	isb	sy
		ret = _priq_wait_best(&wait_q->waitq);
    6090:	f7ff ff75 	bl	5f7e <z_priq_dumb_best>
    6094:	4604      	mov	r4, r0
	__asm__ volatile(
    6096:	f382 8811 	msr	BASEPRI, r2
    609a:	f3bf 8f6f 	isb	sy

static inline struct k_thread *z_unpend1_no_timeout(_wait_q_t *wait_q)
{
	struct k_thread *thread = z_find_first_thread_to_unpend(wait_q, NULL);

	if (thread != NULL) {
    609e:	b1c8      	cbz	r0, 60d4 <z_unpend_first_thread+0x56>
	__asm__ volatile(
    60a0:	f04f 0320 	mov.w	r3, #32
    60a4:	f3ef 8511 	mrs	r5, BASEPRI
    60a8:	f383 8811 	msr	BASEPRI, r3
    60ac:	f3bf 8f6f 	isb	sy
		_priq_wait_remove(&pended_on(thread)->waitq, thread);
    60b0:	4601      	mov	r1, r0
    60b2:	6880      	ldr	r0, [r0, #8]
    60b4:	f7fd fae8 	bl	3688 <z_priq_dumb_remove>
	thread->base.thread_state &= ~_THREAD_PENDING;
    60b8:	7b63      	ldrb	r3, [r4, #13]
    60ba:	f023 0302 	bic.w	r3, r3, #2
    60be:	7363      	strb	r3, [r4, #13]
		thread->base.pended_on = NULL;
    60c0:	2300      	movs	r3, #0
    60c2:	60a3      	str	r3, [r4, #8]
	__asm__ volatile(
    60c4:	f385 8811 	msr	BASEPRI, r5
    60c8:	f3bf 8f6f 	isb	sy
    60cc:	f104 0018 	add.w	r0, r4, #24
    60d0:	f000 f887 	bl	61e2 <z_abort_timeout>
}
    60d4:	4620      	mov	r0, r4
    60d6:	bd38      	pop	{r3, r4, r5, pc}

000060d8 <z_unpend_all>:
{
    60d8:	b538      	push	{r3, r4, r5, lr}
    60da:	4605      	mov	r5, r0
	int need_sched = 0;
    60dc:	2000      	movs	r0, #0
	return list->head == list;
    60de:	682c      	ldr	r4, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    60e0:	42a5      	cmp	r5, r4
    60e2:	d000      	beq.n	60e6 <z_unpend_all+0xe>
	while ((thread = z_waitq_head(wait_q)) != NULL) {
    60e4:	b904      	cbnz	r4, 60e8 <z_unpend_all+0x10>
}
    60e6:	bd38      	pop	{r3, r4, r5, pc}
		z_unpend_thread(thread);
    60e8:	4620      	mov	r0, r4
    60ea:	f7ff ff2b 	bl	5f44 <z_unpend_thread>
		z_ready_thread(thread);
    60ee:	4620      	mov	r0, r4
    60f0:	f7ff ff4f 	bl	5f92 <z_ready_thread>
		need_sched = 1;
    60f4:	2001      	movs	r0, #1
    60f6:	e7f2      	b.n	60de <z_unpend_all+0x6>

000060f8 <z_impl_k_wakeup>:
{
    60f8:	b510      	push	{r4, lr}
	if (z_is_thread_pending(thread)) {
    60fa:	7b43      	ldrb	r3, [r0, #13]
    60fc:	079b      	lsls	r3, r3, #30
{
    60fe:	4604      	mov	r4, r0
	if (z_is_thread_pending(thread)) {
    6100:	d415      	bmi.n	612e <z_impl_k_wakeup+0x36>
    6102:	3018      	adds	r0, #24
    6104:	f000 f86d 	bl	61e2 <z_abort_timeout>
	if (z_abort_thread_timeout(thread) < 0) {
    6108:	2800      	cmp	r0, #0
    610a:	da02      	bge.n	6112 <z_impl_k_wakeup+0x1a>
		if (thread->base.thread_state != _THREAD_SUSPENDED) {
    610c:	7b63      	ldrb	r3, [r4, #13]
    610e:	2b10      	cmp	r3, #16
    6110:	d10d      	bne.n	612e <z_impl_k_wakeup+0x36>
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
    6112:	7b63      	ldrb	r3, [r4, #13]
    6114:	f023 0310 	bic.w	r3, r3, #16
    6118:	7363      	strb	r3, [r4, #13]
	z_ready_thread(thread);
    611a:	4620      	mov	r0, r4
    611c:	f7ff ff39 	bl	5f92 <z_ready_thread>
    6120:	f3ef 8305 	mrs	r3, IPSR
	if (!arch_is_in_isr()) {
    6124:	b91b      	cbnz	r3, 612e <z_impl_k_wakeup+0x36>
}
    6126:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		z_reschedule_unlocked();
    612a:	f7ff bf01 	b.w	5f30 <z_reschedule_unlocked>
}
    612e:	bd10      	pop	{r4, pc}

00006130 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6130:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6134:	b923      	cbnz	r3, 6140 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6136:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    613a:	f000 0001 	and.w	r0, r0, #1
    613e:	4770      	bx	lr
		return false;
    6140:	2000      	movs	r0, #0
}
    6142:	4770      	bx	lr

00006144 <z_impl_k_sem_init>:
{
    6144:	b508      	push	{r3, lr}
	CHECKIF(limit == 0U || initial_count > limit) {
    6146:	b16a      	cbz	r2, 6164 <z_impl_k_sem_init+0x20>
    6148:	428a      	cmp	r2, r1
    614a:	d30b      	bcc.n	6164 <z_impl_k_sem_init+0x20>
	sem->limit = limit;
    614c:	e9c0 1202 	strd	r1, r2, [r0, #8]
	sys_dlist_init(&sem->poll_events);
    6150:	f100 0210 	add.w	r2, r0, #16
	list->tail = (sys_dnode_t *)list;
    6154:	e9c0 0000 	strd	r0, r0, [r0]
    6158:	e9c0 2204 	strd	r2, r2, [r0, #16]
	z_object_init(sem);
    615c:	f000 fb0e 	bl	677c <z_object_init>
	return 0;
    6160:	2000      	movs	r0, #0
}
    6162:	bd08      	pop	{r3, pc}
		return -EINVAL;
    6164:	f06f 0015 	mvn.w	r0, #21
    6168:	e7fb      	b.n	6162 <z_impl_k_sem_init+0x1e>

0000616a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    616a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    616e:	b923      	cbnz	r3, 617a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6170:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6174:	f000 0001 	and.w	r0, r0, #1
    6178:	4770      	bx	lr
		return false;
    617a:	2000      	movs	r0, #0
}
    617c:	4770      	bx	lr

0000617e <k_is_in_isr>:
    617e:	f3ef 8005 	mrs	r0, IPSR
}
    6182:	3800      	subs	r0, #0
    6184:	bf18      	it	ne
    6186:	2001      	movne	r0, #1
    6188:	4770      	bx	lr

0000618a <z_impl_k_busy_wait>:
	arch_busy_wait(usec_to_wait);
    618a:	f7fb bf55 	b.w	2038 <arch_busy_wait>

0000618e <z_impl_k_thread_name_set>:
}
    618e:	f06f 0046 	mvn.w	r0, #70	; 0x46
    6192:	4770      	bx	lr

00006194 <z_stack_is_user_capable>:
{
    6194:	b508      	push	{r3, lr}
	return z_object_find(stack) != NULL;
    6196:	f7f9 ffa1 	bl	dc <z_object_find>
}
    619a:	3800      	subs	r0, #0
    619c:	bf18      	it	ne
    619e:	2001      	movne	r0, #1
    61a0:	bd08      	pop	{r3, pc}

000061a2 <z_impl_k_thread_create>:
{
    61a2:	b5f0      	push	{r4, r5, r6, r7, lr}
    61a4:	b087      	sub	sp, #28
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    61a6:	2500      	movs	r5, #0
    61a8:	9505      	str	r5, [sp, #20]
    61aa:	9d10      	ldr	r5, [sp, #64]	; 0x40
    61ac:	9504      	str	r5, [sp, #16]
    61ae:	9d0f      	ldr	r5, [sp, #60]	; 0x3c
    61b0:	9503      	str	r5, [sp, #12]
    61b2:	9d0e      	ldr	r5, [sp, #56]	; 0x38
    61b4:	9502      	str	r5, [sp, #8]
{
    61b6:	e9dd 6712 	ldrd	r6, r7, [sp, #72]	; 0x48
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    61ba:	9d0d      	ldr	r5, [sp, #52]	; 0x34
    61bc:	9501      	str	r5, [sp, #4]
    61be:	9d0c      	ldr	r5, [sp, #48]	; 0x30
    61c0:	9500      	str	r5, [sp, #0]
{
    61c2:	4604      	mov	r4, r0
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
    61c4:	f7fe f88e 	bl	42e4 <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
    61c8:	1c7b      	adds	r3, r7, #1
    61ca:	bf08      	it	eq
    61cc:	f1b6 3fff 	cmpeq.w	r6, #4294967295	; 0xffffffff
    61d0:	d004      	beq.n	61dc <z_impl_k_thread_create+0x3a>
		schedule_new_thread(new_thread, delay);
    61d2:	4632      	mov	r2, r6
    61d4:	463b      	mov	r3, r7
    61d6:	4620      	mov	r0, r4
    61d8:	f7fe f830 	bl	423c <schedule_new_thread>
}
    61dc:	4620      	mov	r0, r4
    61de:	b007      	add	sp, #28
    61e0:	bdf0      	pop	{r4, r5, r6, r7, pc}

000061e2 <z_abort_timeout>:
{
    61e2:	b510      	push	{r4, lr}
	__asm__ volatile(
    61e4:	f04f 0220 	mov.w	r2, #32
    61e8:	f3ef 8411 	mrs	r4, BASEPRI
    61ec:	f382 8811 	msr	BASEPRI, r2
    61f0:	f3bf 8f6f 	isb	sy
		if (sys_dnode_is_linked(&to->node)) {
    61f4:	6803      	ldr	r3, [r0, #0]
    61f6:	b13b      	cbz	r3, 6208 <z_abort_timeout+0x26>
			remove_timeout(to);
    61f8:	f7fe fa40 	bl	467c <remove_timeout>
			ret = 0;
    61fc:	2000      	movs	r0, #0
	__asm__ volatile(
    61fe:	f384 8811 	msr	BASEPRI, r4
    6202:	f3bf 8f6f 	isb	sy
}
    6206:	bd10      	pop	{r4, pc}
	int ret = -EINVAL;
    6208:	f06f 0015 	mvn.w	r0, #21
    620c:	e7f7      	b.n	61fe <z_abort_timeout+0x1c>

0000620e <z_timeout_remaining>:
{
    620e:	b510      	push	{r4, lr}
	__asm__ volatile(
    6210:	f04f 0320 	mov.w	r3, #32
    6214:	f3ef 8411 	mrs	r4, BASEPRI
    6218:	f383 8811 	msr	BASEPRI, r3
    621c:	f3bf 8f6f 	isb	sy
		ticks = timeout_rem(timeout);
    6220:	f7fe fa60 	bl	46e4 <timeout_rem>
	__asm__ volatile(
    6224:	f384 8811 	msr	BASEPRI, r4
    6228:	f3bf 8f6f 	isb	sy
}
    622c:	bd10      	pop	{r4, pc}

0000622e <z_get_next_timeout_expiry>:
{
    622e:	b510      	push	{r4, lr}
	__asm__ volatile(
    6230:	f04f 0320 	mov.w	r3, #32
    6234:	f3ef 8411 	mrs	r4, BASEPRI
    6238:	f383 8811 	msr	BASEPRI, r3
    623c:	f3bf 8f6f 	isb	sy
		ret = next_timeout();
    6240:	f7fe fa36 	bl	46b0 <next_timeout>
	__asm__ volatile(
    6244:	f384 8811 	msr	BASEPRI, r4
    6248:	f3bf 8f6f 	isb	sy
}
    624c:	bd10      	pop	{r4, pc}

0000624e <z_set_timeout_expiry>:
{
    624e:	b570      	push	{r4, r5, r6, lr}
    6250:	4604      	mov	r4, r0
    6252:	460d      	mov	r5, r1
	__asm__ volatile(
    6254:	f04f 0320 	mov.w	r3, #32
    6258:	f3ef 8611 	mrs	r6, BASEPRI
    625c:	f383 8811 	msr	BASEPRI, r3
    6260:	f3bf 8f6f 	isb	sy
		int next_to = next_timeout();
    6264:	f7fe fa24 	bl	46b0 <next_timeout>
		if (!imminent && (sooner || IS_ENABLED(CONFIG_SMP))) {
    6268:	2801      	cmp	r0, #1
    626a:	dd05      	ble.n	6278 <z_set_timeout_expiry+0x2a>
    626c:	42a0      	cmp	r0, r4
    626e:	dd03      	ble.n	6278 <z_set_timeout_expiry+0x2a>
			z_clock_set_timeout(ticks, is_idle);
    6270:	4629      	mov	r1, r5
    6272:	4620      	mov	r0, r4
    6274:	f7fb f818 	bl	12a8 <z_clock_set_timeout>
	__asm__ volatile(
    6278:	f386 8811 	msr	BASEPRI, r6
    627c:	f3bf 8f6f 	isb	sy
}
    6280:	bd70      	pop	{r4, r5, r6, pc}

00006282 <z_tick_get_32>:
{
    6282:	b508      	push	{r3, lr}
	return (uint32_t)z_tick_get();
    6284:	f7fe fb62 	bl	494c <z_tick_get>
}
    6288:	bd08      	pop	{r3, pc}

0000628a <z_timeout_end_calc>:
 * timeout object.  When used correctly, this should be called once,
 * synchronously with the user passing a new timeout value.  It should
 * not be used iteratively to adjust a timeout.
 */
uint64_t z_timeout_end_calc(k_timeout_t timeout)
{
    628a:	b538      	push	{r3, r4, r5, lr}
	k_ticks_t dt;

	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    628c:	1c4b      	adds	r3, r1, #1
    628e:	bf08      	it	eq
    6290:	f1b0 3fff 	cmpeq.w	r0, #4294967295	; 0xffffffff
{
    6294:	4604      	mov	r4, r0
    6296:	460d      	mov	r5, r1
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
    6298:	d013      	beq.n	62c2 <z_timeout_end_calc+0x38>
		return UINT64_MAX;
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
    629a:	ea54 0105 	orrs.w	r1, r4, r5
    629e:	d103      	bne.n	62a8 <z_timeout_end_calc+0x1e>
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(dt) >= 0) {
		return Z_TICK_ABS(dt);
	}
#endif
	return z_tick_get() + MAX(1, dt);
}
    62a0:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		return z_tick_get();
    62a4:	f7fe bb52 	b.w	494c <z_tick_get>
	if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) && Z_TICK_ABS(dt) >= 0) {
    62a8:	f06f 0101 	mvn.w	r1, #1
    62ac:	1a0a      	subs	r2, r1, r0
    62ae:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
    62b2:	eb61 0305 	sbc.w	r3, r1, r5
    62b6:	2a00      	cmp	r2, #0
    62b8:	f173 0100 	sbcs.w	r1, r3, #0
    62bc:	db02      	blt.n	62c4 <z_timeout_end_calc+0x3a>
		return Z_TICK_ABS(dt);
    62be:	4610      	mov	r0, r2
    62c0:	4619      	mov	r1, r3
}
    62c2:	bd38      	pop	{r3, r4, r5, pc}
	return z_tick_get() + MAX(1, dt);
    62c4:	f7fe fb42 	bl	494c <z_tick_get>
    62c8:	2c01      	cmp	r4, #1
    62ca:	f175 0300 	sbcs.w	r3, r5, #0
    62ce:	bfbc      	itt	lt
    62d0:	2401      	movlt	r4, #1
    62d2:	2500      	movlt	r5, #0
    62d4:	1820      	adds	r0, r4, r0
    62d6:	eb45 0101 	adc.w	r1, r5, r1
    62da:	e7f2      	b.n	62c2 <z_timeout_end_calc+0x38>

000062dc <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    62dc:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    62e0:	b923      	cbnz	r3, 62ec <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    62e2:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    62e6:	f000 0001 	and.w	r0, r0, #1
    62ea:	4770      	bx	lr
		return false;
    62ec:	2000      	movs	r0, #0
}
    62ee:	4770      	bx	lr

000062f0 <clear_event_registrations>:
	while (num_events--) {
    62f0:	2314      	movs	r3, #20
{
    62f2:	b530      	push	{r4, r5, lr}
    62f4:	fb03 0101 	mla	r1, r3, r1, r0
	event->poller = NULL;
    62f8:	2400      	movs	r4, #0
	while (num_events--) {
    62fa:	4281      	cmp	r1, r0
    62fc:	d100      	bne.n	6300 <clear_event_registrations+0x10>
}
    62fe:	bd30      	pop	{r4, r5, pc}
	switch (event->type) {
    6300:	f811 3c07 	ldrb.w	r3, [r1, #-7]
	event->poller = NULL;
    6304:	f841 4c0c 	str.w	r4, [r1, #-12]
	switch (event->type) {
    6308:	f003 030f 	and.w	r3, r3, #15
    630c:	2b02      	cmp	r3, #2
    630e:	d80a      	bhi.n	6326 <clear_event_registrations+0x36>
    6310:	b15b      	cbz	r3, 632a <clear_event_registrations+0x3a>
	if (remove && sys_dnode_is_linked(&event->_node)) {
    6312:	f851 3c14 	ldr.w	r3, [r1, #-20]
    6316:	b143      	cbz	r3, 632a <clear_event_registrations+0x3a>
	node->prev->next = node->next;
    6318:	f851 5c10 	ldr.w	r5, [r1, #-16]
    631c:	602b      	str	r3, [r5, #0]
	node->next->prev = node->prev;
    631e:	605d      	str	r5, [r3, #4]
	node->prev = NULL;
    6320:	e941 4405 	strd	r4, r4, [r1, #-20]
}
    6324:	e001      	b.n	632a <clear_event_registrations+0x3a>
	switch (event->type) {
    6326:	2b04      	cmp	r3, #4
    6328:	d0f3      	beq.n	6312 <clear_event_registrations+0x22>
    632a:	f382 8811 	msr	BASEPRI, r2
    632e:	f3bf 8f6f 	isb	sy
	__asm__ volatile(
    6332:	f04f 0320 	mov.w	r3, #32
    6336:	f3ef 8211 	mrs	r2, BASEPRI
    633a:	f383 8811 	msr	BASEPRI, r3
    633e:	f3bf 8f6f 	isb	sy
    6342:	3914      	subs	r1, #20
    6344:	e7d9      	b.n	62fa <clear_event_registrations+0xa>

00006346 <signal_poll_event>:
{
    6346:	b570      	push	{r4, r5, r6, lr}
	struct _poller *poller = event->poller;
    6348:	6884      	ldr	r4, [r0, #8]
{
    634a:	4605      	mov	r5, r0
    634c:	460e      	mov	r6, r1
	if (poller) {
    634e:	b19c      	cbz	r4, 6378 <signal_poll_event+0x32>
		if (poller->cb != NULL) {
    6350:	68a3      	ldr	r3, [r4, #8]
    6352:	b95b      	cbnz	r3, 636c <signal_poll_event+0x26>
		poller->is_polling = false;
    6354:	7023      	strb	r3, [r4, #0]
	int retcode = 0;
    6356:	4618      	mov	r0, r3
	event->poller = NULL;
    6358:	2300      	movs	r3, #0
    635a:	60ab      	str	r3, [r5, #8]
	event->state |= state;
    635c:	68eb      	ldr	r3, [r5, #12]
    635e:	f3c3 3104 	ubfx	r1, r3, #12, #5
    6362:	430e      	orrs	r6, r1
    6364:	f366 3310 	bfi	r3, r6, #12, #5
    6368:	60eb      	str	r3, [r5, #12]
	return retcode;
    636a:	e004      	b.n	6376 <signal_poll_event+0x30>
			retcode = poller->cb(event, state);
    636c:	4798      	blx	r3
		poller->is_polling = false;
    636e:	2300      	movs	r3, #0
		if (retcode < 0) {
    6370:	2800      	cmp	r0, #0
		poller->is_polling = false;
    6372:	7023      	strb	r3, [r4, #0]
		if (retcode < 0) {
    6374:	daf0      	bge.n	6358 <signal_poll_event+0x12>
}
    6376:	bd70      	pop	{r4, r5, r6, pc}
	int retcode = 0;
    6378:	4620      	mov	r0, r4
    637a:	e7ed      	b.n	6358 <signal_poll_event+0x12>

0000637c <k_poll_poller_cb>:
{
    637c:	b538      	push	{r3, r4, r5, lr}
	struct k_thread *thread = event->poller->thread;
    637e:	6883      	ldr	r3, [r0, #8]
    6380:	685c      	ldr	r4, [r3, #4]
	if (!z_is_thread_pending(thread)) {
    6382:	7b63      	ldrb	r3, [r4, #13]
    6384:	079a      	lsls	r2, r3, #30
{
    6386:	460d      	mov	r5, r1
	if (!z_is_thread_pending(thread)) {
    6388:	d516      	bpl.n	63b8 <k_poll_poller_cb+0x3c>
	if (z_is_thread_timeout_expired(thread)) {
    638a:	e9d4 230a 	ldrd	r2, r3, [r4, #40]	; 0x28
    638e:	f04f 31ff 	mov.w	r1, #4294967295	; 0xffffffff
    6392:	f06f 0001 	mvn.w	r0, #1
    6396:	428b      	cmp	r3, r1
    6398:	bf08      	it	eq
    639a:	4282      	cmpeq	r2, r0
    639c:	d015      	beq.n	63ca <k_poll_poller_cb+0x4e>
	z_unpend_thread(thread);
    639e:	4620      	mov	r0, r4
    63a0:	f7ff fdd0 	bl	5f44 <z_unpend_thread>
	arch_thread_return_value_set(thread,
    63a4:	2d08      	cmp	r5, #8
    63a6:	bf0c      	ite	eq
    63a8:	f06f 0303 	mvneq.w	r3, #3
    63ac:	2300      	movne	r3, #0
    63ae:	f8c4 3090 	str.w	r3, [r4, #144]	; 0x90
	return !((z_is_thread_prevented_from_running(thread)) != 0 ||
    63b2:	7b63      	ldrb	r3, [r4, #13]
    63b4:	06db      	lsls	r3, r3, #27
    63b6:	d001      	beq.n	63bc <k_poll_poller_cb+0x40>
		return 0;
    63b8:	2000      	movs	r0, #0
}
    63ba:	bd38      	pop	{r3, r4, r5, pc}
	if (!z_is_thread_ready(thread)) {
    63bc:	69a5      	ldr	r5, [r4, #24]
    63be:	2d00      	cmp	r5, #0
    63c0:	d1fa      	bne.n	63b8 <k_poll_poller_cb+0x3c>
	z_ready_thread(thread);
    63c2:	4620      	mov	r0, r4
    63c4:	f7ff fde5 	bl	5f92 <z_ready_thread>
	return 0;
    63c8:	e7f6      	b.n	63b8 <k_poll_poller_cb+0x3c>
		return -EAGAIN;
    63ca:	f06f 000a 	mvn.w	r0, #10
    63ce:	e7f4      	b.n	63ba <k_poll_poller_cb+0x3e>

000063d0 <add_event>:
{
    63d0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    63d2:	4617      	mov	r7, r2
	return sys_dlist_is_empty(list) ? NULL : list->tail;
    63d4:	e9d0 2300 	ldrd	r2, r3, [r0]
    63d8:	4290      	cmp	r0, r2
    63da:	4604      	mov	r4, r0
    63dc:	460d      	mov	r5, r1
    63de:	d106      	bne.n	63ee <add_event+0x1e>
	node->prev = list->tail;
    63e0:	6863      	ldr	r3, [r4, #4]
    63e2:	606b      	str	r3, [r5, #4]
	list->tail->next = node;
    63e4:	6863      	ldr	r3, [r4, #4]
	node->next = list;
    63e6:	602c      	str	r4, [r5, #0]
	list->tail->next = node;
    63e8:	601d      	str	r5, [r3, #0]
	list->tail = node;
    63ea:	6065      	str	r5, [r4, #4]
}
    63ec:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	if ((pending == NULL) ||
    63ee:	2b00      	cmp	r3, #0
    63f0:	d0f6      	beq.n	63e0 <add_event+0x10>
		z_is_t1_higher_prio_than_t2(pending->poller->thread,
    63f2:	689b      	ldr	r3, [r3, #8]
    63f4:	6879      	ldr	r1, [r7, #4]
    63f6:	6858      	ldr	r0, [r3, #4]
    63f8:	f7ff fd7a 	bl	5ef0 <z_is_t1_higher_prio_than_t2>
	if ((pending == NULL) ||
    63fc:	2800      	cmp	r0, #0
    63fe:	d1ef      	bne.n	63e0 <add_event+0x10>
	return list->head == list;
    6400:	6826      	ldr	r6, [r4, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
    6402:	42b4      	cmp	r4, r6
    6404:	d0ec      	beq.n	63e0 <add_event+0x10>
    6406:	2e00      	cmp	r6, #0
    6408:	bf38      	it	cc
    640a:	2600      	movcc	r6, #0
	SYS_DLIST_FOR_EACH_CONTAINER(events, pending, _node) {
    640c:	2e00      	cmp	r6, #0
    640e:	d0e7      	beq.n	63e0 <add_event+0x10>
		if (z_is_t1_higher_prio_than_t2(poller->thread,
    6410:	68b3      	ldr	r3, [r6, #8]
    6412:	6878      	ldr	r0, [r7, #4]
    6414:	6859      	ldr	r1, [r3, #4]
    6416:	f7ff fd6b 	bl	5ef0 <z_is_t1_higher_prio_than_t2>
    641a:	b128      	cbz	r0, 6428 <add_event+0x58>
	node->prev = successor->prev;
    641c:	6873      	ldr	r3, [r6, #4]
	node->next = successor;
    641e:	e9c5 6300 	strd	r6, r3, [r5]
	successor->prev->next = node;
    6422:	601d      	str	r5, [r3, #0]
	successor->prev = node;
    6424:	6075      	str	r5, [r6, #4]
			return;
    6426:	e7e1      	b.n	63ec <add_event+0x1c>
	return (node == list->tail) ? NULL : node->next;
    6428:	6863      	ldr	r3, [r4, #4]
    642a:	42b3      	cmp	r3, r6
    642c:	d0d8      	beq.n	63e0 <add_event+0x10>
    642e:	6836      	ldr	r6, [r6, #0]
    6430:	e7ec      	b.n	640c <add_event+0x3c>

00006432 <register_events>:
{
    6432:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	for (int ii = 0; ii < num_events; ii++) {
    6436:	f04f 0a00 	mov.w	sl, #0
{
    643a:	460e      	mov	r6, r1
    643c:	4614      	mov	r4, r2
    643e:	461f      	mov	r7, r3
    6440:	4683      	mov	fp, r0
	int events_registered = 0;
    6442:	4655      	mov	r5, sl
	event->poller = NULL;
    6444:	46d0      	mov	r8, sl
	for (int ii = 0; ii < num_events; ii++) {
    6446:	45b2      	cmp	sl, r6
    6448:	db02      	blt.n	6450 <register_events+0x1e>
}
    644a:	4628      	mov	r0, r5
    644c:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
    6450:	f04f 0320 	mov.w	r3, #32
    6454:	f3ef 8911 	mrs	r9, BASEPRI
    6458:	f383 8811 	msr	BASEPRI, r3
    645c:	f3bf 8f6f 	isb	sy
	switch (event->type) {
    6460:	f89b 200d 	ldrb.w	r2, [fp, #13]
    6464:	f002 020f 	and.w	r2, r2, #15
    6468:	2a02      	cmp	r2, #2
    646a:	d006      	beq.n	647a <register_events+0x48>
    646c:	2a04      	cmp	r2, #4
    646e:	d008      	beq.n	6482 <register_events+0x50>
    6470:	2a01      	cmp	r2, #1
    6472:	d120      	bne.n	64b6 <register_events+0x84>
		if (event->signal->signaled != 0U) {
    6474:	f8db 3010 	ldr.w	r3, [fp, #16]
    6478:	e001      	b.n	647e <register_events+0x4c>
		if (k_sem_count_get(event->sem) > 0) {
    647a:	f8db 3010 	ldr.w	r3, [fp, #16]
		if (event->signal->signaled != 0U) {
    647e:	689b      	ldr	r3, [r3, #8]
    6480:	e002      	b.n	6488 <register_events+0x56>
		if (!k_queue_is_empty(event->queue)) {
    6482:	f8db 3010 	ldr.w	r3, [fp, #16]
    6486:	681b      	ldr	r3, [r3, #0]
		if (event->signal->signaled != 0U) {
    6488:	b1ab      	cbz	r3, 64b6 <register_events+0x84>
	event->state |= state;
    648a:	f8db 300c 	ldr.w	r3, [fp, #12]
	event->poller = NULL;
    648e:	f8cb 8008 	str.w	r8, [fp, #8]
	event->state |= state;
    6492:	f3c3 3104 	ubfx	r1, r3, #12, #5
    6496:	430a      	orrs	r2, r1
    6498:	f362 3310 	bfi	r3, r2, #12, #5
    649c:	f8cb 300c 	str.w	r3, [fp, #12]
			poller->is_polling = false;
    64a0:	f884 8000 	strb.w	r8, [r4]
	__asm__ volatile(
    64a4:	f389 8811 	msr	BASEPRI, r9
    64a8:	f3bf 8f6f 	isb	sy
	for (int ii = 0; ii < num_events; ii++) {
    64ac:	f10a 0a01 	add.w	sl, sl, #1
    64b0:	f10b 0b14 	add.w	fp, fp, #20
    64b4:	e7c7      	b.n	6446 <register_events+0x14>
		} else if (!just_check && poller->is_polling) {
    64b6:	2f00      	cmp	r7, #0
    64b8:	d1f4      	bne.n	64a4 <register_events+0x72>
    64ba:	7823      	ldrb	r3, [r4, #0]
    64bc:	2b00      	cmp	r3, #0
    64be:	d0f1      	beq.n	64a4 <register_events+0x72>
	switch (event->type) {
    64c0:	f89b 300d 	ldrb.w	r3, [fp, #13]
    64c4:	f003 030f 	and.w	r3, r3, #15
    64c8:	2b02      	cmp	r3, #2
    64ca:	d008      	beq.n	64de <register_events+0xac>
    64cc:	2b04      	cmp	r3, #4
    64ce:	d006      	beq.n	64de <register_events+0xac>
    64d0:	2b01      	cmp	r3, #1
    64d2:	d10b      	bne.n	64ec <register_events+0xba>
		add_event(&event->signal->poll_events, event, poller);
    64d4:	f8db 0010 	ldr.w	r0, [fp, #16]
    64d8:	4622      	mov	r2, r4
    64da:	4659      	mov	r1, fp
    64dc:	e004      	b.n	64e8 <register_events+0xb6>
		add_event(&event->queue->poll_events, event, poller);
    64de:	f8db 0010 	ldr.w	r0, [fp, #16]
    64e2:	4622      	mov	r2, r4
    64e4:	4659      	mov	r1, fp
    64e6:	3010      	adds	r0, #16
		add_event(&event->signal->poll_events, event, poller);
    64e8:	f7ff ff72 	bl	63d0 <add_event>
	event->poller = poller;
    64ec:	f8cb 4008 	str.w	r4, [fp, #8]
				events_registered += 1;
    64f0:	3501      	adds	r5, #1
    64f2:	e7d7      	b.n	64a4 <register_events+0x72>

000064f4 <k_poll_event_init>:
{
    64f4:	b510      	push	{r4, lr}
	event->type = type;
    64f6:	0452      	lsls	r2, r2, #17
    64f8:	0209      	lsls	r1, r1, #8
    64fa:	f401 6170 	and.w	r1, r1, #3840	; 0xf00
    64fe:	f402 3200 	and.w	r2, r2, #131072	; 0x20000
    6502:	430a      	orrs	r2, r1
    6504:	7b01      	ldrb	r1, [r0, #12]
	event->poller = NULL;
    6506:	2400      	movs	r4, #0
	event->type = type;
    6508:	430a      	orrs	r2, r1
	event->obj = obj;
    650a:	e9c0 2303 	strd	r2, r3, [r0, #12]
	event->poller = NULL;
    650e:	6084      	str	r4, [r0, #8]
}
    6510:	bd10      	pop	{r4, pc}

00006512 <z_handle_obj_poll_events>:
{
    6512:	4603      	mov	r3, r0
	return list->head == list;
    6514:	6800      	ldr	r0, [r0, #0]
	if (!sys_dlist_is_empty(list)) {
    6516:	4283      	cmp	r3, r0
    6518:	d008      	beq.n	652c <z_handle_obj_poll_events+0x1a>
	node->prev->next = node->next;
    651a:	e9d0 3200 	ldrd	r3, r2, [r0]
    651e:	6013      	str	r3, [r2, #0]
	node->next->prev = node->prev;
    6520:	605a      	str	r2, [r3, #4]
	node->next = NULL;
    6522:	2300      	movs	r3, #0
	node->prev = NULL;
    6524:	e9c0 3300 	strd	r3, r3, [r0]
		(void) signal_poll_event(poll_event, state);
    6528:	f7ff bf0d 	b.w	6346 <signal_poll_event>
}
    652c:	4770      	bx	lr

0000652e <z_impl_k_poll_signal_init>:
	signal->signaled = 0U;
    652e:	2200      	movs	r2, #0
	list->tail = (sys_dnode_t *)list;
    6530:	e9c0 0000 	strd	r0, r0, [r0]
    6534:	6082      	str	r2, [r0, #8]
	z_object_init(signal);
    6536:	f000 b921 	b.w	677c <z_object_init>

0000653a <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    653a:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    653e:	b923      	cbnz	r3, 654a <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6540:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6544:	f000 0001 	and.w	r0, r0, #1
    6548:	4770      	bx	lr
		return false;
    654a:	2000      	movs	r0, #0
}
    654c:	4770      	bx	lr

0000654e <z_impl_k_futex_wake>:
{
    654e:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    6552:	460e      	mov	r6, r1
	obj = z_object_find(futex);
    6554:	f7f9 fdc2 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_FUTEX) {
    6558:	b318      	cbz	r0, 65a2 <z_impl_k_futex_wake+0x54>
    655a:	7983      	ldrb	r3, [r0, #6]
    655c:	2b0f      	cmp	r3, #15
    655e:	d120      	bne.n	65a2 <z_impl_k_futex_wake+0x54>
	return obj->data.futex_data;
    6560:	6887      	ldr	r7, [r0, #8]
	if (futex_data == NULL) {
    6562:	b1f7      	cbz	r7, 65a2 <z_impl_k_futex_wake+0x54>
	key = k_spin_lock(&futex_data->lock);
    6564:	f107 0808 	add.w	r8, r7, #8
	__asm__ volatile(
    6568:	f04f 0320 	mov.w	r3, #32
    656c:	f3ef 8911 	mrs	r9, BASEPRI
    6570:	f383 8811 	msr	BASEPRI, r3
    6574:	f3bf 8f6f 	isb	sy
	unsigned int woken = 0;
    6578:	2400      	movs	r4, #0
    657a:	46a2      	mov	sl, r4
		thread = z_unpend_first_thread(&futex_data->wait_q);
    657c:	4638      	mov	r0, r7
    657e:	f7ff fd7e 	bl	607e <z_unpend_first_thread>
		if (thread) {
    6582:	4605      	mov	r5, r0
    6584:	b130      	cbz	r0, 6594 <z_impl_k_futex_wake+0x46>
			z_ready_thread(thread);
    6586:	f7ff fd04 	bl	5f92 <z_ready_thread>
			woken++;
    658a:	3401      	adds	r4, #1
    658c:	f8c5 a090 	str.w	sl, [r5, #144]	; 0x90
	} while (thread && wake_all);
    6590:	2e00      	cmp	r6, #0
    6592:	d1f3      	bne.n	657c <z_impl_k_futex_wake+0x2e>
	z_reschedule(&futex_data->lock, key);
    6594:	4640      	mov	r0, r8
    6596:	4649      	mov	r1, r9
    6598:	f7ff fcb3 	bl	5f02 <z_reschedule>
	return woken;
    659c:	4620      	mov	r0, r4
}
    659e:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
		return -EINVAL;
    65a2:	f06f 0015 	mvn.w	r0, #21
    65a6:	e7fa      	b.n	659e <z_impl_k_futex_wake+0x50>

000065a8 <z_impl_k_futex_wait>:
{
    65a8:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    65aa:	4607      	mov	r7, r0
    65ac:	460e      	mov	r6, r1
    65ae:	4615      	mov	r5, r2
    65b0:	461c      	mov	r4, r3
	obj = z_object_find(futex);
    65b2:	f7f9 fd93 	bl	dc <z_object_find>
	if (obj == NULL || obj->type != K_OBJ_FUTEX) {
    65b6:	b338      	cbz	r0, 6608 <z_impl_k_futex_wait+0x60>
    65b8:	7983      	ldrb	r3, [r0, #6]
    65ba:	2b0f      	cmp	r3, #15
    65bc:	d124      	bne.n	6608 <z_impl_k_futex_wait+0x60>
	return obj->data.futex_data;
    65be:	6882      	ldr	r2, [r0, #8]
	if (futex_data == NULL) {
    65c0:	b312      	cbz	r2, 6608 <z_impl_k_futex_wait+0x60>
	key = k_spin_lock(&futex_data->lock);
    65c2:	f102 0008 	add.w	r0, r2, #8
    65c6:	f04f 0320 	mov.w	r3, #32
    65ca:	f3ef 8111 	mrs	r1, BASEPRI
    65ce:	f383 8811 	msr	BASEPRI, r3
    65d2:	f3bf 8f6f 	isb	sy
	return __atomic_load_n(target, __ATOMIC_SEQ_CST);
    65d6:	f3bf 8f5b 	dmb	ish
    65da:	683b      	ldr	r3, [r7, #0]
    65dc:	f3bf 8f5b 	dmb	ish
	if (atomic_get(&futex->val) != (atomic_val_t)expected) {
    65e0:	429e      	cmp	r6, r3
    65e2:	d007      	beq.n	65f4 <z_impl_k_futex_wait+0x4c>
	__asm__ volatile(
    65e4:	f381 8811 	msr	BASEPRI, r1
    65e8:	f3bf 8f6f 	isb	sy
		return -EAGAIN;
    65ec:	f06f 000a 	mvn.w	r0, #10
}
    65f0:	b003      	add	sp, #12
    65f2:	bdf0      	pop	{r4, r5, r6, r7, pc}
	ret = z_pend_curr(&futex_data->lock,
    65f4:	e9cd 5400 	strd	r5, r4, [sp]
    65f8:	f7fd face 	bl	3b98 <z_pend_curr>
	if (ret == -EAGAIN) {
    65fc:	f110 0f0b 	cmn.w	r0, #11
		ret = -ETIMEDOUT;
    6600:	bf08      	it	eq
    6602:	f06f 003b 	mvneq.w	r0, #59	; 0x3b
    6606:	e7f3      	b.n	65f0 <z_impl_k_futex_wait+0x48>
		return -EINVAL;
    6608:	f06f 0015 	mvn.w	r0, #21
    660c:	e7f0      	b.n	65f0 <z_impl_k_futex_wait+0x48>

0000660e <k_mem_domain_add_thread>:
{
    660e:	4603      	mov	r3, r0
    6610:	b510      	push	{r4, lr}
    6612:	4608      	mov	r0, r1
	__asm__ volatile(
    6614:	f04f 0220 	mov.w	r2, #32
    6618:	f3ef 8411 	mrs	r4, BASEPRI
    661c:	f382 8811 	msr	BASEPRI, r2
    6620:	f3bf 8f6f 	isb	sy
	sys_dlist_append(&domain->mem_domain_q,
    6624:	f101 0274 	add.w	r2, r1, #116	; 0x74
    6628:	f103 01c0 	add.w	r1, r3, #192	; 0xc0
	node->next = list;
    662c:	6741      	str	r1, [r0, #116]	; 0x74
	node->prev = list->tail;
    662e:	f8d3 10c4 	ldr.w	r1, [r3, #196]	; 0xc4
    6632:	6781      	str	r1, [r0, #120]	; 0x78
	list->tail->next = node;
    6634:	f8d3 10c4 	ldr.w	r1, [r3, #196]	; 0xc4
    6638:	600a      	str	r2, [r1, #0]
	list->tail = node;
    663a:	f8c3 20c4 	str.w	r2, [r3, #196]	; 0xc4
	thread->mem_domain_info.mem_domain = domain;
    663e:	67c3      	str	r3, [r0, #124]	; 0x7c
	arch_mem_domain_thread_add(thread);
    6640:	f7fb fb38 	bl	1cb4 <arch_mem_domain_thread_add>
	__asm__ volatile(
    6644:	f384 8811 	msr	BASEPRI, r4
    6648:	f3bf 8f6f 	isb	sy
}
    664c:	bd10      	pop	{r4, pc}

0000664e <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    664e:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    6652:	b923      	cbnz	r3, 665e <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    6654:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6658:	f000 0001 	and.w	r0, r0, #1
    665c:	4770      	bx	lr
		return false;
    665e:	2000      	movs	r0, #0
}
    6660:	4770      	bx	lr

00006662 <unref_check>:
{
    6662:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
    6664:	f04f 0320 	mov.w	r3, #32
    6668:	f3ef 8511 	mrs	r5, BASEPRI
    666c:	f383 8811 	msr	BASEPRI, r3
    6670:	f3bf 8f6f 	isb	sy
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6674:	094c      	lsrs	r4, r1, #5
	sys_bitfield_clear_bit((mem_addr_t)&ko->perms, index);
    6676:	3004      	adds	r0, #4
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6678:	2201      	movs	r2, #1
	uint32_t temp = *(volatile uint32_t *)addr;
    667a:	f850 3024 	ldr.w	r3, [r0, r4, lsl #2]
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    667e:	f001 011f 	and.w	r1, r1, #31
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    6682:	fa02 f101 	lsl.w	r1, r2, r1
    6686:	ea23 0101 	bic.w	r1, r3, r1
    668a:	f840 1024 	str.w	r1, [r0, r4, lsl #2]
	__asm__ volatile(
    668e:	f385 8811 	msr	BASEPRI, r5
    6692:	f3bf 8f6f 	isb	sy
}
    6696:	bd30      	pop	{r4, r5, pc}

00006698 <wordlist_cb>:
	if (sys_bitfield_test_bit((mem_addr_t)&ko->perms, ctx->parent_id) &&
    6698:	680b      	ldr	r3, [r1, #0]
{
    669a:	b530      	push	{r4, r5, lr}
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    669c:	095a      	lsrs	r2, r3, #5
	if (sys_bitfield_test_bit((mem_addr_t)&ko->perms, ctx->parent_id) &&
    669e:	1d04      	adds	r4, r0, #4
	uint32_t temp = *(volatile uint32_t *)addr;
    66a0:	f854 5022 	ldr.w	r5, [r4, r2, lsl #2]
	return sys_test_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    66a4:	f003 021f 	and.w	r2, r3, #31
	return temp & (1 << bit);
    66a8:	2301      	movs	r3, #1
    66aa:	fa03 f202 	lsl.w	r2, r3, r2
    66ae:	422a      	tst	r2, r5
    66b0:	d00d      	beq.n	66ce <wordlist_cb+0x36>
    66b2:	6800      	ldr	r0, [r0, #0]
    66b4:	688a      	ldr	r2, [r1, #8]
    66b6:	4290      	cmp	r0, r2
    66b8:	d009      	beq.n	66ce <wordlist_cb+0x36>
		sys_bitfield_set_bit((mem_addr_t)&ko->perms, ctx->child_id);
    66ba:	684a      	ldr	r2, [r1, #4]
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    66bc:	0951      	lsrs	r1, r2, #5
    66be:	f002 021f 	and.w	r2, r2, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    66c2:	f854 0021 	ldr.w	r0, [r4, r1, lsl #2]
	*(volatile uint32_t *)addr = temp | (1 << bit);
    66c6:	4093      	lsls	r3, r2
    66c8:	4303      	orrs	r3, r0
    66ca:	f844 3021 	str.w	r3, [r4, r1, lsl #2]
}
    66ce:	bd30      	pop	{r4, r5, pc}

000066d0 <clear_perms_cb>:
	unref_check(ko, id);
    66d0:	f7ff bfc7 	b.w	6662 <unref_check>

000066d4 <thread_index_get>:
{
    66d4:	b508      	push	{r3, lr}
	ko = z_object_find(thread);
    66d6:	f7f9 fd01 	bl	dc <z_object_find>
	if (ko == NULL) {
    66da:	b108      	cbz	r0, 66e0 <thread_index_get+0xc>
	return ko->data.thread_id;
    66dc:	6880      	ldr	r0, [r0, #8]
}
    66de:	bd08      	pop	{r3, pc}
		return -1;
    66e0:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
    66e4:	e7fb      	b.n	66de <thread_index_get+0xa>

000066e6 <handler_bad_syscall>:

static uintptr_t handler_bad_syscall(uintptr_t bad_id, uintptr_t arg2,
				     uintptr_t arg3, uintptr_t arg4,
				     uintptr_t arg5, uintptr_t arg6,
				     void *ssf)
{
    66e6:	b508      	push	{r3, lr}
    66e8:	f7ff ffb1 	bl	664e <arch_is_user_context>
	LOG_ERR("Bad system call id %" PRIuPTR " invoked", bad_id);
	arch_syscall_oops(ssf);
    66ec:	9804      	ldr	r0, [sp, #16]
    66ee:	f7ff f9a4 	bl	5a3a <arch_syscall_oops>

000066f2 <z_mrsh_adc_channel_setup>:
    66f2:	b508      	push	{r3, lr}
    66f4:	f7ff ffab 	bl	664e <arch_is_user_context>
    66f8:	9804      	ldr	r0, [sp, #16]
    66fa:	f7ff f99e 	bl	5a3a <arch_syscall_oops>

000066fe <z_priv_stack_find>:
{
    66fe:	b508      	push	{r3, lr}
	struct z_object *obj = z_object_find(stack);
    6700:	f7f9 fcec 	bl	dc <z_object_find>
	return obj->data.stack_data->priv;
    6704:	6883      	ldr	r3, [r0, #8]
}
    6706:	6858      	ldr	r0, [r3, #4]
    6708:	bd08      	pop	{r3, pc}

0000670a <z_thread_perms_set>:
{
    670a:	b510      	push	{r4, lr}
    670c:	4604      	mov	r4, r0
	int index = thread_index_get(thread);
    670e:	4608      	mov	r0, r1
    6710:	f7ff ffe0 	bl	66d4 <thread_index_get>
	if (index != -1) {
    6714:	1c43      	adds	r3, r0, #1
    6716:	d00b      	beq.n	6730 <z_thread_perms_set+0x26>
	sys_set_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6718:	0941      	lsrs	r1, r0, #5
		sys_bitfield_set_bit((mem_addr_t)&ko->perms, index);
    671a:	1d23      	adds	r3, r4, #4
    671c:	f000 001f 	and.w	r0, r0, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    6720:	f853 4021 	ldr.w	r4, [r3, r1, lsl #2]
	*(volatile uint32_t *)addr = temp | (1 << bit);
    6724:	2201      	movs	r2, #1
    6726:	fa02 f000 	lsl.w	r0, r2, r0
    672a:	4320      	orrs	r0, r4
    672c:	f843 0021 	str.w	r0, [r3, r1, lsl #2]
}
    6730:	bd10      	pop	{r4, pc}

00006732 <z_thread_perms_clear>:
{
    6732:	b570      	push	{r4, r5, r6, lr}
    6734:	4604      	mov	r4, r0
	int index = thread_index_get(thread);
    6736:	4608      	mov	r0, r1
    6738:	f7ff ffcc 	bl	66d4 <thread_index_get>
	if (index != -1) {
    673c:	1c43      	adds	r3, r0, #1
	int index = thread_index_get(thread);
    673e:	4601      	mov	r1, r0
	if (index != -1) {
    6740:	d010      	beq.n	6764 <z_thread_perms_clear+0x32>
	sys_clear_bit(addr + ((bit >> 5) << 2), bit & 0x1F);
    6742:	0945      	lsrs	r5, r0, #5
		sys_bitfield_clear_bit((mem_addr_t)&ko->perms, index);
    6744:	1d20      	adds	r0, r4, #4
    6746:	f001 061f 	and.w	r6, r1, #31
	uint32_t temp = *(volatile uint32_t *)addr;
    674a:	f850 3025 	ldr.w	r3, [r0, r5, lsl #2]
	*(volatile uint32_t *)addr = temp & ~(1 << bit);
    674e:	2201      	movs	r2, #1
    6750:	40b2      	lsls	r2, r6
    6752:	ea23 0302 	bic.w	r3, r3, r2
    6756:	f840 3025 	str.w	r3, [r0, r5, lsl #2]
		unref_check(ko, index);
    675a:	4620      	mov	r0, r4
}
    675c:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		unref_check(ko, index);
    6760:	f7ff bf7f 	b.w	6662 <unref_check>
}
    6764:	bd70      	pop	{r4, r5, r6, pc}

00006766 <z_impl_k_object_access_grant>:
{
    6766:	b510      	push	{r4, lr}
    6768:	460c      	mov	r4, r1
	struct z_object *ko = z_object_find(object);
    676a:	f7f9 fcb7 	bl	dc <z_object_find>
	if (ko != NULL) {
    676e:	b120      	cbz	r0, 677a <z_impl_k_object_access_grant+0x14>
		z_thread_perms_set(ko, thread);
    6770:	4621      	mov	r1, r4
}
    6772:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		z_thread_perms_set(ko, thread);
    6776:	f7ff bfc8 	b.w	670a <z_thread_perms_set>
}
    677a:	bd10      	pop	{r4, pc}

0000677c <z_object_init>:
{
    677c:	b508      	push	{r3, lr}
	ko = z_object_find(obj);
    677e:	f7f9 fcad 	bl	dc <z_object_find>
	if (ko == NULL) {
    6782:	b118      	cbz	r0, 678c <z_object_init+0x10>
	ko->flags |= K_OBJ_FLAG_INITIALIZED;
    6784:	79c3      	ldrb	r3, [r0, #7]
    6786:	f043 0301 	orr.w	r3, r3, #1
    678a:	71c3      	strb	r3, [r0, #7]
}
    678c:	bd08      	pop	{r3, pc}

0000678e <z_object_uninit>:
{
    678e:	b508      	push	{r3, lr}
	ko = z_object_find(obj);
    6790:	f7f9 fca4 	bl	dc <z_object_find>
	if (ko == NULL) {
    6794:	b118      	cbz	r0, 679e <z_object_uninit+0x10>
	ko->flags &= ~K_OBJ_FLAG_INITIALIZED;
    6796:	79c3      	ldrb	r3, [r0, #7]
    6798:	f023 0301 	bic.w	r3, r3, #1
    679c:	71c3      	strb	r3, [r0, #7]
}
    679e:	bd08      	pop	{r3, pc}

000067a0 <z_user_from_copy>:
{
    67a0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    67a2:	460d      	mov	r5, r1
    67a4:	4616      	mov	r6, r2
    67a6:	4607      	mov	r7, r0
			Z_SYSCALL_MEMORY_READ(src, size)) {
    67a8:	2200      	movs	r2, #0
    67aa:	4631      	mov	r1, r6
    67ac:	4628      	mov	r0, r5
    67ae:	f7ff f972 	bl	5a96 <arch_buffer_validate>
    67b2:	4604      	mov	r4, r0
    67b4:	b120      	cbz	r0, 67c0 <z_user_from_copy+0x20>
    67b6:	f7ff ff4a 	bl	664e <arch_is_user_context>
	int ret = EFAULT;
    67ba:	240e      	movs	r4, #14
}
    67bc:	4620      	mov	r0, r4
    67be:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	(void)memcpy(dst, src, size);
    67c0:	4632      	mov	r2, r6
    67c2:	4629      	mov	r1, r5
    67c4:	4638      	mov	r0, r7
    67c6:	f7ff f988 	bl	5ada <memcpy>
	ret = 0;
    67ca:	e7f7      	b.n	67bc <z_user_from_copy+0x1c>

000067cc <z_user_string_copy>:
{
    67cc:	b5f7      	push	{r0, r1, r2, r4, r5, r6, r7, lr}
    67ce:	460e      	mov	r6, r1
    67d0:	4614      	mov	r4, r2
    67d2:	4605      	mov	r5, r0
	return arch_user_string_nlen(src, maxlen, err);
    67d4:	aa01      	add	r2, sp, #4
    67d6:	4621      	mov	r1, r4
    67d8:	4630      	mov	r0, r6
    67da:	f7fb f837 	bl	184c <arch_user_string_nlen>
	if (err != 0) {
    67de:	9f01      	ldr	r7, [sp, #4]
    67e0:	b997      	cbnz	r7, 6808 <z_user_string_copy+0x3c>
	if (actual_len == maxlen) {
    67e2:	4284      	cmp	r4, r0
    67e4:	d104      	bne.n	67f0 <z_user_string_copy+0x24>
    67e6:	f7ff ff32 	bl	664e <arch_is_user_context>
		ret = EINVAL;
    67ea:	2016      	movs	r0, #22
}
    67ec:	b003      	add	sp, #12
    67ee:	bdf0      	pop	{r4, r5, r6, r7, pc}
	return __builtin_add_overflow(a, b, result);
    67f0:	2401      	movs	r4, #1
    67f2:	1904      	adds	r4, r0, r4
    67f4:	d2f7      	bcs.n	67e6 <z_user_string_copy+0x1a>
	ret = z_user_from_copy(dst, src, actual_len);
    67f6:	4622      	mov	r2, r4
	dst[actual_len - 1] = '\0';
    67f8:	442c      	add	r4, r5
	ret = z_user_from_copy(dst, src, actual_len);
    67fa:	4631      	mov	r1, r6
    67fc:	4628      	mov	r0, r5
    67fe:	f7ff ffcf 	bl	67a0 <z_user_from_copy>
	dst[actual_len - 1] = '\0';
    6802:	f804 7c01 	strb.w	r7, [r4, #-1]
    6806:	e7f1      	b.n	67ec <z_user_string_copy+0x20>
		ret = EFAULT;
    6808:	200e      	movs	r0, #14
	return ret;
    680a:	e7ef      	b.n	67ec <z_user_string_copy+0x20>

0000680c <k_mem_pool_malloc>:
{
    680c:	b5df      	push	{r0, r1, r2, r3, r4, r6, r7, lr}
    680e:	2408      	movs	r4, #8
    6810:	190a      	adds	r2, r1, r4
    6812:	d208      	bcs.n	6826 <k_mem_pool_malloc+0x1a>
	if (k_mem_pool_alloc(pool, &block, size, K_NO_WAIT) != 0) {
    6814:	2600      	movs	r6, #0
    6816:	2700      	movs	r7, #0
    6818:	e9cd 6700 	strd	r6, r7, [sp]
    681c:	eb0d 0104 	add.w	r1, sp, r4
    6820:	f000 f890 	bl	6944 <k_mem_pool_alloc>
    6824:	b110      	cbz	r0, 682c <k_mem_pool_malloc+0x20>
		return NULL;
    6826:	2000      	movs	r0, #0
}
    6828:	b004      	add	sp, #16
    682a:	bdd0      	pop	{r4, r6, r7, pc}
	(void)memcpy(block.data, &block.id, sizeof(struct k_mem_block_id));
    682c:	9802      	ldr	r0, [sp, #8]
    682e:	4622      	mov	r2, r4
    6830:	a902      	add	r1, sp, #8
    6832:	f7ff f952 	bl	5ada <memcpy>
	return (char *)block.data + WB_UP(sizeof(struct k_mem_block_id));
    6836:	9802      	ldr	r0, [sp, #8]
    6838:	3008      	adds	r0, #8
    683a:	e7f5      	b.n	6828 <k_mem_pool_malloc+0x1c>

0000683c <k_free>:
	if (ptr != NULL) {
    683c:	b110      	cbz	r0, 6844 <k_free+0x8>
		k_mem_pool_free_id(ptr);
    683e:	3808      	subs	r0, #8
    6840:	f000 b899 	b.w	6976 <k_mem_pool_free_id>
}
    6844:	4770      	bx	lr

00006846 <arch_is_user_context>:
	__asm__ volatile("mrs %0, IPSR\n\t" : "=r"(value));
    6846:	f3ef 8305 	mrs	r3, IPSR
	if (value) {
    684a:	b923      	cbnz	r3, 6856 <arch_is_user_context+0x10>
	__asm__ volatile("mrs %0, CONTROL\n\t" : "=r"(value));
    684c:	f3ef 8014 	mrs	r0, CONTROL
	return (value & CONTROL_nPRIV_Msk) ? true : false;
    6850:	f000 0001 	and.w	r0, r0, #1
    6854:	4770      	bx	lr
		return false;
    6856:	2000      	movs	r0, #0
}
    6858:	4770      	bx	lr

0000685a <validate_any_object>:
{
    685a:	b510      	push	{r4, lr}
	ko = z_object_find(obj);
    685c:	f7f9 fc3e 	bl	dc <z_object_find>
	ret = z_object_validate(ko, K_OBJ_ANY, _OBJ_INIT_ANY);
    6860:	2201      	movs	r2, #1
    6862:	2100      	movs	r1, #0
	ko = z_object_find(obj);
    6864:	4604      	mov	r4, r0
	ret = z_object_validate(ko, K_OBJ_ANY, _OBJ_INIT_ANY);
    6866:	f7fe faff 	bl	4e68 <z_object_validate>
	if (ret != 0) {
    686a:	2800      	cmp	r0, #0
}
    686c:	bf0c      	ite	eq
    686e:	4620      	moveq	r0, r4
    6870:	2000      	movne	r0, #0
    6872:	bd10      	pop	{r4, pc}

00006874 <k_heap_init>:
{
    6874:	b410      	push	{r4}
    6876:	f100 040c 	add.w	r4, r0, #12
	list->tail = (sys_dnode_t *)list;
    687a:	e9c0 4403 	strd	r4, r4, [r0, #12]
}
    687e:	bc10      	pop	{r4}
	sys_heap_init(&h->heap, mem, bytes);
    6880:	f7fe bf5d 	b.w	573e <sys_heap_init>

00006884 <k_heap_alloc>:

SYS_INIT(statics_init, PRE_KERNEL_1, CONFIG_KERNEL_INIT_PRIORITY_OBJECTS);

void *k_heap_alloc(struct k_heap *h, size_t bytes, k_timeout_t timeout)
{
    6884:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    6888:	4604      	mov	r4, r0
    688a:	b085      	sub	sp, #20
    688c:	460e      	mov	r6, r1
	int64_t now, end = z_timeout_end_calc(timeout);
    688e:	4610      	mov	r0, r2
    6890:	4619      	mov	r1, r3
    6892:	f7ff fcfa 	bl	628a <z_timeout_end_calc>
	void *ret = NULL;
	k_spinlock_key_t key = k_spin_lock(&h->lock);
    6896:	f104 0a14 	add.w	sl, r4, #20
	int64_t now, end = z_timeout_end_calc(timeout);
    689a:	4605      	mov	r5, r0
    689c:	460f      	mov	r7, r1
	__asm__ volatile(
    689e:	f04f 0220 	mov.w	r2, #32
    68a2:	f3ef 8311 	mrs	r3, BASEPRI
    68a6:	f382 8811 	msr	BASEPRI, r2
    68aa:	f3bf 8f6f 	isb	sy
		now = z_tick_get();
		if ((ret != NULL) || ((end - now) <= 0)) {
			break;
		}

		(void) z_pend_curr(&h->lock, key, &h->wait_q,
    68ae:	f104 0b0c 	add.w	fp, r4, #12
		ret = sys_heap_alloc(&h->heap, bytes);
    68b2:	4631      	mov	r1, r6
    68b4:	4620      	mov	r0, r4
    68b6:	9303      	str	r3, [sp, #12]
    68b8:	f7fe ff0d 	bl	56d6 <sys_heap_alloc>
    68bc:	9002      	str	r0, [sp, #8]
		now = z_tick_get();
    68be:	f7fe f845 	bl	494c <z_tick_get>
		if ((ret != NULL) || ((end - now) <= 0)) {
    68c2:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
    68c6:	b13a      	cbz	r2, 68d8 <k_heap_alloc+0x54>
	__asm__ volatile(
    68c8:	f383 8811 	msr	BASEPRI, r3
    68cc:	f3bf 8f6f 	isb	sy
		key = k_spin_lock(&h->lock);
	}

	k_spin_unlock(&h->lock, key);
	return ret;
}
    68d0:	4610      	mov	r0, r2
    68d2:	b005      	add	sp, #20
    68d4:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		if ((ret != NULL) || ((end - now) <= 0)) {
    68d8:	ebb5 0800 	subs.w	r8, r5, r0
    68dc:	eb67 0901 	sbc.w	r9, r7, r1
    68e0:	f1b8 0f01 	cmp.w	r8, #1
    68e4:	f179 0100 	sbcs.w	r1, r9, #0
    68e8:	dbee      	blt.n	68c8 <k_heap_alloc+0x44>
		(void) z_pend_curr(&h->lock, key, &h->wait_q,
    68ea:	e9cd 8900 	strd	r8, r9, [sp]
    68ee:	465a      	mov	r2, fp
    68f0:	4619      	mov	r1, r3
    68f2:	4650      	mov	r0, sl
    68f4:	f7fd f950 	bl	3b98 <z_pend_curr>
	__asm__ volatile(
    68f8:	f04f 0220 	mov.w	r2, #32
    68fc:	f3ef 8311 	mrs	r3, BASEPRI
    6900:	f382 8811 	msr	BASEPRI, r2
    6904:	f3bf 8f6f 	isb	sy
    6908:	e7d3      	b.n	68b2 <k_heap_alloc+0x2e>

0000690a <k_heap_free>:

void k_heap_free(struct k_heap *h, void *mem)
{
    690a:	b538      	push	{r3, r4, r5, lr}
    690c:	4604      	mov	r4, r0
    690e:	f04f 0320 	mov.w	r3, #32
    6912:	f3ef 8511 	mrs	r5, BASEPRI
    6916:	f383 8811 	msr	BASEPRI, r3
    691a:	f3bf 8f6f 	isb	sy
	k_spinlock_key_t key = k_spin_lock(&h->lock);

	sys_heap_free(&h->heap, mem);
    691e:	f7fe fe85 	bl	562c <sys_heap_free>

	if (z_unpend_all(&h->wait_q) != 0) {
    6922:	f104 000c 	add.w	r0, r4, #12
    6926:	f7ff fbd7 	bl	60d8 <z_unpend_all>
    692a:	b130      	cbz	r0, 693a <k_heap_free+0x30>
		z_reschedule(&h->lock, key);
    692c:	4629      	mov	r1, r5
    692e:	f104 0014 	add.w	r0, r4, #20
	} else {
		k_spin_unlock(&h->lock, key);
	}
}
    6932:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&h->lock, key);
    6936:	f7ff bae4 	b.w	5f02 <z_reschedule>
	__asm__ volatile(
    693a:	f385 8811 	msr	BASEPRI, r5
    693e:	f3bf 8f6f 	isb	sy
}
    6942:	bd38      	pop	{r3, r4, r5, pc}

00006944 <k_mem_pool_alloc>:
 * backend.
 */

int k_mem_pool_alloc(struct k_mem_pool *p, struct k_mem_block *block,
		     size_t size, k_timeout_t timeout)
{
    6944:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
    6946:	e9dd 6706 	ldrd	r6, r7, [sp, #24]
	block->id.heap = p->heap;
    694a:	6800      	ldr	r0, [r0, #0]
    694c:	6048      	str	r0, [r1, #4]
{
    694e:	4614      	mov	r4, r2
    6950:	460d      	mov	r5, r1
	block->data = k_heap_alloc(p->heap, size, timeout);
    6952:	4632      	mov	r2, r6
    6954:	463b      	mov	r3, r7
    6956:	4621      	mov	r1, r4
    6958:	f7ff ff94 	bl	6884 <k_heap_alloc>
    695c:	6028      	str	r0, [r5, #0]

	/* The legacy API returns -EAGAIN on timeout expiration, but
	 * -ENOMEM if the timeout was K_NO_WAIT. Don't ask.
	 */
	if (size != 0 && block->data == NULL) {
    695e:	b144      	cbz	r4, 6972 <k_mem_pool_alloc+0x2e>
    6960:	b938      	cbnz	r0, 6972 <k_mem_pool_alloc+0x2e>
		return K_TIMEOUT_EQ(timeout, K_NO_WAIT) ? -ENOMEM : -EAGAIN;
    6962:	ea56 0307 	orrs.w	r3, r6, r7
    6966:	bf0c      	ite	eq
    6968:	f06f 000b 	mvneq.w	r0, #11
    696c:	f06f 000a 	mvnne.w	r0, #10
	} else {
		return 0;
	}
}
    6970:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		return 0;
    6972:	2000      	movs	r0, #0
    6974:	e7fc      	b.n	6970 <k_mem_pool_alloc+0x2c>

00006976 <k_mem_pool_free_id>:

void k_mem_pool_free_id(struct k_mem_block_id *id)
{
	k_heap_free(id->heap, id->data);
    6976:	e9d0 1000 	ldrd	r1, r0, [r0]
    697a:	f7ff bfc6 	b.w	690a <k_heap_free>

0000697e <_OffsetAbsSyms>:
#include "offsets_aarch64.c"
#else
#include "offsets_aarch32.c"
#endif

GEN_ABS_SYM_END
    697e:	4770      	bx	lr
